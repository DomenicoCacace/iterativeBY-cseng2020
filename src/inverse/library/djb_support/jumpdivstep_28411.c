/**
  * @author Domenico Cacace <domenico.cacace@mail.polimi.it>
  * 
  *
  * This code is hereby placed in the public domain.
  *
  * THIS SOFTWARE IS PROVIDED BY THE AUTHORS ''AS IS'' AND ANY EXPRESS
  * OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
  * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHORS OR CONTRIBUTORS BE
  * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
  * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
  * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
  * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
  * EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **/

#include "../../include/inverse_DJB_facilities.h"

int jumpdivstep_28411(int delta, DIGIT *f, DIGIT *g, DIGIT *t_00, DIGIT *t_01, DIGIT *t_10, DIGIT *t_11) {
	DIGIT p_00[895];
	DIGIT p_01[895];
	DIGIT p_10[895];
	DIGIT p_11[895];
	
	DIGIT q_00[886];
	DIGIT q_01[886];
	DIGIT q_10[886];
	DIGIT q_11[886];
	
	DIGIT f_sum[2683];
	DIGIT g_sum[2683];
	
	DIGIT temp[894];
	DIGIT temp2[894];
	

	delta = divstepsx_256(255, delta, f+884, g+884, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f+884, p_00+891);
	gf2x_mul_4_avx(temp2, g+884, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f+880, p_00+891);
	gf2x_mul_4_avx(temp2, g+880, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f+884, p_10+891);
	gf2x_mul_4_avx(temp2, g+884, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f+880, p_10+891);
	gf2x_mul_4_avx(temp2, g+880, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f+880, p_00+883);
	gf2x_mul_8_avx(temp2, g+880, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f+872, p_00+883);
	gf2x_mul_8_avx(temp2, g+872, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f+880, p_10+883);
	gf2x_mul_8_avx(temp2, g+880, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f+872, p_10+883);
	gf2x_mul_8_avx(temp2, g+872, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f+872, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g+872, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f+860);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g+860);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f+872, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g+872, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f+860);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g+860);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(p_00+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, p_00+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+847, 8, p_00+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+843, 8, p_00+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+839, 8, p_00+839, 8, temp);
	memset(p_01+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, p_01+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+847, 8, p_01+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+843, 8, p_01+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+839, 8, p_01+839, 8, temp);
	memset(p_10+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, p_10+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+847, 8, p_10+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+843, 8, p_10+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+839, 8, p_10+839, 8, temp);
	memset(p_11+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, p_11+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+847, 8, p_11+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+843, 8, p_11+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+839, 8, p_11+839, 8, temp);
	
	// Calculating left operands: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, f+860, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g+860, 28, p_01+839);
	gf2x_add(56, f_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f+832, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g+832, 28, p_01+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+2514, 28, f_sum+2514, 28, temp+28);
	right_bit_shift_n(56, f_sum+2514, 57);
	GF2X_MUL(56, temp, 28, f+860, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g+860, 28, p_11+839);
	gf2x_add(56, g_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f+832, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g+832, 28, p_11+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+2514, 28, g_sum+2514, 28, temp+28);
	right_bit_shift_n(56, g_sum+2514, 57);
	
	delta = divstepsx_256(255, delta, f_sum+2539, g_sum+2539, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2539, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2539, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2535, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2535, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(q_00+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, q_00+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+842, 8, q_00+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+838, 8, q_00+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+834, 8, q_00+834, 8, temp);
	memset(q_01+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, q_01+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+842, 8, q_01+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+838, 8, q_01+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+834, 8, q_01+834, 8, temp);
	memset(q_10+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, q_10+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+842, 8, q_10+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+838, 8, q_10+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+834, 8, q_10+834, 8, temp);
	memset(q_11+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, q_11+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+842, 8, q_11+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+838, 8, q_11+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+834, 8, q_11+834, 8, temp);
	
	// Recombining results: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_10+839);
	gf2x_add(56, p_00+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_11+839);
	gf2x_add(56, p_01+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_10+839);
	gf2x_add(56, p_10+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_11+839);
	gf2x_add(56, p_11+783, 56, temp, 56, temp2);
	
	// Calculating left operands: n: 7140, depth: 3
	GF2X_MUL(112, temp, 56, f+832, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, g+832, 56, p_01+783);
	gf2x_add(112, f_sum+2345, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, f+776, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, g+776, 56, p_01+783);
	gf2x_add(112, temp, 112, temp, 112, temp2);
	gf2x_add(56, f_sum+2345, 56, f_sum+2345, 56, temp+56);
	right_bit_shift_n(112, f_sum+2345, 50);
	GF2X_MUL(112, temp, 56, f+832, 56, p_10+783);
	GF2X_MUL(112, temp2, 56, g+832, 56, p_11+783);
	gf2x_add(112, g_sum+2345, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, f+776, 56, p_10+783);
	GF2X_MUL(112, temp2, 56, g+776, 56, p_11+783);
	gf2x_add(112, temp, 112, temp, 112, temp2);
	gf2x_add(56, g_sum+2345, 56, g_sum+2345, 56, temp+56);
	right_bit_shift_n(112, g_sum+2345, 50);
	
	delta = divstepsx_256(255, delta, f_sum+2398, g_sum+2398, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2398, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2398, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2394, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2394, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2398, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2398, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2394, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2394, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2394, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2394, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2386, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2386, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2394, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2394, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2386, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2386, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2386, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2386, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2374);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2374);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2386, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2386, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2374);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2374);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(p_00+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, p_00+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+847, 8, p_00+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+843, 8, p_00+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+839, 8, p_00+839, 8, temp);
	memset(p_01+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, p_01+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+847, 8, p_01+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+843, 8, p_01+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+839, 8, p_01+839, 8, temp);
	memset(p_10+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, p_10+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+847, 8, p_10+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+843, 8, p_10+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+839, 8, p_10+839, 8, temp);
	memset(p_11+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, p_11+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+847, 8, p_11+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+843, 8, p_11+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+839, 8, p_11+839, 8, temp);
	
	// Calculating left operands: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, f_sum+2374, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2374, 28, p_01+839);
	gf2x_add(56, f_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2346, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2346, 28, p_01+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+2514, 28, f_sum+2514, 28, temp+28);
	right_bit_shift_n(56, f_sum+2514, 57);
	GF2X_MUL(56, temp, 28, f_sum+2374, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2374, 28, p_11+839);
	gf2x_add(56, g_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2346, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2346, 28, p_11+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+2514, 28, g_sum+2514, 28, temp+28);
	right_bit_shift_n(56, g_sum+2514, 57);
	
	delta = divstepsx_256(255, delta, f_sum+2539, g_sum+2539, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2539, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2539, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2535, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2535, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(q_00+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, q_00+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+842, 8, q_00+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+838, 8, q_00+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+834, 8, q_00+834, 8, temp);
	memset(q_01+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, q_01+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+842, 8, q_01+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+838, 8, q_01+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+834, 8, q_01+834, 8, temp);
	memset(q_10+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, q_10+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+842, 8, q_10+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+838, 8, q_10+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+834, 8, q_10+834, 8, temp);
	memset(q_11+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, q_11+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+842, 8, q_11+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+838, 8, q_11+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+834, 8, q_11+834, 8, temp);
	
	// Recombining results: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_10+839);
	gf2x_add(56, q_00+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_11+839);
	gf2x_add(56, q_01+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_10+839);
	gf2x_add(56, q_10+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_11+839);
	gf2x_add(56, q_11+778, 56, temp, 56, temp2);
	
	// Recombining results: n: 7140, depth: 3
	GF2X_MUL(112, temp, 56, q_00+778, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, q_01+778, 56, p_10+783);
	gf2x_add(112, p_00+671, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_00+778, 56, p_01+783);
	GF2X_MUL(112, temp2, 56, q_01+778, 56, p_11+783);
	gf2x_add(112, p_01+671, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_10+778, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, q_11+778, 56, p_10+783);
	gf2x_add(112, p_10+671, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_10+778, 56, p_01+783);
	GF2X_MUL(112, temp2, 56, q_11+778, 56, p_11+783);
	gf2x_add(112, p_11+671, 112, temp, 112, temp2);
	
	// Calculating left operands: n: 14280, depth: 2
	GF2X_MUL(224, temp, 112, f+776, 112, p_00+671);
	GF2X_MUL(224, temp2, 112, g+776, 112, p_01+671);
	gf2x_add(224, f_sum+2008, 224, temp, 224, temp2);
	GF2X_MUL(224, temp, 112, f+664, 112, p_00+671);
	GF2X_MUL(224, temp2, 112, g+664, 112, p_01+671);
	gf2x_add(224, temp, 224, temp, 224, temp2);
	gf2x_add(112, f_sum+2008, 112, f_sum+2008, 112, temp+112);
	right_bit_shift_n(224, f_sum+2008, 36);
	GF2X_MUL(224, temp, 112, f+776, 112, p_10+671);
	GF2X_MUL(224, temp2, 112, g+776, 112, p_11+671);
	gf2x_add(224, g_sum+2008, 224, temp, 224, temp2);
	GF2X_MUL(224, temp, 112, f+664, 112, p_10+671);
	GF2X_MUL(224, temp2, 112, g+664, 112, p_11+671);
	gf2x_add(224, temp, 224, temp, 224, temp2);
	gf2x_add(112, g_sum+2008, 112, g_sum+2008, 112, temp+112);
	right_bit_shift_n(224, g_sum+2008, 36);
	
	delta = divstepsx_256(255, delta, f_sum+2117, g_sum+2117, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2117, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2117, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2113, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2113, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2117, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2117, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2113, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2113, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2113, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2113, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2105, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2105, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2113, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2113, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2105, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2105, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2105, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2105, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2093);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2093);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2105, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2105, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2093);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2093);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(p_00+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, p_00+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+847, 8, p_00+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+843, 8, p_00+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+839, 8, p_00+839, 8, temp);
	memset(p_01+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, p_01+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+847, 8, p_01+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+843, 8, p_01+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+839, 8, p_01+839, 8, temp);
	memset(p_10+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, p_10+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+847, 8, p_10+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+843, 8, p_10+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+839, 8, p_10+839, 8, temp);
	memset(p_11+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, p_11+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+847, 8, p_11+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+843, 8, p_11+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+839, 8, p_11+839, 8, temp);
	
	// Calculating left operands: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, f_sum+2093, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2093, 28, p_01+839);
	gf2x_add(56, f_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2065, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2065, 28, p_01+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+2514, 28, f_sum+2514, 28, temp+28);
	right_bit_shift_n(56, f_sum+2514, 57);
	GF2X_MUL(56, temp, 28, f_sum+2093, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2093, 28, p_11+839);
	gf2x_add(56, g_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2065, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2065, 28, p_11+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+2514, 28, g_sum+2514, 28, temp+28);
	right_bit_shift_n(56, g_sum+2514, 57);
	
	delta = divstepsx_256(255, delta, f_sum+2539, g_sum+2539, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2539, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2539, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2535, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2535, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(q_00+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, q_00+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+842, 8, q_00+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+838, 8, q_00+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+834, 8, q_00+834, 8, temp);
	memset(q_01+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, q_01+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+842, 8, q_01+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+838, 8, q_01+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+834, 8, q_01+834, 8, temp);
	memset(q_10+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, q_10+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+842, 8, q_10+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+838, 8, q_10+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+834, 8, q_10+834, 8, temp);
	memset(q_11+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, q_11+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+842, 8, q_11+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+838, 8, q_11+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+834, 8, q_11+834, 8, temp);
	
	// Recombining results: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_10+839);
	gf2x_add(56, p_00+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_11+839);
	gf2x_add(56, p_01+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_10+839);
	gf2x_add(56, p_10+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_11+839);
	gf2x_add(56, p_11+783, 56, temp, 56, temp2);
	
	// Calculating left operands: n: 7140, depth: 3
	GF2X_MUL(112, temp, 56, f_sum+2065, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, g_sum+2065, 56, p_01+783);
	gf2x_add(112, f_sum+2345, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, f_sum+2009, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, g_sum+2009, 56, p_01+783);
	gf2x_add(112, temp, 112, temp, 112, temp2);
	gf2x_add(56, f_sum+2345, 56, f_sum+2345, 56, temp+56);
	right_bit_shift_n(112, f_sum+2345, 50);
	GF2X_MUL(112, temp, 56, f_sum+2065, 56, p_10+783);
	GF2X_MUL(112, temp2, 56, g_sum+2065, 56, p_11+783);
	gf2x_add(112, g_sum+2345, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, f_sum+2009, 56, p_10+783);
	GF2X_MUL(112, temp2, 56, g_sum+2009, 56, p_11+783);
	gf2x_add(112, temp, 112, temp, 112, temp2);
	gf2x_add(56, g_sum+2345, 56, g_sum+2345, 56, temp+56);
	right_bit_shift_n(112, g_sum+2345, 50);
	
	delta = divstepsx_256(255, delta, f_sum+2398, g_sum+2398, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2398, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2398, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2394, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2394, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2398, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2398, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2394, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2394, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2394, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2394, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2386, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2386, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2394, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2394, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2386, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2386, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2386, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2386, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2374);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2374);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2386, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2386, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2374);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2374);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(p_00+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, p_00+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+847, 8, p_00+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+843, 8, p_00+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+839, 8, p_00+839, 8, temp);
	memset(p_01+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, p_01+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+847, 8, p_01+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+843, 8, p_01+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+839, 8, p_01+839, 8, temp);
	memset(p_10+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, p_10+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+847, 8, p_10+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+843, 8, p_10+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+839, 8, p_10+839, 8, temp);
	memset(p_11+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, p_11+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+847, 8, p_11+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+843, 8, p_11+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+839, 8, p_11+839, 8, temp);
	
	// Calculating left operands: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, f_sum+2374, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2374, 28, p_01+839);
	gf2x_add(56, f_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2346, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2346, 28, p_01+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+2514, 28, f_sum+2514, 28, temp+28);
	right_bit_shift_n(56, f_sum+2514, 57);
	GF2X_MUL(56, temp, 28, f_sum+2374, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2374, 28, p_11+839);
	gf2x_add(56, g_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2346, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2346, 28, p_11+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+2514, 28, g_sum+2514, 28, temp+28);
	right_bit_shift_n(56, g_sum+2514, 57);
	
	delta = divstepsx_256(255, delta, f_sum+2539, g_sum+2539, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2539, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2539, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2535, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2535, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(q_00+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, q_00+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+842, 8, q_00+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+838, 8, q_00+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+834, 8, q_00+834, 8, temp);
	memset(q_01+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, q_01+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+842, 8, q_01+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+838, 8, q_01+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+834, 8, q_01+834, 8, temp);
	memset(q_10+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, q_10+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+842, 8, q_10+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+838, 8, q_10+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+834, 8, q_10+834, 8, temp);
	memset(q_11+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, q_11+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+842, 8, q_11+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+838, 8, q_11+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+834, 8, q_11+834, 8, temp);
	
	// Recombining results: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_10+839);
	gf2x_add(56, q_00+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_11+839);
	gf2x_add(56, q_01+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_10+839);
	gf2x_add(56, q_10+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_11+839);
	gf2x_add(56, q_11+778, 56, temp, 56, temp2);
	
	// Recombining results: n: 7140, depth: 3
	GF2X_MUL(112, temp, 56, q_00+778, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, q_01+778, 56, p_10+783);
	gf2x_add(112, q_00+666, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_00+778, 56, p_01+783);
	GF2X_MUL(112, temp2, 56, q_01+778, 56, p_11+783);
	gf2x_add(112, q_01+666, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_10+778, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, q_11+778, 56, p_10+783);
	gf2x_add(112, q_10+666, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_10+778, 56, p_01+783);
	GF2X_MUL(112, temp2, 56, q_11+778, 56, p_11+783);
	gf2x_add(112, q_11+666, 112, temp, 112, temp2);
	
	// Recombining results: n: 14280, depth: 2
	GF2X_MUL(224, temp, 112, q_00+666, 112, p_00+671);
	GF2X_MUL(224, temp2, 112, q_01+666, 112, p_10+671);
	gf2x_add(224, p_00+447, 224, temp, 224, temp2);
	GF2X_MUL(224, temp, 112, q_00+666, 112, p_01+671);
	GF2X_MUL(224, temp2, 112, q_01+666, 112, p_11+671);
	gf2x_add(224, p_01+447, 224, temp, 224, temp2);
	GF2X_MUL(224, temp, 112, q_10+666, 112, p_00+671);
	GF2X_MUL(224, temp2, 112, q_11+666, 112, p_10+671);
	gf2x_add(224, p_10+447, 224, temp, 224, temp2);
	GF2X_MUL(224, temp, 112, q_10+666, 112, p_01+671);
	GF2X_MUL(224, temp2, 112, q_11+666, 112, p_11+671);
	gf2x_add(224, p_11+447, 224, temp, 224, temp2);
	
	// Calculating left operands: n: 28560, depth: 1
	GF2X_MUL(448, temp, 224, f+664, 224, p_00+447);
	GF2X_MUL(448, temp2, 224, g+664, 224, p_01+447);
	gf2x_add(448, f_sum+1336, 448, temp, 448, temp2);
	GF2X_MUL(446, temp, 223, p_00+448, 223, f+441);
	GF2X_MUL(446, temp2, 223, p_01+448, 223, g+441);
	gf2x_add(446, temp, 446, temp, 446, temp2);
	gf2x_add(224, f_sum+1336, 224, f_sum+1336, 224, temp+222);
	gf2x_mul_1_avx(temp, f+663, p_00+447);
	gf2x_mul_1_avx(temp2, g+663, p_01+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, f_sum+1336, 1, f_sum+1336, 1, temp+1);
	right_bit_shift_n(447, f_sum+1336, 8);
	GF2X_MUL(448, temp, 224, f+664, 224, p_10+447);
	GF2X_MUL(448, temp2, 224, g+664, 224, p_11+447);
	gf2x_add(448, g_sum+1336, 448, temp, 448, temp2);
	GF2X_MUL(446, temp, 223, p_10+448, 223, f+441);
	GF2X_MUL(446, temp2, 223, p_11+448, 223, g+441);
	gf2x_add(446, temp, 446, temp, 446, temp2);
	gf2x_add(224, g_sum+1336, 224, g_sum+1336, 224, temp+222);
	gf2x_mul_1_avx(temp, f+663, p_10+447);
	gf2x_mul_1_avx(temp2, g+663, p_11+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, g_sum+1336, 1, g_sum+1336, 1, temp+1);
	right_bit_shift_n(447, g_sum+1336, 8);
	
	delta = divstepsx_256(255, delta, f_sum+1557, g_sum+1557, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+1557, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+1557, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1553, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+1553, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+1557, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+1557, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1553, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+1553, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+1553, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+1553, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1545, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+1545, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+1553, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+1553, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1545, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+1545, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+1545, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+1545, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+1533);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+1533);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+1545, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+1545, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+1533);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+1533);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(p_00+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, p_00+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+847, 8, p_00+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+843, 8, p_00+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+839, 8, p_00+839, 8, temp);
	memset(p_01+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, p_01+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+847, 8, p_01+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+843, 8, p_01+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+839, 8, p_01+839, 8, temp);
	memset(p_10+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, p_10+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+847, 8, p_10+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+843, 8, p_10+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+839, 8, p_10+839, 8, temp);
	memset(p_11+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, p_11+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+847, 8, p_11+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+843, 8, p_11+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+839, 8, p_11+839, 8, temp);
	
	// Calculating left operands: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, f_sum+1533, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+1533, 28, p_01+839);
	gf2x_add(56, f_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+1505, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+1505, 28, p_01+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+2514, 28, f_sum+2514, 28, temp+28);
	right_bit_shift_n(56, f_sum+2514, 57);
	GF2X_MUL(56, temp, 28, f_sum+1533, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+1533, 28, p_11+839);
	gf2x_add(56, g_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+1505, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+1505, 28, p_11+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+2514, 28, g_sum+2514, 28, temp+28);
	right_bit_shift_n(56, g_sum+2514, 57);
	
	delta = divstepsx_256(255, delta, f_sum+2539, g_sum+2539, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2539, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2539, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2535, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2535, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(q_00+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, q_00+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+842, 8, q_00+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+838, 8, q_00+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+834, 8, q_00+834, 8, temp);
	memset(q_01+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, q_01+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+842, 8, q_01+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+838, 8, q_01+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+834, 8, q_01+834, 8, temp);
	memset(q_10+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, q_10+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+842, 8, q_10+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+838, 8, q_10+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+834, 8, q_10+834, 8, temp);
	memset(q_11+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, q_11+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+842, 8, q_11+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+838, 8, q_11+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+834, 8, q_11+834, 8, temp);
	
	// Recombining results: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_10+839);
	gf2x_add(56, p_00+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_11+839);
	gf2x_add(56, p_01+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_10+839);
	gf2x_add(56, p_10+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_11+839);
	gf2x_add(56, p_11+783, 56, temp, 56, temp2);
	
	// Calculating left operands: n: 7140, depth: 3
	GF2X_MUL(112, temp, 56, f_sum+1505, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, g_sum+1505, 56, p_01+783);
	gf2x_add(112, f_sum+2345, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, f_sum+1449, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, g_sum+1449, 56, p_01+783);
	gf2x_add(112, temp, 112, temp, 112, temp2);
	gf2x_add(56, f_sum+2345, 56, f_sum+2345, 56, temp+56);
	right_bit_shift_n(112, f_sum+2345, 50);
	GF2X_MUL(112, temp, 56, f_sum+1505, 56, p_10+783);
	GF2X_MUL(112, temp2, 56, g_sum+1505, 56, p_11+783);
	gf2x_add(112, g_sum+2345, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, f_sum+1449, 56, p_10+783);
	GF2X_MUL(112, temp2, 56, g_sum+1449, 56, p_11+783);
	gf2x_add(112, temp, 112, temp, 112, temp2);
	gf2x_add(56, g_sum+2345, 56, g_sum+2345, 56, temp+56);
	right_bit_shift_n(112, g_sum+2345, 50);
	
	delta = divstepsx_256(255, delta, f_sum+2398, g_sum+2398, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2398, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2398, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2394, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2394, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2398, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2398, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2394, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2394, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2394, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2394, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2386, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2386, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2394, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2394, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2386, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2386, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2386, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2386, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2374);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2374);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2386, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2386, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2374);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2374);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(p_00+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, p_00+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+847, 8, p_00+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+843, 8, p_00+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+839, 8, p_00+839, 8, temp);
	memset(p_01+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, p_01+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+847, 8, p_01+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+843, 8, p_01+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+839, 8, p_01+839, 8, temp);
	memset(p_10+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, p_10+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+847, 8, p_10+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+843, 8, p_10+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+839, 8, p_10+839, 8, temp);
	memset(p_11+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, p_11+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+847, 8, p_11+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+843, 8, p_11+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+839, 8, p_11+839, 8, temp);
	
	// Calculating left operands: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, f_sum+2374, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2374, 28, p_01+839);
	gf2x_add(56, f_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2346, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2346, 28, p_01+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+2514, 28, f_sum+2514, 28, temp+28);
	right_bit_shift_n(56, f_sum+2514, 57);
	GF2X_MUL(56, temp, 28, f_sum+2374, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2374, 28, p_11+839);
	gf2x_add(56, g_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2346, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2346, 28, p_11+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+2514, 28, g_sum+2514, 28, temp+28);
	right_bit_shift_n(56, g_sum+2514, 57);
	
	delta = divstepsx_256(255, delta, f_sum+2539, g_sum+2539, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2539, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2539, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2535, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2535, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(q_00+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, q_00+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+842, 8, q_00+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+838, 8, q_00+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+834, 8, q_00+834, 8, temp);
	memset(q_01+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, q_01+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+842, 8, q_01+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+838, 8, q_01+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+834, 8, q_01+834, 8, temp);
	memset(q_10+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, q_10+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+842, 8, q_10+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+838, 8, q_10+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+834, 8, q_10+834, 8, temp);
	memset(q_11+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, q_11+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+842, 8, q_11+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+838, 8, q_11+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+834, 8, q_11+834, 8, temp);
	
	// Recombining results: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_10+839);
	gf2x_add(56, q_00+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_11+839);
	gf2x_add(56, q_01+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_10+839);
	gf2x_add(56, q_10+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_11+839);
	gf2x_add(56, q_11+778, 56, temp, 56, temp2);
	
	// Recombining results: n: 7140, depth: 3
	GF2X_MUL(112, temp, 56, q_00+778, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, q_01+778, 56, p_10+783);
	gf2x_add(112, p_00+671, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_00+778, 56, p_01+783);
	GF2X_MUL(112, temp2, 56, q_01+778, 56, p_11+783);
	gf2x_add(112, p_01+671, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_10+778, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, q_11+778, 56, p_10+783);
	gf2x_add(112, p_10+671, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_10+778, 56, p_01+783);
	GF2X_MUL(112, temp2, 56, q_11+778, 56, p_11+783);
	gf2x_add(112, p_11+671, 112, temp, 112, temp2);
	
	// Calculating left operands: n: 14280, depth: 2
	GF2X_MUL(224, temp, 112, f_sum+1449, 112, p_00+671);
	GF2X_MUL(224, temp2, 112, g_sum+1449, 112, p_01+671);
	gf2x_add(224, f_sum+2008, 224, temp, 224, temp2);
	GF2X_MUL(224, temp, 112, f_sum+1337, 112, p_00+671);
	GF2X_MUL(224, temp2, 112, g_sum+1337, 112, p_01+671);
	gf2x_add(224, temp, 224, temp, 224, temp2);
	gf2x_add(112, f_sum+2008, 112, f_sum+2008, 112, temp+112);
	right_bit_shift_n(224, f_sum+2008, 36);
	GF2X_MUL(224, temp, 112, f_sum+1449, 112, p_10+671);
	GF2X_MUL(224, temp2, 112, g_sum+1449, 112, p_11+671);
	gf2x_add(224, g_sum+2008, 224, temp, 224, temp2);
	GF2X_MUL(224, temp, 112, f_sum+1337, 112, p_10+671);
	GF2X_MUL(224, temp2, 112, g_sum+1337, 112, p_11+671);
	gf2x_add(224, temp, 224, temp, 224, temp2);
	gf2x_add(112, g_sum+2008, 112, g_sum+2008, 112, temp+112);
	right_bit_shift_n(224, g_sum+2008, 36);
	
	delta = divstepsx_256(255, delta, f_sum+2117, g_sum+2117, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2117, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2117, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2113, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2113, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2117, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2117, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2113, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2113, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2113, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2113, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2105, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2105, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2113, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2113, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2105, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2105, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2105, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2105, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2093);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2093);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2105, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2105, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2093);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2093);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(p_00+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, p_00+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+847, 8, p_00+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+843, 8, p_00+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+839, 8, p_00+839, 8, temp);
	memset(p_01+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, p_01+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+847, 8, p_01+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+843, 8, p_01+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+839, 8, p_01+839, 8, temp);
	memset(p_10+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, p_10+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+847, 8, p_10+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+843, 8, p_10+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+839, 8, p_10+839, 8, temp);
	memset(p_11+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, p_11+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+847, 8, p_11+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+843, 8, p_11+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+839, 8, p_11+839, 8, temp);
	
	// Calculating left operands: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, f_sum+2093, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2093, 28, p_01+839);
	gf2x_add(56, f_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2065, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2065, 28, p_01+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+2514, 28, f_sum+2514, 28, temp+28);
	right_bit_shift_n(56, f_sum+2514, 57);
	GF2X_MUL(56, temp, 28, f_sum+2093, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2093, 28, p_11+839);
	gf2x_add(56, g_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2065, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2065, 28, p_11+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+2514, 28, g_sum+2514, 28, temp+28);
	right_bit_shift_n(56, g_sum+2514, 57);
	
	delta = divstepsx_256(255, delta, f_sum+2539, g_sum+2539, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2539, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2539, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2535, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2535, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(q_00+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, q_00+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+842, 8, q_00+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+838, 8, q_00+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+834, 8, q_00+834, 8, temp);
	memset(q_01+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, q_01+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+842, 8, q_01+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+838, 8, q_01+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+834, 8, q_01+834, 8, temp);
	memset(q_10+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, q_10+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+842, 8, q_10+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+838, 8, q_10+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+834, 8, q_10+834, 8, temp);
	memset(q_11+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, q_11+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+842, 8, q_11+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+838, 8, q_11+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+834, 8, q_11+834, 8, temp);
	
	// Recombining results: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_10+839);
	gf2x_add(56, p_00+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_11+839);
	gf2x_add(56, p_01+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_10+839);
	gf2x_add(56, p_10+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_11+839);
	gf2x_add(56, p_11+783, 56, temp, 56, temp2);
	
	// Calculating left operands: n: 7140, depth: 3
	GF2X_MUL(112, temp, 56, f_sum+2065, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, g_sum+2065, 56, p_01+783);
	gf2x_add(112, f_sum+2345, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, f_sum+2009, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, g_sum+2009, 56, p_01+783);
	gf2x_add(112, temp, 112, temp, 112, temp2);
	gf2x_add(56, f_sum+2345, 56, f_sum+2345, 56, temp+56);
	right_bit_shift_n(112, f_sum+2345, 50);
	GF2X_MUL(112, temp, 56, f_sum+2065, 56, p_10+783);
	GF2X_MUL(112, temp2, 56, g_sum+2065, 56, p_11+783);
	gf2x_add(112, g_sum+2345, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, f_sum+2009, 56, p_10+783);
	GF2X_MUL(112, temp2, 56, g_sum+2009, 56, p_11+783);
	gf2x_add(112, temp, 112, temp, 112, temp2);
	gf2x_add(56, g_sum+2345, 56, g_sum+2345, 56, temp+56);
	right_bit_shift_n(112, g_sum+2345, 50);
	
	delta = divstepsx_256(255, delta, f_sum+2398, g_sum+2398, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2398, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2398, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2394, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2394, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2398, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2398, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2394, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2394, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2394, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2394, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2386, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2386, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2394, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2394, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2386, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2386, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2386, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2386, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2374);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2374);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2386, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2386, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2374);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2374);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(p_00+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, p_00+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+847, 8, p_00+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+843, 8, p_00+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+839, 8, p_00+839, 8, temp);
	memset(p_01+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, p_01+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+847, 8, p_01+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+843, 8, p_01+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+839, 8, p_01+839, 8, temp);
	memset(p_10+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, p_10+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+847, 8, p_10+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+843, 8, p_10+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+839, 8, p_10+839, 8, temp);
	memset(p_11+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, p_11+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+847, 8, p_11+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+843, 8, p_11+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+839, 8, p_11+839, 8, temp);
	
	// Calculating left operands: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, f_sum+2374, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2374, 28, p_01+839);
	gf2x_add(56, f_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2346, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2346, 28, p_01+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+2514, 28, f_sum+2514, 28, temp+28);
	right_bit_shift_n(56, f_sum+2514, 57);
	GF2X_MUL(56, temp, 28, f_sum+2374, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2374, 28, p_11+839);
	gf2x_add(56, g_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2346, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2346, 28, p_11+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+2514, 28, g_sum+2514, 28, temp+28);
	right_bit_shift_n(56, g_sum+2514, 57);
	
	delta = divstepsx_256(255, delta, f_sum+2539, g_sum+2539, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2539, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2539, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2535, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2535, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(q_00+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, q_00+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+842, 8, q_00+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+838, 8, q_00+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+834, 8, q_00+834, 8, temp);
	memset(q_01+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, q_01+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+842, 8, q_01+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+838, 8, q_01+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+834, 8, q_01+834, 8, temp);
	memset(q_10+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, q_10+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+842, 8, q_10+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+838, 8, q_10+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+834, 8, q_10+834, 8, temp);
	memset(q_11+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, q_11+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+842, 8, q_11+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+838, 8, q_11+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+834, 8, q_11+834, 8, temp);
	
	// Recombining results: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_10+839);
	gf2x_add(56, q_00+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_11+839);
	gf2x_add(56, q_01+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_10+839);
	gf2x_add(56, q_10+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_11+839);
	gf2x_add(56, q_11+778, 56, temp, 56, temp2);
	
	// Recombining results: n: 7140, depth: 3
	GF2X_MUL(112, temp, 56, q_00+778, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, q_01+778, 56, p_10+783);
	gf2x_add(112, q_00+666, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_00+778, 56, p_01+783);
	GF2X_MUL(112, temp2, 56, q_01+778, 56, p_11+783);
	gf2x_add(112, q_01+666, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_10+778, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, q_11+778, 56, p_10+783);
	gf2x_add(112, q_10+666, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_10+778, 56, p_01+783);
	GF2X_MUL(112, temp2, 56, q_11+778, 56, p_11+783);
	gf2x_add(112, q_11+666, 112, temp, 112, temp2);
	
	// Recombining results: n: 14280, depth: 2
	GF2X_MUL(224, temp, 112, q_00+666, 112, p_00+671);
	GF2X_MUL(224, temp2, 112, q_01+666, 112, p_10+671);
	gf2x_add(224, q_00+442, 224, temp, 224, temp2);
	GF2X_MUL(224, temp, 112, q_00+666, 112, p_01+671);
	GF2X_MUL(224, temp2, 112, q_01+666, 112, p_11+671);
	gf2x_add(224, q_01+442, 224, temp, 224, temp2);
	GF2X_MUL(224, temp, 112, q_10+666, 112, p_00+671);
	GF2X_MUL(224, temp2, 112, q_11+666, 112, p_10+671);
	gf2x_add(224, q_10+442, 224, temp, 224, temp2);
	GF2X_MUL(224, temp, 112, q_10+666, 112, p_01+671);
	GF2X_MUL(224, temp2, 112, q_11+666, 112, p_11+671);
	gf2x_add(224, q_11+442, 224, temp, 224, temp2);
	
	// Recombining results: n: 28560, depth: 1
	GF2X_MUL(448, temp, 224, q_00+442, 224, p_00+447);
	GF2X_MUL(448, temp2, 224, q_01+442, 224, p_10+447);
	gf2x_add(447, p_00+0, 447, temp+1, 447, temp2+1);
	GF2X_MUL(448, temp, 224, q_00+442, 224, p_01+447);
	GF2X_MUL(448, temp2, 224, q_01+442, 224, p_11+447);
	gf2x_add(447, p_01+0, 447, temp+1, 447, temp2+1);
	GF2X_MUL(448, temp, 224, q_10+442, 224, p_00+447);
	GF2X_MUL(448, temp2, 224, q_11+442, 224, p_10+447);
	gf2x_add(447, p_10+0, 447, temp+1, 447, temp2+1);
	GF2X_MUL(448, temp, 224, q_10+442, 224, p_01+447);
	GF2X_MUL(448, temp2, 224, q_11+442, 224, p_11+447);
	gf2x_add(447, p_11+0, 447, temp+1, 447, temp2+1);
	
	// Calculating left operands: n: 56821, depth: 0
	GF2X_MUL(894, temp, 447, f+441, 447, p_00+0);
	GF2X_MUL(894, temp2, 447, g+441, 447, p_01+0);
	gf2x_add(889, f_sum+0, 889, temp+5, 889, temp2+5);
	GF2X_MUL(882, temp, 441, p_00+6, 441, f+0);
	GF2X_MUL(882, temp2, 441, p_01+6, 441, g+0);
	gf2x_add(882, temp, 882, temp, 882, temp2);
	gf2x_add(442, f_sum+0, 442, f_sum+0, 442, temp+440);
	gf2x_mul_6_avx(temp, f+435, p_00+0);
	gf2x_mul_6_avx(temp2, g+435, p_01+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(1, f_sum+0, 1, f_sum+0, 1, temp+11);
	right_bit_shift_n(888, f_sum+0, 16);
	GF2X_MUL(894, temp, 447, f+441, 447, p_10+0);
	GF2X_MUL(894, temp2, 447, g+441, 447, p_11+0);
	gf2x_add(889, g_sum+0, 889, temp+5, 889, temp2+5);
	GF2X_MUL(882, temp, 441, p_10+6, 441, f+0);
	GF2X_MUL(882, temp2, 441, p_11+6, 441, g+0);
	gf2x_add(882, temp, 882, temp, 882, temp2);
	gf2x_add(442, g_sum+0, 442, g_sum+0, 442, temp+440);
	gf2x_mul_6_avx(temp, f+435, p_10+0);
	gf2x_mul_6_avx(temp2, g+435, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(1, g_sum+0, 1, g_sum+0, 1, temp+11);
	right_bit_shift_n(888, g_sum+0, 16);
	
	delta = divstepsx_256(255, delta, f_sum+439, g_sum+439, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+439, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+439, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+435, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+435, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+439, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+439, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+435, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+435, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+435, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+435, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+427, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+427, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+435, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+435, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+427, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+427, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+427, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+427, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+415);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+415);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+427, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+427, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+415);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+415);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(p_00+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, p_00+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+847, 8, p_00+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+843, 8, p_00+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+839, 8, p_00+839, 8, temp);
	memset(p_01+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, p_01+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+847, 8, p_01+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+843, 8, p_01+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+839, 8, p_01+839, 8, temp);
	memset(p_10+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, p_10+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+847, 8, p_10+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+843, 8, p_10+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+839, 8, p_10+839, 8, temp);
	memset(p_11+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, p_11+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+847, 8, p_11+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+843, 8, p_11+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+839, 8, p_11+839, 8, temp);
	
	// Calculating left operands: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, f_sum+415, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+415, 28, p_01+839);
	gf2x_add(56, f_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+387, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+387, 28, p_01+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+2514, 28, f_sum+2514, 28, temp+28);
	right_bit_shift_n(56, f_sum+2514, 57);
	GF2X_MUL(56, temp, 28, f_sum+415, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+415, 28, p_11+839);
	gf2x_add(56, g_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+387, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+387, 28, p_11+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+2514, 28, g_sum+2514, 28, temp+28);
	right_bit_shift_n(56, g_sum+2514, 57);
	
	delta = divstepsx_256(255, delta, f_sum+2539, g_sum+2539, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2539, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2539, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2535, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2535, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(q_00+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, q_00+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+842, 8, q_00+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+838, 8, q_00+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+834, 8, q_00+834, 8, temp);
	memset(q_01+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, q_01+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+842, 8, q_01+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+838, 8, q_01+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+834, 8, q_01+834, 8, temp);
	memset(q_10+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, q_10+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+842, 8, q_10+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+838, 8, q_10+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+834, 8, q_10+834, 8, temp);
	memset(q_11+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, q_11+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+842, 8, q_11+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+838, 8, q_11+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+834, 8, q_11+834, 8, temp);
	
	// Recombining results: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_10+839);
	gf2x_add(56, p_00+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_11+839);
	gf2x_add(56, p_01+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_10+839);
	gf2x_add(56, p_10+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_11+839);
	gf2x_add(56, p_11+783, 56, temp, 56, temp2);
	
	// Calculating left operands: n: 7140, depth: 3
	GF2X_MUL(112, temp, 56, f_sum+387, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, g_sum+387, 56, p_01+783);
	gf2x_add(112, f_sum+2345, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, f_sum+331, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, g_sum+331, 56, p_01+783);
	gf2x_add(112, temp, 112, temp, 112, temp2);
	gf2x_add(56, f_sum+2345, 56, f_sum+2345, 56, temp+56);
	right_bit_shift_n(112, f_sum+2345, 50);
	GF2X_MUL(112, temp, 56, f_sum+387, 56, p_10+783);
	GF2X_MUL(112, temp2, 56, g_sum+387, 56, p_11+783);
	gf2x_add(112, g_sum+2345, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, f_sum+331, 56, p_10+783);
	GF2X_MUL(112, temp2, 56, g_sum+331, 56, p_11+783);
	gf2x_add(112, temp, 112, temp, 112, temp2);
	gf2x_add(56, g_sum+2345, 56, g_sum+2345, 56, temp+56);
	right_bit_shift_n(112, g_sum+2345, 50);
	
	delta = divstepsx_256(255, delta, f_sum+2398, g_sum+2398, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2398, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2398, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2394, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2394, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2398, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2398, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2394, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2394, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2394, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2394, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2386, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2386, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2394, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2394, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2386, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2386, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2386, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2386, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2374);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2374);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2386, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2386, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2374);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2374);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(p_00+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, p_00+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+847, 8, p_00+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+843, 8, p_00+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+839, 8, p_00+839, 8, temp);
	memset(p_01+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, p_01+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+847, 8, p_01+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+843, 8, p_01+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+839, 8, p_01+839, 8, temp);
	memset(p_10+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, p_10+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+847, 8, p_10+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+843, 8, p_10+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+839, 8, p_10+839, 8, temp);
	memset(p_11+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, p_11+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+847, 8, p_11+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+843, 8, p_11+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+839, 8, p_11+839, 8, temp);
	
	// Calculating left operands: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, f_sum+2374, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2374, 28, p_01+839);
	gf2x_add(56, f_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2346, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2346, 28, p_01+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+2514, 28, f_sum+2514, 28, temp+28);
	right_bit_shift_n(56, f_sum+2514, 57);
	GF2X_MUL(56, temp, 28, f_sum+2374, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2374, 28, p_11+839);
	gf2x_add(56, g_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2346, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2346, 28, p_11+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+2514, 28, g_sum+2514, 28, temp+28);
	right_bit_shift_n(56, g_sum+2514, 57);
	
	delta = divstepsx_256(255, delta, f_sum+2539, g_sum+2539, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2539, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2539, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2535, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2535, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(q_00+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, q_00+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+842, 8, q_00+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+838, 8, q_00+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+834, 8, q_00+834, 8, temp);
	memset(q_01+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, q_01+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+842, 8, q_01+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+838, 8, q_01+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+834, 8, q_01+834, 8, temp);
	memset(q_10+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, q_10+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+842, 8, q_10+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+838, 8, q_10+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+834, 8, q_10+834, 8, temp);
	memset(q_11+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, q_11+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+842, 8, q_11+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+838, 8, q_11+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+834, 8, q_11+834, 8, temp);
	
	// Recombining results: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_10+839);
	gf2x_add(56, q_00+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_11+839);
	gf2x_add(56, q_01+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_10+839);
	gf2x_add(56, q_10+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_11+839);
	gf2x_add(56, q_11+778, 56, temp, 56, temp2);
	
	// Recombining results: n: 7140, depth: 3
	GF2X_MUL(112, temp, 56, q_00+778, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, q_01+778, 56, p_10+783);
	gf2x_add(112, p_00+671, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_00+778, 56, p_01+783);
	GF2X_MUL(112, temp2, 56, q_01+778, 56, p_11+783);
	gf2x_add(112, p_01+671, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_10+778, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, q_11+778, 56, p_10+783);
	gf2x_add(112, p_10+671, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_10+778, 56, p_01+783);
	GF2X_MUL(112, temp2, 56, q_11+778, 56, p_11+783);
	gf2x_add(112, p_11+671, 112, temp, 112, temp2);
	
	// Calculating left operands: n: 14280, depth: 2
	GF2X_MUL(224, temp, 112, f_sum+331, 112, p_00+671);
	GF2X_MUL(224, temp2, 112, g_sum+331, 112, p_01+671);
	gf2x_add(224, f_sum+2008, 224, temp, 224, temp2);
	GF2X_MUL(224, temp, 112, f_sum+219, 112, p_00+671);
	GF2X_MUL(224, temp2, 112, g_sum+219, 112, p_01+671);
	gf2x_add(224, temp, 224, temp, 224, temp2);
	gf2x_add(112, f_sum+2008, 112, f_sum+2008, 112, temp+112);
	right_bit_shift_n(224, f_sum+2008, 36);
	GF2X_MUL(224, temp, 112, f_sum+331, 112, p_10+671);
	GF2X_MUL(224, temp2, 112, g_sum+331, 112, p_11+671);
	gf2x_add(224, g_sum+2008, 224, temp, 224, temp2);
	GF2X_MUL(224, temp, 112, f_sum+219, 112, p_10+671);
	GF2X_MUL(224, temp2, 112, g_sum+219, 112, p_11+671);
	gf2x_add(224, temp, 224, temp, 224, temp2);
	gf2x_add(112, g_sum+2008, 112, g_sum+2008, 112, temp+112);
	right_bit_shift_n(224, g_sum+2008, 36);
	
	delta = divstepsx_256(255, delta, f_sum+2117, g_sum+2117, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2117, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2117, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2113, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2113, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2117, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2117, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2113, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2113, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2113, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2113, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2105, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2105, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2113, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2113, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2105, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2105, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2105, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2105, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2093);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2093);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2105, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2105, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2093);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2093);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(p_00+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, p_00+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+847, 8, p_00+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+843, 8, p_00+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+839, 8, p_00+839, 8, temp);
	memset(p_01+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, p_01+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+847, 8, p_01+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+843, 8, p_01+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+839, 8, p_01+839, 8, temp);
	memset(p_10+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, p_10+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+847, 8, p_10+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+843, 8, p_10+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+839, 8, p_10+839, 8, temp);
	memset(p_11+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, p_11+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+847, 8, p_11+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+843, 8, p_11+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+839, 8, p_11+839, 8, temp);
	
	// Calculating left operands: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, f_sum+2093, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2093, 28, p_01+839);
	gf2x_add(56, f_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2065, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2065, 28, p_01+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+2514, 28, f_sum+2514, 28, temp+28);
	right_bit_shift_n(56, f_sum+2514, 57);
	GF2X_MUL(56, temp, 28, f_sum+2093, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2093, 28, p_11+839);
	gf2x_add(56, g_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2065, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2065, 28, p_11+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+2514, 28, g_sum+2514, 28, temp+28);
	right_bit_shift_n(56, g_sum+2514, 57);
	
	delta = divstepsx_256(255, delta, f_sum+2539, g_sum+2539, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2539, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2539, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2535, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2535, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(q_00+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, q_00+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+842, 8, q_00+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+838, 8, q_00+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+834, 8, q_00+834, 8, temp);
	memset(q_01+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, q_01+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+842, 8, q_01+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+838, 8, q_01+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+834, 8, q_01+834, 8, temp);
	memset(q_10+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, q_10+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+842, 8, q_10+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+838, 8, q_10+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+834, 8, q_10+834, 8, temp);
	memset(q_11+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, q_11+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+842, 8, q_11+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+838, 8, q_11+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+834, 8, q_11+834, 8, temp);
	
	// Recombining results: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_10+839);
	gf2x_add(56, p_00+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_11+839);
	gf2x_add(56, p_01+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_10+839);
	gf2x_add(56, p_10+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_11+839);
	gf2x_add(56, p_11+783, 56, temp, 56, temp2);
	
	// Calculating left operands: n: 7140, depth: 3
	GF2X_MUL(112, temp, 56, f_sum+2065, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, g_sum+2065, 56, p_01+783);
	gf2x_add(112, f_sum+2345, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, f_sum+2009, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, g_sum+2009, 56, p_01+783);
	gf2x_add(112, temp, 112, temp, 112, temp2);
	gf2x_add(56, f_sum+2345, 56, f_sum+2345, 56, temp+56);
	right_bit_shift_n(112, f_sum+2345, 50);
	GF2X_MUL(112, temp, 56, f_sum+2065, 56, p_10+783);
	GF2X_MUL(112, temp2, 56, g_sum+2065, 56, p_11+783);
	gf2x_add(112, g_sum+2345, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, f_sum+2009, 56, p_10+783);
	GF2X_MUL(112, temp2, 56, g_sum+2009, 56, p_11+783);
	gf2x_add(112, temp, 112, temp, 112, temp2);
	gf2x_add(56, g_sum+2345, 56, g_sum+2345, 56, temp+56);
	right_bit_shift_n(112, g_sum+2345, 50);
	
	delta = divstepsx_256(255, delta, f_sum+2398, g_sum+2398, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2398, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2398, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2394, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2394, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2398, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2398, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2394, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2394, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2394, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2394, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2386, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2386, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2394, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2394, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2386, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2386, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2386, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2386, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2374);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2374);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2386, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2386, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2374);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2374);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(p_00+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, p_00+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+847, 8, p_00+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+843, 8, p_00+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+839, 8, p_00+839, 8, temp);
	memset(p_01+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, p_01+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+847, 8, p_01+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+843, 8, p_01+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+839, 8, p_01+839, 8, temp);
	memset(p_10+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, p_10+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+847, 8, p_10+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+843, 8, p_10+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+839, 8, p_10+839, 8, temp);
	memset(p_11+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, p_11+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+847, 8, p_11+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+843, 8, p_11+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+839, 8, p_11+839, 8, temp);
	
	// Calculating left operands: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, f_sum+2374, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2374, 28, p_01+839);
	gf2x_add(56, f_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2346, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2346, 28, p_01+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+2514, 28, f_sum+2514, 28, temp+28);
	right_bit_shift_n(56, f_sum+2514, 57);
	GF2X_MUL(56, temp, 28, f_sum+2374, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2374, 28, p_11+839);
	gf2x_add(56, g_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2346, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2346, 28, p_11+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+2514, 28, g_sum+2514, 28, temp+28);
	right_bit_shift_n(56, g_sum+2514, 57);
	
	delta = divstepsx_256(255, delta, f_sum+2539, g_sum+2539, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2539, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2539, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2535, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2535, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(q_00+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, q_00+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+842, 8, q_00+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+838, 8, q_00+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+834, 8, q_00+834, 8, temp);
	memset(q_01+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, q_01+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+842, 8, q_01+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+838, 8, q_01+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+834, 8, q_01+834, 8, temp);
	memset(q_10+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, q_10+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+842, 8, q_10+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+838, 8, q_10+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+834, 8, q_10+834, 8, temp);
	memset(q_11+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, q_11+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+842, 8, q_11+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+838, 8, q_11+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+834, 8, q_11+834, 8, temp);
	
	// Recombining results: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_10+839);
	gf2x_add(56, q_00+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_11+839);
	gf2x_add(56, q_01+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_10+839);
	gf2x_add(56, q_10+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_11+839);
	gf2x_add(56, q_11+778, 56, temp, 56, temp2);
	
	// Recombining results: n: 7140, depth: 3
	GF2X_MUL(112, temp, 56, q_00+778, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, q_01+778, 56, p_10+783);
	gf2x_add(112, q_00+666, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_00+778, 56, p_01+783);
	GF2X_MUL(112, temp2, 56, q_01+778, 56, p_11+783);
	gf2x_add(112, q_01+666, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_10+778, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, q_11+778, 56, p_10+783);
	gf2x_add(112, q_10+666, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_10+778, 56, p_01+783);
	GF2X_MUL(112, temp2, 56, q_11+778, 56, p_11+783);
	gf2x_add(112, q_11+666, 112, temp, 112, temp2);
	
	// Recombining results: n: 14280, depth: 2
	GF2X_MUL(224, temp, 112, q_00+666, 112, p_00+671);
	GF2X_MUL(224, temp2, 112, q_01+666, 112, p_10+671);
	gf2x_add(224, p_00+447, 224, temp, 224, temp2);
	GF2X_MUL(224, temp, 112, q_00+666, 112, p_01+671);
	GF2X_MUL(224, temp2, 112, q_01+666, 112, p_11+671);
	gf2x_add(224, p_01+447, 224, temp, 224, temp2);
	GF2X_MUL(224, temp, 112, q_10+666, 112, p_00+671);
	GF2X_MUL(224, temp2, 112, q_11+666, 112, p_10+671);
	gf2x_add(224, p_10+447, 224, temp, 224, temp2);
	GF2X_MUL(224, temp, 112, q_10+666, 112, p_01+671);
	GF2X_MUL(224, temp2, 112, q_11+666, 112, p_11+671);
	gf2x_add(224, p_11+447, 224, temp, 224, temp2);
	
	// Calculating left operands: n: 28261, depth: 1
	GF2X_MUL(448, temp, 224, f_sum+219, 224, p_00+447);
	GF2X_MUL(448, temp2, 224, g_sum+219, 224, p_01+447);
	gf2x_add(443, f_sum+1336, 443, temp+5, 443, temp2+5);
	GF2X_MUL(436, temp, 218, p_00+453, 218, f_sum+1);
	GF2X_MUL(436, temp2, 218, p_01+453, 218, g_sum+1);
	gf2x_add(436, temp, 436, temp, 436, temp2);
	gf2x_add(219, f_sum+1336, 219, f_sum+1336, 219, temp+217);
	gf2x_mul_6_avx(temp, f_sum+213, p_00+447);
	gf2x_mul_6_avx(temp2, g_sum+213, p_01+447);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(1, f_sum+1336, 1, f_sum+1336, 1, temp+11);
	right_bit_shift_n(442, f_sum+1336, 8);
	GF2X_MUL(448, temp, 224, f_sum+219, 224, p_10+447);
	GF2X_MUL(448, temp2, 224, g_sum+219, 224, p_11+447);
	gf2x_add(443, g_sum+1336, 443, temp+5, 443, temp2+5);
	GF2X_MUL(436, temp, 218, p_10+453, 218, f_sum+1);
	GF2X_MUL(436, temp2, 218, p_11+453, 218, g_sum+1);
	gf2x_add(436, temp, 436, temp, 436, temp2);
	gf2x_add(219, g_sum+1336, 219, g_sum+1336, 219, temp+217);
	gf2x_mul_6_avx(temp, f_sum+213, p_10+447);
	gf2x_mul_6_avx(temp2, g_sum+213, p_11+447);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(1, g_sum+1336, 1, g_sum+1336, 1, temp+11);
	right_bit_shift_n(442, g_sum+1336, 8);
	
	delta = divstepsx_256(255, delta, f_sum+1552, g_sum+1552, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+1552, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+1552, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1548, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+1548, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+1552, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+1552, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1548, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+1548, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+1548, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+1548, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1540, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+1540, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+1548, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+1548, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1540, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+1540, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+1540, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+1540, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+1528);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+1528);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+1540, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+1540, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+1528);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+1528);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(p_00+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, p_00+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+847, 8, p_00+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+843, 8, p_00+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+839, 8, p_00+839, 8, temp);
	memset(p_01+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, p_01+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+847, 8, p_01+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+843, 8, p_01+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+839, 8, p_01+839, 8, temp);
	memset(p_10+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, p_10+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+847, 8, p_10+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+843, 8, p_10+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+839, 8, p_10+839, 8, temp);
	memset(p_11+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, p_11+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+847, 8, p_11+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+843, 8, p_11+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+839, 8, p_11+839, 8, temp);
	
	// Calculating left operands: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, f_sum+1528, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+1528, 28, p_01+839);
	gf2x_add(56, f_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+1500, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+1500, 28, p_01+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+2514, 28, f_sum+2514, 28, temp+28);
	right_bit_shift_n(56, f_sum+2514, 57);
	GF2X_MUL(56, temp, 28, f_sum+1528, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+1528, 28, p_11+839);
	gf2x_add(56, g_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+1500, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+1500, 28, p_11+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+2514, 28, g_sum+2514, 28, temp+28);
	right_bit_shift_n(56, g_sum+2514, 57);
	
	delta = divstepsx_256(255, delta, f_sum+2539, g_sum+2539, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2539, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2539, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2535, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2535, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(q_00+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, q_00+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+842, 8, q_00+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+838, 8, q_00+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+834, 8, q_00+834, 8, temp);
	memset(q_01+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, q_01+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+842, 8, q_01+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+838, 8, q_01+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+834, 8, q_01+834, 8, temp);
	memset(q_10+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, q_10+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+842, 8, q_10+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+838, 8, q_10+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+834, 8, q_10+834, 8, temp);
	memset(q_11+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, q_11+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+842, 8, q_11+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+838, 8, q_11+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+834, 8, q_11+834, 8, temp);
	
	// Recombining results: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_10+839);
	gf2x_add(56, p_00+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_11+839);
	gf2x_add(56, p_01+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_10+839);
	gf2x_add(56, p_10+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_11+839);
	gf2x_add(56, p_11+783, 56, temp, 56, temp2);
	
	// Calculating left operands: n: 7140, depth: 3
	GF2X_MUL(112, temp, 56, f_sum+1500, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, g_sum+1500, 56, p_01+783);
	gf2x_add(112, f_sum+2345, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, f_sum+1444, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, g_sum+1444, 56, p_01+783);
	gf2x_add(112, temp, 112, temp, 112, temp2);
	gf2x_add(56, f_sum+2345, 56, f_sum+2345, 56, temp+56);
	right_bit_shift_n(112, f_sum+2345, 50);
	GF2X_MUL(112, temp, 56, f_sum+1500, 56, p_10+783);
	GF2X_MUL(112, temp2, 56, g_sum+1500, 56, p_11+783);
	gf2x_add(112, g_sum+2345, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, f_sum+1444, 56, p_10+783);
	GF2X_MUL(112, temp2, 56, g_sum+1444, 56, p_11+783);
	gf2x_add(112, temp, 112, temp, 112, temp2);
	gf2x_add(56, g_sum+2345, 56, g_sum+2345, 56, temp+56);
	right_bit_shift_n(112, g_sum+2345, 50);
	
	delta = divstepsx_256(255, delta, f_sum+2398, g_sum+2398, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2398, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2398, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2394, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2394, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2398, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2398, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2394, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2394, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2394, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2394, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2386, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2386, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2394, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2394, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2386, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2386, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2386, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2386, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2374);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2374);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2386, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2386, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2374);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2374);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(p_00+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, p_00+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+847, 8, p_00+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+843, 8, p_00+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+839, 8, p_00+839, 8, temp);
	memset(p_01+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, p_01+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+847, 8, p_01+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+843, 8, p_01+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+839, 8, p_01+839, 8, temp);
	memset(p_10+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, p_10+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+847, 8, p_10+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+843, 8, p_10+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+839, 8, p_10+839, 8, temp);
	memset(p_11+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, p_11+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+847, 8, p_11+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+843, 8, p_11+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+839, 8, p_11+839, 8, temp);
	
	// Calculating left operands: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, f_sum+2374, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2374, 28, p_01+839);
	gf2x_add(56, f_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2346, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2346, 28, p_01+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+2514, 28, f_sum+2514, 28, temp+28);
	right_bit_shift_n(56, f_sum+2514, 57);
	GF2X_MUL(56, temp, 28, f_sum+2374, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2374, 28, p_11+839);
	gf2x_add(56, g_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2346, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2346, 28, p_11+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+2514, 28, g_sum+2514, 28, temp+28);
	right_bit_shift_n(56, g_sum+2514, 57);
	
	delta = divstepsx_256(255, delta, f_sum+2539, g_sum+2539, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2539, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2539, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2535, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2535, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(q_00+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, q_00+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+842, 8, q_00+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+838, 8, q_00+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+834, 8, q_00+834, 8, temp);
	memset(q_01+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, q_01+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+842, 8, q_01+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+838, 8, q_01+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+834, 8, q_01+834, 8, temp);
	memset(q_10+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, q_10+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+842, 8, q_10+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+838, 8, q_10+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+834, 8, q_10+834, 8, temp);
	memset(q_11+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, q_11+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+842, 8, q_11+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+838, 8, q_11+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+834, 8, q_11+834, 8, temp);
	
	// Recombining results: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_10+839);
	gf2x_add(56, q_00+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_11+839);
	gf2x_add(56, q_01+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_10+839);
	gf2x_add(56, q_10+778, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_11+839);
	gf2x_add(56, q_11+778, 56, temp, 56, temp2);
	
	// Recombining results: n: 7140, depth: 3
	GF2X_MUL(112, temp, 56, q_00+778, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, q_01+778, 56, p_10+783);
	gf2x_add(112, p_00+671, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_00+778, 56, p_01+783);
	GF2X_MUL(112, temp2, 56, q_01+778, 56, p_11+783);
	gf2x_add(112, p_01+671, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_10+778, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, q_11+778, 56, p_10+783);
	gf2x_add(112, p_10+671, 112, temp, 112, temp2);
	GF2X_MUL(112, temp, 56, q_10+778, 56, p_01+783);
	GF2X_MUL(112, temp2, 56, q_11+778, 56, p_11+783);
	gf2x_add(112, p_11+671, 112, temp, 112, temp2);
	
	// Calculating left operands: n: 13981, depth: 2
	GF2X_MUL(224, temp, 112, f_sum+1444, 112, p_00+671);
	GF2X_MUL(224, temp2, 112, g_sum+1444, 112, p_01+671);
	gf2x_add(219, f_sum+2008, 219, temp+5, 219, temp2+5);
	GF2X_MUL(214, temp, 107, p_00+676, 107, f_sum+1337);
	GF2X_MUL(214, temp2, 107, p_01+676, 107, g_sum+1337);
	gf2x_add(214, temp, 214, temp, 214, temp2);
	gf2x_add(107, f_sum+2008, 107, f_sum+2008, 107, temp+107);
	right_bit_shift_n(219, f_sum+2008, 36);
	GF2X_MUL(224, temp, 112, f_sum+1444, 112, p_10+671);
	GF2X_MUL(224, temp2, 112, g_sum+1444, 112, p_11+671);
	gf2x_add(219, g_sum+2008, 219, temp+5, 219, temp2+5);
	GF2X_MUL(214, temp, 107, p_10+676, 107, f_sum+1337);
	GF2X_MUL(214, temp2, 107, p_11+676, 107, g_sum+1337);
	gf2x_add(214, temp, 214, temp, 214, temp2);
	gf2x_add(107, g_sum+2008, 107, g_sum+2008, 107, temp+107);
	right_bit_shift_n(219, g_sum+2008, 36);
	
	delta = divstepsx_256(255, delta, f_sum+2112, g_sum+2112, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2112, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2112, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2108, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2108, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2112, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2112, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2108, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2108, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2108, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2108, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2100, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2100, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2108, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2108, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2100, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2100, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2100, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2100, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2088);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2088);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2100, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2100, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2088);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2088);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(p_00+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, p_00+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+847, 8, p_00+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+843, 8, p_00+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+839, 8, p_00+839, 8, temp);
	memset(p_01+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, p_01+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+847, 8, p_01+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+843, 8, p_01+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+839, 8, p_01+839, 8, temp);
	memset(p_10+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, p_10+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+847, 8, p_10+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+843, 8, p_10+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+839, 8, p_10+839, 8, temp);
	memset(p_11+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, p_11+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+847, 8, p_11+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+843, 8, p_11+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+839, 8, p_11+839, 8, temp);
	
	// Calculating left operands: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, f_sum+2088, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2088, 28, p_01+839);
	gf2x_add(56, f_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2060, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2060, 28, p_01+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+2514, 28, f_sum+2514, 28, temp+28);
	right_bit_shift_n(56, f_sum+2514, 57);
	GF2X_MUL(56, temp, 28, f_sum+2088, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2088, 28, p_11+839);
	gf2x_add(56, g_sum+2514, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+2060, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2060, 28, p_11+839);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+2514, 28, g_sum+2514, 28, temp+28);
	right_bit_shift_n(56, g_sum+2514, 57);
	
	delta = divstepsx_256(255, delta, f_sum+2539, g_sum+2539, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2539, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2539, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2539, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2535, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2535, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2535, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2535, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2527, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2527, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2527, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2527, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2515);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2515);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(q_00+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, q_00+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+842, 8, q_00+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+838, 8, q_00+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+834, 8, q_00+834, 8, temp);
	memset(q_01+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, q_01+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+842, 8, q_01+842, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+838, 8, q_01+838, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+834, 8, q_01+834, 8, temp);
	memset(q_10+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, q_10+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+842, 8, q_10+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+838, 8, q_10+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+834, 8, q_10+834, 8, temp);
	memset(q_11+834, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, q_11+838, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+842, 8, q_11+842, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+838, 8, q_11+838, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+834, 8, q_11+834, 8, temp);
	
	// Recombining results: n: 3570, depth: 4
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_10+839);
	gf2x_add(56, p_00+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_00+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_01+834, 28, p_11+839);
	gf2x_add(56, p_01+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_10+839);
	gf2x_add(56, p_10+783, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+834, 28, p_01+839);
	GF2X_MUL(56, temp2, 28, q_11+834, 28, p_11+839);
	gf2x_add(56, p_11+783, 56, temp, 56, temp2);
	
	// Calculating left operands: n: 6841, depth: 3
	GF2X_MUL(112, temp, 56, f_sum+2060, 56, p_00+783);
	GF2X_MUL(112, temp2, 56, g_sum+2060, 56, p_01+783);
	gf2x_add(108, f_sum+2345, 108, temp+4, 108, temp2+4);
	GF2X_MUL(102, temp, 51, p_00+788, 51, f_sum+2009);
	GF2X_MUL(102, temp2, 51, p_01+788, 51, g_sum+2009);
	gf2x_add(102, temp, 102, temp, 102, temp2);
	gf2x_add(52, f_sum+2345, 52, f_sum+2345, 52, temp+50);
	gf2x_mul_5_avx(temp, f_sum+2055, p_00+783);
	gf2x_mul_5_avx(temp2, g_sum+2055, p_01+783);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(1, f_sum+2345, 1, f_sum+2345, 1, temp+9);
	right_bit_shift_n(107, f_sum+2345, 50);
	GF2X_MUL(112, temp, 56, f_sum+2060, 56, p_10+783);
	GF2X_MUL(112, temp2, 56, g_sum+2060, 56, p_11+783);
	gf2x_add(108, g_sum+2345, 108, temp+4, 108, temp2+4);
	GF2X_MUL(102, temp, 51, p_10+788, 51, f_sum+2009);
	GF2X_MUL(102, temp2, 51, p_11+788, 51, g_sum+2009);
	gf2x_add(102, temp, 102, temp, 102, temp2);
	gf2x_add(52, g_sum+2345, 52, g_sum+2345, 52, temp+50);
	gf2x_mul_5_avx(temp, f_sum+2055, p_10+783);
	gf2x_mul_5_avx(temp2, g_sum+2055, p_11+783);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(1, g_sum+2345, 1, g_sum+2345, 1, temp+9);
	right_bit_shift_n(107, g_sum+2345, 50);
	
	delta = divstepsx_256(255, delta, f_sum+2394, g_sum+2394, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2394, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2394, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2390, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2390, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2394, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2394, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2390, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2390, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2390, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2390, p_01+883);
	gf2x_add(16, f_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2382, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2382, p_01+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+2644, 8, f_sum+2644, 8, temp+8);
	right_bit_shift_n(16, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2390, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2390, p_11+883);
	gf2x_add(16, g_sum+2644, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+2382, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2382, p_11+883);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+2644, 8, g_sum+2644, 8, temp+8);
	right_bit_shift_n(16, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2649, g_sum+2649, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2649, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2649, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2649, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2645, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2645, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, q_00+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, q_01+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, q_10+874, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, q_11+874, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 6
	gf2x_mul_8_avx(temp, q_00+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_10+883);
	gf2x_add(16, p_00+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_01+874, p_11+883);
	gf2x_add(16, p_01+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_00+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_10+883);
	gf2x_add(16, p_10+867, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+874, p_01+883);
	gf2x_mul_8_avx(temp2, q_11+874, p_11+883);
	gf2x_add(16, p_11+867, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 5
	GF2X_MUL(32, temp, 16, f_sum+2382, 16, p_00+867);
	GF2X_MUL(32, temp2, 16, g_sum+2382, 16, p_01+867);
	gf2x_add(28, f_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+871, 12, f_sum+2370);
	GF2X_MUL(24, temp2, 12, p_01+871, 12, g_sum+2370);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(28, f_sum+2599, 60);
	GF2X_MUL(32, temp, 16, f_sum+2382, 16, p_10+867);
	GF2X_MUL(32, temp2, 16, g_sum+2382, 16, p_11+867);
	gf2x_add(28, g_sum+2599, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+871, 12, f_sum+2370);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, g_sum+2370);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(28, g_sum+2599, 60);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1785, depth: 5
	memset(p_00+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_01+862);
	gf2x_add(24, p_00+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+847, 8, p_00+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+843, 8, p_00+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+839, 8, p_00+839, 8, temp);
	memset(p_01+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_00+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_01+862);
	gf2x_add(24, p_01+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+847, 8, p_01+847, 8, temp);
	gf2x_mul_4_avx(temp, q_00+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+843, 8, p_01+843, 8, temp);
	gf2x_mul_4_avx(temp, q_00+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_01+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+839, 8, p_01+839, 8, temp);
	memset(p_10+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_10+871, 12, q_11+862);
	gf2x_add(24, p_10+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+847, 8, p_10+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+843, 8, p_10+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_00+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_10+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+839, 8, p_10+839, 8, temp);
	memset(p_11+839, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+871, 12, q_10+862);
	GF2X_MUL(24, temp2, 12, p_11+871, 12, q_11+862);
	gf2x_add(24, p_11+843, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+870, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+870, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+847, 8, p_11+847, 8, temp);
	gf2x_mul_4_avx(temp, q_10+866, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+866, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+843, 8, p_11+843, 8, temp);
	gf2x_mul_4_avx(temp, q_10+862, p_01+867);
	gf2x_mul_4_avx(temp2, q_11+862, p_11+867);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+839, 8, p_11+839, 8, temp);
	
	// Calculating left operands: n: 3271, depth: 4
	GF2X_MUL(56, temp, 28, f_sum+2370, 28, p_00+839);
	GF2X_MUL(56, temp2, 28, g_sum+2370, 28, p_01+839);
	gf2x_add(52, f_sum+2514, 52, temp+4, 52, temp2+4);
	GF2X_MUL(48, temp, 24, p_00+843, 24, f_sum+2346);
	GF2X_MUL(48, temp2, 24, p_01+843, 24, g_sum+2346);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, f_sum+2514, 24, f_sum+2514, 24, temp+24);
	right_bit_shift_n(52, f_sum+2514, 57);
	GF2X_MUL(56, temp, 28, f_sum+2370, 28, p_10+839);
	GF2X_MUL(56, temp2, 28, g_sum+2370, 28, p_11+839);
	gf2x_add(52, g_sum+2514, 52, temp+4, 52, temp2+4);
	GF2X_MUL(48, temp, 24, p_10+843, 24, f_sum+2346);
	GF2X_MUL(48, temp2, 24, p_11+843, 24, g_sum+2346);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, g_sum+2514, 24, g_sum+2514, 24, temp+24);
	right_bit_shift_n(52, g_sum+2514, 57);
	
	delta = divstepsx_256(255, delta, f_sum+2535, g_sum+2535, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2535, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2531, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2531, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2535, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2535, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2531, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2531, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2531, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2531, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2527);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2527);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2531, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2531, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2527);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2527);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(255, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 765, depth: 6
	memset(p_00+867, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, p_00+871, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+867, 8, p_00+867, 8, temp);
	memset(p_01+867, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, p_01+871, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+867, 8, p_01+867, 8, temp);
	memset(p_10+867, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, p_10+871, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+867, 8, p_10+867, 8, temp);
	memset(p_11+867, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, p_11+871, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+867, 8, p_11+867, 8, temp);
	
	// Calculating left operands: n: 1486, depth: 5
	GF2X_MUL(24, temp, 12, f_sum+2527, 12, p_00+867);
	GF2X_MUL(24, temp2, 12, g_sum+2527, 12, p_01+867);
	gf2x_add(24, f_sum+2599, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+2515, 12, p_00+867);
	GF2X_MUL(24, temp2, 12, g_sum+2515, 12, p_01+867);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+2599, 12, f_sum+2599, 12, temp+12);
	right_bit_shift_n(24, f_sum+2599, 61);
	GF2X_MUL(24, temp, 12, f_sum+2527, 12, p_10+867);
	GF2X_MUL(24, temp2, 12, g_sum+2527, 12, p_11+867);
	gf2x_add(24, g_sum+2599, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+2515, 12, p_10+867);
	GF2X_MUL(24, temp2, 12, g_sum+2515, 12, p_11+867);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+2599, 12, g_sum+2599, 12, temp+12);
	right_bit_shift_n(24, g_sum+2599, 61);
	
	delta = divstepsx_256(255, delta, f_sum+2608, g_sum+2608, p_00+891, p_01+891, p_10+891, p_11+891);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+2608, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_01+891);
	gf2x_add(8, f_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_00+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_01+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2669, 4, f_sum+2669, 4, temp+4);
	right_bit_shift_n(8, f_sum+2669, 63);
	gf2x_mul_4_avx(temp, f_sum+2608, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2608, p_11+891);
	gf2x_add(8, g_sum+2669, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2604, p_10+891);
	gf2x_mul_4_avx(temp2, g_sum+2604, p_11+891);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2669, 4, g_sum+2669, 4, temp+4);
	right_bit_shift_n(8, g_sum+2669, 63);
	
	delta = divstepsx_256(255, delta, f_sum+2670, g_sum+2670, q_00+882, q_01+882, q_10+882, q_11+882);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_10+891);
	gf2x_add(8, p_00+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_01+882, p_11+891);
	gf2x_add(8, p_01+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_00+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_10+891);
	gf2x_add(8, p_10+883, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+882, p_01+891);
	gf2x_mul_4_avx(temp2, q_11+882, p_11+891);
	gf2x_add(8, p_11+883, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 721, depth: 6
	gf2x_mul_8_avx(temp, f_sum+2604, p_00+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_01+883);
	gf2x_add(12, f_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_01+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+2644, 4, f_sum+2644, 4, temp+4);
	right_bit_shift_n(12, f_sum+2644, 62);
	gf2x_mul_8_avx(temp, f_sum+2604, p_10+883);
	gf2x_mul_8_avx(temp2, g_sum+2604, p_11+883);
	gf2x_add(12, g_sum+2644, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+887, f_sum+2600);
	gf2x_mul_4_avx(temp2, p_11+887, g_sum+2600);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+2644, 4, g_sum+2644, 4, temp+4);
	right_bit_shift_n(12, g_sum+2644, 62);
	
	delta = divstepsx_256(211, delta, f_sum+2645, g_sum+2645, q_00+874, q_01+874, q_10+874, q_11+874);

	// Recombining results: n: 721, depth: 6
	memset(q_00+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_01+874);
	gf2x_add(8, q_00+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+862, 8, q_00+862, 8, temp);
	memset(q_01+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_00+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_01+874);
	gf2x_add(8, q_01+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_01+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+862, 8, q_01+862, 8, temp);
	memset(q_10+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_10+887, q_11+874);
	gf2x_add(8, q_10+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_00+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_10+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+862, 8, q_10+862, 8, temp);
	memset(q_11+862, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+887, q_10+874);
	gf2x_mul_4_avx(temp2, p_11+887, q_11+874);
	gf2x_add(8, q_11+866, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+874, p_01+883);
	gf2x_mul_4_avx(temp2, q_11+874, p_11+883);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+862, 8, q_11+862, 8, temp);
	
	// Recombining results: n: 1486, depth: 5
	GF2X_MUL(24, temp, 12, q_00+862, 12, p_00+867);
	GF2X_MUL(24, temp2, 12, q_01+862, 12, p_10+867);
	gf2x_add(24, q_00+834, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+862, 12, p_01+867);
	GF2X_MUL(24, temp2, 12, q_01+862, 12, p_11+867);
	gf2x_add(24, q_01+834, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+862, 12, p_00+867);
	GF2X_MUL(24, temp2, 12, q_11+862, 12, p_10+867);
	gf2x_add(24, q_10+834, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+862, 12, p_01+867);
	GF2X_MUL(24, temp2, 12, q_11+862, 12, p_11+867);
	gf2x_add(24, q_11+834, 24, temp, 24, temp2);
	
	// Recombining results: n: 3271, depth: 4
	memset(q_00+778, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_00+843, 24, q_00+834);
	GF2X_MUL(48, temp2, 24, p_10+843, 24, q_01+834);
	gf2x_add(48, q_00+782, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_00+854, p_00+839);
	gf2x_mul_4_avx(temp2, q_01+854, p_10+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+798, 8, q_00+798, 8, temp);
	gf2x_mul_4_avx(temp, q_00+850, p_00+839);
	gf2x_mul_4_avx(temp2, q_01+850, p_10+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+794, 8, q_00+794, 8, temp);
	gf2x_mul_4_avx(temp, q_00+846, p_00+839);
	gf2x_mul_4_avx(temp2, q_01+846, p_10+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+790, 8, q_00+790, 8, temp);
	gf2x_mul_4_avx(temp, q_00+842, p_00+839);
	gf2x_mul_4_avx(temp2, q_01+842, p_10+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+786, 8, q_00+786, 8, temp);
	gf2x_mul_4_avx(temp, q_00+838, p_00+839);
	gf2x_mul_4_avx(temp2, q_01+838, p_10+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+782, 8, q_00+782, 8, temp);
	gf2x_mul_4_avx(temp, q_00+834, p_00+839);
	gf2x_mul_4_avx(temp2, q_01+834, p_10+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+778, 8, q_00+778, 8, temp);
	memset(q_01+778, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_01+843, 24, q_00+834);
	GF2X_MUL(48, temp2, 24, p_11+843, 24, q_01+834);
	gf2x_add(48, q_01+782, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_00+854, p_01+839);
	gf2x_mul_4_avx(temp2, q_01+854, p_11+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+798, 8, q_01+798, 8, temp);
	gf2x_mul_4_avx(temp, q_00+850, p_01+839);
	gf2x_mul_4_avx(temp2, q_01+850, p_11+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+794, 8, q_01+794, 8, temp);
	gf2x_mul_4_avx(temp, q_00+846, p_01+839);
	gf2x_mul_4_avx(temp2, q_01+846, p_11+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+790, 8, q_01+790, 8, temp);
	gf2x_mul_4_avx(temp, q_00+842, p_01+839);
	gf2x_mul_4_avx(temp2, q_01+842, p_11+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+786, 8, q_01+786, 8, temp);
	gf2x_mul_4_avx(temp, q_00+838, p_01+839);
	gf2x_mul_4_avx(temp2, q_01+838, p_11+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+782, 8, q_01+782, 8, temp);
	gf2x_mul_4_avx(temp, q_00+834, p_01+839);
	gf2x_mul_4_avx(temp2, q_01+834, p_11+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+778, 8, q_01+778, 8, temp);
	memset(q_10+778, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_00+843, 24, q_10+834);
	GF2X_MUL(48, temp2, 24, p_10+843, 24, q_11+834);
	gf2x_add(48, q_10+782, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_10+854, p_00+839);
	gf2x_mul_4_avx(temp2, q_11+854, p_10+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+798, 8, q_10+798, 8, temp);
	gf2x_mul_4_avx(temp, q_10+850, p_00+839);
	gf2x_mul_4_avx(temp2, q_11+850, p_10+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+794, 8, q_10+794, 8, temp);
	gf2x_mul_4_avx(temp, q_10+846, p_00+839);
	gf2x_mul_4_avx(temp2, q_11+846, p_10+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+790, 8, q_10+790, 8, temp);
	gf2x_mul_4_avx(temp, q_10+842, p_00+839);
	gf2x_mul_4_avx(temp2, q_11+842, p_10+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+786, 8, q_10+786, 8, temp);
	gf2x_mul_4_avx(temp, q_10+838, p_00+839);
	gf2x_mul_4_avx(temp2, q_11+838, p_10+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+782, 8, q_10+782, 8, temp);
	gf2x_mul_4_avx(temp, q_10+834, p_00+839);
	gf2x_mul_4_avx(temp2, q_11+834, p_10+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+778, 8, q_10+778, 8, temp);
	memset(q_11+778, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_01+843, 24, q_10+834);
	GF2X_MUL(48, temp2, 24, p_11+843, 24, q_11+834);
	gf2x_add(48, q_11+782, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_10+854, p_01+839);
	gf2x_mul_4_avx(temp2, q_11+854, p_11+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+798, 8, q_11+798, 8, temp);
	gf2x_mul_4_avx(temp, q_10+850, p_01+839);
	gf2x_mul_4_avx(temp2, q_11+850, p_11+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+794, 8, q_11+794, 8, temp);
	gf2x_mul_4_avx(temp, q_10+846, p_01+839);
	gf2x_mul_4_avx(temp2, q_11+846, p_11+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+790, 8, q_11+790, 8, temp);
	gf2x_mul_4_avx(temp, q_10+842, p_01+839);
	gf2x_mul_4_avx(temp2, q_11+842, p_11+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+786, 8, q_11+786, 8, temp);
	gf2x_mul_4_avx(temp, q_10+838, p_01+839);
	gf2x_mul_4_avx(temp2, q_11+838, p_11+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+782, 8, q_11+782, 8, temp);
	gf2x_mul_4_avx(temp, q_10+834, p_01+839);
	gf2x_mul_4_avx(temp2, q_11+834, p_11+839);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+778, 8, q_11+778, 8, temp);
	
	// Recombining results: n: 6841, depth: 3
	memset(q_00+666, 0x00, 3*DIGIT_SIZE_B);
	GF2X_MUL(104, temp, 52, p_00+787, 52, q_00+778);
	GF2X_MUL(104, temp2, 52, p_10+787, 52, q_01+778);
	gf2x_add(104, q_00+669, 104, temp, 104, temp2);
	gf2x_mul_4_avx(temp, q_00+826, p_00+783);
	gf2x_mul_4_avx(temp2, q_01+826, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+713, 8, q_00+713, 8, temp);
	gf2x_mul_4_avx(temp, q_00+822, p_00+783);
	gf2x_mul_4_avx(temp2, q_01+822, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+709, 8, q_00+709, 8, temp);
	gf2x_mul_4_avx(temp, q_00+818, p_00+783);
	gf2x_mul_4_avx(temp2, q_01+818, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+705, 8, q_00+705, 8, temp);
	gf2x_mul_4_avx(temp, q_00+814, p_00+783);
	gf2x_mul_4_avx(temp2, q_01+814, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+701, 8, q_00+701, 8, temp);
	gf2x_mul_4_avx(temp, q_00+810, p_00+783);
	gf2x_mul_4_avx(temp2, q_01+810, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+697, 8, q_00+697, 8, temp);
	gf2x_mul_4_avx(temp, q_00+806, p_00+783);
	gf2x_mul_4_avx(temp2, q_01+806, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+693, 8, q_00+693, 8, temp);
	gf2x_mul_4_avx(temp, q_00+802, p_00+783);
	gf2x_mul_4_avx(temp2, q_01+802, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+689, 8, q_00+689, 8, temp);
	gf2x_mul_4_avx(temp, q_00+798, p_00+783);
	gf2x_mul_4_avx(temp2, q_01+798, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+685, 8, q_00+685, 8, temp);
	gf2x_mul_4_avx(temp, q_00+794, p_00+783);
	gf2x_mul_4_avx(temp2, q_01+794, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+681, 8, q_00+681, 8, temp);
	gf2x_mul_4_avx(temp, q_00+790, p_00+783);
	gf2x_mul_4_avx(temp2, q_01+790, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+677, 8, q_00+677, 8, temp);
	gf2x_mul_4_avx(temp, q_00+786, p_00+783);
	gf2x_mul_4_avx(temp2, q_01+786, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+673, 8, q_00+673, 8, temp);
	gf2x_mul_4_avx(temp, q_00+782, p_00+783);
	gf2x_mul_4_avx(temp2, q_01+782, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+669, 8, q_00+669, 8, temp);
	gf2x_mul_4_avx(temp, q_00+778, p_00+783);
	gf2x_mul_4_avx(temp2, q_01+778, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(7, q_00+666, 7, q_00+666, 7, temp+1);
	memset(q_01+666, 0x00, 3*DIGIT_SIZE_B);
	GF2X_MUL(104, temp, 52, p_01+787, 52, q_00+778);
	GF2X_MUL(104, temp2, 52, p_11+787, 52, q_01+778);
	gf2x_add(104, q_01+669, 104, temp, 104, temp2);
	gf2x_mul_4_avx(temp, q_00+826, p_01+783);
	gf2x_mul_4_avx(temp2, q_01+826, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+713, 8, q_01+713, 8, temp);
	gf2x_mul_4_avx(temp, q_00+822, p_01+783);
	gf2x_mul_4_avx(temp2, q_01+822, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+709, 8, q_01+709, 8, temp);
	gf2x_mul_4_avx(temp, q_00+818, p_01+783);
	gf2x_mul_4_avx(temp2, q_01+818, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+705, 8, q_01+705, 8, temp);
	gf2x_mul_4_avx(temp, q_00+814, p_01+783);
	gf2x_mul_4_avx(temp2, q_01+814, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+701, 8, q_01+701, 8, temp);
	gf2x_mul_4_avx(temp, q_00+810, p_01+783);
	gf2x_mul_4_avx(temp2, q_01+810, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+697, 8, q_01+697, 8, temp);
	gf2x_mul_4_avx(temp, q_00+806, p_01+783);
	gf2x_mul_4_avx(temp2, q_01+806, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+693, 8, q_01+693, 8, temp);
	gf2x_mul_4_avx(temp, q_00+802, p_01+783);
	gf2x_mul_4_avx(temp2, q_01+802, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+689, 8, q_01+689, 8, temp);
	gf2x_mul_4_avx(temp, q_00+798, p_01+783);
	gf2x_mul_4_avx(temp2, q_01+798, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+685, 8, q_01+685, 8, temp);
	gf2x_mul_4_avx(temp, q_00+794, p_01+783);
	gf2x_mul_4_avx(temp2, q_01+794, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+681, 8, q_01+681, 8, temp);
	gf2x_mul_4_avx(temp, q_00+790, p_01+783);
	gf2x_mul_4_avx(temp2, q_01+790, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+677, 8, q_01+677, 8, temp);
	gf2x_mul_4_avx(temp, q_00+786, p_01+783);
	gf2x_mul_4_avx(temp2, q_01+786, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+673, 8, q_01+673, 8, temp);
	gf2x_mul_4_avx(temp, q_00+782, p_01+783);
	gf2x_mul_4_avx(temp2, q_01+782, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+669, 8, q_01+669, 8, temp);
	gf2x_mul_4_avx(temp, q_00+778, p_01+783);
	gf2x_mul_4_avx(temp2, q_01+778, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(7, q_01+666, 7, q_01+666, 7, temp+1);
	memset(q_10+666, 0x00, 3*DIGIT_SIZE_B);
	GF2X_MUL(104, temp, 52, p_00+787, 52, q_10+778);
	GF2X_MUL(104, temp2, 52, p_10+787, 52, q_11+778);
	gf2x_add(104, q_10+669, 104, temp, 104, temp2);
	gf2x_mul_4_avx(temp, q_10+826, p_00+783);
	gf2x_mul_4_avx(temp2, q_11+826, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+713, 8, q_10+713, 8, temp);
	gf2x_mul_4_avx(temp, q_10+822, p_00+783);
	gf2x_mul_4_avx(temp2, q_11+822, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+709, 8, q_10+709, 8, temp);
	gf2x_mul_4_avx(temp, q_10+818, p_00+783);
	gf2x_mul_4_avx(temp2, q_11+818, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+705, 8, q_10+705, 8, temp);
	gf2x_mul_4_avx(temp, q_10+814, p_00+783);
	gf2x_mul_4_avx(temp2, q_11+814, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+701, 8, q_10+701, 8, temp);
	gf2x_mul_4_avx(temp, q_10+810, p_00+783);
	gf2x_mul_4_avx(temp2, q_11+810, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+697, 8, q_10+697, 8, temp);
	gf2x_mul_4_avx(temp, q_10+806, p_00+783);
	gf2x_mul_4_avx(temp2, q_11+806, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+693, 8, q_10+693, 8, temp);
	gf2x_mul_4_avx(temp, q_10+802, p_00+783);
	gf2x_mul_4_avx(temp2, q_11+802, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+689, 8, q_10+689, 8, temp);
	gf2x_mul_4_avx(temp, q_10+798, p_00+783);
	gf2x_mul_4_avx(temp2, q_11+798, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+685, 8, q_10+685, 8, temp);
	gf2x_mul_4_avx(temp, q_10+794, p_00+783);
	gf2x_mul_4_avx(temp2, q_11+794, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+681, 8, q_10+681, 8, temp);
	gf2x_mul_4_avx(temp, q_10+790, p_00+783);
	gf2x_mul_4_avx(temp2, q_11+790, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+677, 8, q_10+677, 8, temp);
	gf2x_mul_4_avx(temp, q_10+786, p_00+783);
	gf2x_mul_4_avx(temp2, q_11+786, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+673, 8, q_10+673, 8, temp);
	gf2x_mul_4_avx(temp, q_10+782, p_00+783);
	gf2x_mul_4_avx(temp2, q_11+782, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+669, 8, q_10+669, 8, temp);
	gf2x_mul_4_avx(temp, q_10+778, p_00+783);
	gf2x_mul_4_avx(temp2, q_11+778, p_10+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(7, q_10+666, 7, q_10+666, 7, temp+1);
	memset(q_11+666, 0x00, 3*DIGIT_SIZE_B);
	GF2X_MUL(104, temp, 52, p_01+787, 52, q_10+778);
	GF2X_MUL(104, temp2, 52, p_11+787, 52, q_11+778);
	gf2x_add(104, q_11+669, 104, temp, 104, temp2);
	gf2x_mul_4_avx(temp, q_10+826, p_01+783);
	gf2x_mul_4_avx(temp2, q_11+826, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+713, 8, q_11+713, 8, temp);
	gf2x_mul_4_avx(temp, q_10+822, p_01+783);
	gf2x_mul_4_avx(temp2, q_11+822, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+709, 8, q_11+709, 8, temp);
	gf2x_mul_4_avx(temp, q_10+818, p_01+783);
	gf2x_mul_4_avx(temp2, q_11+818, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+705, 8, q_11+705, 8, temp);
	gf2x_mul_4_avx(temp, q_10+814, p_01+783);
	gf2x_mul_4_avx(temp2, q_11+814, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+701, 8, q_11+701, 8, temp);
	gf2x_mul_4_avx(temp, q_10+810, p_01+783);
	gf2x_mul_4_avx(temp2, q_11+810, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+697, 8, q_11+697, 8, temp);
	gf2x_mul_4_avx(temp, q_10+806, p_01+783);
	gf2x_mul_4_avx(temp2, q_11+806, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+693, 8, q_11+693, 8, temp);
	gf2x_mul_4_avx(temp, q_10+802, p_01+783);
	gf2x_mul_4_avx(temp2, q_11+802, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+689, 8, q_11+689, 8, temp);
	gf2x_mul_4_avx(temp, q_10+798, p_01+783);
	gf2x_mul_4_avx(temp2, q_11+798, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+685, 8, q_11+685, 8, temp);
	gf2x_mul_4_avx(temp, q_10+794, p_01+783);
	gf2x_mul_4_avx(temp2, q_11+794, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+681, 8, q_11+681, 8, temp);
	gf2x_mul_4_avx(temp, q_10+790, p_01+783);
	gf2x_mul_4_avx(temp2, q_11+790, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+677, 8, q_11+677, 8, temp);
	gf2x_mul_4_avx(temp, q_10+786, p_01+783);
	gf2x_mul_4_avx(temp2, q_11+786, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+673, 8, q_11+673, 8, temp);
	gf2x_mul_4_avx(temp, q_10+782, p_01+783);
	gf2x_mul_4_avx(temp2, q_11+782, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+669, 8, q_11+669, 8, temp);
	gf2x_mul_4_avx(temp, q_10+778, p_01+783);
	gf2x_mul_4_avx(temp2, q_11+778, p_11+783);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(7, q_11+666, 7, q_11+666, 7, temp+1);
	
	// Recombining results: n: 13981, depth: 2
	memset(q_00+442, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(214, temp, 107, p_00+676, 107, q_00+666);
	GF2X_MUL(214, temp2, 107, p_10+676, 107, q_01+666);
	gf2x_add(214, q_00+447, 214, temp, 214, temp2);
	gf2x_mul_5_avx(temp, q_00+768, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+768, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+544, 10, q_00+544, 10, temp);
	gf2x_mul_5_avx(temp, q_00+763, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+763, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+539, 10, q_00+539, 10, temp);
	gf2x_mul_5_avx(temp, q_00+758, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+758, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+534, 10, q_00+534, 10, temp);
	gf2x_mul_5_avx(temp, q_00+753, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+753, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+529, 10, q_00+529, 10, temp);
	gf2x_mul_5_avx(temp, q_00+748, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+748, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+524, 10, q_00+524, 10, temp);
	gf2x_mul_5_avx(temp, q_00+743, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+743, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+519, 10, q_00+519, 10, temp);
	gf2x_mul_5_avx(temp, q_00+738, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+738, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+514, 10, q_00+514, 10, temp);
	gf2x_mul_5_avx(temp, q_00+733, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+733, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+509, 10, q_00+509, 10, temp);
	gf2x_mul_5_avx(temp, q_00+728, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+728, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+504, 10, q_00+504, 10, temp);
	gf2x_mul_5_avx(temp, q_00+723, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+723, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+499, 10, q_00+499, 10, temp);
	gf2x_mul_5_avx(temp, q_00+718, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+718, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+494, 10, q_00+494, 10, temp);
	gf2x_mul_5_avx(temp, q_00+713, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+713, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+489, 10, q_00+489, 10, temp);
	gf2x_mul_5_avx(temp, q_00+708, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+708, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+484, 10, q_00+484, 10, temp);
	gf2x_mul_5_avx(temp, q_00+703, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+703, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+479, 10, q_00+479, 10, temp);
	gf2x_mul_5_avx(temp, q_00+698, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+698, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+474, 10, q_00+474, 10, temp);
	gf2x_mul_5_avx(temp, q_00+693, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+693, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+469, 10, q_00+469, 10, temp);
	gf2x_mul_5_avx(temp, q_00+688, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+688, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+464, 10, q_00+464, 10, temp);
	gf2x_mul_5_avx(temp, q_00+683, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+683, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+459, 10, q_00+459, 10, temp);
	gf2x_mul_5_avx(temp, q_00+678, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+678, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+454, 10, q_00+454, 10, temp);
	gf2x_mul_5_avx(temp, q_00+673, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+673, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+449, 10, q_00+449, 10, temp);
	gf2x_mul_5_avx(temp, q_00+668, p_00+671);
	gf2x_mul_5_avx(temp2, q_01+668, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+444, 10, q_00+444, 10, temp);
	gf2x_mul_2_avx(temp, p_00+674, q_00+666);
	gf2x_mul_2_avx(temp2, p_10+674, q_01+666);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+445, 4, q_00+445, 4, temp);
	gf2x_mul_2_avx(temp, p_00+672, q_00+666);
	gf2x_mul_2_avx(temp2, p_10+672, q_01+666);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+443, 4, q_00+443, 4, temp);
	gf2x_mul_1_avx(temp, q_00+667, p_00+671);
	gf2x_mul_1_avx(temp2, q_01+667, p_10+671);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+443, 2, q_00+443, 2, temp);
	gf2x_mul_1_avx(temp, q_00+666, p_00+671);
	gf2x_mul_1_avx(temp2, q_01+666, p_10+671);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+442, 2, q_00+442, 2, temp);
	memset(q_01+442, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(214, temp, 107, p_01+676, 107, q_00+666);
	GF2X_MUL(214, temp2, 107, p_11+676, 107, q_01+666);
	gf2x_add(214, q_01+447, 214, temp, 214, temp2);
	gf2x_mul_5_avx(temp, q_00+768, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+768, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+544, 10, q_01+544, 10, temp);
	gf2x_mul_5_avx(temp, q_00+763, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+763, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+539, 10, q_01+539, 10, temp);
	gf2x_mul_5_avx(temp, q_00+758, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+758, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+534, 10, q_01+534, 10, temp);
	gf2x_mul_5_avx(temp, q_00+753, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+753, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+529, 10, q_01+529, 10, temp);
	gf2x_mul_5_avx(temp, q_00+748, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+748, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+524, 10, q_01+524, 10, temp);
	gf2x_mul_5_avx(temp, q_00+743, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+743, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+519, 10, q_01+519, 10, temp);
	gf2x_mul_5_avx(temp, q_00+738, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+738, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+514, 10, q_01+514, 10, temp);
	gf2x_mul_5_avx(temp, q_00+733, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+733, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+509, 10, q_01+509, 10, temp);
	gf2x_mul_5_avx(temp, q_00+728, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+728, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+504, 10, q_01+504, 10, temp);
	gf2x_mul_5_avx(temp, q_00+723, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+723, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+499, 10, q_01+499, 10, temp);
	gf2x_mul_5_avx(temp, q_00+718, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+718, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+494, 10, q_01+494, 10, temp);
	gf2x_mul_5_avx(temp, q_00+713, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+713, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+489, 10, q_01+489, 10, temp);
	gf2x_mul_5_avx(temp, q_00+708, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+708, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+484, 10, q_01+484, 10, temp);
	gf2x_mul_5_avx(temp, q_00+703, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+703, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+479, 10, q_01+479, 10, temp);
	gf2x_mul_5_avx(temp, q_00+698, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+698, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+474, 10, q_01+474, 10, temp);
	gf2x_mul_5_avx(temp, q_00+693, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+693, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+469, 10, q_01+469, 10, temp);
	gf2x_mul_5_avx(temp, q_00+688, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+688, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+464, 10, q_01+464, 10, temp);
	gf2x_mul_5_avx(temp, q_00+683, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+683, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+459, 10, q_01+459, 10, temp);
	gf2x_mul_5_avx(temp, q_00+678, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+678, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+454, 10, q_01+454, 10, temp);
	gf2x_mul_5_avx(temp, q_00+673, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+673, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+449, 10, q_01+449, 10, temp);
	gf2x_mul_5_avx(temp, q_00+668, p_01+671);
	gf2x_mul_5_avx(temp2, q_01+668, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+444, 10, q_01+444, 10, temp);
	gf2x_mul_2_avx(temp, p_01+674, q_00+666);
	gf2x_mul_2_avx(temp2, p_11+674, q_01+666);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+445, 4, q_01+445, 4, temp);
	gf2x_mul_2_avx(temp, p_01+672, q_00+666);
	gf2x_mul_2_avx(temp2, p_11+672, q_01+666);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+443, 4, q_01+443, 4, temp);
	gf2x_mul_1_avx(temp, q_00+667, p_01+671);
	gf2x_mul_1_avx(temp2, q_01+667, p_11+671);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+443, 2, q_01+443, 2, temp);
	gf2x_mul_1_avx(temp, q_00+666, p_01+671);
	gf2x_mul_1_avx(temp2, q_01+666, p_11+671);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+442, 2, q_01+442, 2, temp);
	memset(q_10+442, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(214, temp, 107, p_00+676, 107, q_10+666);
	GF2X_MUL(214, temp2, 107, p_10+676, 107, q_11+666);
	gf2x_add(214, q_10+447, 214, temp, 214, temp2);
	gf2x_mul_5_avx(temp, q_10+768, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+768, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+544, 10, q_10+544, 10, temp);
	gf2x_mul_5_avx(temp, q_10+763, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+763, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+539, 10, q_10+539, 10, temp);
	gf2x_mul_5_avx(temp, q_10+758, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+758, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+534, 10, q_10+534, 10, temp);
	gf2x_mul_5_avx(temp, q_10+753, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+753, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+529, 10, q_10+529, 10, temp);
	gf2x_mul_5_avx(temp, q_10+748, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+748, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+524, 10, q_10+524, 10, temp);
	gf2x_mul_5_avx(temp, q_10+743, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+743, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+519, 10, q_10+519, 10, temp);
	gf2x_mul_5_avx(temp, q_10+738, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+738, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+514, 10, q_10+514, 10, temp);
	gf2x_mul_5_avx(temp, q_10+733, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+733, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+509, 10, q_10+509, 10, temp);
	gf2x_mul_5_avx(temp, q_10+728, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+728, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+504, 10, q_10+504, 10, temp);
	gf2x_mul_5_avx(temp, q_10+723, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+723, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+499, 10, q_10+499, 10, temp);
	gf2x_mul_5_avx(temp, q_10+718, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+718, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+494, 10, q_10+494, 10, temp);
	gf2x_mul_5_avx(temp, q_10+713, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+713, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+489, 10, q_10+489, 10, temp);
	gf2x_mul_5_avx(temp, q_10+708, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+708, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+484, 10, q_10+484, 10, temp);
	gf2x_mul_5_avx(temp, q_10+703, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+703, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+479, 10, q_10+479, 10, temp);
	gf2x_mul_5_avx(temp, q_10+698, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+698, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+474, 10, q_10+474, 10, temp);
	gf2x_mul_5_avx(temp, q_10+693, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+693, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+469, 10, q_10+469, 10, temp);
	gf2x_mul_5_avx(temp, q_10+688, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+688, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+464, 10, q_10+464, 10, temp);
	gf2x_mul_5_avx(temp, q_10+683, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+683, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+459, 10, q_10+459, 10, temp);
	gf2x_mul_5_avx(temp, q_10+678, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+678, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+454, 10, q_10+454, 10, temp);
	gf2x_mul_5_avx(temp, q_10+673, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+673, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+449, 10, q_10+449, 10, temp);
	gf2x_mul_5_avx(temp, q_10+668, p_00+671);
	gf2x_mul_5_avx(temp2, q_11+668, p_10+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+444, 10, q_10+444, 10, temp);
	gf2x_mul_2_avx(temp, p_00+674, q_10+666);
	gf2x_mul_2_avx(temp2, p_10+674, q_11+666);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+445, 4, q_10+445, 4, temp);
	gf2x_mul_2_avx(temp, p_00+672, q_10+666);
	gf2x_mul_2_avx(temp2, p_10+672, q_11+666);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+443, 4, q_10+443, 4, temp);
	gf2x_mul_1_avx(temp, q_10+667, p_00+671);
	gf2x_mul_1_avx(temp2, q_11+667, p_10+671);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+443, 2, q_10+443, 2, temp);
	gf2x_mul_1_avx(temp, q_10+666, p_00+671);
	gf2x_mul_1_avx(temp2, q_11+666, p_10+671);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+442, 2, q_10+442, 2, temp);
	memset(q_11+442, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(214, temp, 107, p_01+676, 107, q_10+666);
	GF2X_MUL(214, temp2, 107, p_11+676, 107, q_11+666);
	gf2x_add(214, q_11+447, 214, temp, 214, temp2);
	gf2x_mul_5_avx(temp, q_10+768, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+768, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+544, 10, q_11+544, 10, temp);
	gf2x_mul_5_avx(temp, q_10+763, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+763, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+539, 10, q_11+539, 10, temp);
	gf2x_mul_5_avx(temp, q_10+758, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+758, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+534, 10, q_11+534, 10, temp);
	gf2x_mul_5_avx(temp, q_10+753, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+753, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+529, 10, q_11+529, 10, temp);
	gf2x_mul_5_avx(temp, q_10+748, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+748, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+524, 10, q_11+524, 10, temp);
	gf2x_mul_5_avx(temp, q_10+743, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+743, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+519, 10, q_11+519, 10, temp);
	gf2x_mul_5_avx(temp, q_10+738, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+738, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+514, 10, q_11+514, 10, temp);
	gf2x_mul_5_avx(temp, q_10+733, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+733, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+509, 10, q_11+509, 10, temp);
	gf2x_mul_5_avx(temp, q_10+728, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+728, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+504, 10, q_11+504, 10, temp);
	gf2x_mul_5_avx(temp, q_10+723, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+723, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+499, 10, q_11+499, 10, temp);
	gf2x_mul_5_avx(temp, q_10+718, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+718, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+494, 10, q_11+494, 10, temp);
	gf2x_mul_5_avx(temp, q_10+713, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+713, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+489, 10, q_11+489, 10, temp);
	gf2x_mul_5_avx(temp, q_10+708, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+708, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+484, 10, q_11+484, 10, temp);
	gf2x_mul_5_avx(temp, q_10+703, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+703, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+479, 10, q_11+479, 10, temp);
	gf2x_mul_5_avx(temp, q_10+698, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+698, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+474, 10, q_11+474, 10, temp);
	gf2x_mul_5_avx(temp, q_10+693, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+693, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+469, 10, q_11+469, 10, temp);
	gf2x_mul_5_avx(temp, q_10+688, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+688, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+464, 10, q_11+464, 10, temp);
	gf2x_mul_5_avx(temp, q_10+683, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+683, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+459, 10, q_11+459, 10, temp);
	gf2x_mul_5_avx(temp, q_10+678, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+678, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+454, 10, q_11+454, 10, temp);
	gf2x_mul_5_avx(temp, q_10+673, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+673, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+449, 10, q_11+449, 10, temp);
	gf2x_mul_5_avx(temp, q_10+668, p_01+671);
	gf2x_mul_5_avx(temp2, q_11+668, p_11+671);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+444, 10, q_11+444, 10, temp);
	gf2x_mul_2_avx(temp, p_01+674, q_10+666);
	gf2x_mul_2_avx(temp2, p_11+674, q_11+666);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+445, 4, q_11+445, 4, temp);
	gf2x_mul_2_avx(temp, p_01+672, q_10+666);
	gf2x_mul_2_avx(temp2, p_11+672, q_11+666);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+443, 4, q_11+443, 4, temp);
	gf2x_mul_1_avx(temp, q_10+667, p_01+671);
	gf2x_mul_1_avx(temp2, q_11+667, p_11+671);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+443, 2, q_11+443, 2, temp);
	gf2x_mul_1_avx(temp, q_10+666, p_01+671);
	gf2x_mul_1_avx(temp2, q_11+666, p_11+671);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+442, 2, q_11+442, 2, temp);
	
	// Recombining results: n: 28261, depth: 1
	memset(q_00+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(438, temp, 219, p_00+452, 219, q_00+442);
	GF2X_MUL(438, temp2, 219, p_10+452, 219, q_01+442);
	gf2x_add(438, q_00+4, 438, temp, 438, temp2);
	gf2x_mul_5_avx(temp, q_00+656, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+656, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+213, 10, q_00+213, 10, temp);
	gf2x_mul_5_avx(temp, q_00+651, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+651, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+208, 10, q_00+208, 10, temp);
	gf2x_mul_5_avx(temp, q_00+646, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+646, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+203, 10, q_00+203, 10, temp);
	gf2x_mul_5_avx(temp, q_00+641, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+641, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+198, 10, q_00+198, 10, temp);
	gf2x_mul_5_avx(temp, q_00+636, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+636, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+193, 10, q_00+193, 10, temp);
	gf2x_mul_5_avx(temp, q_00+631, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+631, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+188, 10, q_00+188, 10, temp);
	gf2x_mul_5_avx(temp, q_00+626, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+626, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+183, 10, q_00+183, 10, temp);
	gf2x_mul_5_avx(temp, q_00+621, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+621, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+178, 10, q_00+178, 10, temp);
	gf2x_mul_5_avx(temp, q_00+616, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+616, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+173, 10, q_00+173, 10, temp);
	gf2x_mul_5_avx(temp, q_00+611, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+611, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+168, 10, q_00+168, 10, temp);
	gf2x_mul_5_avx(temp, q_00+606, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+606, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+163, 10, q_00+163, 10, temp);
	gf2x_mul_5_avx(temp, q_00+601, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+601, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+158, 10, q_00+158, 10, temp);
	gf2x_mul_5_avx(temp, q_00+596, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+596, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+153, 10, q_00+153, 10, temp);
	gf2x_mul_5_avx(temp, q_00+591, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+591, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+148, 10, q_00+148, 10, temp);
	gf2x_mul_5_avx(temp, q_00+586, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+586, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+143, 10, q_00+143, 10, temp);
	gf2x_mul_5_avx(temp, q_00+581, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+581, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+138, 10, q_00+138, 10, temp);
	gf2x_mul_5_avx(temp, q_00+576, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+576, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+133, 10, q_00+133, 10, temp);
	gf2x_mul_5_avx(temp, q_00+571, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+571, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+128, 10, q_00+128, 10, temp);
	gf2x_mul_5_avx(temp, q_00+566, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+566, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+123, 10, q_00+123, 10, temp);
	gf2x_mul_5_avx(temp, q_00+561, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+561, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+118, 10, q_00+118, 10, temp);
	gf2x_mul_5_avx(temp, q_00+556, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+556, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+113, 10, q_00+113, 10, temp);
	gf2x_mul_5_avx(temp, q_00+551, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+551, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+108, 10, q_00+108, 10, temp);
	gf2x_mul_5_avx(temp, q_00+546, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+546, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+103, 10, q_00+103, 10, temp);
	gf2x_mul_5_avx(temp, q_00+541, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+541, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+98, 10, q_00+98, 10, temp);
	gf2x_mul_5_avx(temp, q_00+536, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+536, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+93, 10, q_00+93, 10, temp);
	gf2x_mul_5_avx(temp, q_00+531, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+531, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+88, 10, q_00+88, 10, temp);
	gf2x_mul_5_avx(temp, q_00+526, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+526, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+83, 10, q_00+83, 10, temp);
	gf2x_mul_5_avx(temp, q_00+521, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+521, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+78, 10, q_00+78, 10, temp);
	gf2x_mul_5_avx(temp, q_00+516, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+516, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+73, 10, q_00+73, 10, temp);
	gf2x_mul_5_avx(temp, q_00+511, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+511, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+68, 10, q_00+68, 10, temp);
	gf2x_mul_5_avx(temp, q_00+506, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+506, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+63, 10, q_00+63, 10, temp);
	gf2x_mul_5_avx(temp, q_00+501, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+501, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+58, 10, q_00+58, 10, temp);
	gf2x_mul_5_avx(temp, q_00+496, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+496, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+53, 10, q_00+53, 10, temp);
	gf2x_mul_5_avx(temp, q_00+491, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+491, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+48, 10, q_00+48, 10, temp);
	gf2x_mul_5_avx(temp, q_00+486, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+486, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+43, 10, q_00+43, 10, temp);
	gf2x_mul_5_avx(temp, q_00+481, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+481, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+38, 10, q_00+38, 10, temp);
	gf2x_mul_5_avx(temp, q_00+476, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+476, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+33, 10, q_00+33, 10, temp);
	gf2x_mul_5_avx(temp, q_00+471, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+471, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+28, 10, q_00+28, 10, temp);
	gf2x_mul_5_avx(temp, q_00+466, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+466, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+23, 10, q_00+23, 10, temp);
	gf2x_mul_5_avx(temp, q_00+461, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+461, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+18, 10, q_00+18, 10, temp);
	gf2x_mul_5_avx(temp, q_00+456, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+456, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+13, 10, q_00+13, 10, temp);
	gf2x_mul_5_avx(temp, q_00+451, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+451, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+8, 10, q_00+8, 10, temp);
	gf2x_mul_5_avx(temp, q_00+446, p_00+447);
	gf2x_mul_5_avx(temp2, q_01+446, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+3, 10, q_00+3, 10, temp);
	gf2x_mul_4_avx(temp, p_00+448, q_00+442);
	gf2x_mul_4_avx(temp2, p_10+448, q_01+442);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+0, 8, q_00+0, 8, temp);
	gf2x_mul_1_avx(temp, q_00+445, p_00+447);
	gf2x_mul_1_avx(temp2, q_01+445, p_10+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+2, 2, q_00+2, 2, temp);
	gf2x_mul_1_avx(temp, q_00+444, p_00+447);
	gf2x_mul_1_avx(temp2, q_01+444, p_10+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1, 2, q_00+1, 2, temp);
	gf2x_mul_1_avx(temp, q_00+443, p_00+447);
	gf2x_mul_1_avx(temp2, q_01+443, p_10+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+0, 2, q_00+0, 2, temp);
	gf2x_mul_1_avx(temp, q_00+442, p_00+447);
	gf2x_mul_1_avx(temp2, q_01+442, p_10+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, q_00+0, 1, q_00+0, 1, temp+1);
	memset(q_01+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(438, temp, 219, p_01+452, 219, q_00+442);
	GF2X_MUL(438, temp2, 219, p_11+452, 219, q_01+442);
	gf2x_add(438, q_01+4, 438, temp, 438, temp2);
	gf2x_mul_5_avx(temp, q_00+656, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+656, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+213, 10, q_01+213, 10, temp);
	gf2x_mul_5_avx(temp, q_00+651, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+651, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+208, 10, q_01+208, 10, temp);
	gf2x_mul_5_avx(temp, q_00+646, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+646, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+203, 10, q_01+203, 10, temp);
	gf2x_mul_5_avx(temp, q_00+641, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+641, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+198, 10, q_01+198, 10, temp);
	gf2x_mul_5_avx(temp, q_00+636, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+636, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+193, 10, q_01+193, 10, temp);
	gf2x_mul_5_avx(temp, q_00+631, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+631, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+188, 10, q_01+188, 10, temp);
	gf2x_mul_5_avx(temp, q_00+626, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+626, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+183, 10, q_01+183, 10, temp);
	gf2x_mul_5_avx(temp, q_00+621, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+621, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+178, 10, q_01+178, 10, temp);
	gf2x_mul_5_avx(temp, q_00+616, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+616, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+173, 10, q_01+173, 10, temp);
	gf2x_mul_5_avx(temp, q_00+611, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+611, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+168, 10, q_01+168, 10, temp);
	gf2x_mul_5_avx(temp, q_00+606, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+606, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+163, 10, q_01+163, 10, temp);
	gf2x_mul_5_avx(temp, q_00+601, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+601, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+158, 10, q_01+158, 10, temp);
	gf2x_mul_5_avx(temp, q_00+596, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+596, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+153, 10, q_01+153, 10, temp);
	gf2x_mul_5_avx(temp, q_00+591, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+591, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+148, 10, q_01+148, 10, temp);
	gf2x_mul_5_avx(temp, q_00+586, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+586, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+143, 10, q_01+143, 10, temp);
	gf2x_mul_5_avx(temp, q_00+581, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+581, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+138, 10, q_01+138, 10, temp);
	gf2x_mul_5_avx(temp, q_00+576, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+576, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+133, 10, q_01+133, 10, temp);
	gf2x_mul_5_avx(temp, q_00+571, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+571, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+128, 10, q_01+128, 10, temp);
	gf2x_mul_5_avx(temp, q_00+566, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+566, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+123, 10, q_01+123, 10, temp);
	gf2x_mul_5_avx(temp, q_00+561, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+561, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+118, 10, q_01+118, 10, temp);
	gf2x_mul_5_avx(temp, q_00+556, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+556, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+113, 10, q_01+113, 10, temp);
	gf2x_mul_5_avx(temp, q_00+551, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+551, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+108, 10, q_01+108, 10, temp);
	gf2x_mul_5_avx(temp, q_00+546, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+546, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+103, 10, q_01+103, 10, temp);
	gf2x_mul_5_avx(temp, q_00+541, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+541, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+98, 10, q_01+98, 10, temp);
	gf2x_mul_5_avx(temp, q_00+536, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+536, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+93, 10, q_01+93, 10, temp);
	gf2x_mul_5_avx(temp, q_00+531, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+531, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+88, 10, q_01+88, 10, temp);
	gf2x_mul_5_avx(temp, q_00+526, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+526, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+83, 10, q_01+83, 10, temp);
	gf2x_mul_5_avx(temp, q_00+521, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+521, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+78, 10, q_01+78, 10, temp);
	gf2x_mul_5_avx(temp, q_00+516, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+516, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+73, 10, q_01+73, 10, temp);
	gf2x_mul_5_avx(temp, q_00+511, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+511, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+68, 10, q_01+68, 10, temp);
	gf2x_mul_5_avx(temp, q_00+506, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+506, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+63, 10, q_01+63, 10, temp);
	gf2x_mul_5_avx(temp, q_00+501, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+501, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+58, 10, q_01+58, 10, temp);
	gf2x_mul_5_avx(temp, q_00+496, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+496, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+53, 10, q_01+53, 10, temp);
	gf2x_mul_5_avx(temp, q_00+491, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+491, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+48, 10, q_01+48, 10, temp);
	gf2x_mul_5_avx(temp, q_00+486, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+486, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+43, 10, q_01+43, 10, temp);
	gf2x_mul_5_avx(temp, q_00+481, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+481, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+38, 10, q_01+38, 10, temp);
	gf2x_mul_5_avx(temp, q_00+476, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+476, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+33, 10, q_01+33, 10, temp);
	gf2x_mul_5_avx(temp, q_00+471, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+471, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+28, 10, q_01+28, 10, temp);
	gf2x_mul_5_avx(temp, q_00+466, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+466, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+23, 10, q_01+23, 10, temp);
	gf2x_mul_5_avx(temp, q_00+461, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+461, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+18, 10, q_01+18, 10, temp);
	gf2x_mul_5_avx(temp, q_00+456, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+456, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+13, 10, q_01+13, 10, temp);
	gf2x_mul_5_avx(temp, q_00+451, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+451, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+8, 10, q_01+8, 10, temp);
	gf2x_mul_5_avx(temp, q_00+446, p_01+447);
	gf2x_mul_5_avx(temp2, q_01+446, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+3, 10, q_01+3, 10, temp);
	gf2x_mul_4_avx(temp, p_01+448, q_00+442);
	gf2x_mul_4_avx(temp2, p_11+448, q_01+442);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+0, 8, q_01+0, 8, temp);
	gf2x_mul_1_avx(temp, q_00+445, p_01+447);
	gf2x_mul_1_avx(temp2, q_01+445, p_11+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+2, 2, q_01+2, 2, temp);
	gf2x_mul_1_avx(temp, q_00+444, p_01+447);
	gf2x_mul_1_avx(temp2, q_01+444, p_11+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1, 2, q_01+1, 2, temp);
	gf2x_mul_1_avx(temp, q_00+443, p_01+447);
	gf2x_mul_1_avx(temp2, q_01+443, p_11+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+0, 2, q_01+0, 2, temp);
	gf2x_mul_1_avx(temp, q_00+442, p_01+447);
	gf2x_mul_1_avx(temp2, q_01+442, p_11+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, q_01+0, 1, q_01+0, 1, temp+1);
	memset(q_10+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(438, temp, 219, p_00+452, 219, q_10+442);
	GF2X_MUL(438, temp2, 219, p_10+452, 219, q_11+442);
	gf2x_add(438, q_10+4, 438, temp, 438, temp2);
	gf2x_mul_5_avx(temp, q_10+656, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+656, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+213, 10, q_10+213, 10, temp);
	gf2x_mul_5_avx(temp, q_10+651, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+651, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+208, 10, q_10+208, 10, temp);
	gf2x_mul_5_avx(temp, q_10+646, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+646, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+203, 10, q_10+203, 10, temp);
	gf2x_mul_5_avx(temp, q_10+641, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+641, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+198, 10, q_10+198, 10, temp);
	gf2x_mul_5_avx(temp, q_10+636, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+636, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+193, 10, q_10+193, 10, temp);
	gf2x_mul_5_avx(temp, q_10+631, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+631, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+188, 10, q_10+188, 10, temp);
	gf2x_mul_5_avx(temp, q_10+626, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+626, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+183, 10, q_10+183, 10, temp);
	gf2x_mul_5_avx(temp, q_10+621, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+621, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+178, 10, q_10+178, 10, temp);
	gf2x_mul_5_avx(temp, q_10+616, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+616, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+173, 10, q_10+173, 10, temp);
	gf2x_mul_5_avx(temp, q_10+611, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+611, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+168, 10, q_10+168, 10, temp);
	gf2x_mul_5_avx(temp, q_10+606, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+606, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+163, 10, q_10+163, 10, temp);
	gf2x_mul_5_avx(temp, q_10+601, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+601, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+158, 10, q_10+158, 10, temp);
	gf2x_mul_5_avx(temp, q_10+596, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+596, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+153, 10, q_10+153, 10, temp);
	gf2x_mul_5_avx(temp, q_10+591, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+591, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+148, 10, q_10+148, 10, temp);
	gf2x_mul_5_avx(temp, q_10+586, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+586, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+143, 10, q_10+143, 10, temp);
	gf2x_mul_5_avx(temp, q_10+581, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+581, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+138, 10, q_10+138, 10, temp);
	gf2x_mul_5_avx(temp, q_10+576, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+576, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+133, 10, q_10+133, 10, temp);
	gf2x_mul_5_avx(temp, q_10+571, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+571, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+128, 10, q_10+128, 10, temp);
	gf2x_mul_5_avx(temp, q_10+566, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+566, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+123, 10, q_10+123, 10, temp);
	gf2x_mul_5_avx(temp, q_10+561, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+561, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+118, 10, q_10+118, 10, temp);
	gf2x_mul_5_avx(temp, q_10+556, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+556, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+113, 10, q_10+113, 10, temp);
	gf2x_mul_5_avx(temp, q_10+551, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+551, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+108, 10, q_10+108, 10, temp);
	gf2x_mul_5_avx(temp, q_10+546, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+546, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+103, 10, q_10+103, 10, temp);
	gf2x_mul_5_avx(temp, q_10+541, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+541, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+98, 10, q_10+98, 10, temp);
	gf2x_mul_5_avx(temp, q_10+536, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+536, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+93, 10, q_10+93, 10, temp);
	gf2x_mul_5_avx(temp, q_10+531, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+531, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+88, 10, q_10+88, 10, temp);
	gf2x_mul_5_avx(temp, q_10+526, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+526, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+83, 10, q_10+83, 10, temp);
	gf2x_mul_5_avx(temp, q_10+521, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+521, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+78, 10, q_10+78, 10, temp);
	gf2x_mul_5_avx(temp, q_10+516, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+516, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+73, 10, q_10+73, 10, temp);
	gf2x_mul_5_avx(temp, q_10+511, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+511, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+68, 10, q_10+68, 10, temp);
	gf2x_mul_5_avx(temp, q_10+506, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+506, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+63, 10, q_10+63, 10, temp);
	gf2x_mul_5_avx(temp, q_10+501, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+501, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+58, 10, q_10+58, 10, temp);
	gf2x_mul_5_avx(temp, q_10+496, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+496, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+53, 10, q_10+53, 10, temp);
	gf2x_mul_5_avx(temp, q_10+491, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+491, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+48, 10, q_10+48, 10, temp);
	gf2x_mul_5_avx(temp, q_10+486, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+486, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+43, 10, q_10+43, 10, temp);
	gf2x_mul_5_avx(temp, q_10+481, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+481, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+38, 10, q_10+38, 10, temp);
	gf2x_mul_5_avx(temp, q_10+476, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+476, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+33, 10, q_10+33, 10, temp);
	gf2x_mul_5_avx(temp, q_10+471, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+471, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+28, 10, q_10+28, 10, temp);
	gf2x_mul_5_avx(temp, q_10+466, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+466, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+23, 10, q_10+23, 10, temp);
	gf2x_mul_5_avx(temp, q_10+461, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+461, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+18, 10, q_10+18, 10, temp);
	gf2x_mul_5_avx(temp, q_10+456, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+456, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+13, 10, q_10+13, 10, temp);
	gf2x_mul_5_avx(temp, q_10+451, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+451, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+8, 10, q_10+8, 10, temp);
	gf2x_mul_5_avx(temp, q_10+446, p_00+447);
	gf2x_mul_5_avx(temp2, q_11+446, p_10+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+3, 10, q_10+3, 10, temp);
	gf2x_mul_4_avx(temp, p_00+448, q_10+442);
	gf2x_mul_4_avx(temp2, p_10+448, q_11+442);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+0, 8, q_10+0, 8, temp);
	gf2x_mul_1_avx(temp, q_10+445, p_00+447);
	gf2x_mul_1_avx(temp2, q_11+445, p_10+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+2, 2, q_10+2, 2, temp);
	gf2x_mul_1_avx(temp, q_10+444, p_00+447);
	gf2x_mul_1_avx(temp2, q_11+444, p_10+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1, 2, q_10+1, 2, temp);
	gf2x_mul_1_avx(temp, q_10+443, p_00+447);
	gf2x_mul_1_avx(temp2, q_11+443, p_10+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+0, 2, q_10+0, 2, temp);
	gf2x_mul_1_avx(temp, q_10+442, p_00+447);
	gf2x_mul_1_avx(temp2, q_11+442, p_10+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, q_10+0, 1, q_10+0, 1, temp+1);
	memset(q_11+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(438, temp, 219, p_01+452, 219, q_10+442);
	GF2X_MUL(438, temp2, 219, p_11+452, 219, q_11+442);
	gf2x_add(438, q_11+4, 438, temp, 438, temp2);
	gf2x_mul_5_avx(temp, q_10+656, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+656, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+213, 10, q_11+213, 10, temp);
	gf2x_mul_5_avx(temp, q_10+651, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+651, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+208, 10, q_11+208, 10, temp);
	gf2x_mul_5_avx(temp, q_10+646, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+646, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+203, 10, q_11+203, 10, temp);
	gf2x_mul_5_avx(temp, q_10+641, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+641, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+198, 10, q_11+198, 10, temp);
	gf2x_mul_5_avx(temp, q_10+636, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+636, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+193, 10, q_11+193, 10, temp);
	gf2x_mul_5_avx(temp, q_10+631, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+631, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+188, 10, q_11+188, 10, temp);
	gf2x_mul_5_avx(temp, q_10+626, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+626, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+183, 10, q_11+183, 10, temp);
	gf2x_mul_5_avx(temp, q_10+621, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+621, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+178, 10, q_11+178, 10, temp);
	gf2x_mul_5_avx(temp, q_10+616, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+616, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+173, 10, q_11+173, 10, temp);
	gf2x_mul_5_avx(temp, q_10+611, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+611, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+168, 10, q_11+168, 10, temp);
	gf2x_mul_5_avx(temp, q_10+606, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+606, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+163, 10, q_11+163, 10, temp);
	gf2x_mul_5_avx(temp, q_10+601, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+601, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+158, 10, q_11+158, 10, temp);
	gf2x_mul_5_avx(temp, q_10+596, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+596, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+153, 10, q_11+153, 10, temp);
	gf2x_mul_5_avx(temp, q_10+591, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+591, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+148, 10, q_11+148, 10, temp);
	gf2x_mul_5_avx(temp, q_10+586, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+586, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+143, 10, q_11+143, 10, temp);
	gf2x_mul_5_avx(temp, q_10+581, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+581, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+138, 10, q_11+138, 10, temp);
	gf2x_mul_5_avx(temp, q_10+576, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+576, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+133, 10, q_11+133, 10, temp);
	gf2x_mul_5_avx(temp, q_10+571, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+571, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+128, 10, q_11+128, 10, temp);
	gf2x_mul_5_avx(temp, q_10+566, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+566, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+123, 10, q_11+123, 10, temp);
	gf2x_mul_5_avx(temp, q_10+561, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+561, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+118, 10, q_11+118, 10, temp);
	gf2x_mul_5_avx(temp, q_10+556, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+556, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+113, 10, q_11+113, 10, temp);
	gf2x_mul_5_avx(temp, q_10+551, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+551, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+108, 10, q_11+108, 10, temp);
	gf2x_mul_5_avx(temp, q_10+546, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+546, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+103, 10, q_11+103, 10, temp);
	gf2x_mul_5_avx(temp, q_10+541, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+541, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+98, 10, q_11+98, 10, temp);
	gf2x_mul_5_avx(temp, q_10+536, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+536, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+93, 10, q_11+93, 10, temp);
	gf2x_mul_5_avx(temp, q_10+531, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+531, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+88, 10, q_11+88, 10, temp);
	gf2x_mul_5_avx(temp, q_10+526, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+526, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+83, 10, q_11+83, 10, temp);
	gf2x_mul_5_avx(temp, q_10+521, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+521, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+78, 10, q_11+78, 10, temp);
	gf2x_mul_5_avx(temp, q_10+516, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+516, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+73, 10, q_11+73, 10, temp);
	gf2x_mul_5_avx(temp, q_10+511, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+511, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+68, 10, q_11+68, 10, temp);
	gf2x_mul_5_avx(temp, q_10+506, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+506, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+63, 10, q_11+63, 10, temp);
	gf2x_mul_5_avx(temp, q_10+501, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+501, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+58, 10, q_11+58, 10, temp);
	gf2x_mul_5_avx(temp, q_10+496, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+496, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+53, 10, q_11+53, 10, temp);
	gf2x_mul_5_avx(temp, q_10+491, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+491, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+48, 10, q_11+48, 10, temp);
	gf2x_mul_5_avx(temp, q_10+486, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+486, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+43, 10, q_11+43, 10, temp);
	gf2x_mul_5_avx(temp, q_10+481, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+481, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+38, 10, q_11+38, 10, temp);
	gf2x_mul_5_avx(temp, q_10+476, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+476, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+33, 10, q_11+33, 10, temp);
	gf2x_mul_5_avx(temp, q_10+471, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+471, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+28, 10, q_11+28, 10, temp);
	gf2x_mul_5_avx(temp, q_10+466, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+466, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+23, 10, q_11+23, 10, temp);
	gf2x_mul_5_avx(temp, q_10+461, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+461, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+18, 10, q_11+18, 10, temp);
	gf2x_mul_5_avx(temp, q_10+456, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+456, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+13, 10, q_11+13, 10, temp);
	gf2x_mul_5_avx(temp, q_10+451, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+451, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+8, 10, q_11+8, 10, temp);
	gf2x_mul_5_avx(temp, q_10+446, p_01+447);
	gf2x_mul_5_avx(temp2, q_11+446, p_11+447);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+3, 10, q_11+3, 10, temp);
	gf2x_mul_4_avx(temp, p_01+448, q_10+442);
	gf2x_mul_4_avx(temp2, p_11+448, q_11+442);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+0, 8, q_11+0, 8, temp);
	gf2x_mul_1_avx(temp, q_10+445, p_01+447);
	gf2x_mul_1_avx(temp2, q_11+445, p_11+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+2, 2, q_11+2, 2, temp);
	gf2x_mul_1_avx(temp, q_10+444, p_01+447);
	gf2x_mul_1_avx(temp2, q_11+444, p_11+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1, 2, q_11+1, 2, temp);
	gf2x_mul_1_avx(temp, q_10+443, p_01+447);
	gf2x_mul_1_avx(temp2, q_11+443, p_11+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+0, 2, q_11+0, 2, temp);
	gf2x_mul_1_avx(temp, q_10+442, p_01+447);
	gf2x_mul_1_avx(temp2, q_11+442, p_11+447);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, q_11+0, 1, q_11+0, 1, temp+1);
	
	// Recombining results: n: 56821, depth: 0
	memset(t_00+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(884, temp, 442, p_00+5, 442, q_00+0);
	GF2X_MUL(884, temp2, 442, p_10+5, 442, q_01+0);
	gf2x_add(884, t_00+4, 884, temp, 884, temp2);
	gf2x_mul_5_avx(temp, q_00+437, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+437, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+436, 10, t_00+436, 10, temp);
	gf2x_mul_5_avx(temp, q_00+432, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+432, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+431, 10, t_00+431, 10, temp);
	gf2x_mul_5_avx(temp, q_00+427, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+427, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+426, 10, t_00+426, 10, temp);
	gf2x_mul_5_avx(temp, q_00+422, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+422, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+421, 10, t_00+421, 10, temp);
	gf2x_mul_5_avx(temp, q_00+417, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+417, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+416, 10, t_00+416, 10, temp);
	gf2x_mul_5_avx(temp, q_00+412, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+412, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+411, 10, t_00+411, 10, temp);
	gf2x_mul_5_avx(temp, q_00+407, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+407, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+406, 10, t_00+406, 10, temp);
	gf2x_mul_5_avx(temp, q_00+402, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+402, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+401, 10, t_00+401, 10, temp);
	gf2x_mul_5_avx(temp, q_00+397, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+397, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+396, 10, t_00+396, 10, temp);
	gf2x_mul_5_avx(temp, q_00+392, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+392, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+391, 10, t_00+391, 10, temp);
	gf2x_mul_5_avx(temp, q_00+387, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+387, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+386, 10, t_00+386, 10, temp);
	gf2x_mul_5_avx(temp, q_00+382, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+382, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+381, 10, t_00+381, 10, temp);
	gf2x_mul_5_avx(temp, q_00+377, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+377, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+376, 10, t_00+376, 10, temp);
	gf2x_mul_5_avx(temp, q_00+372, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+372, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+371, 10, t_00+371, 10, temp);
	gf2x_mul_5_avx(temp, q_00+367, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+367, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+366, 10, t_00+366, 10, temp);
	gf2x_mul_5_avx(temp, q_00+362, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+362, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+361, 10, t_00+361, 10, temp);
	gf2x_mul_5_avx(temp, q_00+357, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+357, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+356, 10, t_00+356, 10, temp);
	gf2x_mul_5_avx(temp, q_00+352, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+352, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+351, 10, t_00+351, 10, temp);
	gf2x_mul_5_avx(temp, q_00+347, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+347, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+346, 10, t_00+346, 10, temp);
	gf2x_mul_5_avx(temp, q_00+342, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+342, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+341, 10, t_00+341, 10, temp);
	gf2x_mul_5_avx(temp, q_00+337, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+337, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+336, 10, t_00+336, 10, temp);
	gf2x_mul_5_avx(temp, q_00+332, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+332, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+331, 10, t_00+331, 10, temp);
	gf2x_mul_5_avx(temp, q_00+327, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+327, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+326, 10, t_00+326, 10, temp);
	gf2x_mul_5_avx(temp, q_00+322, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+322, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+321, 10, t_00+321, 10, temp);
	gf2x_mul_5_avx(temp, q_00+317, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+317, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+316, 10, t_00+316, 10, temp);
	gf2x_mul_5_avx(temp, q_00+312, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+312, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+311, 10, t_00+311, 10, temp);
	gf2x_mul_5_avx(temp, q_00+307, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+307, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+306, 10, t_00+306, 10, temp);
	gf2x_mul_5_avx(temp, q_00+302, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+302, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+301, 10, t_00+301, 10, temp);
	gf2x_mul_5_avx(temp, q_00+297, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+297, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+296, 10, t_00+296, 10, temp);
	gf2x_mul_5_avx(temp, q_00+292, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+292, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+291, 10, t_00+291, 10, temp);
	gf2x_mul_5_avx(temp, q_00+287, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+287, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+286, 10, t_00+286, 10, temp);
	gf2x_mul_5_avx(temp, q_00+282, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+282, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+281, 10, t_00+281, 10, temp);
	gf2x_mul_5_avx(temp, q_00+277, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+277, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+276, 10, t_00+276, 10, temp);
	gf2x_mul_5_avx(temp, q_00+272, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+272, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+271, 10, t_00+271, 10, temp);
	gf2x_mul_5_avx(temp, q_00+267, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+267, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+266, 10, t_00+266, 10, temp);
	gf2x_mul_5_avx(temp, q_00+262, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+262, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+261, 10, t_00+261, 10, temp);
	gf2x_mul_5_avx(temp, q_00+257, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+257, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+256, 10, t_00+256, 10, temp);
	gf2x_mul_5_avx(temp, q_00+252, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+252, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+251, 10, t_00+251, 10, temp);
	gf2x_mul_5_avx(temp, q_00+247, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+247, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+246, 10, t_00+246, 10, temp);
	gf2x_mul_5_avx(temp, q_00+242, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+242, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+241, 10, t_00+241, 10, temp);
	gf2x_mul_5_avx(temp, q_00+237, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+237, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+236, 10, t_00+236, 10, temp);
	gf2x_mul_5_avx(temp, q_00+232, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+232, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+231, 10, t_00+231, 10, temp);
	gf2x_mul_5_avx(temp, q_00+227, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+227, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+226, 10, t_00+226, 10, temp);
	gf2x_mul_5_avx(temp, q_00+222, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+222, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+221, 10, t_00+221, 10, temp);
	gf2x_mul_5_avx(temp, q_00+217, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+217, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+216, 10, t_00+216, 10, temp);
	gf2x_mul_5_avx(temp, q_00+212, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+212, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+211, 10, t_00+211, 10, temp);
	gf2x_mul_5_avx(temp, q_00+207, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+207, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+206, 10, t_00+206, 10, temp);
	gf2x_mul_5_avx(temp, q_00+202, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+202, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+201, 10, t_00+201, 10, temp);
	gf2x_mul_5_avx(temp, q_00+197, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+197, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+196, 10, t_00+196, 10, temp);
	gf2x_mul_5_avx(temp, q_00+192, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+192, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+191, 10, t_00+191, 10, temp);
	gf2x_mul_5_avx(temp, q_00+187, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+187, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+186, 10, t_00+186, 10, temp);
	gf2x_mul_5_avx(temp, q_00+182, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+182, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+181, 10, t_00+181, 10, temp);
	gf2x_mul_5_avx(temp, q_00+177, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+177, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+176, 10, t_00+176, 10, temp);
	gf2x_mul_5_avx(temp, q_00+172, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+172, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+171, 10, t_00+171, 10, temp);
	gf2x_mul_5_avx(temp, q_00+167, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+167, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+166, 10, t_00+166, 10, temp);
	gf2x_mul_5_avx(temp, q_00+162, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+162, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+161, 10, t_00+161, 10, temp);
	gf2x_mul_5_avx(temp, q_00+157, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+157, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+156, 10, t_00+156, 10, temp);
	gf2x_mul_5_avx(temp, q_00+152, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+152, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+151, 10, t_00+151, 10, temp);
	gf2x_mul_5_avx(temp, q_00+147, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+147, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+146, 10, t_00+146, 10, temp);
	gf2x_mul_5_avx(temp, q_00+142, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+142, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+141, 10, t_00+141, 10, temp);
	gf2x_mul_5_avx(temp, q_00+137, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+137, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+136, 10, t_00+136, 10, temp);
	gf2x_mul_5_avx(temp, q_00+132, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+132, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+131, 10, t_00+131, 10, temp);
	gf2x_mul_5_avx(temp, q_00+127, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+127, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+126, 10, t_00+126, 10, temp);
	gf2x_mul_5_avx(temp, q_00+122, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+122, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+121, 10, t_00+121, 10, temp);
	gf2x_mul_5_avx(temp, q_00+117, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+117, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+116, 10, t_00+116, 10, temp);
	gf2x_mul_5_avx(temp, q_00+112, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+112, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+111, 10, t_00+111, 10, temp);
	gf2x_mul_5_avx(temp, q_00+107, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+107, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+106, 10, t_00+106, 10, temp);
	gf2x_mul_5_avx(temp, q_00+102, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+102, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+101, 10, t_00+101, 10, temp);
	gf2x_mul_5_avx(temp, q_00+97, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+97, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+96, 10, t_00+96, 10, temp);
	gf2x_mul_5_avx(temp, q_00+92, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+92, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+91, 10, t_00+91, 10, temp);
	gf2x_mul_5_avx(temp, q_00+87, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+87, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+86, 10, t_00+86, 10, temp);
	gf2x_mul_5_avx(temp, q_00+82, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+82, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+81, 10, t_00+81, 10, temp);
	gf2x_mul_5_avx(temp, q_00+77, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+77, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+76, 10, t_00+76, 10, temp);
	gf2x_mul_5_avx(temp, q_00+72, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+72, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+71, 10, t_00+71, 10, temp);
	gf2x_mul_5_avx(temp, q_00+67, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+67, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+66, 10, t_00+66, 10, temp);
	gf2x_mul_5_avx(temp, q_00+62, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+62, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+61, 10, t_00+61, 10, temp);
	gf2x_mul_5_avx(temp, q_00+57, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+57, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+56, 10, t_00+56, 10, temp);
	gf2x_mul_5_avx(temp, q_00+52, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+52, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+51, 10, t_00+51, 10, temp);
	gf2x_mul_5_avx(temp, q_00+47, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+47, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+46, 10, t_00+46, 10, temp);
	gf2x_mul_5_avx(temp, q_00+42, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+42, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+41, 10, t_00+41, 10, temp);
	gf2x_mul_5_avx(temp, q_00+37, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+37, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+36, 10, t_00+36, 10, temp);
	gf2x_mul_5_avx(temp, q_00+32, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+32, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+31, 10, t_00+31, 10, temp);
	gf2x_mul_5_avx(temp, q_00+27, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+27, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+26, 10, t_00+26, 10, temp);
	gf2x_mul_5_avx(temp, q_00+22, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+22, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+21, 10, t_00+21, 10, temp);
	gf2x_mul_5_avx(temp, q_00+17, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+17, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+16, 10, t_00+16, 10, temp);
	gf2x_mul_5_avx(temp, q_00+12, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+12, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+11, 10, t_00+11, 10, temp);
	gf2x_mul_5_avx(temp, q_00+7, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+7, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+6, 10, t_00+6, 10, temp);
	gf2x_mul_5_avx(temp, q_00+2, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+2, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+1, 10, t_00+1, 10, temp);
	gf2x_mul_2_avx(temp, p_00+3, q_00+0);
	gf2x_mul_2_avx(temp2, p_10+3, q_01+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_00+2, 4, t_00+2, 4, temp);
	gf2x_mul_2_avx(temp, p_00+1, q_00+0);
	gf2x_mul_2_avx(temp2, p_10+1, q_01+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_00+0, 4, t_00+0, 4, temp);
	gf2x_mul_1_avx(temp, q_00+1, p_00+0);
	gf2x_mul_1_avx(temp2, q_01+1, p_10+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, t_00+0, 2, t_00+0, 2, temp);
	gf2x_mul_1_avx(temp, q_00+0, p_00+0);
	gf2x_mul_1_avx(temp2, q_01+0, p_10+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, t_00+0, 1, t_00+0, 1, temp+1);
	memset(t_01+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(884, temp, 442, p_01+5, 442, q_00+0);
	GF2X_MUL(884, temp2, 442, p_11+5, 442, q_01+0);
	gf2x_add(884, t_01+4, 884, temp, 884, temp2);
	gf2x_mul_5_avx(temp, q_00+437, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+437, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+436, 10, t_01+436, 10, temp);
	gf2x_mul_5_avx(temp, q_00+432, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+432, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+431, 10, t_01+431, 10, temp);
	gf2x_mul_5_avx(temp, q_00+427, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+427, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+426, 10, t_01+426, 10, temp);
	gf2x_mul_5_avx(temp, q_00+422, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+422, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+421, 10, t_01+421, 10, temp);
	gf2x_mul_5_avx(temp, q_00+417, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+417, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+416, 10, t_01+416, 10, temp);
	gf2x_mul_5_avx(temp, q_00+412, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+412, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+411, 10, t_01+411, 10, temp);
	gf2x_mul_5_avx(temp, q_00+407, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+407, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+406, 10, t_01+406, 10, temp);
	gf2x_mul_5_avx(temp, q_00+402, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+402, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+401, 10, t_01+401, 10, temp);
	gf2x_mul_5_avx(temp, q_00+397, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+397, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+396, 10, t_01+396, 10, temp);
	gf2x_mul_5_avx(temp, q_00+392, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+392, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+391, 10, t_01+391, 10, temp);
	gf2x_mul_5_avx(temp, q_00+387, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+387, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+386, 10, t_01+386, 10, temp);
	gf2x_mul_5_avx(temp, q_00+382, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+382, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+381, 10, t_01+381, 10, temp);
	gf2x_mul_5_avx(temp, q_00+377, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+377, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+376, 10, t_01+376, 10, temp);
	gf2x_mul_5_avx(temp, q_00+372, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+372, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+371, 10, t_01+371, 10, temp);
	gf2x_mul_5_avx(temp, q_00+367, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+367, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+366, 10, t_01+366, 10, temp);
	gf2x_mul_5_avx(temp, q_00+362, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+362, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+361, 10, t_01+361, 10, temp);
	gf2x_mul_5_avx(temp, q_00+357, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+357, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+356, 10, t_01+356, 10, temp);
	gf2x_mul_5_avx(temp, q_00+352, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+352, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+351, 10, t_01+351, 10, temp);
	gf2x_mul_5_avx(temp, q_00+347, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+347, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+346, 10, t_01+346, 10, temp);
	gf2x_mul_5_avx(temp, q_00+342, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+342, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+341, 10, t_01+341, 10, temp);
	gf2x_mul_5_avx(temp, q_00+337, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+337, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+336, 10, t_01+336, 10, temp);
	gf2x_mul_5_avx(temp, q_00+332, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+332, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+331, 10, t_01+331, 10, temp);
	gf2x_mul_5_avx(temp, q_00+327, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+327, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+326, 10, t_01+326, 10, temp);
	gf2x_mul_5_avx(temp, q_00+322, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+322, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+321, 10, t_01+321, 10, temp);
	gf2x_mul_5_avx(temp, q_00+317, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+317, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+316, 10, t_01+316, 10, temp);
	gf2x_mul_5_avx(temp, q_00+312, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+312, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+311, 10, t_01+311, 10, temp);
	gf2x_mul_5_avx(temp, q_00+307, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+307, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+306, 10, t_01+306, 10, temp);
	gf2x_mul_5_avx(temp, q_00+302, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+302, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+301, 10, t_01+301, 10, temp);
	gf2x_mul_5_avx(temp, q_00+297, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+297, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+296, 10, t_01+296, 10, temp);
	gf2x_mul_5_avx(temp, q_00+292, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+292, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+291, 10, t_01+291, 10, temp);
	gf2x_mul_5_avx(temp, q_00+287, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+287, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+286, 10, t_01+286, 10, temp);
	gf2x_mul_5_avx(temp, q_00+282, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+282, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+281, 10, t_01+281, 10, temp);
	gf2x_mul_5_avx(temp, q_00+277, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+277, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+276, 10, t_01+276, 10, temp);
	gf2x_mul_5_avx(temp, q_00+272, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+272, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+271, 10, t_01+271, 10, temp);
	gf2x_mul_5_avx(temp, q_00+267, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+267, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+266, 10, t_01+266, 10, temp);
	gf2x_mul_5_avx(temp, q_00+262, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+262, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+261, 10, t_01+261, 10, temp);
	gf2x_mul_5_avx(temp, q_00+257, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+257, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+256, 10, t_01+256, 10, temp);
	gf2x_mul_5_avx(temp, q_00+252, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+252, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+251, 10, t_01+251, 10, temp);
	gf2x_mul_5_avx(temp, q_00+247, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+247, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+246, 10, t_01+246, 10, temp);
	gf2x_mul_5_avx(temp, q_00+242, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+242, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+241, 10, t_01+241, 10, temp);
	gf2x_mul_5_avx(temp, q_00+237, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+237, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+236, 10, t_01+236, 10, temp);
	gf2x_mul_5_avx(temp, q_00+232, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+232, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+231, 10, t_01+231, 10, temp);
	gf2x_mul_5_avx(temp, q_00+227, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+227, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+226, 10, t_01+226, 10, temp);
	gf2x_mul_5_avx(temp, q_00+222, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+222, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+221, 10, t_01+221, 10, temp);
	gf2x_mul_5_avx(temp, q_00+217, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+217, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+216, 10, t_01+216, 10, temp);
	gf2x_mul_5_avx(temp, q_00+212, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+212, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+211, 10, t_01+211, 10, temp);
	gf2x_mul_5_avx(temp, q_00+207, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+207, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+206, 10, t_01+206, 10, temp);
	gf2x_mul_5_avx(temp, q_00+202, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+202, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+201, 10, t_01+201, 10, temp);
	gf2x_mul_5_avx(temp, q_00+197, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+197, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+196, 10, t_01+196, 10, temp);
	gf2x_mul_5_avx(temp, q_00+192, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+192, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+191, 10, t_01+191, 10, temp);
	gf2x_mul_5_avx(temp, q_00+187, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+187, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+186, 10, t_01+186, 10, temp);
	gf2x_mul_5_avx(temp, q_00+182, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+182, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+181, 10, t_01+181, 10, temp);
	gf2x_mul_5_avx(temp, q_00+177, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+177, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+176, 10, t_01+176, 10, temp);
	gf2x_mul_5_avx(temp, q_00+172, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+172, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+171, 10, t_01+171, 10, temp);
	gf2x_mul_5_avx(temp, q_00+167, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+167, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+166, 10, t_01+166, 10, temp);
	gf2x_mul_5_avx(temp, q_00+162, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+162, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+161, 10, t_01+161, 10, temp);
	gf2x_mul_5_avx(temp, q_00+157, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+157, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+156, 10, t_01+156, 10, temp);
	gf2x_mul_5_avx(temp, q_00+152, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+152, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+151, 10, t_01+151, 10, temp);
	gf2x_mul_5_avx(temp, q_00+147, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+147, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+146, 10, t_01+146, 10, temp);
	gf2x_mul_5_avx(temp, q_00+142, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+142, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+141, 10, t_01+141, 10, temp);
	gf2x_mul_5_avx(temp, q_00+137, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+137, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+136, 10, t_01+136, 10, temp);
	gf2x_mul_5_avx(temp, q_00+132, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+132, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+131, 10, t_01+131, 10, temp);
	gf2x_mul_5_avx(temp, q_00+127, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+127, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+126, 10, t_01+126, 10, temp);
	gf2x_mul_5_avx(temp, q_00+122, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+122, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+121, 10, t_01+121, 10, temp);
	gf2x_mul_5_avx(temp, q_00+117, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+117, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+116, 10, t_01+116, 10, temp);
	gf2x_mul_5_avx(temp, q_00+112, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+112, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+111, 10, t_01+111, 10, temp);
	gf2x_mul_5_avx(temp, q_00+107, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+107, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+106, 10, t_01+106, 10, temp);
	gf2x_mul_5_avx(temp, q_00+102, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+102, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+101, 10, t_01+101, 10, temp);
	gf2x_mul_5_avx(temp, q_00+97, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+97, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+96, 10, t_01+96, 10, temp);
	gf2x_mul_5_avx(temp, q_00+92, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+92, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+91, 10, t_01+91, 10, temp);
	gf2x_mul_5_avx(temp, q_00+87, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+87, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+86, 10, t_01+86, 10, temp);
	gf2x_mul_5_avx(temp, q_00+82, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+82, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+81, 10, t_01+81, 10, temp);
	gf2x_mul_5_avx(temp, q_00+77, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+77, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+76, 10, t_01+76, 10, temp);
	gf2x_mul_5_avx(temp, q_00+72, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+72, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+71, 10, t_01+71, 10, temp);
	gf2x_mul_5_avx(temp, q_00+67, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+67, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+66, 10, t_01+66, 10, temp);
	gf2x_mul_5_avx(temp, q_00+62, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+62, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+61, 10, t_01+61, 10, temp);
	gf2x_mul_5_avx(temp, q_00+57, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+57, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+56, 10, t_01+56, 10, temp);
	gf2x_mul_5_avx(temp, q_00+52, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+52, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+51, 10, t_01+51, 10, temp);
	gf2x_mul_5_avx(temp, q_00+47, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+47, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+46, 10, t_01+46, 10, temp);
	gf2x_mul_5_avx(temp, q_00+42, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+42, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+41, 10, t_01+41, 10, temp);
	gf2x_mul_5_avx(temp, q_00+37, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+37, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+36, 10, t_01+36, 10, temp);
	gf2x_mul_5_avx(temp, q_00+32, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+32, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+31, 10, t_01+31, 10, temp);
	gf2x_mul_5_avx(temp, q_00+27, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+27, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+26, 10, t_01+26, 10, temp);
	gf2x_mul_5_avx(temp, q_00+22, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+22, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+21, 10, t_01+21, 10, temp);
	gf2x_mul_5_avx(temp, q_00+17, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+17, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+16, 10, t_01+16, 10, temp);
	gf2x_mul_5_avx(temp, q_00+12, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+12, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+11, 10, t_01+11, 10, temp);
	gf2x_mul_5_avx(temp, q_00+7, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+7, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+6, 10, t_01+6, 10, temp);
	gf2x_mul_5_avx(temp, q_00+2, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+2, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+1, 10, t_01+1, 10, temp);
	gf2x_mul_2_avx(temp, p_01+3, q_00+0);
	gf2x_mul_2_avx(temp2, p_11+3, q_01+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_01+2, 4, t_01+2, 4, temp);
	gf2x_mul_2_avx(temp, p_01+1, q_00+0);
	gf2x_mul_2_avx(temp2, p_11+1, q_01+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_01+0, 4, t_01+0, 4, temp);
	gf2x_mul_1_avx(temp, q_00+1, p_01+0);
	gf2x_mul_1_avx(temp2, q_01+1, p_11+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, t_01+0, 2, t_01+0, 2, temp);
	gf2x_mul_1_avx(temp, q_00+0, p_01+0);
	gf2x_mul_1_avx(temp2, q_01+0, p_11+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, t_01+0, 1, t_01+0, 1, temp+1);
	memset(t_10+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(884, temp, 442, p_00+5, 442, q_10+0);
	GF2X_MUL(884, temp2, 442, p_10+5, 442, q_11+0);
	gf2x_add(884, t_10+4, 884, temp, 884, temp2);
	gf2x_mul_5_avx(temp, q_10+437, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+437, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+436, 10, t_10+436, 10, temp);
	gf2x_mul_5_avx(temp, q_10+432, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+432, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+431, 10, t_10+431, 10, temp);
	gf2x_mul_5_avx(temp, q_10+427, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+427, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+426, 10, t_10+426, 10, temp);
	gf2x_mul_5_avx(temp, q_10+422, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+422, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+421, 10, t_10+421, 10, temp);
	gf2x_mul_5_avx(temp, q_10+417, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+417, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+416, 10, t_10+416, 10, temp);
	gf2x_mul_5_avx(temp, q_10+412, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+412, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+411, 10, t_10+411, 10, temp);
	gf2x_mul_5_avx(temp, q_10+407, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+407, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+406, 10, t_10+406, 10, temp);
	gf2x_mul_5_avx(temp, q_10+402, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+402, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+401, 10, t_10+401, 10, temp);
	gf2x_mul_5_avx(temp, q_10+397, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+397, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+396, 10, t_10+396, 10, temp);
	gf2x_mul_5_avx(temp, q_10+392, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+392, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+391, 10, t_10+391, 10, temp);
	gf2x_mul_5_avx(temp, q_10+387, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+387, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+386, 10, t_10+386, 10, temp);
	gf2x_mul_5_avx(temp, q_10+382, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+382, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+381, 10, t_10+381, 10, temp);
	gf2x_mul_5_avx(temp, q_10+377, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+377, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+376, 10, t_10+376, 10, temp);
	gf2x_mul_5_avx(temp, q_10+372, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+372, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+371, 10, t_10+371, 10, temp);
	gf2x_mul_5_avx(temp, q_10+367, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+367, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+366, 10, t_10+366, 10, temp);
	gf2x_mul_5_avx(temp, q_10+362, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+362, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+361, 10, t_10+361, 10, temp);
	gf2x_mul_5_avx(temp, q_10+357, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+357, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+356, 10, t_10+356, 10, temp);
	gf2x_mul_5_avx(temp, q_10+352, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+352, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+351, 10, t_10+351, 10, temp);
	gf2x_mul_5_avx(temp, q_10+347, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+347, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+346, 10, t_10+346, 10, temp);
	gf2x_mul_5_avx(temp, q_10+342, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+342, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+341, 10, t_10+341, 10, temp);
	gf2x_mul_5_avx(temp, q_10+337, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+337, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+336, 10, t_10+336, 10, temp);
	gf2x_mul_5_avx(temp, q_10+332, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+332, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+331, 10, t_10+331, 10, temp);
	gf2x_mul_5_avx(temp, q_10+327, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+327, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+326, 10, t_10+326, 10, temp);
	gf2x_mul_5_avx(temp, q_10+322, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+322, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+321, 10, t_10+321, 10, temp);
	gf2x_mul_5_avx(temp, q_10+317, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+317, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+316, 10, t_10+316, 10, temp);
	gf2x_mul_5_avx(temp, q_10+312, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+312, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+311, 10, t_10+311, 10, temp);
	gf2x_mul_5_avx(temp, q_10+307, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+307, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+306, 10, t_10+306, 10, temp);
	gf2x_mul_5_avx(temp, q_10+302, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+302, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+301, 10, t_10+301, 10, temp);
	gf2x_mul_5_avx(temp, q_10+297, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+297, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+296, 10, t_10+296, 10, temp);
	gf2x_mul_5_avx(temp, q_10+292, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+292, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+291, 10, t_10+291, 10, temp);
	gf2x_mul_5_avx(temp, q_10+287, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+287, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+286, 10, t_10+286, 10, temp);
	gf2x_mul_5_avx(temp, q_10+282, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+282, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+281, 10, t_10+281, 10, temp);
	gf2x_mul_5_avx(temp, q_10+277, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+277, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+276, 10, t_10+276, 10, temp);
	gf2x_mul_5_avx(temp, q_10+272, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+272, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+271, 10, t_10+271, 10, temp);
	gf2x_mul_5_avx(temp, q_10+267, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+267, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+266, 10, t_10+266, 10, temp);
	gf2x_mul_5_avx(temp, q_10+262, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+262, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+261, 10, t_10+261, 10, temp);
	gf2x_mul_5_avx(temp, q_10+257, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+257, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+256, 10, t_10+256, 10, temp);
	gf2x_mul_5_avx(temp, q_10+252, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+252, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+251, 10, t_10+251, 10, temp);
	gf2x_mul_5_avx(temp, q_10+247, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+247, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+246, 10, t_10+246, 10, temp);
	gf2x_mul_5_avx(temp, q_10+242, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+242, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+241, 10, t_10+241, 10, temp);
	gf2x_mul_5_avx(temp, q_10+237, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+237, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+236, 10, t_10+236, 10, temp);
	gf2x_mul_5_avx(temp, q_10+232, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+232, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+231, 10, t_10+231, 10, temp);
	gf2x_mul_5_avx(temp, q_10+227, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+227, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+226, 10, t_10+226, 10, temp);
	gf2x_mul_5_avx(temp, q_10+222, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+222, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+221, 10, t_10+221, 10, temp);
	gf2x_mul_5_avx(temp, q_10+217, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+217, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+216, 10, t_10+216, 10, temp);
	gf2x_mul_5_avx(temp, q_10+212, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+212, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+211, 10, t_10+211, 10, temp);
	gf2x_mul_5_avx(temp, q_10+207, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+207, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+206, 10, t_10+206, 10, temp);
	gf2x_mul_5_avx(temp, q_10+202, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+202, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+201, 10, t_10+201, 10, temp);
	gf2x_mul_5_avx(temp, q_10+197, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+197, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+196, 10, t_10+196, 10, temp);
	gf2x_mul_5_avx(temp, q_10+192, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+192, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+191, 10, t_10+191, 10, temp);
	gf2x_mul_5_avx(temp, q_10+187, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+187, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+186, 10, t_10+186, 10, temp);
	gf2x_mul_5_avx(temp, q_10+182, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+182, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+181, 10, t_10+181, 10, temp);
	gf2x_mul_5_avx(temp, q_10+177, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+177, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+176, 10, t_10+176, 10, temp);
	gf2x_mul_5_avx(temp, q_10+172, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+172, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+171, 10, t_10+171, 10, temp);
	gf2x_mul_5_avx(temp, q_10+167, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+167, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+166, 10, t_10+166, 10, temp);
	gf2x_mul_5_avx(temp, q_10+162, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+162, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+161, 10, t_10+161, 10, temp);
	gf2x_mul_5_avx(temp, q_10+157, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+157, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+156, 10, t_10+156, 10, temp);
	gf2x_mul_5_avx(temp, q_10+152, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+152, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+151, 10, t_10+151, 10, temp);
	gf2x_mul_5_avx(temp, q_10+147, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+147, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+146, 10, t_10+146, 10, temp);
	gf2x_mul_5_avx(temp, q_10+142, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+142, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+141, 10, t_10+141, 10, temp);
	gf2x_mul_5_avx(temp, q_10+137, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+137, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+136, 10, t_10+136, 10, temp);
	gf2x_mul_5_avx(temp, q_10+132, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+132, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+131, 10, t_10+131, 10, temp);
	gf2x_mul_5_avx(temp, q_10+127, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+127, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+126, 10, t_10+126, 10, temp);
	gf2x_mul_5_avx(temp, q_10+122, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+122, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+121, 10, t_10+121, 10, temp);
	gf2x_mul_5_avx(temp, q_10+117, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+117, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+116, 10, t_10+116, 10, temp);
	gf2x_mul_5_avx(temp, q_10+112, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+112, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+111, 10, t_10+111, 10, temp);
	gf2x_mul_5_avx(temp, q_10+107, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+107, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+106, 10, t_10+106, 10, temp);
	gf2x_mul_5_avx(temp, q_10+102, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+102, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+101, 10, t_10+101, 10, temp);
	gf2x_mul_5_avx(temp, q_10+97, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+97, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+96, 10, t_10+96, 10, temp);
	gf2x_mul_5_avx(temp, q_10+92, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+92, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+91, 10, t_10+91, 10, temp);
	gf2x_mul_5_avx(temp, q_10+87, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+87, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+86, 10, t_10+86, 10, temp);
	gf2x_mul_5_avx(temp, q_10+82, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+82, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+81, 10, t_10+81, 10, temp);
	gf2x_mul_5_avx(temp, q_10+77, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+77, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+76, 10, t_10+76, 10, temp);
	gf2x_mul_5_avx(temp, q_10+72, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+72, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+71, 10, t_10+71, 10, temp);
	gf2x_mul_5_avx(temp, q_10+67, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+67, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+66, 10, t_10+66, 10, temp);
	gf2x_mul_5_avx(temp, q_10+62, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+62, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+61, 10, t_10+61, 10, temp);
	gf2x_mul_5_avx(temp, q_10+57, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+57, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+56, 10, t_10+56, 10, temp);
	gf2x_mul_5_avx(temp, q_10+52, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+52, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+51, 10, t_10+51, 10, temp);
	gf2x_mul_5_avx(temp, q_10+47, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+47, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+46, 10, t_10+46, 10, temp);
	gf2x_mul_5_avx(temp, q_10+42, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+42, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+41, 10, t_10+41, 10, temp);
	gf2x_mul_5_avx(temp, q_10+37, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+37, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+36, 10, t_10+36, 10, temp);
	gf2x_mul_5_avx(temp, q_10+32, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+32, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+31, 10, t_10+31, 10, temp);
	gf2x_mul_5_avx(temp, q_10+27, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+27, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+26, 10, t_10+26, 10, temp);
	gf2x_mul_5_avx(temp, q_10+22, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+22, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+21, 10, t_10+21, 10, temp);
	gf2x_mul_5_avx(temp, q_10+17, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+17, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+16, 10, t_10+16, 10, temp);
	gf2x_mul_5_avx(temp, q_10+12, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+12, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+11, 10, t_10+11, 10, temp);
	gf2x_mul_5_avx(temp, q_10+7, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+7, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+6, 10, t_10+6, 10, temp);
	gf2x_mul_5_avx(temp, q_10+2, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+2, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+1, 10, t_10+1, 10, temp);
	gf2x_mul_2_avx(temp, p_00+3, q_10+0);
	gf2x_mul_2_avx(temp2, p_10+3, q_11+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_10+2, 4, t_10+2, 4, temp);
	gf2x_mul_2_avx(temp, p_00+1, q_10+0);
	gf2x_mul_2_avx(temp2, p_10+1, q_11+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_10+0, 4, t_10+0, 4, temp);
	gf2x_mul_1_avx(temp, q_10+1, p_00+0);
	gf2x_mul_1_avx(temp2, q_11+1, p_10+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, t_10+0, 2, t_10+0, 2, temp);
	gf2x_mul_1_avx(temp, q_10+0, p_00+0);
	gf2x_mul_1_avx(temp2, q_11+0, p_10+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, t_10+0, 1, t_10+0, 1, temp+1);
	memset(t_11+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(884, temp, 442, p_01+5, 442, q_10+0);
	GF2X_MUL(884, temp2, 442, p_11+5, 442, q_11+0);
	gf2x_add(884, t_11+4, 884, temp, 884, temp2);
	gf2x_mul_5_avx(temp, q_10+437, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+437, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+436, 10, t_11+436, 10, temp);
	gf2x_mul_5_avx(temp, q_10+432, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+432, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+431, 10, t_11+431, 10, temp);
	gf2x_mul_5_avx(temp, q_10+427, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+427, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+426, 10, t_11+426, 10, temp);
	gf2x_mul_5_avx(temp, q_10+422, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+422, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+421, 10, t_11+421, 10, temp);
	gf2x_mul_5_avx(temp, q_10+417, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+417, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+416, 10, t_11+416, 10, temp);
	gf2x_mul_5_avx(temp, q_10+412, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+412, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+411, 10, t_11+411, 10, temp);
	gf2x_mul_5_avx(temp, q_10+407, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+407, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+406, 10, t_11+406, 10, temp);
	gf2x_mul_5_avx(temp, q_10+402, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+402, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+401, 10, t_11+401, 10, temp);
	gf2x_mul_5_avx(temp, q_10+397, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+397, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+396, 10, t_11+396, 10, temp);
	gf2x_mul_5_avx(temp, q_10+392, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+392, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+391, 10, t_11+391, 10, temp);
	gf2x_mul_5_avx(temp, q_10+387, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+387, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+386, 10, t_11+386, 10, temp);
	gf2x_mul_5_avx(temp, q_10+382, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+382, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+381, 10, t_11+381, 10, temp);
	gf2x_mul_5_avx(temp, q_10+377, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+377, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+376, 10, t_11+376, 10, temp);
	gf2x_mul_5_avx(temp, q_10+372, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+372, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+371, 10, t_11+371, 10, temp);
	gf2x_mul_5_avx(temp, q_10+367, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+367, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+366, 10, t_11+366, 10, temp);
	gf2x_mul_5_avx(temp, q_10+362, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+362, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+361, 10, t_11+361, 10, temp);
	gf2x_mul_5_avx(temp, q_10+357, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+357, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+356, 10, t_11+356, 10, temp);
	gf2x_mul_5_avx(temp, q_10+352, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+352, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+351, 10, t_11+351, 10, temp);
	gf2x_mul_5_avx(temp, q_10+347, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+347, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+346, 10, t_11+346, 10, temp);
	gf2x_mul_5_avx(temp, q_10+342, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+342, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+341, 10, t_11+341, 10, temp);
	gf2x_mul_5_avx(temp, q_10+337, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+337, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+336, 10, t_11+336, 10, temp);
	gf2x_mul_5_avx(temp, q_10+332, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+332, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+331, 10, t_11+331, 10, temp);
	gf2x_mul_5_avx(temp, q_10+327, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+327, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+326, 10, t_11+326, 10, temp);
	gf2x_mul_5_avx(temp, q_10+322, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+322, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+321, 10, t_11+321, 10, temp);
	gf2x_mul_5_avx(temp, q_10+317, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+317, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+316, 10, t_11+316, 10, temp);
	gf2x_mul_5_avx(temp, q_10+312, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+312, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+311, 10, t_11+311, 10, temp);
	gf2x_mul_5_avx(temp, q_10+307, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+307, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+306, 10, t_11+306, 10, temp);
	gf2x_mul_5_avx(temp, q_10+302, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+302, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+301, 10, t_11+301, 10, temp);
	gf2x_mul_5_avx(temp, q_10+297, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+297, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+296, 10, t_11+296, 10, temp);
	gf2x_mul_5_avx(temp, q_10+292, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+292, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+291, 10, t_11+291, 10, temp);
	gf2x_mul_5_avx(temp, q_10+287, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+287, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+286, 10, t_11+286, 10, temp);
	gf2x_mul_5_avx(temp, q_10+282, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+282, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+281, 10, t_11+281, 10, temp);
	gf2x_mul_5_avx(temp, q_10+277, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+277, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+276, 10, t_11+276, 10, temp);
	gf2x_mul_5_avx(temp, q_10+272, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+272, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+271, 10, t_11+271, 10, temp);
	gf2x_mul_5_avx(temp, q_10+267, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+267, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+266, 10, t_11+266, 10, temp);
	gf2x_mul_5_avx(temp, q_10+262, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+262, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+261, 10, t_11+261, 10, temp);
	gf2x_mul_5_avx(temp, q_10+257, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+257, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+256, 10, t_11+256, 10, temp);
	gf2x_mul_5_avx(temp, q_10+252, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+252, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+251, 10, t_11+251, 10, temp);
	gf2x_mul_5_avx(temp, q_10+247, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+247, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+246, 10, t_11+246, 10, temp);
	gf2x_mul_5_avx(temp, q_10+242, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+242, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+241, 10, t_11+241, 10, temp);
	gf2x_mul_5_avx(temp, q_10+237, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+237, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+236, 10, t_11+236, 10, temp);
	gf2x_mul_5_avx(temp, q_10+232, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+232, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+231, 10, t_11+231, 10, temp);
	gf2x_mul_5_avx(temp, q_10+227, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+227, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+226, 10, t_11+226, 10, temp);
	gf2x_mul_5_avx(temp, q_10+222, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+222, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+221, 10, t_11+221, 10, temp);
	gf2x_mul_5_avx(temp, q_10+217, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+217, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+216, 10, t_11+216, 10, temp);
	gf2x_mul_5_avx(temp, q_10+212, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+212, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+211, 10, t_11+211, 10, temp);
	gf2x_mul_5_avx(temp, q_10+207, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+207, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+206, 10, t_11+206, 10, temp);
	gf2x_mul_5_avx(temp, q_10+202, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+202, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+201, 10, t_11+201, 10, temp);
	gf2x_mul_5_avx(temp, q_10+197, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+197, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+196, 10, t_11+196, 10, temp);
	gf2x_mul_5_avx(temp, q_10+192, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+192, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+191, 10, t_11+191, 10, temp);
	gf2x_mul_5_avx(temp, q_10+187, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+187, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+186, 10, t_11+186, 10, temp);
	gf2x_mul_5_avx(temp, q_10+182, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+182, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+181, 10, t_11+181, 10, temp);
	gf2x_mul_5_avx(temp, q_10+177, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+177, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+176, 10, t_11+176, 10, temp);
	gf2x_mul_5_avx(temp, q_10+172, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+172, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+171, 10, t_11+171, 10, temp);
	gf2x_mul_5_avx(temp, q_10+167, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+167, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+166, 10, t_11+166, 10, temp);
	gf2x_mul_5_avx(temp, q_10+162, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+162, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+161, 10, t_11+161, 10, temp);
	gf2x_mul_5_avx(temp, q_10+157, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+157, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+156, 10, t_11+156, 10, temp);
	gf2x_mul_5_avx(temp, q_10+152, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+152, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+151, 10, t_11+151, 10, temp);
	gf2x_mul_5_avx(temp, q_10+147, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+147, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+146, 10, t_11+146, 10, temp);
	gf2x_mul_5_avx(temp, q_10+142, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+142, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+141, 10, t_11+141, 10, temp);
	gf2x_mul_5_avx(temp, q_10+137, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+137, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+136, 10, t_11+136, 10, temp);
	gf2x_mul_5_avx(temp, q_10+132, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+132, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+131, 10, t_11+131, 10, temp);
	gf2x_mul_5_avx(temp, q_10+127, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+127, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+126, 10, t_11+126, 10, temp);
	gf2x_mul_5_avx(temp, q_10+122, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+122, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+121, 10, t_11+121, 10, temp);
	gf2x_mul_5_avx(temp, q_10+117, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+117, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+116, 10, t_11+116, 10, temp);
	gf2x_mul_5_avx(temp, q_10+112, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+112, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+111, 10, t_11+111, 10, temp);
	gf2x_mul_5_avx(temp, q_10+107, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+107, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+106, 10, t_11+106, 10, temp);
	gf2x_mul_5_avx(temp, q_10+102, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+102, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+101, 10, t_11+101, 10, temp);
	gf2x_mul_5_avx(temp, q_10+97, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+97, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+96, 10, t_11+96, 10, temp);
	gf2x_mul_5_avx(temp, q_10+92, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+92, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+91, 10, t_11+91, 10, temp);
	gf2x_mul_5_avx(temp, q_10+87, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+87, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+86, 10, t_11+86, 10, temp);
	gf2x_mul_5_avx(temp, q_10+82, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+82, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+81, 10, t_11+81, 10, temp);
	gf2x_mul_5_avx(temp, q_10+77, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+77, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+76, 10, t_11+76, 10, temp);
	gf2x_mul_5_avx(temp, q_10+72, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+72, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+71, 10, t_11+71, 10, temp);
	gf2x_mul_5_avx(temp, q_10+67, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+67, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+66, 10, t_11+66, 10, temp);
	gf2x_mul_5_avx(temp, q_10+62, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+62, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+61, 10, t_11+61, 10, temp);
	gf2x_mul_5_avx(temp, q_10+57, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+57, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+56, 10, t_11+56, 10, temp);
	gf2x_mul_5_avx(temp, q_10+52, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+52, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+51, 10, t_11+51, 10, temp);
	gf2x_mul_5_avx(temp, q_10+47, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+47, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+46, 10, t_11+46, 10, temp);
	gf2x_mul_5_avx(temp, q_10+42, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+42, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+41, 10, t_11+41, 10, temp);
	gf2x_mul_5_avx(temp, q_10+37, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+37, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+36, 10, t_11+36, 10, temp);
	gf2x_mul_5_avx(temp, q_10+32, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+32, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+31, 10, t_11+31, 10, temp);
	gf2x_mul_5_avx(temp, q_10+27, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+27, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+26, 10, t_11+26, 10, temp);
	gf2x_mul_5_avx(temp, q_10+22, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+22, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+21, 10, t_11+21, 10, temp);
	gf2x_mul_5_avx(temp, q_10+17, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+17, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+16, 10, t_11+16, 10, temp);
	gf2x_mul_5_avx(temp, q_10+12, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+12, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+11, 10, t_11+11, 10, temp);
	gf2x_mul_5_avx(temp, q_10+7, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+7, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+6, 10, t_11+6, 10, temp);
	gf2x_mul_5_avx(temp, q_10+2, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+2, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+1, 10, t_11+1, 10, temp);
	gf2x_mul_2_avx(temp, p_01+3, q_10+0);
	gf2x_mul_2_avx(temp2, p_11+3, q_11+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_11+2, 4, t_11+2, 4, temp);
	gf2x_mul_2_avx(temp, p_01+1, q_10+0);
	gf2x_mul_2_avx(temp2, p_11+1, q_11+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_11+0, 4, t_11+0, 4, temp);
	gf2x_mul_1_avx(temp, q_10+1, p_01+0);
	gf2x_mul_1_avx(temp2, q_11+1, p_11+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, t_11+0, 2, t_11+0, 2, temp);
	gf2x_mul_1_avx(temp, q_10+0, p_01+0);
	gf2x_mul_1_avx(temp2, q_11+0, p_11+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, t_11+0, 1, t_11+0, 1, temp+1);
	
	return delta;
}