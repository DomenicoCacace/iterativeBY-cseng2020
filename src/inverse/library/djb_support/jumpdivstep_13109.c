/**
  * @author Domenico Cacace <domenico.cacace@mail.polimi.it>
  * 
  *
  * This code is hereby placed in the public domain.
  *
  * THIS SOFTWARE IS PROVIDED BY THE AUTHORS ''AS IS'' AND ANY EXPRESS
  * OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
  * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHORS OR CONTRIBUTORS BE
  * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
  * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
  * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
  * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
  * EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **/

#include "../../include/inverse_DJB_facilities.h"

int jumpdivstep_13109(int delta, DIGIT *f, DIGIT *g, DIGIT *t_00, DIGIT *t_01, DIGIT *t_10, DIGIT *t_11) {
	DIGIT p_00[420];
	DIGIT p_01[420];
	DIGIT p_10[420];
	DIGIT p_11[420];
	
	DIGIT q_00[407];
	DIGIT q_01[407];
	DIGIT q_10[407];
	DIGIT q_11[407];
	
	DIGIT f_sum[1254];
	DIGIT g_sum[1254];
	
	DIGIT temp[416];
	DIGIT temp2[416];
	

	delta = divstepsx_256(255, delta, f+406, g+406, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f+406, p_00+416);
	gf2x_mul_4_avx(temp2, g+406, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f+402, p_00+416);
	gf2x_mul_4_avx(temp2, g+402, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f+406, p_10+416);
	gf2x_mul_4_avx(temp2, g+406, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f+402, p_10+416);
	gf2x_mul_4_avx(temp2, g+402, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f+402, p_00+408);
	gf2x_mul_8_avx(temp2, g+402, p_01+408);
	gf2x_add(16, f_sum+1215, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f+394, p_00+408);
	gf2x_mul_8_avx(temp2, g+394, p_01+408);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1215, 8, f_sum+1215, 8, temp+8);
	right_bit_shift_n(16, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f+402, p_10+408);
	gf2x_mul_8_avx(temp2, g+402, p_11+408);
	gf2x_add(16, g_sum+1215, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f+394, p_10+408);
	gf2x_mul_8_avx(temp2, g+394, p_11+408);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1215, 8, g_sum+1215, 8, temp+8);
	right_bit_shift_n(16, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1220, g_sum+1220, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1220, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1220, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1216, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1216, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1220, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1220, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1216, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1216, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, q_00+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, q_01+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, q_10+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, q_11+395, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+395, p_00+408);
	gf2x_mul_8_avx(temp2, q_01+395, p_10+408);
	gf2x_add(16, p_00+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+395, p_01+408);
	gf2x_mul_8_avx(temp2, q_01+395, p_11+408);
	gf2x_add(16, p_01+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+395, p_00+408);
	gf2x_mul_8_avx(temp2, q_11+395, p_10+408);
	gf2x_add(16, p_10+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+395, p_01+408);
	gf2x_mul_8_avx(temp2, q_11+395, p_11+408);
	gf2x_add(16, p_11+392, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 4
	GF2X_MUL(32, temp, 16, f+394, 16, p_00+392);
	GF2X_MUL(32, temp2, 16, g+394, 16, p_01+392);
	gf2x_add(28, f_sum+1170, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+396, 12, f+382);
	GF2X_MUL(24, temp2, 12, p_01+396, 12, g+382);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+1170, 12, f_sum+1170, 12, temp+12);
	right_bit_shift_n(28, f_sum+1170, 60);
	GF2X_MUL(32, temp, 16, f+394, 16, p_10+392);
	GF2X_MUL(32, temp2, 16, g+394, 16, p_11+392);
	gf2x_add(28, g_sum+1170, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+396, 12, f+382);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, g+382);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+1170, 12, g_sum+1170, 12, temp+12);
	right_bit_shift_n(28, g_sum+1170, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1179, g_sum+1179, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1179, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1179, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1175, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1175, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(q_00+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, q_00+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+383, 8, q_00+383, 8, temp);
	memset(q_01+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, q_01+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+383, 8, q_01+383, 8, temp);
	memset(q_10+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, q_10+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+383, 8, q_10+383, 8, temp);
	memset(q_11+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, q_11+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+383, 8, q_11+383, 8, temp);
	
	// Recombining results: n: 1785, depth: 4
	memset(p_00+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+396, 12, q_00+383);
	GF2X_MUL(24, temp2, 12, p_10+396, 12, q_01+383);
	gf2x_add(24, p_00+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+391, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+391, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+372, 8, p_00+372, 8, temp);
	gf2x_mul_4_avx(temp, q_00+387, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+387, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+368, 8, p_00+368, 8, temp);
	gf2x_mul_4_avx(temp, q_00+383, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+383, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+364, 8, p_00+364, 8, temp);
	memset(p_01+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+396, 12, q_00+383);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, q_01+383);
	gf2x_add(24, p_01+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+391, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+391, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+372, 8, p_01+372, 8, temp);
	gf2x_mul_4_avx(temp, q_00+387, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+387, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+368, 8, p_01+368, 8, temp);
	gf2x_mul_4_avx(temp, q_00+383, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+383, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+364, 8, p_01+364, 8, temp);
	memset(p_10+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+396, 12, q_10+383);
	GF2X_MUL(24, temp2, 12, p_10+396, 12, q_11+383);
	gf2x_add(24, p_10+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+391, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+391, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+372, 8, p_10+372, 8, temp);
	gf2x_mul_4_avx(temp, q_10+387, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+387, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+368, 8, p_10+368, 8, temp);
	gf2x_mul_4_avx(temp, q_10+383, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+383, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+364, 8, p_10+364, 8, temp);
	memset(p_11+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+396, 12, q_10+383);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, q_11+383);
	gf2x_add(24, p_11+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+391, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+391, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+372, 8, p_11+372, 8, temp);
	gf2x_mul_4_avx(temp, q_10+387, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+387, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+368, 8, p_11+368, 8, temp);
	gf2x_mul_4_avx(temp, q_10+383, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+383, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+364, 8, p_11+364, 8, temp);
	
	// Calculating left operands: n: 3315, depth: 3
	GF2X_MUL(56, temp, 28, f+382, 28, p_00+364);
	GF2X_MUL(56, temp2, 28, g+382, 28, p_01+364);
	gf2x_add(52, f_sum+1089, 52, temp+4, 52, temp2+4);
	GF2X_MUL(48, temp, 24, p_00+368, 24, f+358);
	GF2X_MUL(48, temp2, 24, p_01+368, 24, g+358);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, f_sum+1089, 24, f_sum+1089, 24, temp+24);
	right_bit_shift_n(52, f_sum+1089, 57);
	GF2X_MUL(56, temp, 28, f+382, 28, p_10+364);
	GF2X_MUL(56, temp2, 28, g+382, 28, p_11+364);
	gf2x_add(52, g_sum+1089, 52, temp+4, 52, temp2+4);
	GF2X_MUL(48, temp, 24, p_10+368, 24, f+358);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, g+358);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, g_sum+1089, 24, g_sum+1089, 24, temp+24);
	right_bit_shift_n(52, g_sum+1089, 57);
	
	delta = divstepsx_256(255, delta, f_sum+1110, g_sum+1110, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1110, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1110, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1106, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1106, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1110, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1110, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1106, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1106, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1106, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1106, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1102);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1102);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1106, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1106, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1102);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1102);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(p_00+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, p_00+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+392, 8, p_00+392, 8, temp);
	memset(p_01+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, p_01+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+392, 8, p_01+392, 8, temp);
	memset(p_10+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, p_10+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+392, 8, p_10+392, 8, temp);
	memset(p_11+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, p_11+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+392, 8, p_11+392, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 4
	GF2X_MUL(24, temp, 12, f_sum+1102, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+1102, 12, p_01+392);
	gf2x_add(24, f_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+1090, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+1090, 12, p_01+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+1170, 12, f_sum+1170, 12, temp+12);
	right_bit_shift_n(24, f_sum+1170, 61);
	GF2X_MUL(24, temp, 12, f_sum+1102, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+1102, 12, p_11+392);
	gf2x_add(24, g_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+1090, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+1090, 12, p_11+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+1170, 12, g_sum+1170, 12, temp+12);
	right_bit_shift_n(24, g_sum+1170, 61);
	
	delta = divstepsx_256(255, delta, f_sum+1179, g_sum+1179, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1179, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1179, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1175, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1175, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(q_00+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, q_00+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+383, 8, q_00+383, 8, temp);
	memset(q_01+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, q_01+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+383, 8, q_01+383, 8, temp);
	memset(q_10+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, q_10+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+383, 8, q_10+383, 8, temp);
	memset(q_11+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, q_11+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+383, 8, q_11+383, 8, temp);
	
	// Recombining results: n: 1530, depth: 4
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_10+392);
	gf2x_add(24, q_00+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_11+392);
	gf2x_add(24, q_01+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_10+392);
	gf2x_add(24, q_10+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_11+392);
	gf2x_add(24, q_11+359, 24, temp, 24, temp2);
	
	// Recombining results: n: 3315, depth: 3
	memset(p_00+312, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_00+368, 24, q_00+359);
	GF2X_MUL(48, temp2, 24, p_10+368, 24, q_01+359);
	gf2x_add(48, p_00+316, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_00+379, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+379, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+332, 8, p_00+332, 8, temp);
	gf2x_mul_4_avx(temp, q_00+375, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+375, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+328, 8, p_00+328, 8, temp);
	gf2x_mul_4_avx(temp, q_00+371, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+371, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+324, 8, p_00+324, 8, temp);
	gf2x_mul_4_avx(temp, q_00+367, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+367, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+320, 8, p_00+320, 8, temp);
	gf2x_mul_4_avx(temp, q_00+363, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+363, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+316, 8, p_00+316, 8, temp);
	gf2x_mul_4_avx(temp, q_00+359, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+359, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+312, 8, p_00+312, 8, temp);
	memset(p_01+312, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_01+368, 24, q_00+359);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, q_01+359);
	gf2x_add(48, p_01+316, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_00+379, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+379, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+332, 8, p_01+332, 8, temp);
	gf2x_mul_4_avx(temp, q_00+375, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+375, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+328, 8, p_01+328, 8, temp);
	gf2x_mul_4_avx(temp, q_00+371, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+371, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+324, 8, p_01+324, 8, temp);
	gf2x_mul_4_avx(temp, q_00+367, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+367, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+320, 8, p_01+320, 8, temp);
	gf2x_mul_4_avx(temp, q_00+363, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+363, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+316, 8, p_01+316, 8, temp);
	gf2x_mul_4_avx(temp, q_00+359, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+359, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+312, 8, p_01+312, 8, temp);
	memset(p_10+312, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_00+368, 24, q_10+359);
	GF2X_MUL(48, temp2, 24, p_10+368, 24, q_11+359);
	gf2x_add(48, p_10+316, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_10+379, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+379, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+332, 8, p_10+332, 8, temp);
	gf2x_mul_4_avx(temp, q_10+375, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+375, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+328, 8, p_10+328, 8, temp);
	gf2x_mul_4_avx(temp, q_10+371, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+371, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+324, 8, p_10+324, 8, temp);
	gf2x_mul_4_avx(temp, q_10+367, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+367, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+320, 8, p_10+320, 8, temp);
	gf2x_mul_4_avx(temp, q_10+363, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+363, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+316, 8, p_10+316, 8, temp);
	gf2x_mul_4_avx(temp, q_10+359, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+359, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+312, 8, p_10+312, 8, temp);
	memset(p_11+312, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_01+368, 24, q_10+359);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, q_11+359);
	gf2x_add(48, p_11+316, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_10+379, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+379, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+332, 8, p_11+332, 8, temp);
	gf2x_mul_4_avx(temp, q_10+375, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+375, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+328, 8, p_11+328, 8, temp);
	gf2x_mul_4_avx(temp, q_10+371, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+371, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+324, 8, p_11+324, 8, temp);
	gf2x_mul_4_avx(temp, q_10+367, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+367, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+320, 8, p_11+320, 8, temp);
	gf2x_mul_4_avx(temp, q_10+363, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+363, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+316, 8, p_11+316, 8, temp);
	gf2x_mul_4_avx(temp, q_10+359, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+359, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+312, 8, p_11+312, 8, temp);
	
	// Calculating left operands: n: 6630, depth: 2
	GF2X_MUL(104, temp, 52, f+358, 52, p_00+312);
	GF2X_MUL(104, temp2, 52, g+358, 52, p_01+312);
	gf2x_add(104, f_sum+932, 104, temp, 104, temp2);
	GF2X_MUL(104, temp, 52, f+306, 52, p_00+312);
	GF2X_MUL(104, temp2, 52, g+306, 52, p_01+312);
	gf2x_add(104, temp, 104, temp, 104, temp2);
	gf2x_add(52, f_sum+932, 52, f_sum+932, 52, temp+52);
	right_bit_shift_n(104, f_sum+932, 51);
	GF2X_MUL(104, temp, 52, f+358, 52, p_10+312);
	GF2X_MUL(104, temp2, 52, g+358, 52, p_11+312);
	gf2x_add(104, g_sum+932, 104, temp, 104, temp2);
	GF2X_MUL(104, temp, 52, f+306, 52, p_10+312);
	GF2X_MUL(104, temp2, 52, g+306, 52, p_11+312);
	gf2x_add(104, temp, 104, temp, 104, temp2);
	gf2x_add(52, g_sum+932, 52, g_sum+932, 52, temp+52);
	right_bit_shift_n(104, g_sum+932, 51);
	
	delta = divstepsx_256(255, delta, f_sum+981, g_sum+981, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+981, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+981, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+977, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+977, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+981, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+981, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+977, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+977, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+977, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+977, p_01+408);
	gf2x_add(16, f_sum+1215, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+969, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+969, p_01+408);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1215, 8, f_sum+1215, 8, temp+8);
	right_bit_shift_n(16, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+977, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+977, p_11+408);
	gf2x_add(16, g_sum+1215, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+969, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+969, p_11+408);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1215, 8, g_sum+1215, 8, temp+8);
	right_bit_shift_n(16, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1220, g_sum+1220, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1220, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1220, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1216, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1216, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1220, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1220, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1216, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1216, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, q_00+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, q_01+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, q_10+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, q_11+395, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+395, p_00+408);
	gf2x_mul_8_avx(temp2, q_01+395, p_10+408);
	gf2x_add(16, p_00+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+395, p_01+408);
	gf2x_mul_8_avx(temp2, q_01+395, p_11+408);
	gf2x_add(16, p_01+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+395, p_00+408);
	gf2x_mul_8_avx(temp2, q_11+395, p_10+408);
	gf2x_add(16, p_10+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+395, p_01+408);
	gf2x_mul_8_avx(temp2, q_11+395, p_11+408);
	gf2x_add(16, p_11+392, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+969, 16, p_00+392);
	GF2X_MUL(32, temp2, 16, g_sum+969, 16, p_01+392);
	gf2x_add(28, f_sum+1170, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+396, 12, f_sum+957);
	GF2X_MUL(24, temp2, 12, p_01+396, 12, g_sum+957);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+1170, 12, f_sum+1170, 12, temp+12);
	right_bit_shift_n(28, f_sum+1170, 60);
	GF2X_MUL(32, temp, 16, f_sum+969, 16, p_10+392);
	GF2X_MUL(32, temp2, 16, g_sum+969, 16, p_11+392);
	gf2x_add(28, g_sum+1170, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+396, 12, f_sum+957);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, g_sum+957);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+1170, 12, g_sum+1170, 12, temp+12);
	right_bit_shift_n(28, g_sum+1170, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1179, g_sum+1179, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1179, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1179, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1175, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1175, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(q_00+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, q_00+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+383, 8, q_00+383, 8, temp);
	memset(q_01+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, q_01+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+383, 8, q_01+383, 8, temp);
	memset(q_10+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, q_10+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+383, 8, q_10+383, 8, temp);
	memset(q_11+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, q_11+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+383, 8, q_11+383, 8, temp);
	
	// Recombining results: n: 1785, depth: 4
	memset(p_00+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+396, 12, q_00+383);
	GF2X_MUL(24, temp2, 12, p_10+396, 12, q_01+383);
	gf2x_add(24, p_00+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+391, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+391, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+372, 8, p_00+372, 8, temp);
	gf2x_mul_4_avx(temp, q_00+387, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+387, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+368, 8, p_00+368, 8, temp);
	gf2x_mul_4_avx(temp, q_00+383, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+383, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+364, 8, p_00+364, 8, temp);
	memset(p_01+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+396, 12, q_00+383);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, q_01+383);
	gf2x_add(24, p_01+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+391, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+391, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+372, 8, p_01+372, 8, temp);
	gf2x_mul_4_avx(temp, q_00+387, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+387, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+368, 8, p_01+368, 8, temp);
	gf2x_mul_4_avx(temp, q_00+383, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+383, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+364, 8, p_01+364, 8, temp);
	memset(p_10+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+396, 12, q_10+383);
	GF2X_MUL(24, temp2, 12, p_10+396, 12, q_11+383);
	gf2x_add(24, p_10+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+391, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+391, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+372, 8, p_10+372, 8, temp);
	gf2x_mul_4_avx(temp, q_10+387, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+387, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+368, 8, p_10+368, 8, temp);
	gf2x_mul_4_avx(temp, q_10+383, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+383, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+364, 8, p_10+364, 8, temp);
	memset(p_11+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+396, 12, q_10+383);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, q_11+383);
	gf2x_add(24, p_11+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+391, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+391, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+372, 8, p_11+372, 8, temp);
	gf2x_mul_4_avx(temp, q_10+387, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+387, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+368, 8, p_11+368, 8, temp);
	gf2x_mul_4_avx(temp, q_10+383, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+383, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+364, 8, p_11+364, 8, temp);
	
	// Calculating left operands: n: 3315, depth: 3
	GF2X_MUL(56, temp, 28, f_sum+957, 28, p_00+364);
	GF2X_MUL(56, temp2, 28, g_sum+957, 28, p_01+364);
	gf2x_add(52, f_sum+1089, 52, temp+4, 52, temp2+4);
	GF2X_MUL(48, temp, 24, p_00+368, 24, f_sum+933);
	GF2X_MUL(48, temp2, 24, p_01+368, 24, g_sum+933);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, f_sum+1089, 24, f_sum+1089, 24, temp+24);
	right_bit_shift_n(52, f_sum+1089, 57);
	GF2X_MUL(56, temp, 28, f_sum+957, 28, p_10+364);
	GF2X_MUL(56, temp2, 28, g_sum+957, 28, p_11+364);
	gf2x_add(52, g_sum+1089, 52, temp+4, 52, temp2+4);
	GF2X_MUL(48, temp, 24, p_10+368, 24, f_sum+933);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, g_sum+933);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, g_sum+1089, 24, g_sum+1089, 24, temp+24);
	right_bit_shift_n(52, g_sum+1089, 57);
	
	delta = divstepsx_256(255, delta, f_sum+1110, g_sum+1110, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1110, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1110, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1106, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1106, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1110, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1110, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1106, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1106, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1106, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1106, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1102);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1102);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1106, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1106, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1102);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1102);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(p_00+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, p_00+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+392, 8, p_00+392, 8, temp);
	memset(p_01+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, p_01+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+392, 8, p_01+392, 8, temp);
	memset(p_10+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, p_10+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+392, 8, p_10+392, 8, temp);
	memset(p_11+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, p_11+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+392, 8, p_11+392, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 4
	GF2X_MUL(24, temp, 12, f_sum+1102, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+1102, 12, p_01+392);
	gf2x_add(24, f_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+1090, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+1090, 12, p_01+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+1170, 12, f_sum+1170, 12, temp+12);
	right_bit_shift_n(24, f_sum+1170, 61);
	GF2X_MUL(24, temp, 12, f_sum+1102, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+1102, 12, p_11+392);
	gf2x_add(24, g_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+1090, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+1090, 12, p_11+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+1170, 12, g_sum+1170, 12, temp+12);
	right_bit_shift_n(24, g_sum+1170, 61);
	
	delta = divstepsx_256(255, delta, f_sum+1179, g_sum+1179, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1179, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1179, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1175, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1175, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(q_00+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, q_00+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+383, 8, q_00+383, 8, temp);
	memset(q_01+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, q_01+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+383, 8, q_01+383, 8, temp);
	memset(q_10+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, q_10+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+383, 8, q_10+383, 8, temp);
	memset(q_11+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, q_11+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+383, 8, q_11+383, 8, temp);
	
	// Recombining results: n: 1530, depth: 4
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_10+392);
	gf2x_add(24, q_00+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_11+392);
	gf2x_add(24, q_01+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_10+392);
	gf2x_add(24, q_10+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_11+392);
	gf2x_add(24, q_11+359, 24, temp, 24, temp2);
	
	// Recombining results: n: 3315, depth: 3
	memset(q_00+307, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_00+368, 24, q_00+359);
	GF2X_MUL(48, temp2, 24, p_10+368, 24, q_01+359);
	gf2x_add(48, q_00+311, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_00+379, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+379, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+327, 8, q_00+327, 8, temp);
	gf2x_mul_4_avx(temp, q_00+375, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+375, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+323, 8, q_00+323, 8, temp);
	gf2x_mul_4_avx(temp, q_00+371, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+371, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+319, 8, q_00+319, 8, temp);
	gf2x_mul_4_avx(temp, q_00+367, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+367, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+315, 8, q_00+315, 8, temp);
	gf2x_mul_4_avx(temp, q_00+363, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+363, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+311, 8, q_00+311, 8, temp);
	gf2x_mul_4_avx(temp, q_00+359, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+359, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+307, 8, q_00+307, 8, temp);
	memset(q_01+307, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_01+368, 24, q_00+359);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, q_01+359);
	gf2x_add(48, q_01+311, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_00+379, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+379, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+327, 8, q_01+327, 8, temp);
	gf2x_mul_4_avx(temp, q_00+375, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+375, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+323, 8, q_01+323, 8, temp);
	gf2x_mul_4_avx(temp, q_00+371, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+371, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+319, 8, q_01+319, 8, temp);
	gf2x_mul_4_avx(temp, q_00+367, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+367, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+315, 8, q_01+315, 8, temp);
	gf2x_mul_4_avx(temp, q_00+363, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+363, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+311, 8, q_01+311, 8, temp);
	gf2x_mul_4_avx(temp, q_00+359, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+359, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+307, 8, q_01+307, 8, temp);
	memset(q_10+307, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_00+368, 24, q_10+359);
	GF2X_MUL(48, temp2, 24, p_10+368, 24, q_11+359);
	gf2x_add(48, q_10+311, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_10+379, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+379, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+327, 8, q_10+327, 8, temp);
	gf2x_mul_4_avx(temp, q_10+375, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+375, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+323, 8, q_10+323, 8, temp);
	gf2x_mul_4_avx(temp, q_10+371, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+371, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+319, 8, q_10+319, 8, temp);
	gf2x_mul_4_avx(temp, q_10+367, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+367, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+315, 8, q_10+315, 8, temp);
	gf2x_mul_4_avx(temp, q_10+363, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+363, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+311, 8, q_10+311, 8, temp);
	gf2x_mul_4_avx(temp, q_10+359, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+359, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+307, 8, q_10+307, 8, temp);
	memset(q_11+307, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_01+368, 24, q_10+359);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, q_11+359);
	gf2x_add(48, q_11+311, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_10+379, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+379, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+327, 8, q_11+327, 8, temp);
	gf2x_mul_4_avx(temp, q_10+375, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+375, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+323, 8, q_11+323, 8, temp);
	gf2x_mul_4_avx(temp, q_10+371, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+371, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+319, 8, q_11+319, 8, temp);
	gf2x_mul_4_avx(temp, q_10+367, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+367, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+315, 8, q_11+315, 8, temp);
	gf2x_mul_4_avx(temp, q_10+363, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+363, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+311, 8, q_11+311, 8, temp);
	gf2x_mul_4_avx(temp, q_10+359, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+359, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+307, 8, q_11+307, 8, temp);
	
	// Recombining results: n: 6630, depth: 2
	GF2X_MUL(104, temp, 52, q_00+307, 52, p_00+312);
	GF2X_MUL(104, temp2, 52, q_01+307, 52, p_10+312);
	gf2x_add(104, p_00+208, 104, temp, 104, temp2);
	GF2X_MUL(104, temp, 52, q_00+307, 52, p_01+312);
	GF2X_MUL(104, temp2, 52, q_01+307, 52, p_11+312);
	gf2x_add(104, p_01+208, 104, temp, 104, temp2);
	GF2X_MUL(104, temp, 52, q_10+307, 52, p_00+312);
	GF2X_MUL(104, temp2, 52, q_11+307, 52, p_10+312);
	gf2x_add(104, p_10+208, 104, temp, 104, temp2);
	GF2X_MUL(104, temp, 52, q_10+307, 52, p_01+312);
	GF2X_MUL(104, temp2, 52, q_11+307, 52, p_11+312);
	gf2x_add(104, p_11+208, 104, temp, 104, temp2);
	
	// Calculating left operands: n: 13260, depth: 1
	GF2X_MUL(208, temp, 104, f+306, 104, p_00+208);
	GF2X_MUL(208, temp2, 104, g+306, 104, p_01+208);
	gf2x_add(208, f_sum+619, 208, temp, 208, temp2);
	GF2X_MUL(208, temp, 104, f+202, 104, p_00+208);
	GF2X_MUL(208, temp2, 104, g+202, 104, p_01+208);
	gf2x_add(208, temp, 208, temp, 208, temp2);
	gf2x_add(104, f_sum+619, 104, f_sum+619, 104, temp+104);
	right_bit_shift_n(208, f_sum+619, 38);
	GF2X_MUL(208, temp, 104, f+306, 104, p_10+208);
	GF2X_MUL(208, temp2, 104, g+306, 104, p_11+208);
	gf2x_add(208, g_sum+619, 208, temp, 208, temp2);
	GF2X_MUL(208, temp, 104, f+202, 104, p_10+208);
	GF2X_MUL(208, temp2, 104, g+202, 104, p_11+208);
	gf2x_add(208, temp, 208, temp, 208, temp2);
	gf2x_add(104, g_sum+619, 104, g_sum+619, 104, temp+104);
	right_bit_shift_n(208, g_sum+619, 38);
	
	delta = divstepsx_256(255, delta, f_sum+720, g_sum+720, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+720, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+720, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+716, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+716, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+720, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+720, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+716, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+716, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+716, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+716, p_01+408);
	gf2x_add(16, f_sum+1215, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+708, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+708, p_01+408);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1215, 8, f_sum+1215, 8, temp+8);
	right_bit_shift_n(16, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+716, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+716, p_11+408);
	gf2x_add(16, g_sum+1215, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+708, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+708, p_11+408);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1215, 8, g_sum+1215, 8, temp+8);
	right_bit_shift_n(16, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1220, g_sum+1220, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1220, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1220, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1216, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1216, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1220, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1220, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1216, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1216, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, q_00+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, q_01+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, q_10+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, q_11+395, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+395, p_00+408);
	gf2x_mul_8_avx(temp2, q_01+395, p_10+408);
	gf2x_add(16, p_00+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+395, p_01+408);
	gf2x_mul_8_avx(temp2, q_01+395, p_11+408);
	gf2x_add(16, p_01+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+395, p_00+408);
	gf2x_mul_8_avx(temp2, q_11+395, p_10+408);
	gf2x_add(16, p_10+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+395, p_01+408);
	gf2x_mul_8_avx(temp2, q_11+395, p_11+408);
	gf2x_add(16, p_11+392, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+708, 16, p_00+392);
	GF2X_MUL(32, temp2, 16, g_sum+708, 16, p_01+392);
	gf2x_add(28, f_sum+1170, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+396, 12, f_sum+696);
	GF2X_MUL(24, temp2, 12, p_01+396, 12, g_sum+696);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+1170, 12, f_sum+1170, 12, temp+12);
	right_bit_shift_n(28, f_sum+1170, 60);
	GF2X_MUL(32, temp, 16, f_sum+708, 16, p_10+392);
	GF2X_MUL(32, temp2, 16, g_sum+708, 16, p_11+392);
	gf2x_add(28, g_sum+1170, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+396, 12, f_sum+696);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, g_sum+696);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+1170, 12, g_sum+1170, 12, temp+12);
	right_bit_shift_n(28, g_sum+1170, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1179, g_sum+1179, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1179, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1179, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1175, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1175, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(q_00+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, q_00+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+383, 8, q_00+383, 8, temp);
	memset(q_01+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, q_01+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+383, 8, q_01+383, 8, temp);
	memset(q_10+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, q_10+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+383, 8, q_10+383, 8, temp);
	memset(q_11+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, q_11+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+383, 8, q_11+383, 8, temp);
	
	// Recombining results: n: 1785, depth: 4
	memset(p_00+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+396, 12, q_00+383);
	GF2X_MUL(24, temp2, 12, p_10+396, 12, q_01+383);
	gf2x_add(24, p_00+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+391, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+391, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+372, 8, p_00+372, 8, temp);
	gf2x_mul_4_avx(temp, q_00+387, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+387, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+368, 8, p_00+368, 8, temp);
	gf2x_mul_4_avx(temp, q_00+383, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+383, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+364, 8, p_00+364, 8, temp);
	memset(p_01+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+396, 12, q_00+383);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, q_01+383);
	gf2x_add(24, p_01+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+391, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+391, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+372, 8, p_01+372, 8, temp);
	gf2x_mul_4_avx(temp, q_00+387, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+387, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+368, 8, p_01+368, 8, temp);
	gf2x_mul_4_avx(temp, q_00+383, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+383, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+364, 8, p_01+364, 8, temp);
	memset(p_10+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+396, 12, q_10+383);
	GF2X_MUL(24, temp2, 12, p_10+396, 12, q_11+383);
	gf2x_add(24, p_10+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+391, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+391, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+372, 8, p_10+372, 8, temp);
	gf2x_mul_4_avx(temp, q_10+387, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+387, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+368, 8, p_10+368, 8, temp);
	gf2x_mul_4_avx(temp, q_10+383, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+383, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+364, 8, p_10+364, 8, temp);
	memset(p_11+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+396, 12, q_10+383);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, q_11+383);
	gf2x_add(24, p_11+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+391, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+391, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+372, 8, p_11+372, 8, temp);
	gf2x_mul_4_avx(temp, q_10+387, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+387, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+368, 8, p_11+368, 8, temp);
	gf2x_mul_4_avx(temp, q_10+383, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+383, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+364, 8, p_11+364, 8, temp);
	
	// Calculating left operands: n: 3315, depth: 3
	GF2X_MUL(56, temp, 28, f_sum+696, 28, p_00+364);
	GF2X_MUL(56, temp2, 28, g_sum+696, 28, p_01+364);
	gf2x_add(52, f_sum+1089, 52, temp+4, 52, temp2+4);
	GF2X_MUL(48, temp, 24, p_00+368, 24, f_sum+672);
	GF2X_MUL(48, temp2, 24, p_01+368, 24, g_sum+672);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, f_sum+1089, 24, f_sum+1089, 24, temp+24);
	right_bit_shift_n(52, f_sum+1089, 57);
	GF2X_MUL(56, temp, 28, f_sum+696, 28, p_10+364);
	GF2X_MUL(56, temp2, 28, g_sum+696, 28, p_11+364);
	gf2x_add(52, g_sum+1089, 52, temp+4, 52, temp2+4);
	GF2X_MUL(48, temp, 24, p_10+368, 24, f_sum+672);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, g_sum+672);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, g_sum+1089, 24, g_sum+1089, 24, temp+24);
	right_bit_shift_n(52, g_sum+1089, 57);
	
	delta = divstepsx_256(255, delta, f_sum+1110, g_sum+1110, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1110, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1110, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1106, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1106, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1110, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1110, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1106, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1106, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1106, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1106, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1102);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1102);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1106, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1106, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1102);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1102);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(p_00+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, p_00+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+392, 8, p_00+392, 8, temp);
	memset(p_01+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, p_01+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+392, 8, p_01+392, 8, temp);
	memset(p_10+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, p_10+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+392, 8, p_10+392, 8, temp);
	memset(p_11+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, p_11+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+392, 8, p_11+392, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 4
	GF2X_MUL(24, temp, 12, f_sum+1102, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+1102, 12, p_01+392);
	gf2x_add(24, f_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+1090, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+1090, 12, p_01+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+1170, 12, f_sum+1170, 12, temp+12);
	right_bit_shift_n(24, f_sum+1170, 61);
	GF2X_MUL(24, temp, 12, f_sum+1102, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+1102, 12, p_11+392);
	gf2x_add(24, g_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+1090, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+1090, 12, p_11+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+1170, 12, g_sum+1170, 12, temp+12);
	right_bit_shift_n(24, g_sum+1170, 61);
	
	delta = divstepsx_256(255, delta, f_sum+1179, g_sum+1179, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1179, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1179, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1175, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1175, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(q_00+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, q_00+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+383, 8, q_00+383, 8, temp);
	memset(q_01+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, q_01+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+383, 8, q_01+383, 8, temp);
	memset(q_10+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, q_10+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+383, 8, q_10+383, 8, temp);
	memset(q_11+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, q_11+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+383, 8, q_11+383, 8, temp);
	
	// Recombining results: n: 1530, depth: 4
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_10+392);
	gf2x_add(24, q_00+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_11+392);
	gf2x_add(24, q_01+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_10+392);
	gf2x_add(24, q_10+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_11+392);
	gf2x_add(24, q_11+359, 24, temp, 24, temp2);
	
	// Recombining results: n: 3315, depth: 3
	memset(p_00+312, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_00+368, 24, q_00+359);
	GF2X_MUL(48, temp2, 24, p_10+368, 24, q_01+359);
	gf2x_add(48, p_00+316, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_00+379, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+379, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+332, 8, p_00+332, 8, temp);
	gf2x_mul_4_avx(temp, q_00+375, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+375, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+328, 8, p_00+328, 8, temp);
	gf2x_mul_4_avx(temp, q_00+371, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+371, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+324, 8, p_00+324, 8, temp);
	gf2x_mul_4_avx(temp, q_00+367, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+367, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+320, 8, p_00+320, 8, temp);
	gf2x_mul_4_avx(temp, q_00+363, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+363, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+316, 8, p_00+316, 8, temp);
	gf2x_mul_4_avx(temp, q_00+359, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+359, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+312, 8, p_00+312, 8, temp);
	memset(p_01+312, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_01+368, 24, q_00+359);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, q_01+359);
	gf2x_add(48, p_01+316, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_00+379, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+379, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+332, 8, p_01+332, 8, temp);
	gf2x_mul_4_avx(temp, q_00+375, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+375, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+328, 8, p_01+328, 8, temp);
	gf2x_mul_4_avx(temp, q_00+371, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+371, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+324, 8, p_01+324, 8, temp);
	gf2x_mul_4_avx(temp, q_00+367, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+367, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+320, 8, p_01+320, 8, temp);
	gf2x_mul_4_avx(temp, q_00+363, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+363, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+316, 8, p_01+316, 8, temp);
	gf2x_mul_4_avx(temp, q_00+359, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+359, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+312, 8, p_01+312, 8, temp);
	memset(p_10+312, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_00+368, 24, q_10+359);
	GF2X_MUL(48, temp2, 24, p_10+368, 24, q_11+359);
	gf2x_add(48, p_10+316, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_10+379, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+379, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+332, 8, p_10+332, 8, temp);
	gf2x_mul_4_avx(temp, q_10+375, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+375, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+328, 8, p_10+328, 8, temp);
	gf2x_mul_4_avx(temp, q_10+371, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+371, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+324, 8, p_10+324, 8, temp);
	gf2x_mul_4_avx(temp, q_10+367, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+367, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+320, 8, p_10+320, 8, temp);
	gf2x_mul_4_avx(temp, q_10+363, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+363, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+316, 8, p_10+316, 8, temp);
	gf2x_mul_4_avx(temp, q_10+359, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+359, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+312, 8, p_10+312, 8, temp);
	memset(p_11+312, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_01+368, 24, q_10+359);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, q_11+359);
	gf2x_add(48, p_11+316, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_10+379, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+379, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+332, 8, p_11+332, 8, temp);
	gf2x_mul_4_avx(temp, q_10+375, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+375, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+328, 8, p_11+328, 8, temp);
	gf2x_mul_4_avx(temp, q_10+371, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+371, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+324, 8, p_11+324, 8, temp);
	gf2x_mul_4_avx(temp, q_10+367, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+367, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+320, 8, p_11+320, 8, temp);
	gf2x_mul_4_avx(temp, q_10+363, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+363, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+316, 8, p_11+316, 8, temp);
	gf2x_mul_4_avx(temp, q_10+359, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+359, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+312, 8, p_11+312, 8, temp);
	
	// Calculating left operands: n: 6630, depth: 2
	GF2X_MUL(104, temp, 52, f_sum+672, 52, p_00+312);
	GF2X_MUL(104, temp2, 52, g_sum+672, 52, p_01+312);
	gf2x_add(104, f_sum+932, 104, temp, 104, temp2);
	GF2X_MUL(104, temp, 52, f_sum+620, 52, p_00+312);
	GF2X_MUL(104, temp2, 52, g_sum+620, 52, p_01+312);
	gf2x_add(104, temp, 104, temp, 104, temp2);
	gf2x_add(52, f_sum+932, 52, f_sum+932, 52, temp+52);
	right_bit_shift_n(104, f_sum+932, 51);
	GF2X_MUL(104, temp, 52, f_sum+672, 52, p_10+312);
	GF2X_MUL(104, temp2, 52, g_sum+672, 52, p_11+312);
	gf2x_add(104, g_sum+932, 104, temp, 104, temp2);
	GF2X_MUL(104, temp, 52, f_sum+620, 52, p_10+312);
	GF2X_MUL(104, temp2, 52, g_sum+620, 52, p_11+312);
	gf2x_add(104, temp, 104, temp, 104, temp2);
	gf2x_add(52, g_sum+932, 52, g_sum+932, 52, temp+52);
	right_bit_shift_n(104, g_sum+932, 51);
	
	delta = divstepsx_256(255, delta, f_sum+981, g_sum+981, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+981, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+981, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+977, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+977, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+981, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+981, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+977, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+977, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+977, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+977, p_01+408);
	gf2x_add(16, f_sum+1215, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+969, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+969, p_01+408);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1215, 8, f_sum+1215, 8, temp+8);
	right_bit_shift_n(16, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+977, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+977, p_11+408);
	gf2x_add(16, g_sum+1215, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+969, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+969, p_11+408);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1215, 8, g_sum+1215, 8, temp+8);
	right_bit_shift_n(16, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1220, g_sum+1220, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1220, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1220, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1216, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1216, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1220, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1220, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1216, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1216, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, q_00+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, q_01+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, q_10+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, q_11+395, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+395, p_00+408);
	gf2x_mul_8_avx(temp2, q_01+395, p_10+408);
	gf2x_add(16, p_00+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+395, p_01+408);
	gf2x_mul_8_avx(temp2, q_01+395, p_11+408);
	gf2x_add(16, p_01+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+395, p_00+408);
	gf2x_mul_8_avx(temp2, q_11+395, p_10+408);
	gf2x_add(16, p_10+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+395, p_01+408);
	gf2x_mul_8_avx(temp2, q_11+395, p_11+408);
	gf2x_add(16, p_11+392, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+969, 16, p_00+392);
	GF2X_MUL(32, temp2, 16, g_sum+969, 16, p_01+392);
	gf2x_add(28, f_sum+1170, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+396, 12, f_sum+957);
	GF2X_MUL(24, temp2, 12, p_01+396, 12, g_sum+957);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+1170, 12, f_sum+1170, 12, temp+12);
	right_bit_shift_n(28, f_sum+1170, 60);
	GF2X_MUL(32, temp, 16, f_sum+969, 16, p_10+392);
	GF2X_MUL(32, temp2, 16, g_sum+969, 16, p_11+392);
	gf2x_add(28, g_sum+1170, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+396, 12, f_sum+957);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, g_sum+957);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+1170, 12, g_sum+1170, 12, temp+12);
	right_bit_shift_n(28, g_sum+1170, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1179, g_sum+1179, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1179, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1179, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1175, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1175, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(q_00+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, q_00+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+383, 8, q_00+383, 8, temp);
	memset(q_01+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, q_01+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+383, 8, q_01+383, 8, temp);
	memset(q_10+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, q_10+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+383, 8, q_10+383, 8, temp);
	memset(q_11+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, q_11+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+383, 8, q_11+383, 8, temp);
	
	// Recombining results: n: 1785, depth: 4
	memset(p_00+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+396, 12, q_00+383);
	GF2X_MUL(24, temp2, 12, p_10+396, 12, q_01+383);
	gf2x_add(24, p_00+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+391, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+391, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+372, 8, p_00+372, 8, temp);
	gf2x_mul_4_avx(temp, q_00+387, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+387, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+368, 8, p_00+368, 8, temp);
	gf2x_mul_4_avx(temp, q_00+383, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+383, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+364, 8, p_00+364, 8, temp);
	memset(p_01+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+396, 12, q_00+383);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, q_01+383);
	gf2x_add(24, p_01+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+391, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+391, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+372, 8, p_01+372, 8, temp);
	gf2x_mul_4_avx(temp, q_00+387, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+387, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+368, 8, p_01+368, 8, temp);
	gf2x_mul_4_avx(temp, q_00+383, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+383, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+364, 8, p_01+364, 8, temp);
	memset(p_10+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+396, 12, q_10+383);
	GF2X_MUL(24, temp2, 12, p_10+396, 12, q_11+383);
	gf2x_add(24, p_10+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+391, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+391, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+372, 8, p_10+372, 8, temp);
	gf2x_mul_4_avx(temp, q_10+387, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+387, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+368, 8, p_10+368, 8, temp);
	gf2x_mul_4_avx(temp, q_10+383, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+383, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+364, 8, p_10+364, 8, temp);
	memset(p_11+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+396, 12, q_10+383);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, q_11+383);
	gf2x_add(24, p_11+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+391, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+391, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+372, 8, p_11+372, 8, temp);
	gf2x_mul_4_avx(temp, q_10+387, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+387, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+368, 8, p_11+368, 8, temp);
	gf2x_mul_4_avx(temp, q_10+383, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+383, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+364, 8, p_11+364, 8, temp);
	
	// Calculating left operands: n: 3315, depth: 3
	GF2X_MUL(56, temp, 28, f_sum+957, 28, p_00+364);
	GF2X_MUL(56, temp2, 28, g_sum+957, 28, p_01+364);
	gf2x_add(52, f_sum+1089, 52, temp+4, 52, temp2+4);
	GF2X_MUL(48, temp, 24, p_00+368, 24, f_sum+933);
	GF2X_MUL(48, temp2, 24, p_01+368, 24, g_sum+933);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, f_sum+1089, 24, f_sum+1089, 24, temp+24);
	right_bit_shift_n(52, f_sum+1089, 57);
	GF2X_MUL(56, temp, 28, f_sum+957, 28, p_10+364);
	GF2X_MUL(56, temp2, 28, g_sum+957, 28, p_11+364);
	gf2x_add(52, g_sum+1089, 52, temp+4, 52, temp2+4);
	GF2X_MUL(48, temp, 24, p_10+368, 24, f_sum+933);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, g_sum+933);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, g_sum+1089, 24, g_sum+1089, 24, temp+24);
	right_bit_shift_n(52, g_sum+1089, 57);
	
	delta = divstepsx_256(255, delta, f_sum+1110, g_sum+1110, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1110, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1110, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1106, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1106, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1110, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1110, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1106, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1106, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1106, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1106, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1102);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1102);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1106, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1106, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1102);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1102);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(p_00+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, p_00+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+392, 8, p_00+392, 8, temp);
	memset(p_01+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, p_01+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+392, 8, p_01+392, 8, temp);
	memset(p_10+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, p_10+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+392, 8, p_10+392, 8, temp);
	memset(p_11+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, p_11+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+392, 8, p_11+392, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 4
	GF2X_MUL(24, temp, 12, f_sum+1102, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+1102, 12, p_01+392);
	gf2x_add(24, f_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+1090, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+1090, 12, p_01+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+1170, 12, f_sum+1170, 12, temp+12);
	right_bit_shift_n(24, f_sum+1170, 61);
	GF2X_MUL(24, temp, 12, f_sum+1102, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+1102, 12, p_11+392);
	gf2x_add(24, g_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+1090, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+1090, 12, p_11+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+1170, 12, g_sum+1170, 12, temp+12);
	right_bit_shift_n(24, g_sum+1170, 61);
	
	delta = divstepsx_256(255, delta, f_sum+1179, g_sum+1179, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1179, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1179, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1175, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1175, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(q_00+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, q_00+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+383, 8, q_00+383, 8, temp);
	memset(q_01+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, q_01+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+383, 8, q_01+383, 8, temp);
	memset(q_10+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, q_10+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+383, 8, q_10+383, 8, temp);
	memset(q_11+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, q_11+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+383, 8, q_11+383, 8, temp);
	
	// Recombining results: n: 1530, depth: 4
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_10+392);
	gf2x_add(24, q_00+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_11+392);
	gf2x_add(24, q_01+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_10+392);
	gf2x_add(24, q_10+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_11+392);
	gf2x_add(24, q_11+359, 24, temp, 24, temp2);
	
	// Recombining results: n: 3315, depth: 3
	memset(q_00+307, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_00+368, 24, q_00+359);
	GF2X_MUL(48, temp2, 24, p_10+368, 24, q_01+359);
	gf2x_add(48, q_00+311, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_00+379, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+379, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+327, 8, q_00+327, 8, temp);
	gf2x_mul_4_avx(temp, q_00+375, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+375, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+323, 8, q_00+323, 8, temp);
	gf2x_mul_4_avx(temp, q_00+371, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+371, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+319, 8, q_00+319, 8, temp);
	gf2x_mul_4_avx(temp, q_00+367, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+367, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+315, 8, q_00+315, 8, temp);
	gf2x_mul_4_avx(temp, q_00+363, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+363, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+311, 8, q_00+311, 8, temp);
	gf2x_mul_4_avx(temp, q_00+359, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+359, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+307, 8, q_00+307, 8, temp);
	memset(q_01+307, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_01+368, 24, q_00+359);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, q_01+359);
	gf2x_add(48, q_01+311, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_00+379, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+379, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+327, 8, q_01+327, 8, temp);
	gf2x_mul_4_avx(temp, q_00+375, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+375, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+323, 8, q_01+323, 8, temp);
	gf2x_mul_4_avx(temp, q_00+371, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+371, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+319, 8, q_01+319, 8, temp);
	gf2x_mul_4_avx(temp, q_00+367, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+367, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+315, 8, q_01+315, 8, temp);
	gf2x_mul_4_avx(temp, q_00+363, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+363, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+311, 8, q_01+311, 8, temp);
	gf2x_mul_4_avx(temp, q_00+359, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+359, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+307, 8, q_01+307, 8, temp);
	memset(q_10+307, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_00+368, 24, q_10+359);
	GF2X_MUL(48, temp2, 24, p_10+368, 24, q_11+359);
	gf2x_add(48, q_10+311, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_10+379, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+379, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+327, 8, q_10+327, 8, temp);
	gf2x_mul_4_avx(temp, q_10+375, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+375, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+323, 8, q_10+323, 8, temp);
	gf2x_mul_4_avx(temp, q_10+371, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+371, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+319, 8, q_10+319, 8, temp);
	gf2x_mul_4_avx(temp, q_10+367, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+367, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+315, 8, q_10+315, 8, temp);
	gf2x_mul_4_avx(temp, q_10+363, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+363, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+311, 8, q_10+311, 8, temp);
	gf2x_mul_4_avx(temp, q_10+359, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+359, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+307, 8, q_10+307, 8, temp);
	memset(q_11+307, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_01+368, 24, q_10+359);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, q_11+359);
	gf2x_add(48, q_11+311, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_10+379, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+379, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+327, 8, q_11+327, 8, temp);
	gf2x_mul_4_avx(temp, q_10+375, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+375, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+323, 8, q_11+323, 8, temp);
	gf2x_mul_4_avx(temp, q_10+371, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+371, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+319, 8, q_11+319, 8, temp);
	gf2x_mul_4_avx(temp, q_10+367, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+367, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+315, 8, q_11+315, 8, temp);
	gf2x_mul_4_avx(temp, q_10+363, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+363, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+311, 8, q_11+311, 8, temp);
	gf2x_mul_4_avx(temp, q_10+359, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+359, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+307, 8, q_11+307, 8, temp);
	
	// Recombining results: n: 6630, depth: 2
	GF2X_MUL(104, temp, 52, q_00+307, 52, p_00+312);
	GF2X_MUL(104, temp2, 52, q_01+307, 52, p_10+312);
	gf2x_add(104, q_00+203, 104, temp, 104, temp2);
	GF2X_MUL(104, temp, 52, q_00+307, 52, p_01+312);
	GF2X_MUL(104, temp2, 52, q_01+307, 52, p_11+312);
	gf2x_add(104, q_01+203, 104, temp, 104, temp2);
	GF2X_MUL(104, temp, 52, q_10+307, 52, p_00+312);
	GF2X_MUL(104, temp2, 52, q_11+307, 52, p_10+312);
	gf2x_add(104, q_10+203, 104, temp, 104, temp2);
	GF2X_MUL(104, temp, 52, q_10+307, 52, p_01+312);
	GF2X_MUL(104, temp2, 52, q_11+307, 52, p_11+312);
	gf2x_add(104, q_11+203, 104, temp, 104, temp2);
	
	// Recombining results: n: 13260, depth: 1
	GF2X_MUL(208, temp, 104, q_00+203, 104, p_00+208);
	GF2X_MUL(208, temp2, 104, q_01+203, 104, p_10+208);
	gf2x_add(208, p_00+0, 208, temp, 208, temp2);
	GF2X_MUL(208, temp, 104, q_00+203, 104, p_01+208);
	GF2X_MUL(208, temp2, 104, q_01+203, 104, p_11+208);
	gf2x_add(208, p_01+0, 208, temp, 208, temp2);
	GF2X_MUL(208, temp, 104, q_10+203, 104, p_00+208);
	GF2X_MUL(208, temp2, 104, q_11+203, 104, p_10+208);
	gf2x_add(208, p_10+0, 208, temp, 208, temp2);
	GF2X_MUL(208, temp, 104, q_10+203, 104, p_01+208);
	GF2X_MUL(208, temp2, 104, q_11+203, 104, p_11+208);
	gf2x_add(208, p_11+0, 208, temp, 208, temp2);
	
	// Calculating left operands: n: 26217, depth: 0
	GF2X_MUL(416, temp, 208, f+202, 208, p_00+0);
	GF2X_MUL(416, temp2, 208, g+202, 208, p_01+0);
	gf2x_add(411, f_sum+0, 411, temp+5, 411, temp2+5);
	GF2X_MUL(404, temp, 202, p_00+6, 202, f+0);
	GF2X_MUL(404, temp2, 202, p_01+6, 202, g+0);
	gf2x_add(404, temp, 404, temp, 404, temp2);
	gf2x_add(203, f_sum+0, 203, f_sum+0, 203, temp+201);
	gf2x_mul_6_avx(temp, f+196, p_00+0);
	gf2x_mul_6_avx(temp2, g+196, p_01+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(1, f_sum+0, 1, f_sum+0, 1, temp+11);
	right_bit_shift_n(410, f_sum+0, 12);
	GF2X_MUL(416, temp, 208, f+202, 208, p_10+0);
	GF2X_MUL(416, temp2, 208, g+202, 208, p_11+0);
	gf2x_add(411, g_sum+0, 411, temp+5, 411, temp2+5);
	GF2X_MUL(404, temp, 202, p_10+6, 202, f+0);
	GF2X_MUL(404, temp2, 202, p_11+6, 202, g+0);
	gf2x_add(404, temp, 404, temp, 404, temp2);
	gf2x_add(203, g_sum+0, 203, g_sum+0, 203, temp+201);
	gf2x_mul_6_avx(temp, f+196, p_10+0);
	gf2x_mul_6_avx(temp2, g+196, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(1, g_sum+0, 1, g_sum+0, 1, temp+11);
	right_bit_shift_n(410, g_sum+0, 12);
	
	delta = divstepsx_256(255, delta, f_sum+200, g_sum+200, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+200, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+200, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+196, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+196, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+200, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+200, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+196, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+196, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+196, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+196, p_01+408);
	gf2x_add(16, f_sum+1215, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+188, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+188, p_01+408);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1215, 8, f_sum+1215, 8, temp+8);
	right_bit_shift_n(16, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+196, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+196, p_11+408);
	gf2x_add(16, g_sum+1215, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+188, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+188, p_11+408);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1215, 8, g_sum+1215, 8, temp+8);
	right_bit_shift_n(16, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1220, g_sum+1220, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1220, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1220, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1216, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1216, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1220, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1220, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1216, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1216, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, q_00+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, q_01+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, q_10+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, q_11+395, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+395, p_00+408);
	gf2x_mul_8_avx(temp2, q_01+395, p_10+408);
	gf2x_add(16, p_00+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+395, p_01+408);
	gf2x_mul_8_avx(temp2, q_01+395, p_11+408);
	gf2x_add(16, p_01+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+395, p_00+408);
	gf2x_mul_8_avx(temp2, q_11+395, p_10+408);
	gf2x_add(16, p_10+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+395, p_01+408);
	gf2x_mul_8_avx(temp2, q_11+395, p_11+408);
	gf2x_add(16, p_11+392, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+188, 16, p_00+392);
	GF2X_MUL(32, temp2, 16, g_sum+188, 16, p_01+392);
	gf2x_add(28, f_sum+1170, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+396, 12, f_sum+176);
	GF2X_MUL(24, temp2, 12, p_01+396, 12, g_sum+176);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+1170, 12, f_sum+1170, 12, temp+12);
	right_bit_shift_n(28, f_sum+1170, 60);
	GF2X_MUL(32, temp, 16, f_sum+188, 16, p_10+392);
	GF2X_MUL(32, temp2, 16, g_sum+188, 16, p_11+392);
	gf2x_add(28, g_sum+1170, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+396, 12, f_sum+176);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, g_sum+176);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+1170, 12, g_sum+1170, 12, temp+12);
	right_bit_shift_n(28, g_sum+1170, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1179, g_sum+1179, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1179, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1179, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1175, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1175, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(q_00+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, q_00+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+383, 8, q_00+383, 8, temp);
	memset(q_01+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, q_01+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+383, 8, q_01+383, 8, temp);
	memset(q_10+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, q_10+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+383, 8, q_10+383, 8, temp);
	memset(q_11+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, q_11+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+383, 8, q_11+383, 8, temp);
	
	// Recombining results: n: 1785, depth: 4
	memset(p_00+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+396, 12, q_00+383);
	GF2X_MUL(24, temp2, 12, p_10+396, 12, q_01+383);
	gf2x_add(24, p_00+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+391, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+391, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+372, 8, p_00+372, 8, temp);
	gf2x_mul_4_avx(temp, q_00+387, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+387, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+368, 8, p_00+368, 8, temp);
	gf2x_mul_4_avx(temp, q_00+383, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+383, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+364, 8, p_00+364, 8, temp);
	memset(p_01+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+396, 12, q_00+383);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, q_01+383);
	gf2x_add(24, p_01+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+391, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+391, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+372, 8, p_01+372, 8, temp);
	gf2x_mul_4_avx(temp, q_00+387, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+387, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+368, 8, p_01+368, 8, temp);
	gf2x_mul_4_avx(temp, q_00+383, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+383, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+364, 8, p_01+364, 8, temp);
	memset(p_10+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+396, 12, q_10+383);
	GF2X_MUL(24, temp2, 12, p_10+396, 12, q_11+383);
	gf2x_add(24, p_10+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+391, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+391, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+372, 8, p_10+372, 8, temp);
	gf2x_mul_4_avx(temp, q_10+387, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+387, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+368, 8, p_10+368, 8, temp);
	gf2x_mul_4_avx(temp, q_10+383, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+383, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+364, 8, p_10+364, 8, temp);
	memset(p_11+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+396, 12, q_10+383);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, q_11+383);
	gf2x_add(24, p_11+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+391, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+391, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+372, 8, p_11+372, 8, temp);
	gf2x_mul_4_avx(temp, q_10+387, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+387, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+368, 8, p_11+368, 8, temp);
	gf2x_mul_4_avx(temp, q_10+383, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+383, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+364, 8, p_11+364, 8, temp);
	
	// Calculating left operands: n: 3315, depth: 3
	GF2X_MUL(56, temp, 28, f_sum+176, 28, p_00+364);
	GF2X_MUL(56, temp2, 28, g_sum+176, 28, p_01+364);
	gf2x_add(52, f_sum+1089, 52, temp+4, 52, temp2+4);
	GF2X_MUL(48, temp, 24, p_00+368, 24, f_sum+152);
	GF2X_MUL(48, temp2, 24, p_01+368, 24, g_sum+152);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, f_sum+1089, 24, f_sum+1089, 24, temp+24);
	right_bit_shift_n(52, f_sum+1089, 57);
	GF2X_MUL(56, temp, 28, f_sum+176, 28, p_10+364);
	GF2X_MUL(56, temp2, 28, g_sum+176, 28, p_11+364);
	gf2x_add(52, g_sum+1089, 52, temp+4, 52, temp2+4);
	GF2X_MUL(48, temp, 24, p_10+368, 24, f_sum+152);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, g_sum+152);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, g_sum+1089, 24, g_sum+1089, 24, temp+24);
	right_bit_shift_n(52, g_sum+1089, 57);
	
	delta = divstepsx_256(255, delta, f_sum+1110, g_sum+1110, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1110, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1110, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1106, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1106, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1110, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1110, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1106, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1106, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1106, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1106, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1102);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1102);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1106, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1106, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1102);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1102);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(p_00+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, p_00+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+392, 8, p_00+392, 8, temp);
	memset(p_01+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, p_01+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+392, 8, p_01+392, 8, temp);
	memset(p_10+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, p_10+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+392, 8, p_10+392, 8, temp);
	memset(p_11+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, p_11+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+392, 8, p_11+392, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 4
	GF2X_MUL(24, temp, 12, f_sum+1102, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+1102, 12, p_01+392);
	gf2x_add(24, f_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+1090, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+1090, 12, p_01+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+1170, 12, f_sum+1170, 12, temp+12);
	right_bit_shift_n(24, f_sum+1170, 61);
	GF2X_MUL(24, temp, 12, f_sum+1102, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+1102, 12, p_11+392);
	gf2x_add(24, g_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+1090, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+1090, 12, p_11+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+1170, 12, g_sum+1170, 12, temp+12);
	right_bit_shift_n(24, g_sum+1170, 61);
	
	delta = divstepsx_256(255, delta, f_sum+1179, g_sum+1179, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1179, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1179, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1175, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1175, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(q_00+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, q_00+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+383, 8, q_00+383, 8, temp);
	memset(q_01+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, q_01+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+383, 8, q_01+383, 8, temp);
	memset(q_10+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, q_10+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+383, 8, q_10+383, 8, temp);
	memset(q_11+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, q_11+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+383, 8, q_11+383, 8, temp);
	
	// Recombining results: n: 1530, depth: 4
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_10+392);
	gf2x_add(24, q_00+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_11+392);
	gf2x_add(24, q_01+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_10+392);
	gf2x_add(24, q_10+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_11+392);
	gf2x_add(24, q_11+359, 24, temp, 24, temp2);
	
	// Recombining results: n: 3315, depth: 3
	memset(p_00+312, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_00+368, 24, q_00+359);
	GF2X_MUL(48, temp2, 24, p_10+368, 24, q_01+359);
	gf2x_add(48, p_00+316, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_00+379, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+379, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+332, 8, p_00+332, 8, temp);
	gf2x_mul_4_avx(temp, q_00+375, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+375, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+328, 8, p_00+328, 8, temp);
	gf2x_mul_4_avx(temp, q_00+371, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+371, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+324, 8, p_00+324, 8, temp);
	gf2x_mul_4_avx(temp, q_00+367, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+367, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+320, 8, p_00+320, 8, temp);
	gf2x_mul_4_avx(temp, q_00+363, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+363, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+316, 8, p_00+316, 8, temp);
	gf2x_mul_4_avx(temp, q_00+359, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+359, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+312, 8, p_00+312, 8, temp);
	memset(p_01+312, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_01+368, 24, q_00+359);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, q_01+359);
	gf2x_add(48, p_01+316, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_00+379, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+379, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+332, 8, p_01+332, 8, temp);
	gf2x_mul_4_avx(temp, q_00+375, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+375, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+328, 8, p_01+328, 8, temp);
	gf2x_mul_4_avx(temp, q_00+371, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+371, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+324, 8, p_01+324, 8, temp);
	gf2x_mul_4_avx(temp, q_00+367, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+367, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+320, 8, p_01+320, 8, temp);
	gf2x_mul_4_avx(temp, q_00+363, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+363, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+316, 8, p_01+316, 8, temp);
	gf2x_mul_4_avx(temp, q_00+359, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+359, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+312, 8, p_01+312, 8, temp);
	memset(p_10+312, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_00+368, 24, q_10+359);
	GF2X_MUL(48, temp2, 24, p_10+368, 24, q_11+359);
	gf2x_add(48, p_10+316, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_10+379, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+379, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+332, 8, p_10+332, 8, temp);
	gf2x_mul_4_avx(temp, q_10+375, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+375, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+328, 8, p_10+328, 8, temp);
	gf2x_mul_4_avx(temp, q_10+371, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+371, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+324, 8, p_10+324, 8, temp);
	gf2x_mul_4_avx(temp, q_10+367, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+367, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+320, 8, p_10+320, 8, temp);
	gf2x_mul_4_avx(temp, q_10+363, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+363, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+316, 8, p_10+316, 8, temp);
	gf2x_mul_4_avx(temp, q_10+359, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+359, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+312, 8, p_10+312, 8, temp);
	memset(p_11+312, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_01+368, 24, q_10+359);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, q_11+359);
	gf2x_add(48, p_11+316, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_10+379, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+379, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+332, 8, p_11+332, 8, temp);
	gf2x_mul_4_avx(temp, q_10+375, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+375, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+328, 8, p_11+328, 8, temp);
	gf2x_mul_4_avx(temp, q_10+371, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+371, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+324, 8, p_11+324, 8, temp);
	gf2x_mul_4_avx(temp, q_10+367, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+367, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+320, 8, p_11+320, 8, temp);
	gf2x_mul_4_avx(temp, q_10+363, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+363, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+316, 8, p_11+316, 8, temp);
	gf2x_mul_4_avx(temp, q_10+359, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+359, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+312, 8, p_11+312, 8, temp);
	
	// Calculating left operands: n: 6630, depth: 2
	GF2X_MUL(104, temp, 52, f_sum+152, 52, p_00+312);
	GF2X_MUL(104, temp2, 52, g_sum+152, 52, p_01+312);
	gf2x_add(104, f_sum+932, 104, temp, 104, temp2);
	GF2X_MUL(104, temp, 52, f_sum+100, 52, p_00+312);
	GF2X_MUL(104, temp2, 52, g_sum+100, 52, p_01+312);
	gf2x_add(104, temp, 104, temp, 104, temp2);
	gf2x_add(52, f_sum+932, 52, f_sum+932, 52, temp+52);
	right_bit_shift_n(104, f_sum+932, 51);
	GF2X_MUL(104, temp, 52, f_sum+152, 52, p_10+312);
	GF2X_MUL(104, temp2, 52, g_sum+152, 52, p_11+312);
	gf2x_add(104, g_sum+932, 104, temp, 104, temp2);
	GF2X_MUL(104, temp, 52, f_sum+100, 52, p_10+312);
	GF2X_MUL(104, temp2, 52, g_sum+100, 52, p_11+312);
	gf2x_add(104, temp, 104, temp, 104, temp2);
	gf2x_add(52, g_sum+932, 52, g_sum+932, 52, temp+52);
	right_bit_shift_n(104, g_sum+932, 51);
	
	delta = divstepsx_256(255, delta, f_sum+981, g_sum+981, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+981, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+981, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+977, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+977, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+981, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+981, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+977, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+977, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+977, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+977, p_01+408);
	gf2x_add(16, f_sum+1215, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+969, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+969, p_01+408);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1215, 8, f_sum+1215, 8, temp+8);
	right_bit_shift_n(16, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+977, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+977, p_11+408);
	gf2x_add(16, g_sum+1215, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+969, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+969, p_11+408);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1215, 8, g_sum+1215, 8, temp+8);
	right_bit_shift_n(16, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1220, g_sum+1220, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1220, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1220, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1216, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1216, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1220, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1220, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1216, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1216, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, q_00+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, q_01+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, q_10+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, q_11+395, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+395, p_00+408);
	gf2x_mul_8_avx(temp2, q_01+395, p_10+408);
	gf2x_add(16, p_00+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+395, p_01+408);
	gf2x_mul_8_avx(temp2, q_01+395, p_11+408);
	gf2x_add(16, p_01+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+395, p_00+408);
	gf2x_mul_8_avx(temp2, q_11+395, p_10+408);
	gf2x_add(16, p_10+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+395, p_01+408);
	gf2x_mul_8_avx(temp2, q_11+395, p_11+408);
	gf2x_add(16, p_11+392, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+969, 16, p_00+392);
	GF2X_MUL(32, temp2, 16, g_sum+969, 16, p_01+392);
	gf2x_add(28, f_sum+1170, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+396, 12, f_sum+957);
	GF2X_MUL(24, temp2, 12, p_01+396, 12, g_sum+957);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+1170, 12, f_sum+1170, 12, temp+12);
	right_bit_shift_n(28, f_sum+1170, 60);
	GF2X_MUL(32, temp, 16, f_sum+969, 16, p_10+392);
	GF2X_MUL(32, temp2, 16, g_sum+969, 16, p_11+392);
	gf2x_add(28, g_sum+1170, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+396, 12, f_sum+957);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, g_sum+957);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+1170, 12, g_sum+1170, 12, temp+12);
	right_bit_shift_n(28, g_sum+1170, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1179, g_sum+1179, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1179, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1179, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1175, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1175, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(q_00+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, q_00+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+383, 8, q_00+383, 8, temp);
	memset(q_01+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, q_01+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+383, 8, q_01+383, 8, temp);
	memset(q_10+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, q_10+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+383, 8, q_10+383, 8, temp);
	memset(q_11+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, q_11+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+383, 8, q_11+383, 8, temp);
	
	// Recombining results: n: 1785, depth: 4
	memset(p_00+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+396, 12, q_00+383);
	GF2X_MUL(24, temp2, 12, p_10+396, 12, q_01+383);
	gf2x_add(24, p_00+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+391, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+391, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+372, 8, p_00+372, 8, temp);
	gf2x_mul_4_avx(temp, q_00+387, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+387, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+368, 8, p_00+368, 8, temp);
	gf2x_mul_4_avx(temp, q_00+383, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+383, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+364, 8, p_00+364, 8, temp);
	memset(p_01+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+396, 12, q_00+383);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, q_01+383);
	gf2x_add(24, p_01+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+391, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+391, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+372, 8, p_01+372, 8, temp);
	gf2x_mul_4_avx(temp, q_00+387, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+387, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+368, 8, p_01+368, 8, temp);
	gf2x_mul_4_avx(temp, q_00+383, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+383, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+364, 8, p_01+364, 8, temp);
	memset(p_10+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+396, 12, q_10+383);
	GF2X_MUL(24, temp2, 12, p_10+396, 12, q_11+383);
	gf2x_add(24, p_10+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+391, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+391, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+372, 8, p_10+372, 8, temp);
	gf2x_mul_4_avx(temp, q_10+387, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+387, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+368, 8, p_10+368, 8, temp);
	gf2x_mul_4_avx(temp, q_10+383, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+383, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+364, 8, p_10+364, 8, temp);
	memset(p_11+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+396, 12, q_10+383);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, q_11+383);
	gf2x_add(24, p_11+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+391, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+391, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+372, 8, p_11+372, 8, temp);
	gf2x_mul_4_avx(temp, q_10+387, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+387, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+368, 8, p_11+368, 8, temp);
	gf2x_mul_4_avx(temp, q_10+383, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+383, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+364, 8, p_11+364, 8, temp);
	
	// Calculating left operands: n: 3315, depth: 3
	GF2X_MUL(56, temp, 28, f_sum+957, 28, p_00+364);
	GF2X_MUL(56, temp2, 28, g_sum+957, 28, p_01+364);
	gf2x_add(52, f_sum+1089, 52, temp+4, 52, temp2+4);
	GF2X_MUL(48, temp, 24, p_00+368, 24, f_sum+933);
	GF2X_MUL(48, temp2, 24, p_01+368, 24, g_sum+933);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, f_sum+1089, 24, f_sum+1089, 24, temp+24);
	right_bit_shift_n(52, f_sum+1089, 57);
	GF2X_MUL(56, temp, 28, f_sum+957, 28, p_10+364);
	GF2X_MUL(56, temp2, 28, g_sum+957, 28, p_11+364);
	gf2x_add(52, g_sum+1089, 52, temp+4, 52, temp2+4);
	GF2X_MUL(48, temp, 24, p_10+368, 24, f_sum+933);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, g_sum+933);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, g_sum+1089, 24, g_sum+1089, 24, temp+24);
	right_bit_shift_n(52, g_sum+1089, 57);
	
	delta = divstepsx_256(255, delta, f_sum+1110, g_sum+1110, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1110, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1110, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1106, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1106, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1110, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1110, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1106, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1106, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1106, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1106, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1102);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1102);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1106, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1106, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1102);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1102);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(p_00+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, p_00+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+392, 8, p_00+392, 8, temp);
	memset(p_01+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, p_01+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+392, 8, p_01+392, 8, temp);
	memset(p_10+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, p_10+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+392, 8, p_10+392, 8, temp);
	memset(p_11+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, p_11+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+392, 8, p_11+392, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 4
	GF2X_MUL(24, temp, 12, f_sum+1102, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+1102, 12, p_01+392);
	gf2x_add(24, f_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+1090, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+1090, 12, p_01+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+1170, 12, f_sum+1170, 12, temp+12);
	right_bit_shift_n(24, f_sum+1170, 61);
	GF2X_MUL(24, temp, 12, f_sum+1102, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+1102, 12, p_11+392);
	gf2x_add(24, g_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+1090, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+1090, 12, p_11+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+1170, 12, g_sum+1170, 12, temp+12);
	right_bit_shift_n(24, g_sum+1170, 61);
	
	delta = divstepsx_256(255, delta, f_sum+1179, g_sum+1179, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1179, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1179, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1175, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1175, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(q_00+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, q_00+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+383, 8, q_00+383, 8, temp);
	memset(q_01+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, q_01+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+383, 8, q_01+383, 8, temp);
	memset(q_10+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, q_10+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+383, 8, q_10+383, 8, temp);
	memset(q_11+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, q_11+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+383, 8, q_11+383, 8, temp);
	
	// Recombining results: n: 1530, depth: 4
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_10+392);
	gf2x_add(24, q_00+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_11+392);
	gf2x_add(24, q_01+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_10+392);
	gf2x_add(24, q_10+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_11+392);
	gf2x_add(24, q_11+359, 24, temp, 24, temp2);
	
	// Recombining results: n: 3315, depth: 3
	memset(q_00+307, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_00+368, 24, q_00+359);
	GF2X_MUL(48, temp2, 24, p_10+368, 24, q_01+359);
	gf2x_add(48, q_00+311, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_00+379, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+379, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+327, 8, q_00+327, 8, temp);
	gf2x_mul_4_avx(temp, q_00+375, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+375, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+323, 8, q_00+323, 8, temp);
	gf2x_mul_4_avx(temp, q_00+371, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+371, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+319, 8, q_00+319, 8, temp);
	gf2x_mul_4_avx(temp, q_00+367, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+367, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+315, 8, q_00+315, 8, temp);
	gf2x_mul_4_avx(temp, q_00+363, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+363, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+311, 8, q_00+311, 8, temp);
	gf2x_mul_4_avx(temp, q_00+359, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+359, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+307, 8, q_00+307, 8, temp);
	memset(q_01+307, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_01+368, 24, q_00+359);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, q_01+359);
	gf2x_add(48, q_01+311, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_00+379, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+379, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+327, 8, q_01+327, 8, temp);
	gf2x_mul_4_avx(temp, q_00+375, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+375, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+323, 8, q_01+323, 8, temp);
	gf2x_mul_4_avx(temp, q_00+371, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+371, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+319, 8, q_01+319, 8, temp);
	gf2x_mul_4_avx(temp, q_00+367, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+367, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+315, 8, q_01+315, 8, temp);
	gf2x_mul_4_avx(temp, q_00+363, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+363, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+311, 8, q_01+311, 8, temp);
	gf2x_mul_4_avx(temp, q_00+359, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+359, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+307, 8, q_01+307, 8, temp);
	memset(q_10+307, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_00+368, 24, q_10+359);
	GF2X_MUL(48, temp2, 24, p_10+368, 24, q_11+359);
	gf2x_add(48, q_10+311, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_10+379, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+379, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+327, 8, q_10+327, 8, temp);
	gf2x_mul_4_avx(temp, q_10+375, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+375, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+323, 8, q_10+323, 8, temp);
	gf2x_mul_4_avx(temp, q_10+371, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+371, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+319, 8, q_10+319, 8, temp);
	gf2x_mul_4_avx(temp, q_10+367, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+367, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+315, 8, q_10+315, 8, temp);
	gf2x_mul_4_avx(temp, q_10+363, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+363, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+311, 8, q_10+311, 8, temp);
	gf2x_mul_4_avx(temp, q_10+359, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+359, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+307, 8, q_10+307, 8, temp);
	memset(q_11+307, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_01+368, 24, q_10+359);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, q_11+359);
	gf2x_add(48, q_11+311, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_10+379, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+379, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+327, 8, q_11+327, 8, temp);
	gf2x_mul_4_avx(temp, q_10+375, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+375, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+323, 8, q_11+323, 8, temp);
	gf2x_mul_4_avx(temp, q_10+371, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+371, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+319, 8, q_11+319, 8, temp);
	gf2x_mul_4_avx(temp, q_10+367, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+367, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+315, 8, q_11+315, 8, temp);
	gf2x_mul_4_avx(temp, q_10+363, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+363, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+311, 8, q_11+311, 8, temp);
	gf2x_mul_4_avx(temp, q_10+359, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+359, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+307, 8, q_11+307, 8, temp);
	
	// Recombining results: n: 6630, depth: 2
	GF2X_MUL(104, temp, 52, q_00+307, 52, p_00+312);
	GF2X_MUL(104, temp2, 52, q_01+307, 52, p_10+312);
	gf2x_add(104, p_00+208, 104, temp, 104, temp2);
	GF2X_MUL(104, temp, 52, q_00+307, 52, p_01+312);
	GF2X_MUL(104, temp2, 52, q_01+307, 52, p_11+312);
	gf2x_add(104, p_01+208, 104, temp, 104, temp2);
	GF2X_MUL(104, temp, 52, q_10+307, 52, p_00+312);
	GF2X_MUL(104, temp2, 52, q_11+307, 52, p_10+312);
	gf2x_add(104, p_10+208, 104, temp, 104, temp2);
	GF2X_MUL(104, temp, 52, q_10+307, 52, p_01+312);
	GF2X_MUL(104, temp2, 52, q_11+307, 52, p_11+312);
	gf2x_add(104, p_11+208, 104, temp, 104, temp2);
	
	// Calculating left operands: n: 12957, depth: 1
	GF2X_MUL(208, temp, 104, f_sum+100, 104, p_00+208);
	GF2X_MUL(208, temp2, 104, g_sum+100, 104, p_01+208);
	gf2x_add(203, f_sum+619, 203, temp+5, 203, temp2+5);
	GF2X_MUL(198, temp, 99, p_00+213, 99, f_sum+1);
	GF2X_MUL(198, temp2, 99, p_01+213, 99, g_sum+1);
	gf2x_add(198, temp, 198, temp, 198, temp2);
	gf2x_add(99, f_sum+619, 99, f_sum+619, 99, temp+99);
	right_bit_shift_n(203, f_sum+619, 38);
	GF2X_MUL(208, temp, 104, f_sum+100, 104, p_10+208);
	GF2X_MUL(208, temp2, 104, g_sum+100, 104, p_11+208);
	gf2x_add(203, g_sum+619, 203, temp+5, 203, temp2+5);
	GF2X_MUL(198, temp, 99, p_10+213, 99, f_sum+1);
	GF2X_MUL(198, temp2, 99, p_11+213, 99, g_sum+1);
	gf2x_add(198, temp, 198, temp, 198, temp2);
	gf2x_add(99, g_sum+619, 99, g_sum+619, 99, temp+99);
	right_bit_shift_n(203, g_sum+619, 38);
	
	delta = divstepsx_256(255, delta, f_sum+715, g_sum+715, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+715, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+715, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+711, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+711, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+715, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+715, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+711, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+711, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+711, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+711, p_01+408);
	gf2x_add(16, f_sum+1215, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+703, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+703, p_01+408);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1215, 8, f_sum+1215, 8, temp+8);
	right_bit_shift_n(16, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+711, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+711, p_11+408);
	gf2x_add(16, g_sum+1215, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+703, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+703, p_11+408);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1215, 8, g_sum+1215, 8, temp+8);
	right_bit_shift_n(16, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1220, g_sum+1220, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1220, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1220, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1216, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1216, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1220, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1220, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1216, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1216, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, q_00+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, q_01+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, q_10+395, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, q_11+395, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+395, p_00+408);
	gf2x_mul_8_avx(temp2, q_01+395, p_10+408);
	gf2x_add(16, p_00+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+395, p_01+408);
	gf2x_mul_8_avx(temp2, q_01+395, p_11+408);
	gf2x_add(16, p_01+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+395, p_00+408);
	gf2x_mul_8_avx(temp2, q_11+395, p_10+408);
	gf2x_add(16, p_10+392, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+395, p_01+408);
	gf2x_mul_8_avx(temp2, q_11+395, p_11+408);
	gf2x_add(16, p_11+392, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+703, 16, p_00+392);
	GF2X_MUL(32, temp2, 16, g_sum+703, 16, p_01+392);
	gf2x_add(28, f_sum+1170, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+396, 12, f_sum+691);
	GF2X_MUL(24, temp2, 12, p_01+396, 12, g_sum+691);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+1170, 12, f_sum+1170, 12, temp+12);
	right_bit_shift_n(28, f_sum+1170, 60);
	GF2X_MUL(32, temp, 16, f_sum+703, 16, p_10+392);
	GF2X_MUL(32, temp2, 16, g_sum+703, 16, p_11+392);
	gf2x_add(28, g_sum+1170, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+396, 12, f_sum+691);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, g_sum+691);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+1170, 12, g_sum+1170, 12, temp+12);
	right_bit_shift_n(28, g_sum+1170, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1179, g_sum+1179, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1179, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1179, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1175, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1175, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(q_00+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, q_00+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+383, 8, q_00+383, 8, temp);
	memset(q_01+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, q_01+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+383, 8, q_01+383, 8, temp);
	memset(q_10+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, q_10+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+383, 8, q_10+383, 8, temp);
	memset(q_11+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, q_11+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+383, 8, q_11+383, 8, temp);
	
	// Recombining results: n: 1785, depth: 4
	memset(p_00+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+396, 12, q_00+383);
	GF2X_MUL(24, temp2, 12, p_10+396, 12, q_01+383);
	gf2x_add(24, p_00+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+391, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+391, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+372, 8, p_00+372, 8, temp);
	gf2x_mul_4_avx(temp, q_00+387, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+387, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+368, 8, p_00+368, 8, temp);
	gf2x_mul_4_avx(temp, q_00+383, p_00+392);
	gf2x_mul_4_avx(temp2, q_01+383, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+364, 8, p_00+364, 8, temp);
	memset(p_01+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+396, 12, q_00+383);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, q_01+383);
	gf2x_add(24, p_01+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+391, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+391, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+372, 8, p_01+372, 8, temp);
	gf2x_mul_4_avx(temp, q_00+387, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+387, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+368, 8, p_01+368, 8, temp);
	gf2x_mul_4_avx(temp, q_00+383, p_01+392);
	gf2x_mul_4_avx(temp2, q_01+383, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+364, 8, p_01+364, 8, temp);
	memset(p_10+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+396, 12, q_10+383);
	GF2X_MUL(24, temp2, 12, p_10+396, 12, q_11+383);
	gf2x_add(24, p_10+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+391, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+391, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+372, 8, p_10+372, 8, temp);
	gf2x_mul_4_avx(temp, q_10+387, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+387, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+368, 8, p_10+368, 8, temp);
	gf2x_mul_4_avx(temp, q_10+383, p_00+392);
	gf2x_mul_4_avx(temp2, q_11+383, p_10+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+364, 8, p_10+364, 8, temp);
	memset(p_11+364, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+396, 12, q_10+383);
	GF2X_MUL(24, temp2, 12, p_11+396, 12, q_11+383);
	gf2x_add(24, p_11+368, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+391, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+391, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+372, 8, p_11+372, 8, temp);
	gf2x_mul_4_avx(temp, q_10+387, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+387, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+368, 8, p_11+368, 8, temp);
	gf2x_mul_4_avx(temp, q_10+383, p_01+392);
	gf2x_mul_4_avx(temp2, q_11+383, p_11+392);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+364, 8, p_11+364, 8, temp);
	
	// Calculating left operands: n: 3315, depth: 3
	GF2X_MUL(56, temp, 28, f_sum+691, 28, p_00+364);
	GF2X_MUL(56, temp2, 28, g_sum+691, 28, p_01+364);
	gf2x_add(52, f_sum+1089, 52, temp+4, 52, temp2+4);
	GF2X_MUL(48, temp, 24, p_00+368, 24, f_sum+667);
	GF2X_MUL(48, temp2, 24, p_01+368, 24, g_sum+667);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, f_sum+1089, 24, f_sum+1089, 24, temp+24);
	right_bit_shift_n(52, f_sum+1089, 57);
	GF2X_MUL(56, temp, 28, f_sum+691, 28, p_10+364);
	GF2X_MUL(56, temp2, 28, g_sum+691, 28, p_11+364);
	gf2x_add(52, g_sum+1089, 52, temp+4, 52, temp2+4);
	GF2X_MUL(48, temp, 24, p_10+368, 24, f_sum+667);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, g_sum+667);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, g_sum+1089, 24, g_sum+1089, 24, temp+24);
	right_bit_shift_n(52, g_sum+1089, 57);
	
	delta = divstepsx_256(255, delta, f_sum+1110, g_sum+1110, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1110, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1110, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1106, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1106, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1110, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1110, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1106, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1106, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1106, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1106, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1102);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1102);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1106, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1106, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1102);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1102);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(p_00+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, p_00+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+392, 8, p_00+392, 8, temp);
	memset(p_01+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, p_01+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+392, 8, p_01+392, 8, temp);
	memset(p_10+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, p_10+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+392, 8, p_10+392, 8, temp);
	memset(p_11+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, p_11+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+392, 8, p_11+392, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 4
	GF2X_MUL(24, temp, 12, f_sum+1102, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+1102, 12, p_01+392);
	gf2x_add(24, f_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+1090, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+1090, 12, p_01+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+1170, 12, f_sum+1170, 12, temp+12);
	right_bit_shift_n(24, f_sum+1170, 61);
	GF2X_MUL(24, temp, 12, f_sum+1102, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+1102, 12, p_11+392);
	gf2x_add(24, g_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+1090, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+1090, 12, p_11+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+1170, 12, g_sum+1170, 12, temp+12);
	right_bit_shift_n(24, g_sum+1170, 61);
	
	delta = divstepsx_256(255, delta, f_sum+1179, g_sum+1179, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1179, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1179, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1175, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1175, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(q_00+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, q_00+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+383, 8, q_00+383, 8, temp);
	memset(q_01+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, q_01+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+383, 8, q_01+383, 8, temp);
	memset(q_10+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, q_10+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+383, 8, q_10+383, 8, temp);
	memset(q_11+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, q_11+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+383, 8, q_11+383, 8, temp);
	
	// Recombining results: n: 1530, depth: 4
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_10+392);
	gf2x_add(24, q_00+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_11+392);
	gf2x_add(24, q_01+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_10+392);
	gf2x_add(24, q_10+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_11+392);
	gf2x_add(24, q_11+359, 24, temp, 24, temp2);
	
	// Recombining results: n: 3315, depth: 3
	memset(p_00+312, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_00+368, 24, q_00+359);
	GF2X_MUL(48, temp2, 24, p_10+368, 24, q_01+359);
	gf2x_add(48, p_00+316, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_00+379, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+379, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+332, 8, p_00+332, 8, temp);
	gf2x_mul_4_avx(temp, q_00+375, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+375, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+328, 8, p_00+328, 8, temp);
	gf2x_mul_4_avx(temp, q_00+371, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+371, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+324, 8, p_00+324, 8, temp);
	gf2x_mul_4_avx(temp, q_00+367, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+367, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+320, 8, p_00+320, 8, temp);
	gf2x_mul_4_avx(temp, q_00+363, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+363, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+316, 8, p_00+316, 8, temp);
	gf2x_mul_4_avx(temp, q_00+359, p_00+364);
	gf2x_mul_4_avx(temp2, q_01+359, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+312, 8, p_00+312, 8, temp);
	memset(p_01+312, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_01+368, 24, q_00+359);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, q_01+359);
	gf2x_add(48, p_01+316, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_00+379, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+379, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+332, 8, p_01+332, 8, temp);
	gf2x_mul_4_avx(temp, q_00+375, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+375, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+328, 8, p_01+328, 8, temp);
	gf2x_mul_4_avx(temp, q_00+371, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+371, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+324, 8, p_01+324, 8, temp);
	gf2x_mul_4_avx(temp, q_00+367, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+367, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+320, 8, p_01+320, 8, temp);
	gf2x_mul_4_avx(temp, q_00+363, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+363, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+316, 8, p_01+316, 8, temp);
	gf2x_mul_4_avx(temp, q_00+359, p_01+364);
	gf2x_mul_4_avx(temp2, q_01+359, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+312, 8, p_01+312, 8, temp);
	memset(p_10+312, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_00+368, 24, q_10+359);
	GF2X_MUL(48, temp2, 24, p_10+368, 24, q_11+359);
	gf2x_add(48, p_10+316, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_10+379, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+379, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+332, 8, p_10+332, 8, temp);
	gf2x_mul_4_avx(temp, q_10+375, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+375, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+328, 8, p_10+328, 8, temp);
	gf2x_mul_4_avx(temp, q_10+371, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+371, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+324, 8, p_10+324, 8, temp);
	gf2x_mul_4_avx(temp, q_10+367, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+367, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+320, 8, p_10+320, 8, temp);
	gf2x_mul_4_avx(temp, q_10+363, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+363, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+316, 8, p_10+316, 8, temp);
	gf2x_mul_4_avx(temp, q_10+359, p_00+364);
	gf2x_mul_4_avx(temp2, q_11+359, p_10+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+312, 8, p_10+312, 8, temp);
	memset(p_11+312, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(48, temp, 24, p_01+368, 24, q_10+359);
	GF2X_MUL(48, temp2, 24, p_11+368, 24, q_11+359);
	gf2x_add(48, p_11+316, 48, temp, 48, temp2);
	gf2x_mul_4_avx(temp, q_10+379, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+379, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+332, 8, p_11+332, 8, temp);
	gf2x_mul_4_avx(temp, q_10+375, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+375, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+328, 8, p_11+328, 8, temp);
	gf2x_mul_4_avx(temp, q_10+371, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+371, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+324, 8, p_11+324, 8, temp);
	gf2x_mul_4_avx(temp, q_10+367, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+367, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+320, 8, p_11+320, 8, temp);
	gf2x_mul_4_avx(temp, q_10+363, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+363, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+316, 8, p_11+316, 8, temp);
	gf2x_mul_4_avx(temp, q_10+359, p_01+364);
	gf2x_mul_4_avx(temp2, q_11+359, p_11+364);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+312, 8, p_11+312, 8, temp);
	
	// Calculating left operands: n: 6327, depth: 2
	GF2X_MUL(104, temp, 52, f_sum+667, 52, p_00+312);
	GF2X_MUL(104, temp2, 52, g_sum+667, 52, p_01+312);
	gf2x_add(100, f_sum+932, 100, temp+4, 100, temp2+4);
	GF2X_MUL(94, temp, 47, p_00+317, 47, f_sum+620);
	GF2X_MUL(94, temp2, 47, p_01+317, 47, g_sum+620);
	gf2x_add(94, temp, 94, temp, 94, temp2);
	gf2x_add(48, f_sum+932, 48, f_sum+932, 48, temp+46);
	gf2x_mul_5_avx(temp, f_sum+662, p_00+312);
	gf2x_mul_5_avx(temp2, g_sum+662, p_01+312);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(1, f_sum+932, 1, f_sum+932, 1, temp+9);
	right_bit_shift_n(99, f_sum+932, 51);
	GF2X_MUL(104, temp, 52, f_sum+667, 52, p_10+312);
	GF2X_MUL(104, temp2, 52, g_sum+667, 52, p_11+312);
	gf2x_add(100, g_sum+932, 100, temp+4, 100, temp2+4);
	GF2X_MUL(94, temp, 47, p_10+317, 47, f_sum+620);
	GF2X_MUL(94, temp2, 47, p_11+317, 47, g_sum+620);
	gf2x_add(94, temp, 94, temp, 94, temp2);
	gf2x_add(48, g_sum+932, 48, g_sum+932, 48, temp+46);
	gf2x_mul_5_avx(temp, f_sum+662, p_10+312);
	gf2x_mul_5_avx(temp2, g_sum+662, p_11+312);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(1, g_sum+932, 1, g_sum+932, 1, temp+9);
	right_bit_shift_n(99, g_sum+932, 51);
	
	delta = divstepsx_256(255, delta, f_sum+977, g_sum+977, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+977, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+977, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+973, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+973, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+977, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+977, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+973, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+973, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+973, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+973, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+969);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+969);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+973, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+973, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+969);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+969);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(p_00+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, p_00+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+392, 8, p_00+392, 8, temp);
	memset(p_01+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, p_01+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+392, 8, p_01+392, 8, temp);
	memset(p_10+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, p_10+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+392, 8, p_10+392, 8, temp);
	memset(p_11+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, p_11+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+392, 8, p_11+392, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 4
	GF2X_MUL(24, temp, 12, f_sum+969, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+969, 12, p_01+392);
	gf2x_add(24, f_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+957, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+957, 12, p_01+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+1170, 12, f_sum+1170, 12, temp+12);
	right_bit_shift_n(24, f_sum+1170, 61);
	GF2X_MUL(24, temp, 12, f_sum+969, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+969, 12, p_11+392);
	gf2x_add(24, g_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+957, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+957, 12, p_11+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+1170, 12, g_sum+1170, 12, temp+12);
	right_bit_shift_n(24, g_sum+1170, 61);
	
	delta = divstepsx_256(255, delta, f_sum+1179, g_sum+1179, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1179, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1179, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1175, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1175, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(q_00+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, q_00+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+383, 8, q_00+383, 8, temp);
	memset(q_01+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, q_01+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+383, 8, q_01+383, 8, temp);
	memset(q_10+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, q_10+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+383, 8, q_10+383, 8, temp);
	memset(q_11+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, q_11+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+383, 8, q_11+383, 8, temp);
	
	// Recombining results: n: 1530, depth: 4
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_10+392);
	gf2x_add(24, p_00+364, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_11+392);
	gf2x_add(24, p_01+364, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_10+392);
	gf2x_add(24, p_10+364, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_11+392);
	gf2x_add(24, p_11+364, 24, temp, 24, temp2);
	
	// Calculating left operands: n: 3012, depth: 3
	GF2X_MUL(48, temp, 24, f_sum+957, 24, p_00+364);
	GF2X_MUL(48, temp2, 24, g_sum+957, 24, p_01+364);
	gf2x_add(48, f_sum+1089, 48, temp, 48, temp2);
	GF2X_MUL(48, temp, 24, f_sum+933, 24, p_00+364);
	GF2X_MUL(48, temp2, 24, g_sum+933, 24, p_01+364);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, f_sum+1089, 24, f_sum+1089, 24, temp+24);
	right_bit_shift_n(48, f_sum+1089, 58);
	GF2X_MUL(48, temp, 24, f_sum+957, 24, p_10+364);
	GF2X_MUL(48, temp2, 24, g_sum+957, 24, p_11+364);
	gf2x_add(48, g_sum+1089, 48, temp, 48, temp2);
	GF2X_MUL(48, temp, 24, f_sum+933, 24, p_10+364);
	GF2X_MUL(48, temp2, 24, g_sum+933, 24, p_11+364);
	gf2x_add(48, temp, 48, temp, 48, temp2);
	gf2x_add(24, g_sum+1089, 24, g_sum+1089, 24, temp+24);
	right_bit_shift_n(48, g_sum+1089, 58);
	
	delta = divstepsx_256(255, delta, f_sum+1110, g_sum+1110, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1110, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1110, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1106, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1106, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1110, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1110, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1106, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1106, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1106, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1106, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1102);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1102);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1106, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1106, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1102);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1102);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 765, depth: 5
	memset(p_00+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, p_00+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+392, 8, p_00+392, 8, temp);
	memset(p_01+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, p_01+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+392, 8, p_01+392, 8, temp);
	memset(p_10+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, p_10+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+392, 8, p_10+392, 8, temp);
	memset(p_11+392, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, p_11+396, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+392, 8, p_11+392, 8, temp);
	
	// Calculating left operands: n: 1482, depth: 4
	GF2X_MUL(24, temp, 12, f_sum+1102, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+1102, 12, p_01+392);
	gf2x_add(24, f_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+1090, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, g_sum+1090, 12, p_01+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+1170, 12, f_sum+1170, 12, temp+12);
	right_bit_shift_n(24, f_sum+1170, 61);
	GF2X_MUL(24, temp, 12, f_sum+1102, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+1102, 12, p_11+392);
	gf2x_add(24, g_sum+1170, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+1090, 12, p_10+392);
	GF2X_MUL(24, temp2, 12, g_sum+1090, 12, p_11+392);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+1170, 12, g_sum+1170, 12, temp+12);
	right_bit_shift_n(24, g_sum+1170, 61);
	
	delta = divstepsx_256(255, delta, f_sum+1179, g_sum+1179, p_00+416, p_01+416, p_10+416, p_11+416);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1179, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_01+416);
	gf2x_add(8, f_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_00+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_01+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1240, 4, f_sum+1240, 4, temp+4);
	right_bit_shift_n(8, f_sum+1240, 63);
	gf2x_mul_4_avx(temp, f_sum+1179, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1179, p_11+416);
	gf2x_add(8, g_sum+1240, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1175, p_10+416);
	gf2x_mul_4_avx(temp2, g_sum+1175, p_11+416);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1240, 4, g_sum+1240, 4, temp+4);
	right_bit_shift_n(8, g_sum+1240, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1241, g_sum+1241, q_00+403, q_01+403, q_10+403, q_11+403);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_10+416);
	gf2x_add(8, p_00+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_01+403, p_11+416);
	gf2x_add(8, p_01+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_00+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_10+416);
	gf2x_add(8, p_10+408, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+403, p_01+416);
	gf2x_mul_4_avx(temp2, q_11+403, p_11+416);
	gf2x_add(8, p_11+408, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 717, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1175, p_00+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_01+408);
	gf2x_add(12, f_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_01+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1215, 4, f_sum+1215, 4, temp+4);
	right_bit_shift_n(12, f_sum+1215, 62);
	gf2x_mul_8_avx(temp, f_sum+1175, p_10+408);
	gf2x_mul_8_avx(temp2, g_sum+1175, p_11+408);
	gf2x_add(12, g_sum+1215, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+412, f_sum+1171);
	gf2x_mul_4_avx(temp2, p_11+412, g_sum+1171);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1215, 4, g_sum+1215, 4, temp+4);
	right_bit_shift_n(12, g_sum+1215, 62);
	
	delta = divstepsx_256(207, delta, f_sum+1216, g_sum+1216, q_00+395, q_01+395, q_10+395, q_11+395);

	// Recombining results: n: 717, depth: 5
	memset(q_00+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_01+395);
	gf2x_add(8, q_00+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+383, 8, q_00+383, 8, temp);
	memset(q_01+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_00+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_01+395);
	gf2x_add(8, q_01+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_01+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+383, 8, q_01+383, 8, temp);
	memset(q_10+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_10+412, q_11+395);
	gf2x_add(8, q_10+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_00+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_10+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+383, 8, q_10+383, 8, temp);
	memset(q_11+383, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+412, q_10+395);
	gf2x_mul_4_avx(temp2, p_11+412, q_11+395);
	gf2x_add(8, q_11+387, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+395, p_01+408);
	gf2x_mul_4_avx(temp2, q_11+395, p_11+408);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+383, 8, q_11+383, 8, temp);
	
	// Recombining results: n: 1482, depth: 4
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_10+392);
	gf2x_add(24, q_00+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_01+383, 12, p_11+392);
	gf2x_add(24, q_01+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_00+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_10+392);
	gf2x_add(24, q_10+359, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+383, 12, p_01+392);
	GF2X_MUL(24, temp2, 12, q_11+383, 12, p_11+392);
	gf2x_add(24, q_11+359, 24, temp, 24, temp2);
	
	// Recombining results: n: 3012, depth: 3
	GF2X_MUL(48, temp, 24, q_00+359, 24, p_00+364);
	GF2X_MUL(48, temp2, 24, q_01+359, 24, p_10+364);
	gf2x_add(48, q_00+307, 48, temp, 48, temp2);
	GF2X_MUL(48, temp, 24, q_00+359, 24, p_01+364);
	GF2X_MUL(48, temp2, 24, q_01+359, 24, p_11+364);
	gf2x_add(48, q_01+307, 48, temp, 48, temp2);
	GF2X_MUL(48, temp, 24, q_10+359, 24, p_00+364);
	GF2X_MUL(48, temp2, 24, q_11+359, 24, p_10+364);
	gf2x_add(48, q_10+307, 48, temp, 48, temp2);
	GF2X_MUL(48, temp, 24, q_10+359, 24, p_01+364);
	GF2X_MUL(48, temp2, 24, q_11+359, 24, p_11+364);
	gf2x_add(48, q_11+307, 48, temp, 48, temp2);
	
	// Recombining results: n: 6327, depth: 2
	memset(q_00+203, 0x00, 3*DIGIT_SIZE_B);
	GF2X_MUL(96, temp, 48, p_00+316, 48, q_00+307);
	GF2X_MUL(96, temp2, 48, p_10+316, 48, q_01+307);
	gf2x_add(96, q_00+206, 96, temp, 96, temp2);
	gf2x_mul_4_avx(temp, q_00+351, p_00+312);
	gf2x_mul_4_avx(temp2, q_01+351, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+246, 8, q_00+246, 8, temp);
	gf2x_mul_4_avx(temp, q_00+347, p_00+312);
	gf2x_mul_4_avx(temp2, q_01+347, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+242, 8, q_00+242, 8, temp);
	gf2x_mul_4_avx(temp, q_00+343, p_00+312);
	gf2x_mul_4_avx(temp2, q_01+343, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+238, 8, q_00+238, 8, temp);
	gf2x_mul_4_avx(temp, q_00+339, p_00+312);
	gf2x_mul_4_avx(temp2, q_01+339, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+234, 8, q_00+234, 8, temp);
	gf2x_mul_4_avx(temp, q_00+335, p_00+312);
	gf2x_mul_4_avx(temp2, q_01+335, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+230, 8, q_00+230, 8, temp);
	gf2x_mul_4_avx(temp, q_00+331, p_00+312);
	gf2x_mul_4_avx(temp2, q_01+331, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+226, 8, q_00+226, 8, temp);
	gf2x_mul_4_avx(temp, q_00+327, p_00+312);
	gf2x_mul_4_avx(temp2, q_01+327, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+222, 8, q_00+222, 8, temp);
	gf2x_mul_4_avx(temp, q_00+323, p_00+312);
	gf2x_mul_4_avx(temp2, q_01+323, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+218, 8, q_00+218, 8, temp);
	gf2x_mul_4_avx(temp, q_00+319, p_00+312);
	gf2x_mul_4_avx(temp2, q_01+319, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+214, 8, q_00+214, 8, temp);
	gf2x_mul_4_avx(temp, q_00+315, p_00+312);
	gf2x_mul_4_avx(temp2, q_01+315, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+210, 8, q_00+210, 8, temp);
	gf2x_mul_4_avx(temp, q_00+311, p_00+312);
	gf2x_mul_4_avx(temp2, q_01+311, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+206, 8, q_00+206, 8, temp);
	gf2x_mul_4_avx(temp, q_00+307, p_00+312);
	gf2x_mul_4_avx(temp2, q_01+307, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(7, q_00+203, 7, q_00+203, 7, temp+1);
	memset(q_01+203, 0x00, 3*DIGIT_SIZE_B);
	GF2X_MUL(96, temp, 48, p_01+316, 48, q_00+307);
	GF2X_MUL(96, temp2, 48, p_11+316, 48, q_01+307);
	gf2x_add(96, q_01+206, 96, temp, 96, temp2);
	gf2x_mul_4_avx(temp, q_00+351, p_01+312);
	gf2x_mul_4_avx(temp2, q_01+351, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+246, 8, q_01+246, 8, temp);
	gf2x_mul_4_avx(temp, q_00+347, p_01+312);
	gf2x_mul_4_avx(temp2, q_01+347, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+242, 8, q_01+242, 8, temp);
	gf2x_mul_4_avx(temp, q_00+343, p_01+312);
	gf2x_mul_4_avx(temp2, q_01+343, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+238, 8, q_01+238, 8, temp);
	gf2x_mul_4_avx(temp, q_00+339, p_01+312);
	gf2x_mul_4_avx(temp2, q_01+339, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+234, 8, q_01+234, 8, temp);
	gf2x_mul_4_avx(temp, q_00+335, p_01+312);
	gf2x_mul_4_avx(temp2, q_01+335, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+230, 8, q_01+230, 8, temp);
	gf2x_mul_4_avx(temp, q_00+331, p_01+312);
	gf2x_mul_4_avx(temp2, q_01+331, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+226, 8, q_01+226, 8, temp);
	gf2x_mul_4_avx(temp, q_00+327, p_01+312);
	gf2x_mul_4_avx(temp2, q_01+327, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+222, 8, q_01+222, 8, temp);
	gf2x_mul_4_avx(temp, q_00+323, p_01+312);
	gf2x_mul_4_avx(temp2, q_01+323, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+218, 8, q_01+218, 8, temp);
	gf2x_mul_4_avx(temp, q_00+319, p_01+312);
	gf2x_mul_4_avx(temp2, q_01+319, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+214, 8, q_01+214, 8, temp);
	gf2x_mul_4_avx(temp, q_00+315, p_01+312);
	gf2x_mul_4_avx(temp2, q_01+315, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+210, 8, q_01+210, 8, temp);
	gf2x_mul_4_avx(temp, q_00+311, p_01+312);
	gf2x_mul_4_avx(temp2, q_01+311, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+206, 8, q_01+206, 8, temp);
	gf2x_mul_4_avx(temp, q_00+307, p_01+312);
	gf2x_mul_4_avx(temp2, q_01+307, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(7, q_01+203, 7, q_01+203, 7, temp+1);
	memset(q_10+203, 0x00, 3*DIGIT_SIZE_B);
	GF2X_MUL(96, temp, 48, p_00+316, 48, q_10+307);
	GF2X_MUL(96, temp2, 48, p_10+316, 48, q_11+307);
	gf2x_add(96, q_10+206, 96, temp, 96, temp2);
	gf2x_mul_4_avx(temp, q_10+351, p_00+312);
	gf2x_mul_4_avx(temp2, q_11+351, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+246, 8, q_10+246, 8, temp);
	gf2x_mul_4_avx(temp, q_10+347, p_00+312);
	gf2x_mul_4_avx(temp2, q_11+347, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+242, 8, q_10+242, 8, temp);
	gf2x_mul_4_avx(temp, q_10+343, p_00+312);
	gf2x_mul_4_avx(temp2, q_11+343, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+238, 8, q_10+238, 8, temp);
	gf2x_mul_4_avx(temp, q_10+339, p_00+312);
	gf2x_mul_4_avx(temp2, q_11+339, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+234, 8, q_10+234, 8, temp);
	gf2x_mul_4_avx(temp, q_10+335, p_00+312);
	gf2x_mul_4_avx(temp2, q_11+335, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+230, 8, q_10+230, 8, temp);
	gf2x_mul_4_avx(temp, q_10+331, p_00+312);
	gf2x_mul_4_avx(temp2, q_11+331, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+226, 8, q_10+226, 8, temp);
	gf2x_mul_4_avx(temp, q_10+327, p_00+312);
	gf2x_mul_4_avx(temp2, q_11+327, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+222, 8, q_10+222, 8, temp);
	gf2x_mul_4_avx(temp, q_10+323, p_00+312);
	gf2x_mul_4_avx(temp2, q_11+323, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+218, 8, q_10+218, 8, temp);
	gf2x_mul_4_avx(temp, q_10+319, p_00+312);
	gf2x_mul_4_avx(temp2, q_11+319, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+214, 8, q_10+214, 8, temp);
	gf2x_mul_4_avx(temp, q_10+315, p_00+312);
	gf2x_mul_4_avx(temp2, q_11+315, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+210, 8, q_10+210, 8, temp);
	gf2x_mul_4_avx(temp, q_10+311, p_00+312);
	gf2x_mul_4_avx(temp2, q_11+311, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+206, 8, q_10+206, 8, temp);
	gf2x_mul_4_avx(temp, q_10+307, p_00+312);
	gf2x_mul_4_avx(temp2, q_11+307, p_10+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(7, q_10+203, 7, q_10+203, 7, temp+1);
	memset(q_11+203, 0x00, 3*DIGIT_SIZE_B);
	GF2X_MUL(96, temp, 48, p_01+316, 48, q_10+307);
	GF2X_MUL(96, temp2, 48, p_11+316, 48, q_11+307);
	gf2x_add(96, q_11+206, 96, temp, 96, temp2);
	gf2x_mul_4_avx(temp, q_10+351, p_01+312);
	gf2x_mul_4_avx(temp2, q_11+351, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+246, 8, q_11+246, 8, temp);
	gf2x_mul_4_avx(temp, q_10+347, p_01+312);
	gf2x_mul_4_avx(temp2, q_11+347, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+242, 8, q_11+242, 8, temp);
	gf2x_mul_4_avx(temp, q_10+343, p_01+312);
	gf2x_mul_4_avx(temp2, q_11+343, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+238, 8, q_11+238, 8, temp);
	gf2x_mul_4_avx(temp, q_10+339, p_01+312);
	gf2x_mul_4_avx(temp2, q_11+339, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+234, 8, q_11+234, 8, temp);
	gf2x_mul_4_avx(temp, q_10+335, p_01+312);
	gf2x_mul_4_avx(temp2, q_11+335, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+230, 8, q_11+230, 8, temp);
	gf2x_mul_4_avx(temp, q_10+331, p_01+312);
	gf2x_mul_4_avx(temp2, q_11+331, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+226, 8, q_11+226, 8, temp);
	gf2x_mul_4_avx(temp, q_10+327, p_01+312);
	gf2x_mul_4_avx(temp2, q_11+327, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+222, 8, q_11+222, 8, temp);
	gf2x_mul_4_avx(temp, q_10+323, p_01+312);
	gf2x_mul_4_avx(temp2, q_11+323, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+218, 8, q_11+218, 8, temp);
	gf2x_mul_4_avx(temp, q_10+319, p_01+312);
	gf2x_mul_4_avx(temp2, q_11+319, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+214, 8, q_11+214, 8, temp);
	gf2x_mul_4_avx(temp, q_10+315, p_01+312);
	gf2x_mul_4_avx(temp2, q_11+315, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+210, 8, q_11+210, 8, temp);
	gf2x_mul_4_avx(temp, q_10+311, p_01+312);
	gf2x_mul_4_avx(temp2, q_11+311, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+206, 8, q_11+206, 8, temp);
	gf2x_mul_4_avx(temp, q_10+307, p_01+312);
	gf2x_mul_4_avx(temp2, q_11+307, p_11+312);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(7, q_11+203, 7, q_11+203, 7, temp+1);
	
	// Recombining results: n: 12957, depth: 1
	memset(q_00+0, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(198, temp, 99, p_00+213, 99, q_00+203);
	GF2X_MUL(198, temp2, 99, p_10+213, 99, q_01+203);
	gf2x_add(198, q_00+5, 198, temp, 198, temp2);
	gf2x_mul_5_avx(temp, q_00+297, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+297, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+94, 10, q_00+94, 10, temp);
	gf2x_mul_5_avx(temp, q_00+292, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+292, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+89, 10, q_00+89, 10, temp);
	gf2x_mul_5_avx(temp, q_00+287, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+287, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+84, 10, q_00+84, 10, temp);
	gf2x_mul_5_avx(temp, q_00+282, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+282, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+79, 10, q_00+79, 10, temp);
	gf2x_mul_5_avx(temp, q_00+277, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+277, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+74, 10, q_00+74, 10, temp);
	gf2x_mul_5_avx(temp, q_00+272, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+272, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+69, 10, q_00+69, 10, temp);
	gf2x_mul_5_avx(temp, q_00+267, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+267, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+64, 10, q_00+64, 10, temp);
	gf2x_mul_5_avx(temp, q_00+262, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+262, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+59, 10, q_00+59, 10, temp);
	gf2x_mul_5_avx(temp, q_00+257, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+257, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+54, 10, q_00+54, 10, temp);
	gf2x_mul_5_avx(temp, q_00+252, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+252, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+49, 10, q_00+49, 10, temp);
	gf2x_mul_5_avx(temp, q_00+247, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+247, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+44, 10, q_00+44, 10, temp);
	gf2x_mul_5_avx(temp, q_00+242, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+242, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+39, 10, q_00+39, 10, temp);
	gf2x_mul_5_avx(temp, q_00+237, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+237, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+34, 10, q_00+34, 10, temp);
	gf2x_mul_5_avx(temp, q_00+232, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+232, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+29, 10, q_00+29, 10, temp);
	gf2x_mul_5_avx(temp, q_00+227, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+227, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+24, 10, q_00+24, 10, temp);
	gf2x_mul_5_avx(temp, q_00+222, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+222, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+19, 10, q_00+19, 10, temp);
	gf2x_mul_5_avx(temp, q_00+217, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+217, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+14, 10, q_00+14, 10, temp);
	gf2x_mul_5_avx(temp, q_00+212, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+212, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+9, 10, q_00+9, 10, temp);
	gf2x_mul_5_avx(temp, q_00+207, p_00+208);
	gf2x_mul_5_avx(temp2, q_01+207, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+4, 10, q_00+4, 10, temp);
	gf2x_mul_4_avx(temp, p_00+209, q_00+203);
	gf2x_mul_4_avx(temp2, p_10+209, q_01+203);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1, 8, q_00+1, 8, temp);
	gf2x_mul_1_avx(temp, q_00+206, p_00+208);
	gf2x_mul_1_avx(temp2, q_01+206, p_10+208);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+3, 2, q_00+3, 2, temp);
	gf2x_mul_1_avx(temp, q_00+205, p_00+208);
	gf2x_mul_1_avx(temp2, q_01+205, p_10+208);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+2, 2, q_00+2, 2, temp);
	gf2x_mul_1_avx(temp, q_00+204, p_00+208);
	gf2x_mul_1_avx(temp2, q_01+204, p_10+208);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1, 2, q_00+1, 2, temp);
	gf2x_mul_1_avx(temp, q_00+203, p_00+208);
	gf2x_mul_1_avx(temp2, q_01+203, p_10+208);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+0, 2, q_00+0, 2, temp);
	memset(q_01+0, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(198, temp, 99, p_01+213, 99, q_00+203);
	GF2X_MUL(198, temp2, 99, p_11+213, 99, q_01+203);
	gf2x_add(198, q_01+5, 198, temp, 198, temp2);
	gf2x_mul_5_avx(temp, q_00+297, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+297, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+94, 10, q_01+94, 10, temp);
	gf2x_mul_5_avx(temp, q_00+292, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+292, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+89, 10, q_01+89, 10, temp);
	gf2x_mul_5_avx(temp, q_00+287, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+287, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+84, 10, q_01+84, 10, temp);
	gf2x_mul_5_avx(temp, q_00+282, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+282, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+79, 10, q_01+79, 10, temp);
	gf2x_mul_5_avx(temp, q_00+277, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+277, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+74, 10, q_01+74, 10, temp);
	gf2x_mul_5_avx(temp, q_00+272, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+272, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+69, 10, q_01+69, 10, temp);
	gf2x_mul_5_avx(temp, q_00+267, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+267, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+64, 10, q_01+64, 10, temp);
	gf2x_mul_5_avx(temp, q_00+262, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+262, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+59, 10, q_01+59, 10, temp);
	gf2x_mul_5_avx(temp, q_00+257, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+257, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+54, 10, q_01+54, 10, temp);
	gf2x_mul_5_avx(temp, q_00+252, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+252, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+49, 10, q_01+49, 10, temp);
	gf2x_mul_5_avx(temp, q_00+247, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+247, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+44, 10, q_01+44, 10, temp);
	gf2x_mul_5_avx(temp, q_00+242, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+242, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+39, 10, q_01+39, 10, temp);
	gf2x_mul_5_avx(temp, q_00+237, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+237, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+34, 10, q_01+34, 10, temp);
	gf2x_mul_5_avx(temp, q_00+232, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+232, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+29, 10, q_01+29, 10, temp);
	gf2x_mul_5_avx(temp, q_00+227, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+227, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+24, 10, q_01+24, 10, temp);
	gf2x_mul_5_avx(temp, q_00+222, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+222, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+19, 10, q_01+19, 10, temp);
	gf2x_mul_5_avx(temp, q_00+217, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+217, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+14, 10, q_01+14, 10, temp);
	gf2x_mul_5_avx(temp, q_00+212, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+212, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+9, 10, q_01+9, 10, temp);
	gf2x_mul_5_avx(temp, q_00+207, p_01+208);
	gf2x_mul_5_avx(temp2, q_01+207, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+4, 10, q_01+4, 10, temp);
	gf2x_mul_4_avx(temp, p_01+209, q_00+203);
	gf2x_mul_4_avx(temp2, p_11+209, q_01+203);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1, 8, q_01+1, 8, temp);
	gf2x_mul_1_avx(temp, q_00+206, p_01+208);
	gf2x_mul_1_avx(temp2, q_01+206, p_11+208);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+3, 2, q_01+3, 2, temp);
	gf2x_mul_1_avx(temp, q_00+205, p_01+208);
	gf2x_mul_1_avx(temp2, q_01+205, p_11+208);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+2, 2, q_01+2, 2, temp);
	gf2x_mul_1_avx(temp, q_00+204, p_01+208);
	gf2x_mul_1_avx(temp2, q_01+204, p_11+208);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1, 2, q_01+1, 2, temp);
	gf2x_mul_1_avx(temp, q_00+203, p_01+208);
	gf2x_mul_1_avx(temp2, q_01+203, p_11+208);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+0, 2, q_01+0, 2, temp);
	memset(q_10+0, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(198, temp, 99, p_00+213, 99, q_10+203);
	GF2X_MUL(198, temp2, 99, p_10+213, 99, q_11+203);
	gf2x_add(198, q_10+5, 198, temp, 198, temp2);
	gf2x_mul_5_avx(temp, q_10+297, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+297, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+94, 10, q_10+94, 10, temp);
	gf2x_mul_5_avx(temp, q_10+292, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+292, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+89, 10, q_10+89, 10, temp);
	gf2x_mul_5_avx(temp, q_10+287, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+287, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+84, 10, q_10+84, 10, temp);
	gf2x_mul_5_avx(temp, q_10+282, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+282, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+79, 10, q_10+79, 10, temp);
	gf2x_mul_5_avx(temp, q_10+277, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+277, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+74, 10, q_10+74, 10, temp);
	gf2x_mul_5_avx(temp, q_10+272, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+272, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+69, 10, q_10+69, 10, temp);
	gf2x_mul_5_avx(temp, q_10+267, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+267, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+64, 10, q_10+64, 10, temp);
	gf2x_mul_5_avx(temp, q_10+262, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+262, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+59, 10, q_10+59, 10, temp);
	gf2x_mul_5_avx(temp, q_10+257, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+257, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+54, 10, q_10+54, 10, temp);
	gf2x_mul_5_avx(temp, q_10+252, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+252, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+49, 10, q_10+49, 10, temp);
	gf2x_mul_5_avx(temp, q_10+247, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+247, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+44, 10, q_10+44, 10, temp);
	gf2x_mul_5_avx(temp, q_10+242, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+242, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+39, 10, q_10+39, 10, temp);
	gf2x_mul_5_avx(temp, q_10+237, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+237, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+34, 10, q_10+34, 10, temp);
	gf2x_mul_5_avx(temp, q_10+232, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+232, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+29, 10, q_10+29, 10, temp);
	gf2x_mul_5_avx(temp, q_10+227, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+227, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+24, 10, q_10+24, 10, temp);
	gf2x_mul_5_avx(temp, q_10+222, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+222, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+19, 10, q_10+19, 10, temp);
	gf2x_mul_5_avx(temp, q_10+217, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+217, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+14, 10, q_10+14, 10, temp);
	gf2x_mul_5_avx(temp, q_10+212, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+212, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+9, 10, q_10+9, 10, temp);
	gf2x_mul_5_avx(temp, q_10+207, p_00+208);
	gf2x_mul_5_avx(temp2, q_11+207, p_10+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+4, 10, q_10+4, 10, temp);
	gf2x_mul_4_avx(temp, p_00+209, q_10+203);
	gf2x_mul_4_avx(temp2, p_10+209, q_11+203);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1, 8, q_10+1, 8, temp);
	gf2x_mul_1_avx(temp, q_10+206, p_00+208);
	gf2x_mul_1_avx(temp2, q_11+206, p_10+208);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+3, 2, q_10+3, 2, temp);
	gf2x_mul_1_avx(temp, q_10+205, p_00+208);
	gf2x_mul_1_avx(temp2, q_11+205, p_10+208);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+2, 2, q_10+2, 2, temp);
	gf2x_mul_1_avx(temp, q_10+204, p_00+208);
	gf2x_mul_1_avx(temp2, q_11+204, p_10+208);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1, 2, q_10+1, 2, temp);
	gf2x_mul_1_avx(temp, q_10+203, p_00+208);
	gf2x_mul_1_avx(temp2, q_11+203, p_10+208);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+0, 2, q_10+0, 2, temp);
	memset(q_11+0, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(198, temp, 99, p_01+213, 99, q_10+203);
	GF2X_MUL(198, temp2, 99, p_11+213, 99, q_11+203);
	gf2x_add(198, q_11+5, 198, temp, 198, temp2);
	gf2x_mul_5_avx(temp, q_10+297, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+297, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+94, 10, q_11+94, 10, temp);
	gf2x_mul_5_avx(temp, q_10+292, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+292, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+89, 10, q_11+89, 10, temp);
	gf2x_mul_5_avx(temp, q_10+287, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+287, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+84, 10, q_11+84, 10, temp);
	gf2x_mul_5_avx(temp, q_10+282, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+282, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+79, 10, q_11+79, 10, temp);
	gf2x_mul_5_avx(temp, q_10+277, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+277, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+74, 10, q_11+74, 10, temp);
	gf2x_mul_5_avx(temp, q_10+272, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+272, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+69, 10, q_11+69, 10, temp);
	gf2x_mul_5_avx(temp, q_10+267, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+267, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+64, 10, q_11+64, 10, temp);
	gf2x_mul_5_avx(temp, q_10+262, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+262, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+59, 10, q_11+59, 10, temp);
	gf2x_mul_5_avx(temp, q_10+257, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+257, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+54, 10, q_11+54, 10, temp);
	gf2x_mul_5_avx(temp, q_10+252, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+252, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+49, 10, q_11+49, 10, temp);
	gf2x_mul_5_avx(temp, q_10+247, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+247, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+44, 10, q_11+44, 10, temp);
	gf2x_mul_5_avx(temp, q_10+242, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+242, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+39, 10, q_11+39, 10, temp);
	gf2x_mul_5_avx(temp, q_10+237, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+237, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+34, 10, q_11+34, 10, temp);
	gf2x_mul_5_avx(temp, q_10+232, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+232, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+29, 10, q_11+29, 10, temp);
	gf2x_mul_5_avx(temp, q_10+227, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+227, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+24, 10, q_11+24, 10, temp);
	gf2x_mul_5_avx(temp, q_10+222, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+222, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+19, 10, q_11+19, 10, temp);
	gf2x_mul_5_avx(temp, q_10+217, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+217, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+14, 10, q_11+14, 10, temp);
	gf2x_mul_5_avx(temp, q_10+212, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+212, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+9, 10, q_11+9, 10, temp);
	gf2x_mul_5_avx(temp, q_10+207, p_01+208);
	gf2x_mul_5_avx(temp2, q_11+207, p_11+208);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+4, 10, q_11+4, 10, temp);
	gf2x_mul_4_avx(temp, p_01+209, q_10+203);
	gf2x_mul_4_avx(temp2, p_11+209, q_11+203);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1, 8, q_11+1, 8, temp);
	gf2x_mul_1_avx(temp, q_10+206, p_01+208);
	gf2x_mul_1_avx(temp2, q_11+206, p_11+208);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+3, 2, q_11+3, 2, temp);
	gf2x_mul_1_avx(temp, q_10+205, p_01+208);
	gf2x_mul_1_avx(temp2, q_11+205, p_11+208);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+2, 2, q_11+2, 2, temp);
	gf2x_mul_1_avx(temp, q_10+204, p_01+208);
	gf2x_mul_1_avx(temp2, q_11+204, p_11+208);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1, 2, q_11+1, 2, temp);
	gf2x_mul_1_avx(temp, q_10+203, p_01+208);
	gf2x_mul_1_avx(temp2, q_11+203, p_11+208);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+0, 2, q_11+0, 2, temp);
	
	// Recombining results: n: 26217, depth: 0
	memset(t_00+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(406, temp, 203, p_00+5, 203, q_00+0);
	GF2X_MUL(406, temp2, 203, p_10+5, 203, q_01+0);
	gf2x_add(406, t_00+4, 406, temp, 406, temp2);
	gf2x_mul_5_avx(temp, q_00+198, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+198, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+197, 10, t_00+197, 10, temp);
	gf2x_mul_5_avx(temp, q_00+193, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+193, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+192, 10, t_00+192, 10, temp);
	gf2x_mul_5_avx(temp, q_00+188, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+188, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+187, 10, t_00+187, 10, temp);
	gf2x_mul_5_avx(temp, q_00+183, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+183, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+182, 10, t_00+182, 10, temp);
	gf2x_mul_5_avx(temp, q_00+178, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+178, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+177, 10, t_00+177, 10, temp);
	gf2x_mul_5_avx(temp, q_00+173, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+173, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+172, 10, t_00+172, 10, temp);
	gf2x_mul_5_avx(temp, q_00+168, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+168, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+167, 10, t_00+167, 10, temp);
	gf2x_mul_5_avx(temp, q_00+163, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+163, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+162, 10, t_00+162, 10, temp);
	gf2x_mul_5_avx(temp, q_00+158, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+158, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+157, 10, t_00+157, 10, temp);
	gf2x_mul_5_avx(temp, q_00+153, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+153, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+152, 10, t_00+152, 10, temp);
	gf2x_mul_5_avx(temp, q_00+148, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+148, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+147, 10, t_00+147, 10, temp);
	gf2x_mul_5_avx(temp, q_00+143, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+143, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+142, 10, t_00+142, 10, temp);
	gf2x_mul_5_avx(temp, q_00+138, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+138, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+137, 10, t_00+137, 10, temp);
	gf2x_mul_5_avx(temp, q_00+133, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+133, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+132, 10, t_00+132, 10, temp);
	gf2x_mul_5_avx(temp, q_00+128, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+128, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+127, 10, t_00+127, 10, temp);
	gf2x_mul_5_avx(temp, q_00+123, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+123, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+122, 10, t_00+122, 10, temp);
	gf2x_mul_5_avx(temp, q_00+118, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+118, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+117, 10, t_00+117, 10, temp);
	gf2x_mul_5_avx(temp, q_00+113, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+113, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+112, 10, t_00+112, 10, temp);
	gf2x_mul_5_avx(temp, q_00+108, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+108, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+107, 10, t_00+107, 10, temp);
	gf2x_mul_5_avx(temp, q_00+103, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+103, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+102, 10, t_00+102, 10, temp);
	gf2x_mul_5_avx(temp, q_00+98, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+98, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+97, 10, t_00+97, 10, temp);
	gf2x_mul_5_avx(temp, q_00+93, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+93, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+92, 10, t_00+92, 10, temp);
	gf2x_mul_5_avx(temp, q_00+88, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+88, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+87, 10, t_00+87, 10, temp);
	gf2x_mul_5_avx(temp, q_00+83, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+83, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+82, 10, t_00+82, 10, temp);
	gf2x_mul_5_avx(temp, q_00+78, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+78, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+77, 10, t_00+77, 10, temp);
	gf2x_mul_5_avx(temp, q_00+73, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+73, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+72, 10, t_00+72, 10, temp);
	gf2x_mul_5_avx(temp, q_00+68, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+68, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+67, 10, t_00+67, 10, temp);
	gf2x_mul_5_avx(temp, q_00+63, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+63, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+62, 10, t_00+62, 10, temp);
	gf2x_mul_5_avx(temp, q_00+58, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+58, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+57, 10, t_00+57, 10, temp);
	gf2x_mul_5_avx(temp, q_00+53, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+53, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+52, 10, t_00+52, 10, temp);
	gf2x_mul_5_avx(temp, q_00+48, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+48, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+47, 10, t_00+47, 10, temp);
	gf2x_mul_5_avx(temp, q_00+43, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+43, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+42, 10, t_00+42, 10, temp);
	gf2x_mul_5_avx(temp, q_00+38, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+38, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+37, 10, t_00+37, 10, temp);
	gf2x_mul_5_avx(temp, q_00+33, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+33, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+32, 10, t_00+32, 10, temp);
	gf2x_mul_5_avx(temp, q_00+28, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+28, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+27, 10, t_00+27, 10, temp);
	gf2x_mul_5_avx(temp, q_00+23, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+23, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+22, 10, t_00+22, 10, temp);
	gf2x_mul_5_avx(temp, q_00+18, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+18, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+17, 10, t_00+17, 10, temp);
	gf2x_mul_5_avx(temp, q_00+13, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+13, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+12, 10, t_00+12, 10, temp);
	gf2x_mul_5_avx(temp, q_00+8, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+8, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+7, 10, t_00+7, 10, temp);
	gf2x_mul_5_avx(temp, q_00+3, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+3, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+2, 10, t_00+2, 10, temp);
	gf2x_mul_3_avx(temp, p_00+2, q_00+0);
	gf2x_mul_3_avx(temp2, p_10+2, q_01+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+1, 6, t_00+1, 6, temp);
	gf2x_mul_2_avx(temp, q_00+1, p_00+0);
	gf2x_mul_2_avx(temp2, q_01+1, p_10+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_00+0, 4, t_00+0, 4, temp);
	gf2x_mul_1_avx(temp, p_00+1, q_00+0);
	gf2x_mul_1_avx(temp2, p_10+1, q_01+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, t_00+0, 2, t_00+0, 2, temp);
	gf2x_mul_1_avx(temp, q_00+0, p_00+0);
	gf2x_mul_1_avx(temp2, q_01+0, p_10+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, t_00+0, 1, t_00+0, 1, temp+1);
	memset(t_01+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(406, temp, 203, p_01+5, 203, q_00+0);
	GF2X_MUL(406, temp2, 203, p_11+5, 203, q_01+0);
	gf2x_add(406, t_01+4, 406, temp, 406, temp2);
	gf2x_mul_5_avx(temp, q_00+198, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+198, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+197, 10, t_01+197, 10, temp);
	gf2x_mul_5_avx(temp, q_00+193, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+193, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+192, 10, t_01+192, 10, temp);
	gf2x_mul_5_avx(temp, q_00+188, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+188, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+187, 10, t_01+187, 10, temp);
	gf2x_mul_5_avx(temp, q_00+183, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+183, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+182, 10, t_01+182, 10, temp);
	gf2x_mul_5_avx(temp, q_00+178, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+178, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+177, 10, t_01+177, 10, temp);
	gf2x_mul_5_avx(temp, q_00+173, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+173, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+172, 10, t_01+172, 10, temp);
	gf2x_mul_5_avx(temp, q_00+168, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+168, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+167, 10, t_01+167, 10, temp);
	gf2x_mul_5_avx(temp, q_00+163, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+163, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+162, 10, t_01+162, 10, temp);
	gf2x_mul_5_avx(temp, q_00+158, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+158, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+157, 10, t_01+157, 10, temp);
	gf2x_mul_5_avx(temp, q_00+153, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+153, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+152, 10, t_01+152, 10, temp);
	gf2x_mul_5_avx(temp, q_00+148, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+148, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+147, 10, t_01+147, 10, temp);
	gf2x_mul_5_avx(temp, q_00+143, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+143, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+142, 10, t_01+142, 10, temp);
	gf2x_mul_5_avx(temp, q_00+138, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+138, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+137, 10, t_01+137, 10, temp);
	gf2x_mul_5_avx(temp, q_00+133, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+133, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+132, 10, t_01+132, 10, temp);
	gf2x_mul_5_avx(temp, q_00+128, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+128, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+127, 10, t_01+127, 10, temp);
	gf2x_mul_5_avx(temp, q_00+123, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+123, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+122, 10, t_01+122, 10, temp);
	gf2x_mul_5_avx(temp, q_00+118, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+118, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+117, 10, t_01+117, 10, temp);
	gf2x_mul_5_avx(temp, q_00+113, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+113, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+112, 10, t_01+112, 10, temp);
	gf2x_mul_5_avx(temp, q_00+108, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+108, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+107, 10, t_01+107, 10, temp);
	gf2x_mul_5_avx(temp, q_00+103, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+103, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+102, 10, t_01+102, 10, temp);
	gf2x_mul_5_avx(temp, q_00+98, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+98, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+97, 10, t_01+97, 10, temp);
	gf2x_mul_5_avx(temp, q_00+93, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+93, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+92, 10, t_01+92, 10, temp);
	gf2x_mul_5_avx(temp, q_00+88, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+88, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+87, 10, t_01+87, 10, temp);
	gf2x_mul_5_avx(temp, q_00+83, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+83, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+82, 10, t_01+82, 10, temp);
	gf2x_mul_5_avx(temp, q_00+78, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+78, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+77, 10, t_01+77, 10, temp);
	gf2x_mul_5_avx(temp, q_00+73, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+73, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+72, 10, t_01+72, 10, temp);
	gf2x_mul_5_avx(temp, q_00+68, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+68, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+67, 10, t_01+67, 10, temp);
	gf2x_mul_5_avx(temp, q_00+63, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+63, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+62, 10, t_01+62, 10, temp);
	gf2x_mul_5_avx(temp, q_00+58, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+58, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+57, 10, t_01+57, 10, temp);
	gf2x_mul_5_avx(temp, q_00+53, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+53, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+52, 10, t_01+52, 10, temp);
	gf2x_mul_5_avx(temp, q_00+48, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+48, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+47, 10, t_01+47, 10, temp);
	gf2x_mul_5_avx(temp, q_00+43, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+43, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+42, 10, t_01+42, 10, temp);
	gf2x_mul_5_avx(temp, q_00+38, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+38, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+37, 10, t_01+37, 10, temp);
	gf2x_mul_5_avx(temp, q_00+33, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+33, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+32, 10, t_01+32, 10, temp);
	gf2x_mul_5_avx(temp, q_00+28, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+28, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+27, 10, t_01+27, 10, temp);
	gf2x_mul_5_avx(temp, q_00+23, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+23, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+22, 10, t_01+22, 10, temp);
	gf2x_mul_5_avx(temp, q_00+18, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+18, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+17, 10, t_01+17, 10, temp);
	gf2x_mul_5_avx(temp, q_00+13, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+13, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+12, 10, t_01+12, 10, temp);
	gf2x_mul_5_avx(temp, q_00+8, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+8, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+7, 10, t_01+7, 10, temp);
	gf2x_mul_5_avx(temp, q_00+3, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+3, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+2, 10, t_01+2, 10, temp);
	gf2x_mul_3_avx(temp, p_01+2, q_00+0);
	gf2x_mul_3_avx(temp2, p_11+2, q_01+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+1, 6, t_01+1, 6, temp);
	gf2x_mul_2_avx(temp, q_00+1, p_01+0);
	gf2x_mul_2_avx(temp2, q_01+1, p_11+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_01+0, 4, t_01+0, 4, temp);
	gf2x_mul_1_avx(temp, p_01+1, q_00+0);
	gf2x_mul_1_avx(temp2, p_11+1, q_01+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, t_01+0, 2, t_01+0, 2, temp);
	gf2x_mul_1_avx(temp, q_00+0, p_01+0);
	gf2x_mul_1_avx(temp2, q_01+0, p_11+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, t_01+0, 1, t_01+0, 1, temp+1);
	memset(t_10+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(406, temp, 203, p_00+5, 203, q_10+0);
	GF2X_MUL(406, temp2, 203, p_10+5, 203, q_11+0);
	gf2x_add(406, t_10+4, 406, temp, 406, temp2);
	gf2x_mul_5_avx(temp, q_10+198, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+198, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+197, 10, t_10+197, 10, temp);
	gf2x_mul_5_avx(temp, q_10+193, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+193, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+192, 10, t_10+192, 10, temp);
	gf2x_mul_5_avx(temp, q_10+188, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+188, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+187, 10, t_10+187, 10, temp);
	gf2x_mul_5_avx(temp, q_10+183, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+183, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+182, 10, t_10+182, 10, temp);
	gf2x_mul_5_avx(temp, q_10+178, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+178, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+177, 10, t_10+177, 10, temp);
	gf2x_mul_5_avx(temp, q_10+173, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+173, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+172, 10, t_10+172, 10, temp);
	gf2x_mul_5_avx(temp, q_10+168, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+168, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+167, 10, t_10+167, 10, temp);
	gf2x_mul_5_avx(temp, q_10+163, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+163, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+162, 10, t_10+162, 10, temp);
	gf2x_mul_5_avx(temp, q_10+158, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+158, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+157, 10, t_10+157, 10, temp);
	gf2x_mul_5_avx(temp, q_10+153, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+153, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+152, 10, t_10+152, 10, temp);
	gf2x_mul_5_avx(temp, q_10+148, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+148, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+147, 10, t_10+147, 10, temp);
	gf2x_mul_5_avx(temp, q_10+143, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+143, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+142, 10, t_10+142, 10, temp);
	gf2x_mul_5_avx(temp, q_10+138, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+138, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+137, 10, t_10+137, 10, temp);
	gf2x_mul_5_avx(temp, q_10+133, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+133, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+132, 10, t_10+132, 10, temp);
	gf2x_mul_5_avx(temp, q_10+128, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+128, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+127, 10, t_10+127, 10, temp);
	gf2x_mul_5_avx(temp, q_10+123, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+123, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+122, 10, t_10+122, 10, temp);
	gf2x_mul_5_avx(temp, q_10+118, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+118, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+117, 10, t_10+117, 10, temp);
	gf2x_mul_5_avx(temp, q_10+113, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+113, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+112, 10, t_10+112, 10, temp);
	gf2x_mul_5_avx(temp, q_10+108, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+108, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+107, 10, t_10+107, 10, temp);
	gf2x_mul_5_avx(temp, q_10+103, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+103, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+102, 10, t_10+102, 10, temp);
	gf2x_mul_5_avx(temp, q_10+98, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+98, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+97, 10, t_10+97, 10, temp);
	gf2x_mul_5_avx(temp, q_10+93, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+93, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+92, 10, t_10+92, 10, temp);
	gf2x_mul_5_avx(temp, q_10+88, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+88, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+87, 10, t_10+87, 10, temp);
	gf2x_mul_5_avx(temp, q_10+83, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+83, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+82, 10, t_10+82, 10, temp);
	gf2x_mul_5_avx(temp, q_10+78, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+78, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+77, 10, t_10+77, 10, temp);
	gf2x_mul_5_avx(temp, q_10+73, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+73, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+72, 10, t_10+72, 10, temp);
	gf2x_mul_5_avx(temp, q_10+68, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+68, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+67, 10, t_10+67, 10, temp);
	gf2x_mul_5_avx(temp, q_10+63, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+63, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+62, 10, t_10+62, 10, temp);
	gf2x_mul_5_avx(temp, q_10+58, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+58, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+57, 10, t_10+57, 10, temp);
	gf2x_mul_5_avx(temp, q_10+53, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+53, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+52, 10, t_10+52, 10, temp);
	gf2x_mul_5_avx(temp, q_10+48, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+48, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+47, 10, t_10+47, 10, temp);
	gf2x_mul_5_avx(temp, q_10+43, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+43, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+42, 10, t_10+42, 10, temp);
	gf2x_mul_5_avx(temp, q_10+38, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+38, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+37, 10, t_10+37, 10, temp);
	gf2x_mul_5_avx(temp, q_10+33, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+33, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+32, 10, t_10+32, 10, temp);
	gf2x_mul_5_avx(temp, q_10+28, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+28, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+27, 10, t_10+27, 10, temp);
	gf2x_mul_5_avx(temp, q_10+23, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+23, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+22, 10, t_10+22, 10, temp);
	gf2x_mul_5_avx(temp, q_10+18, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+18, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+17, 10, t_10+17, 10, temp);
	gf2x_mul_5_avx(temp, q_10+13, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+13, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+12, 10, t_10+12, 10, temp);
	gf2x_mul_5_avx(temp, q_10+8, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+8, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+7, 10, t_10+7, 10, temp);
	gf2x_mul_5_avx(temp, q_10+3, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+3, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+2, 10, t_10+2, 10, temp);
	gf2x_mul_3_avx(temp, p_00+2, q_10+0);
	gf2x_mul_3_avx(temp2, p_10+2, q_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+1, 6, t_10+1, 6, temp);
	gf2x_mul_2_avx(temp, q_10+1, p_00+0);
	gf2x_mul_2_avx(temp2, q_11+1, p_10+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_10+0, 4, t_10+0, 4, temp);
	gf2x_mul_1_avx(temp, p_00+1, q_10+0);
	gf2x_mul_1_avx(temp2, p_10+1, q_11+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, t_10+0, 2, t_10+0, 2, temp);
	gf2x_mul_1_avx(temp, q_10+0, p_00+0);
	gf2x_mul_1_avx(temp2, q_11+0, p_10+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, t_10+0, 1, t_10+0, 1, temp+1);
	memset(t_11+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(406, temp, 203, p_01+5, 203, q_10+0);
	GF2X_MUL(406, temp2, 203, p_11+5, 203, q_11+0);
	gf2x_add(406, t_11+4, 406, temp, 406, temp2);
	gf2x_mul_5_avx(temp, q_10+198, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+198, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+197, 10, t_11+197, 10, temp);
	gf2x_mul_5_avx(temp, q_10+193, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+193, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+192, 10, t_11+192, 10, temp);
	gf2x_mul_5_avx(temp, q_10+188, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+188, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+187, 10, t_11+187, 10, temp);
	gf2x_mul_5_avx(temp, q_10+183, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+183, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+182, 10, t_11+182, 10, temp);
	gf2x_mul_5_avx(temp, q_10+178, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+178, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+177, 10, t_11+177, 10, temp);
	gf2x_mul_5_avx(temp, q_10+173, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+173, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+172, 10, t_11+172, 10, temp);
	gf2x_mul_5_avx(temp, q_10+168, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+168, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+167, 10, t_11+167, 10, temp);
	gf2x_mul_5_avx(temp, q_10+163, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+163, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+162, 10, t_11+162, 10, temp);
	gf2x_mul_5_avx(temp, q_10+158, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+158, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+157, 10, t_11+157, 10, temp);
	gf2x_mul_5_avx(temp, q_10+153, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+153, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+152, 10, t_11+152, 10, temp);
	gf2x_mul_5_avx(temp, q_10+148, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+148, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+147, 10, t_11+147, 10, temp);
	gf2x_mul_5_avx(temp, q_10+143, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+143, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+142, 10, t_11+142, 10, temp);
	gf2x_mul_5_avx(temp, q_10+138, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+138, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+137, 10, t_11+137, 10, temp);
	gf2x_mul_5_avx(temp, q_10+133, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+133, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+132, 10, t_11+132, 10, temp);
	gf2x_mul_5_avx(temp, q_10+128, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+128, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+127, 10, t_11+127, 10, temp);
	gf2x_mul_5_avx(temp, q_10+123, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+123, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+122, 10, t_11+122, 10, temp);
	gf2x_mul_5_avx(temp, q_10+118, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+118, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+117, 10, t_11+117, 10, temp);
	gf2x_mul_5_avx(temp, q_10+113, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+113, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+112, 10, t_11+112, 10, temp);
	gf2x_mul_5_avx(temp, q_10+108, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+108, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+107, 10, t_11+107, 10, temp);
	gf2x_mul_5_avx(temp, q_10+103, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+103, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+102, 10, t_11+102, 10, temp);
	gf2x_mul_5_avx(temp, q_10+98, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+98, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+97, 10, t_11+97, 10, temp);
	gf2x_mul_5_avx(temp, q_10+93, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+93, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+92, 10, t_11+92, 10, temp);
	gf2x_mul_5_avx(temp, q_10+88, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+88, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+87, 10, t_11+87, 10, temp);
	gf2x_mul_5_avx(temp, q_10+83, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+83, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+82, 10, t_11+82, 10, temp);
	gf2x_mul_5_avx(temp, q_10+78, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+78, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+77, 10, t_11+77, 10, temp);
	gf2x_mul_5_avx(temp, q_10+73, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+73, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+72, 10, t_11+72, 10, temp);
	gf2x_mul_5_avx(temp, q_10+68, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+68, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+67, 10, t_11+67, 10, temp);
	gf2x_mul_5_avx(temp, q_10+63, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+63, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+62, 10, t_11+62, 10, temp);
	gf2x_mul_5_avx(temp, q_10+58, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+58, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+57, 10, t_11+57, 10, temp);
	gf2x_mul_5_avx(temp, q_10+53, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+53, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+52, 10, t_11+52, 10, temp);
	gf2x_mul_5_avx(temp, q_10+48, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+48, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+47, 10, t_11+47, 10, temp);
	gf2x_mul_5_avx(temp, q_10+43, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+43, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+42, 10, t_11+42, 10, temp);
	gf2x_mul_5_avx(temp, q_10+38, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+38, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+37, 10, t_11+37, 10, temp);
	gf2x_mul_5_avx(temp, q_10+33, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+33, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+32, 10, t_11+32, 10, temp);
	gf2x_mul_5_avx(temp, q_10+28, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+28, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+27, 10, t_11+27, 10, temp);
	gf2x_mul_5_avx(temp, q_10+23, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+23, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+22, 10, t_11+22, 10, temp);
	gf2x_mul_5_avx(temp, q_10+18, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+18, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+17, 10, t_11+17, 10, temp);
	gf2x_mul_5_avx(temp, q_10+13, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+13, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+12, 10, t_11+12, 10, temp);
	gf2x_mul_5_avx(temp, q_10+8, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+8, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+7, 10, t_11+7, 10, temp);
	gf2x_mul_5_avx(temp, q_10+3, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+3, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+2, 10, t_11+2, 10, temp);
	gf2x_mul_3_avx(temp, p_01+2, q_10+0);
	gf2x_mul_3_avx(temp2, p_11+2, q_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+1, 6, t_11+1, 6, temp);
	gf2x_mul_2_avx(temp, q_10+1, p_01+0);
	gf2x_mul_2_avx(temp2, q_11+1, p_11+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_11+0, 4, t_11+0, 4, temp);
	gf2x_mul_1_avx(temp, p_01+1, q_10+0);
	gf2x_mul_1_avx(temp2, p_11+1, q_11+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, t_11+0, 2, t_11+0, 2, temp);
	gf2x_mul_1_avx(temp, q_10+0, p_01+0);
	gf2x_mul_1_avx(temp2, q_11+0, p_11+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, t_11+0, 1, t_11+0, 1, temp+1);
	
	return delta;
}