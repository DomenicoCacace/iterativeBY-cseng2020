/**
  * @author Domenico Cacace <domenico.cacace@mail.polimi.it>
  * 
  *
  * This code is hereby placed in the public domain.
  *
  * THIS SOFTWARE IS PROVIDED BY THE AUTHORS ''AS IS'' AND ANY EXPRESS
  * OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
  * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHORS OR CONTRIBUTORS BE
  * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
  * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
  * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
  * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
  * EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **/

#include "../../include/inverse_DJB_facilities.h"

int jumpdivstep_42677(int delta, DIGIT *f, DIGIT *g, DIGIT *t_00, DIGIT *t_01, DIGIT *t_10, DIGIT *t_11) {
	DIGIT p_00[1349];
	DIGIT p_01[1349];
	DIGIT p_10[1349];
	DIGIT p_11[1349];
	
	DIGIT q_00[1332];
	DIGIT q_01[1332];
	DIGIT q_10[1332];
	DIGIT q_11[1332];
	
	DIGIT f_sum[4038];
	DIGIT g_sum[4038];
	
	DIGIT temp[1340];
	DIGIT temp2[1340];
	

	delta = divstepsx_256(255, delta, f+1330, g+1330, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f+1330, p_00+1345);
	gf2x_mul_4_avx(temp2, g+1330, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f+1326, p_00+1345);
	gf2x_mul_4_avx(temp2, g+1326, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f+1330, p_10+1345);
	gf2x_mul_4_avx(temp2, g+1330, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f+1326, p_10+1345);
	gf2x_mul_4_avx(temp2, g+1326, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f+1326, p_00+1337);
	gf2x_mul_8_avx(temp2, g+1326, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f+1322);
	gf2x_mul_4_avx(temp2, p_01+1341, g+1322);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f+1326, p_10+1337);
	gf2x_mul_8_avx(temp2, g+1326, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f+1322);
	gf2x_mul_4_avx(temp2, p_11+1341, g+1322);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, f+1322, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g+1322, 12, p_01+1325);
	gf2x_add(24, f_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f+1310, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g+1310, 12, p_01+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+3966, 12, f_sum+3966, 12, temp+12);
	right_bit_shift_n(24, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f+1322, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g+1322, 12, p_11+1325);
	gf2x_add(24, g_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f+1310, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g+1310, 12, p_11+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+3966, 12, g_sum+3966, 12, temp+12);
	right_bit_shift_n(24, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3975, g_sum+3975, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3975, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3975, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(q_00+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, q_00+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1312, 8, q_00+1312, 8, temp);
	memset(q_01+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, q_01+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1312, 8, q_01+1312, 8, temp);
	memset(q_10+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, q_10+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1312, 8, q_10+1312, 8, temp);
	memset(q_11+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, q_11+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1312, 8, q_11+1312, 8, temp);
	
	// Recombining results: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_10+1325);
	gf2x_add(24, p_00+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_11+1325);
	gf2x_add(24, p_01+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_10+1325);
	gf2x_add(24, p_10+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_11+1325);
	gf2x_add(24, p_11+1301, 24, temp, 24, temp2);
	
	// Calculating left operands: n: 2805, depth: 5
	GF2X_MUL(48, temp, 24, f+1310, 24, p_00+1301);
	GF2X_MUL(48, temp2, 24, g+1310, 24, p_01+1301);
	gf2x_add(44, f_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, f+1290);
	GF2X_MUL(40, temp2, 20, p_01+1305, 20, g+1290);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(44, f_sum+3897, 58);
	GF2X_MUL(48, temp, 24, f+1310, 24, p_10+1301);
	GF2X_MUL(48, temp2, 24, g+1310, 24, p_11+1301);
	gf2x_add(44, g_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_10+1305, 20, f+1290);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, g+1290);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(44, g_sum+3897, 58);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2805, depth: 5
	memset(p_00+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_01+1292);
	gf2x_add(40, p_00+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1273, 8, p_00+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1269, 8, p_00+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1265, 8, p_00+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1261, 8, p_00+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1257, 8, p_00+1257, 8, temp);
	memset(p_01+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_01+1292);
	gf2x_add(40, p_01+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1273, 8, p_01+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1269, 8, p_01+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1265, 8, p_01+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1261, 8, p_01+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1257, 8, p_01+1257, 8, temp);
	memset(p_10+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_11+1292);
	gf2x_add(40, p_10+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1273, 8, p_10+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1269, 8, p_10+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1265, 8, p_10+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1261, 8, p_10+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1257, 8, p_10+1257, 8, temp);
	memset(p_11+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_11+1292);
	gf2x_add(40, p_11+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1273, 8, p_11+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1269, 8, p_11+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1265, 8, p_11+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1261, 8, p_11+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1257, 8, p_11+1257, 8, temp);
	
	// Calculating left operands: n: 5355, depth: 4
	GF2X_MUL(88, temp, 44, f+1290, 44, p_00+1257);
	GF2X_MUL(88, temp2, 44, g+1290, 44, p_01+1257);
	gf2x_add(84, f_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, f+1250);
	GF2X_MUL(80, temp2, 40, p_01+1261, 40, g+1250);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, f_sum+3768, 40, f_sum+3768, 40, temp+40);
	right_bit_shift_n(84, f_sum+3768, 53);
	GF2X_MUL(88, temp, 44, f+1290, 44, p_10+1257);
	GF2X_MUL(88, temp2, 44, g+1290, 44, p_11+1257);
	gf2x_add(84, g_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_10+1261, 40, f+1250);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, g+1250);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, g_sum+3768, 40, g_sum+3768, 40, temp+40);
	right_bit_shift_n(84, g_sum+3768, 53);
	
	delta = divstepsx_256(255, delta, f_sum+3805, g_sum+3805, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3805, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3805, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3801, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3801, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(p_00+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, p_00+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1305, 8, p_00+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1301, 8, p_00+1301, 8, temp);
	memset(p_01+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, p_01+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1305, 8, p_01+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1301, 8, p_01+1301, 8, temp);
	memset(p_10+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, p_10+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1305, 8, p_10+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1301, 8, p_10+1301, 8, temp);
	memset(p_11+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, p_11+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1305, 8, p_11+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1301, 8, p_11+1301, 8, temp);
	
	// Calculating left operands: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_01+1301);
	gf2x_add(40, f_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_01+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(40, f_sum+3897, 59);
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_11+1301);
	gf2x_add(40, g_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_11+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(40, g_sum+3897, 59);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_10+1301);
	gf2x_add(40, q_00+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_11+1301);
	gf2x_add(40, q_01+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_10+1301);
	gf2x_add(40, q_10+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_11+1301);
	gf2x_add(40, q_11+1252, 40, temp, 40, temp2);
	
	// Recombining results: n: 5355, depth: 4
	memset(p_00+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_01+1252);
	gf2x_add(80, p_00+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1209, 8, p_00+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1205, 8, p_00+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1201, 8, p_00+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1197, 8, p_00+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1193, 8, p_00+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1189, 8, p_00+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1185, 8, p_00+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1181, 8, p_00+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1177, 8, p_00+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1173, 8, p_00+1173, 8, temp);
	memset(p_01+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_01+1252);
	gf2x_add(80, p_01+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1209, 8, p_01+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1205, 8, p_01+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1201, 8, p_01+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1197, 8, p_01+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1193, 8, p_01+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1189, 8, p_01+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1185, 8, p_01+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1181, 8, p_01+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1177, 8, p_01+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1173, 8, p_01+1173, 8, temp);
	memset(p_10+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_11+1252);
	gf2x_add(80, p_10+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1209, 8, p_10+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1205, 8, p_10+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1201, 8, p_10+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1197, 8, p_10+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1193, 8, p_10+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1189, 8, p_10+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1185, 8, p_10+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1181, 8, p_10+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1177, 8, p_10+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1173, 8, p_10+1173, 8, temp);
	memset(p_11+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_11+1252);
	gf2x_add(80, p_11+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1209, 8, p_11+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1205, 8, p_11+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1201, 8, p_11+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1197, 8, p_11+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1193, 8, p_11+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1189, 8, p_11+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1185, 8, p_11+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1181, 8, p_11+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1177, 8, p_11+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1173, 8, p_11+1173, 8, temp);
	
	// Calculating left operands: n: 10710, depth: 3
	GF2X_MUL(168, temp, 84, f+1250, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, g+1250, 84, p_01+1173);
	gf2x_add(168, f_sum+3515, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, f+1166, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, g+1166, 84, p_01+1173);
	gf2x_add(168, temp, 168, temp, 168, temp2);
	gf2x_add(84, f_sum+3515, 84, f_sum+3515, 84, temp+84);
	right_bit_shift_n(168, f_sum+3515, 43);
	GF2X_MUL(168, temp, 84, f+1250, 84, p_10+1173);
	GF2X_MUL(168, temp2, 84, g+1250, 84, p_11+1173);
	gf2x_add(168, g_sum+3515, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, f+1166, 84, p_10+1173);
	GF2X_MUL(168, temp2, 84, g+1166, 84, p_11+1173);
	gf2x_add(168, temp, 168, temp, 168, temp2);
	gf2x_add(84, g_sum+3515, 84, g_sum+3515, 84, temp+84);
	right_bit_shift_n(168, g_sum+3515, 43);
	
	delta = divstepsx_256(255, delta, f_sum+3596, g_sum+3596, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3596, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3596, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3592, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3592, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3596, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3596, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3592, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3592, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3592, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3592, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3588);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3588);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3592, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3592, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3588);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3588);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3588, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3588, 12, p_01+1325);
	gf2x_add(24, f_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3576, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3576, 12, p_01+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+3966, 12, f_sum+3966, 12, temp+12);
	right_bit_shift_n(24, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3588, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3588, 12, p_11+1325);
	gf2x_add(24, g_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3576, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3576, 12, p_11+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+3966, 12, g_sum+3966, 12, temp+12);
	right_bit_shift_n(24, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3975, g_sum+3975, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3975, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3975, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(q_00+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, q_00+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1312, 8, q_00+1312, 8, temp);
	memset(q_01+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, q_01+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1312, 8, q_01+1312, 8, temp);
	memset(q_10+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, q_10+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1312, 8, q_10+1312, 8, temp);
	memset(q_11+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, q_11+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1312, 8, q_11+1312, 8, temp);
	
	// Recombining results: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_10+1325);
	gf2x_add(24, p_00+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_11+1325);
	gf2x_add(24, p_01+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_10+1325);
	gf2x_add(24, p_10+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_11+1325);
	gf2x_add(24, p_11+1301, 24, temp, 24, temp2);
	
	// Calculating left operands: n: 2805, depth: 5
	GF2X_MUL(48, temp, 24, f_sum+3576, 24, p_00+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3576, 24, p_01+1301);
	gf2x_add(44, f_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, f_sum+3556);
	GF2X_MUL(40, temp2, 20, p_01+1305, 20, g_sum+3556);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(44, f_sum+3897, 58);
	GF2X_MUL(48, temp, 24, f_sum+3576, 24, p_10+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3576, 24, p_11+1301);
	gf2x_add(44, g_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_10+1305, 20, f_sum+3556);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, g_sum+3556);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(44, g_sum+3897, 58);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2805, depth: 5
	memset(p_00+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_01+1292);
	gf2x_add(40, p_00+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1273, 8, p_00+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1269, 8, p_00+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1265, 8, p_00+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1261, 8, p_00+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1257, 8, p_00+1257, 8, temp);
	memset(p_01+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_01+1292);
	gf2x_add(40, p_01+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1273, 8, p_01+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1269, 8, p_01+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1265, 8, p_01+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1261, 8, p_01+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1257, 8, p_01+1257, 8, temp);
	memset(p_10+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_11+1292);
	gf2x_add(40, p_10+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1273, 8, p_10+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1269, 8, p_10+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1265, 8, p_10+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1261, 8, p_10+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1257, 8, p_10+1257, 8, temp);
	memset(p_11+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_11+1292);
	gf2x_add(40, p_11+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1273, 8, p_11+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1269, 8, p_11+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1265, 8, p_11+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1261, 8, p_11+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1257, 8, p_11+1257, 8, temp);
	
	// Calculating left operands: n: 5355, depth: 4
	GF2X_MUL(88, temp, 44, f_sum+3556, 44, p_00+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3556, 44, p_01+1257);
	gf2x_add(84, f_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, f_sum+3516);
	GF2X_MUL(80, temp2, 40, p_01+1261, 40, g_sum+3516);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, f_sum+3768, 40, f_sum+3768, 40, temp+40);
	right_bit_shift_n(84, f_sum+3768, 53);
	GF2X_MUL(88, temp, 44, f_sum+3556, 44, p_10+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3556, 44, p_11+1257);
	gf2x_add(84, g_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_10+1261, 40, f_sum+3516);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, g_sum+3516);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, g_sum+3768, 40, g_sum+3768, 40, temp+40);
	right_bit_shift_n(84, g_sum+3768, 53);
	
	delta = divstepsx_256(255, delta, f_sum+3805, g_sum+3805, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3805, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3805, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3801, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3801, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(p_00+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, p_00+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1305, 8, p_00+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1301, 8, p_00+1301, 8, temp);
	memset(p_01+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, p_01+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1305, 8, p_01+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1301, 8, p_01+1301, 8, temp);
	memset(p_10+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, p_10+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1305, 8, p_10+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1301, 8, p_10+1301, 8, temp);
	memset(p_11+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, p_11+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1305, 8, p_11+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1301, 8, p_11+1301, 8, temp);
	
	// Calculating left operands: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_01+1301);
	gf2x_add(40, f_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_01+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(40, f_sum+3897, 59);
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_11+1301);
	gf2x_add(40, g_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_11+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(40, g_sum+3897, 59);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_10+1301);
	gf2x_add(40, q_00+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_11+1301);
	gf2x_add(40, q_01+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_10+1301);
	gf2x_add(40, q_10+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_11+1301);
	gf2x_add(40, q_11+1252, 40, temp, 40, temp2);
	
	// Recombining results: n: 5355, depth: 4
	memset(q_00+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_01+1252);
	gf2x_add(80, q_00+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1204, 8, q_00+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1200, 8, q_00+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1196, 8, q_00+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1192, 8, q_00+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1188, 8, q_00+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1184, 8, q_00+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1180, 8, q_00+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1176, 8, q_00+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1172, 8, q_00+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1168, 8, q_00+1168, 8, temp);
	memset(q_01+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_01+1252);
	gf2x_add(80, q_01+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1204, 8, q_01+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1200, 8, q_01+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1196, 8, q_01+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1192, 8, q_01+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1188, 8, q_01+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1184, 8, q_01+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1180, 8, q_01+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1176, 8, q_01+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1172, 8, q_01+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1168, 8, q_01+1168, 8, temp);
	memset(q_10+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_11+1252);
	gf2x_add(80, q_10+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1204, 8, q_10+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1200, 8, q_10+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1196, 8, q_10+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1192, 8, q_10+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1188, 8, q_10+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1184, 8, q_10+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1180, 8, q_10+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1176, 8, q_10+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1172, 8, q_10+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1168, 8, q_10+1168, 8, temp);
	memset(q_11+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_11+1252);
	gf2x_add(80, q_11+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1204, 8, q_11+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1200, 8, q_11+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1196, 8, q_11+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1192, 8, q_11+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1188, 8, q_11+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1184, 8, q_11+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1180, 8, q_11+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1176, 8, q_11+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1172, 8, q_11+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1168, 8, q_11+1168, 8, temp);
	
	// Recombining results: n: 10710, depth: 3
	GF2X_MUL(168, temp, 84, q_00+1168, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, q_01+1168, 84, p_10+1173);
	gf2x_add(168, p_00+1005, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_00+1168, 84, p_01+1173);
	GF2X_MUL(168, temp2, 84, q_01+1168, 84, p_11+1173);
	gf2x_add(168, p_01+1005, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_10+1168, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, q_11+1168, 84, p_10+1173);
	gf2x_add(168, p_10+1005, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_10+1168, 84, p_01+1173);
	GF2X_MUL(168, temp2, 84, q_11+1168, 84, p_11+1173);
	gf2x_add(168, p_11+1005, 168, temp, 168, temp2);
	
	// Calculating left operands: n: 21420, depth: 2
	GF2X_MUL(336, temp, 168, f+1166, 168, p_00+1005);
	GF2X_MUL(336, temp2, 168, g+1166, 168, p_01+1005);
	gf2x_add(336, f_sum+3011, 336, temp, 336, temp2);
	GF2X_MUL(334, temp, 167, p_00+1006, 167, f+999);
	GF2X_MUL(334, temp2, 167, p_01+1006, 167, g+999);
	gf2x_add(334, temp, 334, temp, 334, temp2);
	gf2x_add(168, f_sum+3011, 168, f_sum+3011, 168, temp+166);
	gf2x_mul_1_avx(temp, f+1165, p_00+1005);
	gf2x_mul_1_avx(temp2, g+1165, p_01+1005);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, f_sum+3011, 1, f_sum+3011, 1, temp+1);
	right_bit_shift_n(335, f_sum+3011, 22);
	GF2X_MUL(336, temp, 168, f+1166, 168, p_10+1005);
	GF2X_MUL(336, temp2, 168, g+1166, 168, p_11+1005);
	gf2x_add(336, g_sum+3011, 336, temp, 336, temp2);
	GF2X_MUL(334, temp, 167, p_10+1006, 167, f+999);
	GF2X_MUL(334, temp2, 167, p_11+1006, 167, g+999);
	gf2x_add(334, temp, 334, temp, 334, temp2);
	gf2x_add(168, g_sum+3011, 168, g_sum+3011, 168, temp+166);
	gf2x_mul_1_avx(temp, f+1165, p_10+1005);
	gf2x_mul_1_avx(temp2, g+1165, p_11+1005);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, g_sum+3011, 1, g_sum+3011, 1, temp+1);
	right_bit_shift_n(335, g_sum+3011, 22);
	
	delta = divstepsx_256(255, delta, f_sum+3176, g_sum+3176, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3176, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3176, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3172, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3172, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3176, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3176, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3172, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3172, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3172, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3172, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3168);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3168);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3172, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3172, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3168);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3168);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3168, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3168, 12, p_01+1325);
	gf2x_add(24, f_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3156, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3156, 12, p_01+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+3966, 12, f_sum+3966, 12, temp+12);
	right_bit_shift_n(24, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3168, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3168, 12, p_11+1325);
	gf2x_add(24, g_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3156, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3156, 12, p_11+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+3966, 12, g_sum+3966, 12, temp+12);
	right_bit_shift_n(24, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3975, g_sum+3975, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3975, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3975, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(q_00+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, q_00+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1312, 8, q_00+1312, 8, temp);
	memset(q_01+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, q_01+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1312, 8, q_01+1312, 8, temp);
	memset(q_10+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, q_10+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1312, 8, q_10+1312, 8, temp);
	memset(q_11+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, q_11+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1312, 8, q_11+1312, 8, temp);
	
	// Recombining results: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_10+1325);
	gf2x_add(24, p_00+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_11+1325);
	gf2x_add(24, p_01+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_10+1325);
	gf2x_add(24, p_10+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_11+1325);
	gf2x_add(24, p_11+1301, 24, temp, 24, temp2);
	
	// Calculating left operands: n: 2805, depth: 5
	GF2X_MUL(48, temp, 24, f_sum+3156, 24, p_00+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3156, 24, p_01+1301);
	gf2x_add(44, f_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, f_sum+3136);
	GF2X_MUL(40, temp2, 20, p_01+1305, 20, g_sum+3136);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(44, f_sum+3897, 58);
	GF2X_MUL(48, temp, 24, f_sum+3156, 24, p_10+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3156, 24, p_11+1301);
	gf2x_add(44, g_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_10+1305, 20, f_sum+3136);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, g_sum+3136);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(44, g_sum+3897, 58);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2805, depth: 5
	memset(p_00+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_01+1292);
	gf2x_add(40, p_00+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1273, 8, p_00+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1269, 8, p_00+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1265, 8, p_00+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1261, 8, p_00+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1257, 8, p_00+1257, 8, temp);
	memset(p_01+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_01+1292);
	gf2x_add(40, p_01+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1273, 8, p_01+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1269, 8, p_01+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1265, 8, p_01+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1261, 8, p_01+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1257, 8, p_01+1257, 8, temp);
	memset(p_10+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_11+1292);
	gf2x_add(40, p_10+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1273, 8, p_10+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1269, 8, p_10+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1265, 8, p_10+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1261, 8, p_10+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1257, 8, p_10+1257, 8, temp);
	memset(p_11+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_11+1292);
	gf2x_add(40, p_11+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1273, 8, p_11+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1269, 8, p_11+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1265, 8, p_11+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1261, 8, p_11+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1257, 8, p_11+1257, 8, temp);
	
	// Calculating left operands: n: 5355, depth: 4
	GF2X_MUL(88, temp, 44, f_sum+3136, 44, p_00+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3136, 44, p_01+1257);
	gf2x_add(84, f_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, f_sum+3096);
	GF2X_MUL(80, temp2, 40, p_01+1261, 40, g_sum+3096);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, f_sum+3768, 40, f_sum+3768, 40, temp+40);
	right_bit_shift_n(84, f_sum+3768, 53);
	GF2X_MUL(88, temp, 44, f_sum+3136, 44, p_10+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3136, 44, p_11+1257);
	gf2x_add(84, g_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_10+1261, 40, f_sum+3096);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, g_sum+3096);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, g_sum+3768, 40, g_sum+3768, 40, temp+40);
	right_bit_shift_n(84, g_sum+3768, 53);
	
	delta = divstepsx_256(255, delta, f_sum+3805, g_sum+3805, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3805, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3805, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3801, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3801, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(p_00+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, p_00+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1305, 8, p_00+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1301, 8, p_00+1301, 8, temp);
	memset(p_01+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, p_01+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1305, 8, p_01+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1301, 8, p_01+1301, 8, temp);
	memset(p_10+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, p_10+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1305, 8, p_10+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1301, 8, p_10+1301, 8, temp);
	memset(p_11+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, p_11+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1305, 8, p_11+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1301, 8, p_11+1301, 8, temp);
	
	// Calculating left operands: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_01+1301);
	gf2x_add(40, f_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_01+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(40, f_sum+3897, 59);
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_11+1301);
	gf2x_add(40, g_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_11+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(40, g_sum+3897, 59);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_10+1301);
	gf2x_add(40, q_00+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_11+1301);
	gf2x_add(40, q_01+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_10+1301);
	gf2x_add(40, q_10+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_11+1301);
	gf2x_add(40, q_11+1252, 40, temp, 40, temp2);
	
	// Recombining results: n: 5355, depth: 4
	memset(p_00+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_01+1252);
	gf2x_add(80, p_00+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1209, 8, p_00+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1205, 8, p_00+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1201, 8, p_00+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1197, 8, p_00+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1193, 8, p_00+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1189, 8, p_00+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1185, 8, p_00+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1181, 8, p_00+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1177, 8, p_00+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1173, 8, p_00+1173, 8, temp);
	memset(p_01+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_01+1252);
	gf2x_add(80, p_01+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1209, 8, p_01+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1205, 8, p_01+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1201, 8, p_01+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1197, 8, p_01+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1193, 8, p_01+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1189, 8, p_01+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1185, 8, p_01+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1181, 8, p_01+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1177, 8, p_01+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1173, 8, p_01+1173, 8, temp);
	memset(p_10+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_11+1252);
	gf2x_add(80, p_10+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1209, 8, p_10+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1205, 8, p_10+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1201, 8, p_10+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1197, 8, p_10+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1193, 8, p_10+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1189, 8, p_10+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1185, 8, p_10+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1181, 8, p_10+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1177, 8, p_10+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1173, 8, p_10+1173, 8, temp);
	memset(p_11+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_11+1252);
	gf2x_add(80, p_11+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1209, 8, p_11+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1205, 8, p_11+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1201, 8, p_11+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1197, 8, p_11+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1193, 8, p_11+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1189, 8, p_11+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1185, 8, p_11+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1181, 8, p_11+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1177, 8, p_11+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1173, 8, p_11+1173, 8, temp);
	
	// Calculating left operands: n: 10710, depth: 3
	GF2X_MUL(168, temp, 84, f_sum+3096, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, g_sum+3096, 84, p_01+1173);
	gf2x_add(168, f_sum+3515, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, f_sum+3012, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, g_sum+3012, 84, p_01+1173);
	gf2x_add(168, temp, 168, temp, 168, temp2);
	gf2x_add(84, f_sum+3515, 84, f_sum+3515, 84, temp+84);
	right_bit_shift_n(168, f_sum+3515, 43);
	GF2X_MUL(168, temp, 84, f_sum+3096, 84, p_10+1173);
	GF2X_MUL(168, temp2, 84, g_sum+3096, 84, p_11+1173);
	gf2x_add(168, g_sum+3515, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, f_sum+3012, 84, p_10+1173);
	GF2X_MUL(168, temp2, 84, g_sum+3012, 84, p_11+1173);
	gf2x_add(168, temp, 168, temp, 168, temp2);
	gf2x_add(84, g_sum+3515, 84, g_sum+3515, 84, temp+84);
	right_bit_shift_n(168, g_sum+3515, 43);
	
	delta = divstepsx_256(255, delta, f_sum+3596, g_sum+3596, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3596, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3596, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3592, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3592, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3596, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3596, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3592, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3592, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3592, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3592, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3588);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3588);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3592, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3592, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3588);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3588);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3588, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3588, 12, p_01+1325);
	gf2x_add(24, f_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3576, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3576, 12, p_01+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+3966, 12, f_sum+3966, 12, temp+12);
	right_bit_shift_n(24, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3588, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3588, 12, p_11+1325);
	gf2x_add(24, g_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3576, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3576, 12, p_11+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+3966, 12, g_sum+3966, 12, temp+12);
	right_bit_shift_n(24, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3975, g_sum+3975, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3975, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3975, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(q_00+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, q_00+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1312, 8, q_00+1312, 8, temp);
	memset(q_01+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, q_01+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1312, 8, q_01+1312, 8, temp);
	memset(q_10+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, q_10+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1312, 8, q_10+1312, 8, temp);
	memset(q_11+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, q_11+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1312, 8, q_11+1312, 8, temp);
	
	// Recombining results: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_10+1325);
	gf2x_add(24, p_00+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_11+1325);
	gf2x_add(24, p_01+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_10+1325);
	gf2x_add(24, p_10+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_11+1325);
	gf2x_add(24, p_11+1301, 24, temp, 24, temp2);
	
	// Calculating left operands: n: 2805, depth: 5
	GF2X_MUL(48, temp, 24, f_sum+3576, 24, p_00+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3576, 24, p_01+1301);
	gf2x_add(44, f_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, f_sum+3556);
	GF2X_MUL(40, temp2, 20, p_01+1305, 20, g_sum+3556);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(44, f_sum+3897, 58);
	GF2X_MUL(48, temp, 24, f_sum+3576, 24, p_10+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3576, 24, p_11+1301);
	gf2x_add(44, g_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_10+1305, 20, f_sum+3556);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, g_sum+3556);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(44, g_sum+3897, 58);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2805, depth: 5
	memset(p_00+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_01+1292);
	gf2x_add(40, p_00+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1273, 8, p_00+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1269, 8, p_00+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1265, 8, p_00+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1261, 8, p_00+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1257, 8, p_00+1257, 8, temp);
	memset(p_01+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_01+1292);
	gf2x_add(40, p_01+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1273, 8, p_01+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1269, 8, p_01+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1265, 8, p_01+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1261, 8, p_01+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1257, 8, p_01+1257, 8, temp);
	memset(p_10+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_11+1292);
	gf2x_add(40, p_10+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1273, 8, p_10+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1269, 8, p_10+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1265, 8, p_10+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1261, 8, p_10+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1257, 8, p_10+1257, 8, temp);
	memset(p_11+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_11+1292);
	gf2x_add(40, p_11+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1273, 8, p_11+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1269, 8, p_11+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1265, 8, p_11+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1261, 8, p_11+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1257, 8, p_11+1257, 8, temp);
	
	// Calculating left operands: n: 5355, depth: 4
	GF2X_MUL(88, temp, 44, f_sum+3556, 44, p_00+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3556, 44, p_01+1257);
	gf2x_add(84, f_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, f_sum+3516);
	GF2X_MUL(80, temp2, 40, p_01+1261, 40, g_sum+3516);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, f_sum+3768, 40, f_sum+3768, 40, temp+40);
	right_bit_shift_n(84, f_sum+3768, 53);
	GF2X_MUL(88, temp, 44, f_sum+3556, 44, p_10+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3556, 44, p_11+1257);
	gf2x_add(84, g_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_10+1261, 40, f_sum+3516);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, g_sum+3516);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, g_sum+3768, 40, g_sum+3768, 40, temp+40);
	right_bit_shift_n(84, g_sum+3768, 53);
	
	delta = divstepsx_256(255, delta, f_sum+3805, g_sum+3805, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3805, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3805, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3801, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3801, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(p_00+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, p_00+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1305, 8, p_00+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1301, 8, p_00+1301, 8, temp);
	memset(p_01+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, p_01+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1305, 8, p_01+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1301, 8, p_01+1301, 8, temp);
	memset(p_10+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, p_10+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1305, 8, p_10+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1301, 8, p_10+1301, 8, temp);
	memset(p_11+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, p_11+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1305, 8, p_11+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1301, 8, p_11+1301, 8, temp);
	
	// Calculating left operands: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_01+1301);
	gf2x_add(40, f_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_01+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(40, f_sum+3897, 59);
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_11+1301);
	gf2x_add(40, g_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_11+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(40, g_sum+3897, 59);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_10+1301);
	gf2x_add(40, q_00+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_11+1301);
	gf2x_add(40, q_01+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_10+1301);
	gf2x_add(40, q_10+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_11+1301);
	gf2x_add(40, q_11+1252, 40, temp, 40, temp2);
	
	// Recombining results: n: 5355, depth: 4
	memset(q_00+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_01+1252);
	gf2x_add(80, q_00+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1204, 8, q_00+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1200, 8, q_00+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1196, 8, q_00+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1192, 8, q_00+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1188, 8, q_00+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1184, 8, q_00+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1180, 8, q_00+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1176, 8, q_00+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1172, 8, q_00+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1168, 8, q_00+1168, 8, temp);
	memset(q_01+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_01+1252);
	gf2x_add(80, q_01+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1204, 8, q_01+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1200, 8, q_01+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1196, 8, q_01+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1192, 8, q_01+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1188, 8, q_01+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1184, 8, q_01+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1180, 8, q_01+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1176, 8, q_01+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1172, 8, q_01+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1168, 8, q_01+1168, 8, temp);
	memset(q_10+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_11+1252);
	gf2x_add(80, q_10+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1204, 8, q_10+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1200, 8, q_10+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1196, 8, q_10+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1192, 8, q_10+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1188, 8, q_10+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1184, 8, q_10+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1180, 8, q_10+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1176, 8, q_10+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1172, 8, q_10+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1168, 8, q_10+1168, 8, temp);
	memset(q_11+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_11+1252);
	gf2x_add(80, q_11+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1204, 8, q_11+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1200, 8, q_11+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1196, 8, q_11+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1192, 8, q_11+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1188, 8, q_11+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1184, 8, q_11+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1180, 8, q_11+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1176, 8, q_11+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1172, 8, q_11+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1168, 8, q_11+1168, 8, temp);
	
	// Recombining results: n: 10710, depth: 3
	GF2X_MUL(168, temp, 84, q_00+1168, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, q_01+1168, 84, p_10+1173);
	gf2x_add(168, q_00+1000, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_00+1168, 84, p_01+1173);
	GF2X_MUL(168, temp2, 84, q_01+1168, 84, p_11+1173);
	gf2x_add(168, q_01+1000, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_10+1168, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, q_11+1168, 84, p_10+1173);
	gf2x_add(168, q_10+1000, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_10+1168, 84, p_01+1173);
	GF2X_MUL(168, temp2, 84, q_11+1168, 84, p_11+1173);
	gf2x_add(168, q_11+1000, 168, temp, 168, temp2);
	
	// Recombining results: n: 21420, depth: 2
	GF2X_MUL(336, temp, 168, q_00+1000, 168, p_00+1005);
	GF2X_MUL(336, temp2, 168, q_01+1000, 168, p_10+1005);
	gf2x_add(335, p_00+670, 335, temp+1, 335, temp2+1);
	GF2X_MUL(336, temp, 168, q_00+1000, 168, p_01+1005);
	GF2X_MUL(336, temp2, 168, q_01+1000, 168, p_11+1005);
	gf2x_add(335, p_01+670, 335, temp+1, 335, temp2+1);
	GF2X_MUL(336, temp, 168, q_10+1000, 168, p_00+1005);
	GF2X_MUL(336, temp2, 168, q_11+1000, 168, p_10+1005);
	gf2x_add(335, p_10+670, 335, temp+1, 335, temp2+1);
	GF2X_MUL(336, temp, 168, q_10+1000, 168, p_01+1005);
	GF2X_MUL(336, temp2, 168, q_11+1000, 168, p_11+1005);
	gf2x_add(335, p_11+670, 335, temp+1, 335, temp2+1);
	
	// Calculating left operands: n: 42840, depth: 1
	GF2X_MUL(670, temp, 335, f+999, 335, p_00+670);
	GF2X_MUL(670, temp2, 335, g+999, 335, p_01+670);
	gf2x_add(670, f_sum+2005, 670, temp, 670, temp2);
	GF2X_MUL(670, temp, 335, f+664, 335, p_00+670);
	GF2X_MUL(670, temp2, 335, g+664, 335, p_01+670);
	gf2x_add(670, temp, 670, temp, 670, temp2);
	gf2x_add(335, f_sum+2005, 335, f_sum+2005, 335, temp+335);
	right_bit_shift_n(670, f_sum+2005, 44);
	GF2X_MUL(670, temp, 335, f+999, 335, p_10+670);
	GF2X_MUL(670, temp2, 335, g+999, 335, p_11+670);
	gf2x_add(670, g_sum+2005, 670, temp, 670, temp2);
	GF2X_MUL(670, temp, 335, f+664, 335, p_10+670);
	GF2X_MUL(670, temp2, 335, g+664, 335, p_11+670);
	gf2x_add(670, temp, 670, temp, 670, temp2);
	gf2x_add(335, g_sum+2005, 335, g_sum+2005, 335, temp+335);
	right_bit_shift_n(670, g_sum+2005, 44);
	
	delta = divstepsx_256(255, delta, f_sum+2337, g_sum+2337, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+2337, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+2337, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2333, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+2333, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+2337, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+2337, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2333, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+2333, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+2333, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+2333, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+2329);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+2329);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+2333, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+2333, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+2329);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+2329);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+2329, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+2329, 12, p_01+1325);
	gf2x_add(24, f_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+2317, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+2317, 12, p_01+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+3966, 12, f_sum+3966, 12, temp+12);
	right_bit_shift_n(24, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+2329, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+2329, 12, p_11+1325);
	gf2x_add(24, g_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+2317, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+2317, 12, p_11+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+3966, 12, g_sum+3966, 12, temp+12);
	right_bit_shift_n(24, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3975, g_sum+3975, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3975, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3975, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(q_00+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, q_00+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1312, 8, q_00+1312, 8, temp);
	memset(q_01+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, q_01+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1312, 8, q_01+1312, 8, temp);
	memset(q_10+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, q_10+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1312, 8, q_10+1312, 8, temp);
	memset(q_11+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, q_11+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1312, 8, q_11+1312, 8, temp);
	
	// Recombining results: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_10+1325);
	gf2x_add(24, p_00+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_11+1325);
	gf2x_add(24, p_01+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_10+1325);
	gf2x_add(24, p_10+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_11+1325);
	gf2x_add(24, p_11+1301, 24, temp, 24, temp2);
	
	// Calculating left operands: n: 2805, depth: 5
	GF2X_MUL(48, temp, 24, f_sum+2317, 24, p_00+1301);
	GF2X_MUL(48, temp2, 24, g_sum+2317, 24, p_01+1301);
	gf2x_add(44, f_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, f_sum+2297);
	GF2X_MUL(40, temp2, 20, p_01+1305, 20, g_sum+2297);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(44, f_sum+3897, 58);
	GF2X_MUL(48, temp, 24, f_sum+2317, 24, p_10+1301);
	GF2X_MUL(48, temp2, 24, g_sum+2317, 24, p_11+1301);
	gf2x_add(44, g_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_10+1305, 20, f_sum+2297);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, g_sum+2297);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(44, g_sum+3897, 58);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2805, depth: 5
	memset(p_00+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_01+1292);
	gf2x_add(40, p_00+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1273, 8, p_00+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1269, 8, p_00+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1265, 8, p_00+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1261, 8, p_00+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1257, 8, p_00+1257, 8, temp);
	memset(p_01+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_01+1292);
	gf2x_add(40, p_01+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1273, 8, p_01+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1269, 8, p_01+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1265, 8, p_01+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1261, 8, p_01+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1257, 8, p_01+1257, 8, temp);
	memset(p_10+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_11+1292);
	gf2x_add(40, p_10+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1273, 8, p_10+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1269, 8, p_10+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1265, 8, p_10+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1261, 8, p_10+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1257, 8, p_10+1257, 8, temp);
	memset(p_11+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_11+1292);
	gf2x_add(40, p_11+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1273, 8, p_11+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1269, 8, p_11+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1265, 8, p_11+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1261, 8, p_11+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1257, 8, p_11+1257, 8, temp);
	
	// Calculating left operands: n: 5355, depth: 4
	GF2X_MUL(88, temp, 44, f_sum+2297, 44, p_00+1257);
	GF2X_MUL(88, temp2, 44, g_sum+2297, 44, p_01+1257);
	gf2x_add(84, f_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, f_sum+2257);
	GF2X_MUL(80, temp2, 40, p_01+1261, 40, g_sum+2257);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, f_sum+3768, 40, f_sum+3768, 40, temp+40);
	right_bit_shift_n(84, f_sum+3768, 53);
	GF2X_MUL(88, temp, 44, f_sum+2297, 44, p_10+1257);
	GF2X_MUL(88, temp2, 44, g_sum+2297, 44, p_11+1257);
	gf2x_add(84, g_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_10+1261, 40, f_sum+2257);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, g_sum+2257);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, g_sum+3768, 40, g_sum+3768, 40, temp+40);
	right_bit_shift_n(84, g_sum+3768, 53);
	
	delta = divstepsx_256(255, delta, f_sum+3805, g_sum+3805, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3805, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3805, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3801, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3801, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(p_00+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, p_00+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1305, 8, p_00+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1301, 8, p_00+1301, 8, temp);
	memset(p_01+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, p_01+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1305, 8, p_01+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1301, 8, p_01+1301, 8, temp);
	memset(p_10+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, p_10+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1305, 8, p_10+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1301, 8, p_10+1301, 8, temp);
	memset(p_11+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, p_11+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1305, 8, p_11+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1301, 8, p_11+1301, 8, temp);
	
	// Calculating left operands: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_01+1301);
	gf2x_add(40, f_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_01+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(40, f_sum+3897, 59);
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_11+1301);
	gf2x_add(40, g_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_11+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(40, g_sum+3897, 59);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_10+1301);
	gf2x_add(40, q_00+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_11+1301);
	gf2x_add(40, q_01+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_10+1301);
	gf2x_add(40, q_10+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_11+1301);
	gf2x_add(40, q_11+1252, 40, temp, 40, temp2);
	
	// Recombining results: n: 5355, depth: 4
	memset(p_00+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_01+1252);
	gf2x_add(80, p_00+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1209, 8, p_00+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1205, 8, p_00+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1201, 8, p_00+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1197, 8, p_00+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1193, 8, p_00+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1189, 8, p_00+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1185, 8, p_00+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1181, 8, p_00+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1177, 8, p_00+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1173, 8, p_00+1173, 8, temp);
	memset(p_01+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_01+1252);
	gf2x_add(80, p_01+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1209, 8, p_01+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1205, 8, p_01+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1201, 8, p_01+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1197, 8, p_01+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1193, 8, p_01+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1189, 8, p_01+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1185, 8, p_01+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1181, 8, p_01+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1177, 8, p_01+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1173, 8, p_01+1173, 8, temp);
	memset(p_10+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_11+1252);
	gf2x_add(80, p_10+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1209, 8, p_10+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1205, 8, p_10+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1201, 8, p_10+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1197, 8, p_10+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1193, 8, p_10+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1189, 8, p_10+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1185, 8, p_10+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1181, 8, p_10+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1177, 8, p_10+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1173, 8, p_10+1173, 8, temp);
	memset(p_11+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_11+1252);
	gf2x_add(80, p_11+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1209, 8, p_11+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1205, 8, p_11+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1201, 8, p_11+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1197, 8, p_11+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1193, 8, p_11+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1189, 8, p_11+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1185, 8, p_11+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1181, 8, p_11+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1177, 8, p_11+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1173, 8, p_11+1173, 8, temp);
	
	// Calculating left operands: n: 10710, depth: 3
	GF2X_MUL(168, temp, 84, f_sum+2257, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, g_sum+2257, 84, p_01+1173);
	gf2x_add(168, f_sum+3515, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, f_sum+2173, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, g_sum+2173, 84, p_01+1173);
	gf2x_add(168, temp, 168, temp, 168, temp2);
	gf2x_add(84, f_sum+3515, 84, f_sum+3515, 84, temp+84);
	right_bit_shift_n(168, f_sum+3515, 43);
	GF2X_MUL(168, temp, 84, f_sum+2257, 84, p_10+1173);
	GF2X_MUL(168, temp2, 84, g_sum+2257, 84, p_11+1173);
	gf2x_add(168, g_sum+3515, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, f_sum+2173, 84, p_10+1173);
	GF2X_MUL(168, temp2, 84, g_sum+2173, 84, p_11+1173);
	gf2x_add(168, temp, 168, temp, 168, temp2);
	gf2x_add(84, g_sum+3515, 84, g_sum+3515, 84, temp+84);
	right_bit_shift_n(168, g_sum+3515, 43);
	
	delta = divstepsx_256(255, delta, f_sum+3596, g_sum+3596, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3596, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3596, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3592, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3592, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3596, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3596, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3592, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3592, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3592, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3592, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3588);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3588);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3592, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3592, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3588);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3588);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3588, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3588, 12, p_01+1325);
	gf2x_add(24, f_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3576, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3576, 12, p_01+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+3966, 12, f_sum+3966, 12, temp+12);
	right_bit_shift_n(24, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3588, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3588, 12, p_11+1325);
	gf2x_add(24, g_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3576, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3576, 12, p_11+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+3966, 12, g_sum+3966, 12, temp+12);
	right_bit_shift_n(24, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3975, g_sum+3975, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3975, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3975, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(q_00+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, q_00+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1312, 8, q_00+1312, 8, temp);
	memset(q_01+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, q_01+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1312, 8, q_01+1312, 8, temp);
	memset(q_10+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, q_10+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1312, 8, q_10+1312, 8, temp);
	memset(q_11+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, q_11+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1312, 8, q_11+1312, 8, temp);
	
	// Recombining results: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_10+1325);
	gf2x_add(24, p_00+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_11+1325);
	gf2x_add(24, p_01+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_10+1325);
	gf2x_add(24, p_10+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_11+1325);
	gf2x_add(24, p_11+1301, 24, temp, 24, temp2);
	
	// Calculating left operands: n: 2805, depth: 5
	GF2X_MUL(48, temp, 24, f_sum+3576, 24, p_00+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3576, 24, p_01+1301);
	gf2x_add(44, f_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, f_sum+3556);
	GF2X_MUL(40, temp2, 20, p_01+1305, 20, g_sum+3556);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(44, f_sum+3897, 58);
	GF2X_MUL(48, temp, 24, f_sum+3576, 24, p_10+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3576, 24, p_11+1301);
	gf2x_add(44, g_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_10+1305, 20, f_sum+3556);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, g_sum+3556);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(44, g_sum+3897, 58);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2805, depth: 5
	memset(p_00+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_01+1292);
	gf2x_add(40, p_00+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1273, 8, p_00+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1269, 8, p_00+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1265, 8, p_00+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1261, 8, p_00+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1257, 8, p_00+1257, 8, temp);
	memset(p_01+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_01+1292);
	gf2x_add(40, p_01+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1273, 8, p_01+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1269, 8, p_01+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1265, 8, p_01+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1261, 8, p_01+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1257, 8, p_01+1257, 8, temp);
	memset(p_10+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_11+1292);
	gf2x_add(40, p_10+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1273, 8, p_10+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1269, 8, p_10+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1265, 8, p_10+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1261, 8, p_10+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1257, 8, p_10+1257, 8, temp);
	memset(p_11+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_11+1292);
	gf2x_add(40, p_11+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1273, 8, p_11+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1269, 8, p_11+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1265, 8, p_11+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1261, 8, p_11+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1257, 8, p_11+1257, 8, temp);
	
	// Calculating left operands: n: 5355, depth: 4
	GF2X_MUL(88, temp, 44, f_sum+3556, 44, p_00+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3556, 44, p_01+1257);
	gf2x_add(84, f_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, f_sum+3516);
	GF2X_MUL(80, temp2, 40, p_01+1261, 40, g_sum+3516);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, f_sum+3768, 40, f_sum+3768, 40, temp+40);
	right_bit_shift_n(84, f_sum+3768, 53);
	GF2X_MUL(88, temp, 44, f_sum+3556, 44, p_10+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3556, 44, p_11+1257);
	gf2x_add(84, g_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_10+1261, 40, f_sum+3516);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, g_sum+3516);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, g_sum+3768, 40, g_sum+3768, 40, temp+40);
	right_bit_shift_n(84, g_sum+3768, 53);
	
	delta = divstepsx_256(255, delta, f_sum+3805, g_sum+3805, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3805, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3805, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3801, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3801, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(p_00+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, p_00+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1305, 8, p_00+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1301, 8, p_00+1301, 8, temp);
	memset(p_01+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, p_01+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1305, 8, p_01+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1301, 8, p_01+1301, 8, temp);
	memset(p_10+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, p_10+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1305, 8, p_10+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1301, 8, p_10+1301, 8, temp);
	memset(p_11+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, p_11+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1305, 8, p_11+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1301, 8, p_11+1301, 8, temp);
	
	// Calculating left operands: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_01+1301);
	gf2x_add(40, f_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_01+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(40, f_sum+3897, 59);
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_11+1301);
	gf2x_add(40, g_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_11+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(40, g_sum+3897, 59);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_10+1301);
	gf2x_add(40, q_00+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_11+1301);
	gf2x_add(40, q_01+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_10+1301);
	gf2x_add(40, q_10+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_11+1301);
	gf2x_add(40, q_11+1252, 40, temp, 40, temp2);
	
	// Recombining results: n: 5355, depth: 4
	memset(q_00+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_01+1252);
	gf2x_add(80, q_00+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1204, 8, q_00+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1200, 8, q_00+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1196, 8, q_00+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1192, 8, q_00+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1188, 8, q_00+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1184, 8, q_00+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1180, 8, q_00+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1176, 8, q_00+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1172, 8, q_00+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1168, 8, q_00+1168, 8, temp);
	memset(q_01+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_01+1252);
	gf2x_add(80, q_01+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1204, 8, q_01+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1200, 8, q_01+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1196, 8, q_01+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1192, 8, q_01+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1188, 8, q_01+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1184, 8, q_01+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1180, 8, q_01+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1176, 8, q_01+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1172, 8, q_01+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1168, 8, q_01+1168, 8, temp);
	memset(q_10+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_11+1252);
	gf2x_add(80, q_10+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1204, 8, q_10+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1200, 8, q_10+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1196, 8, q_10+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1192, 8, q_10+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1188, 8, q_10+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1184, 8, q_10+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1180, 8, q_10+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1176, 8, q_10+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1172, 8, q_10+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1168, 8, q_10+1168, 8, temp);
	memset(q_11+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_11+1252);
	gf2x_add(80, q_11+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1204, 8, q_11+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1200, 8, q_11+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1196, 8, q_11+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1192, 8, q_11+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1188, 8, q_11+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1184, 8, q_11+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1180, 8, q_11+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1176, 8, q_11+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1172, 8, q_11+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1168, 8, q_11+1168, 8, temp);
	
	// Recombining results: n: 10710, depth: 3
	GF2X_MUL(168, temp, 84, q_00+1168, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, q_01+1168, 84, p_10+1173);
	gf2x_add(168, p_00+1005, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_00+1168, 84, p_01+1173);
	GF2X_MUL(168, temp2, 84, q_01+1168, 84, p_11+1173);
	gf2x_add(168, p_01+1005, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_10+1168, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, q_11+1168, 84, p_10+1173);
	gf2x_add(168, p_10+1005, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_10+1168, 84, p_01+1173);
	GF2X_MUL(168, temp2, 84, q_11+1168, 84, p_11+1173);
	gf2x_add(168, p_11+1005, 168, temp, 168, temp2);
	
	// Calculating left operands: n: 21420, depth: 2
	GF2X_MUL(336, temp, 168, f_sum+2173, 168, p_00+1005);
	GF2X_MUL(336, temp2, 168, g_sum+2173, 168, p_01+1005);
	gf2x_add(336, f_sum+3011, 336, temp, 336, temp2);
	GF2X_MUL(334, temp, 167, p_00+1006, 167, f_sum+2006);
	GF2X_MUL(334, temp2, 167, p_01+1006, 167, g_sum+2006);
	gf2x_add(334, temp, 334, temp, 334, temp2);
	gf2x_add(168, f_sum+3011, 168, f_sum+3011, 168, temp+166);
	gf2x_mul_1_avx(temp, f_sum+2172, p_00+1005);
	gf2x_mul_1_avx(temp2, g_sum+2172, p_01+1005);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, f_sum+3011, 1, f_sum+3011, 1, temp+1);
	right_bit_shift_n(335, f_sum+3011, 22);
	GF2X_MUL(336, temp, 168, f_sum+2173, 168, p_10+1005);
	GF2X_MUL(336, temp2, 168, g_sum+2173, 168, p_11+1005);
	gf2x_add(336, g_sum+3011, 336, temp, 336, temp2);
	GF2X_MUL(334, temp, 167, p_10+1006, 167, f_sum+2006);
	GF2X_MUL(334, temp2, 167, p_11+1006, 167, g_sum+2006);
	gf2x_add(334, temp, 334, temp, 334, temp2);
	gf2x_add(168, g_sum+3011, 168, g_sum+3011, 168, temp+166);
	gf2x_mul_1_avx(temp, f_sum+2172, p_10+1005);
	gf2x_mul_1_avx(temp2, g_sum+2172, p_11+1005);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, g_sum+3011, 1, g_sum+3011, 1, temp+1);
	right_bit_shift_n(335, g_sum+3011, 22);
	
	delta = divstepsx_256(255, delta, f_sum+3176, g_sum+3176, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3176, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3176, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3172, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3172, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3176, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3176, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3172, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3172, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3172, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3172, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3168);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3168);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3172, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3172, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3168);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3168);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3168, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3168, 12, p_01+1325);
	gf2x_add(24, f_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3156, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3156, 12, p_01+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+3966, 12, f_sum+3966, 12, temp+12);
	right_bit_shift_n(24, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3168, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3168, 12, p_11+1325);
	gf2x_add(24, g_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3156, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3156, 12, p_11+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+3966, 12, g_sum+3966, 12, temp+12);
	right_bit_shift_n(24, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3975, g_sum+3975, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3975, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3975, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(q_00+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, q_00+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1312, 8, q_00+1312, 8, temp);
	memset(q_01+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, q_01+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1312, 8, q_01+1312, 8, temp);
	memset(q_10+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, q_10+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1312, 8, q_10+1312, 8, temp);
	memset(q_11+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, q_11+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1312, 8, q_11+1312, 8, temp);
	
	// Recombining results: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_10+1325);
	gf2x_add(24, p_00+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_11+1325);
	gf2x_add(24, p_01+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_10+1325);
	gf2x_add(24, p_10+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_11+1325);
	gf2x_add(24, p_11+1301, 24, temp, 24, temp2);
	
	// Calculating left operands: n: 2805, depth: 5
	GF2X_MUL(48, temp, 24, f_sum+3156, 24, p_00+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3156, 24, p_01+1301);
	gf2x_add(44, f_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, f_sum+3136);
	GF2X_MUL(40, temp2, 20, p_01+1305, 20, g_sum+3136);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(44, f_sum+3897, 58);
	GF2X_MUL(48, temp, 24, f_sum+3156, 24, p_10+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3156, 24, p_11+1301);
	gf2x_add(44, g_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_10+1305, 20, f_sum+3136);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, g_sum+3136);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(44, g_sum+3897, 58);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2805, depth: 5
	memset(p_00+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_01+1292);
	gf2x_add(40, p_00+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1273, 8, p_00+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1269, 8, p_00+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1265, 8, p_00+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1261, 8, p_00+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1257, 8, p_00+1257, 8, temp);
	memset(p_01+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_01+1292);
	gf2x_add(40, p_01+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1273, 8, p_01+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1269, 8, p_01+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1265, 8, p_01+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1261, 8, p_01+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1257, 8, p_01+1257, 8, temp);
	memset(p_10+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_11+1292);
	gf2x_add(40, p_10+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1273, 8, p_10+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1269, 8, p_10+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1265, 8, p_10+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1261, 8, p_10+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1257, 8, p_10+1257, 8, temp);
	memset(p_11+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_11+1292);
	gf2x_add(40, p_11+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1273, 8, p_11+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1269, 8, p_11+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1265, 8, p_11+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1261, 8, p_11+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1257, 8, p_11+1257, 8, temp);
	
	// Calculating left operands: n: 5355, depth: 4
	GF2X_MUL(88, temp, 44, f_sum+3136, 44, p_00+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3136, 44, p_01+1257);
	gf2x_add(84, f_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, f_sum+3096);
	GF2X_MUL(80, temp2, 40, p_01+1261, 40, g_sum+3096);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, f_sum+3768, 40, f_sum+3768, 40, temp+40);
	right_bit_shift_n(84, f_sum+3768, 53);
	GF2X_MUL(88, temp, 44, f_sum+3136, 44, p_10+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3136, 44, p_11+1257);
	gf2x_add(84, g_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_10+1261, 40, f_sum+3096);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, g_sum+3096);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, g_sum+3768, 40, g_sum+3768, 40, temp+40);
	right_bit_shift_n(84, g_sum+3768, 53);
	
	delta = divstepsx_256(255, delta, f_sum+3805, g_sum+3805, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3805, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3805, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3801, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3801, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(p_00+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, p_00+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1305, 8, p_00+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1301, 8, p_00+1301, 8, temp);
	memset(p_01+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, p_01+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1305, 8, p_01+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1301, 8, p_01+1301, 8, temp);
	memset(p_10+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, p_10+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1305, 8, p_10+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1301, 8, p_10+1301, 8, temp);
	memset(p_11+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, p_11+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1305, 8, p_11+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1301, 8, p_11+1301, 8, temp);
	
	// Calculating left operands: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_01+1301);
	gf2x_add(40, f_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_01+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(40, f_sum+3897, 59);
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_11+1301);
	gf2x_add(40, g_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_11+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(40, g_sum+3897, 59);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_10+1301);
	gf2x_add(40, q_00+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_11+1301);
	gf2x_add(40, q_01+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_10+1301);
	gf2x_add(40, q_10+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_11+1301);
	gf2x_add(40, q_11+1252, 40, temp, 40, temp2);
	
	// Recombining results: n: 5355, depth: 4
	memset(p_00+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_01+1252);
	gf2x_add(80, p_00+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1209, 8, p_00+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1205, 8, p_00+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1201, 8, p_00+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1197, 8, p_00+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1193, 8, p_00+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1189, 8, p_00+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1185, 8, p_00+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1181, 8, p_00+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1177, 8, p_00+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1173, 8, p_00+1173, 8, temp);
	memset(p_01+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_01+1252);
	gf2x_add(80, p_01+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1209, 8, p_01+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1205, 8, p_01+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1201, 8, p_01+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1197, 8, p_01+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1193, 8, p_01+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1189, 8, p_01+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1185, 8, p_01+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1181, 8, p_01+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1177, 8, p_01+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1173, 8, p_01+1173, 8, temp);
	memset(p_10+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_11+1252);
	gf2x_add(80, p_10+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1209, 8, p_10+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1205, 8, p_10+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1201, 8, p_10+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1197, 8, p_10+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1193, 8, p_10+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1189, 8, p_10+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1185, 8, p_10+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1181, 8, p_10+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1177, 8, p_10+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1173, 8, p_10+1173, 8, temp);
	memset(p_11+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_11+1252);
	gf2x_add(80, p_11+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1209, 8, p_11+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1205, 8, p_11+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1201, 8, p_11+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1197, 8, p_11+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1193, 8, p_11+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1189, 8, p_11+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1185, 8, p_11+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1181, 8, p_11+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1177, 8, p_11+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1173, 8, p_11+1173, 8, temp);
	
	// Calculating left operands: n: 10710, depth: 3
	GF2X_MUL(168, temp, 84, f_sum+3096, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, g_sum+3096, 84, p_01+1173);
	gf2x_add(168, f_sum+3515, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, f_sum+3012, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, g_sum+3012, 84, p_01+1173);
	gf2x_add(168, temp, 168, temp, 168, temp2);
	gf2x_add(84, f_sum+3515, 84, f_sum+3515, 84, temp+84);
	right_bit_shift_n(168, f_sum+3515, 43);
	GF2X_MUL(168, temp, 84, f_sum+3096, 84, p_10+1173);
	GF2X_MUL(168, temp2, 84, g_sum+3096, 84, p_11+1173);
	gf2x_add(168, g_sum+3515, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, f_sum+3012, 84, p_10+1173);
	GF2X_MUL(168, temp2, 84, g_sum+3012, 84, p_11+1173);
	gf2x_add(168, temp, 168, temp, 168, temp2);
	gf2x_add(84, g_sum+3515, 84, g_sum+3515, 84, temp+84);
	right_bit_shift_n(168, g_sum+3515, 43);
	
	delta = divstepsx_256(255, delta, f_sum+3596, g_sum+3596, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3596, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3596, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3592, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3592, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3596, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3596, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3592, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3592, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3592, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3592, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3588);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3588);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3592, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3592, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3588);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3588);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3588, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3588, 12, p_01+1325);
	gf2x_add(24, f_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3576, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3576, 12, p_01+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+3966, 12, f_sum+3966, 12, temp+12);
	right_bit_shift_n(24, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3588, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3588, 12, p_11+1325);
	gf2x_add(24, g_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3576, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3576, 12, p_11+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+3966, 12, g_sum+3966, 12, temp+12);
	right_bit_shift_n(24, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3975, g_sum+3975, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3975, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3975, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(q_00+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, q_00+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1312, 8, q_00+1312, 8, temp);
	memset(q_01+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, q_01+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1312, 8, q_01+1312, 8, temp);
	memset(q_10+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, q_10+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1312, 8, q_10+1312, 8, temp);
	memset(q_11+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, q_11+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1312, 8, q_11+1312, 8, temp);
	
	// Recombining results: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_10+1325);
	gf2x_add(24, p_00+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_11+1325);
	gf2x_add(24, p_01+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_10+1325);
	gf2x_add(24, p_10+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_11+1325);
	gf2x_add(24, p_11+1301, 24, temp, 24, temp2);
	
	// Calculating left operands: n: 2805, depth: 5
	GF2X_MUL(48, temp, 24, f_sum+3576, 24, p_00+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3576, 24, p_01+1301);
	gf2x_add(44, f_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, f_sum+3556);
	GF2X_MUL(40, temp2, 20, p_01+1305, 20, g_sum+3556);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(44, f_sum+3897, 58);
	GF2X_MUL(48, temp, 24, f_sum+3576, 24, p_10+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3576, 24, p_11+1301);
	gf2x_add(44, g_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_10+1305, 20, f_sum+3556);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, g_sum+3556);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(44, g_sum+3897, 58);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2805, depth: 5
	memset(p_00+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_01+1292);
	gf2x_add(40, p_00+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1273, 8, p_00+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1269, 8, p_00+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1265, 8, p_00+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1261, 8, p_00+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1257, 8, p_00+1257, 8, temp);
	memset(p_01+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_01+1292);
	gf2x_add(40, p_01+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1273, 8, p_01+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1269, 8, p_01+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1265, 8, p_01+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1261, 8, p_01+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1257, 8, p_01+1257, 8, temp);
	memset(p_10+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_11+1292);
	gf2x_add(40, p_10+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1273, 8, p_10+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1269, 8, p_10+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1265, 8, p_10+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1261, 8, p_10+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1257, 8, p_10+1257, 8, temp);
	memset(p_11+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_11+1292);
	gf2x_add(40, p_11+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1273, 8, p_11+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1269, 8, p_11+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1265, 8, p_11+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1261, 8, p_11+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1257, 8, p_11+1257, 8, temp);
	
	// Calculating left operands: n: 5355, depth: 4
	GF2X_MUL(88, temp, 44, f_sum+3556, 44, p_00+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3556, 44, p_01+1257);
	gf2x_add(84, f_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, f_sum+3516);
	GF2X_MUL(80, temp2, 40, p_01+1261, 40, g_sum+3516);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, f_sum+3768, 40, f_sum+3768, 40, temp+40);
	right_bit_shift_n(84, f_sum+3768, 53);
	GF2X_MUL(88, temp, 44, f_sum+3556, 44, p_10+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3556, 44, p_11+1257);
	gf2x_add(84, g_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_10+1261, 40, f_sum+3516);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, g_sum+3516);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, g_sum+3768, 40, g_sum+3768, 40, temp+40);
	right_bit_shift_n(84, g_sum+3768, 53);
	
	delta = divstepsx_256(255, delta, f_sum+3805, g_sum+3805, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3805, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3805, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3801, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3801, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(p_00+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, p_00+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1305, 8, p_00+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1301, 8, p_00+1301, 8, temp);
	memset(p_01+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, p_01+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1305, 8, p_01+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1301, 8, p_01+1301, 8, temp);
	memset(p_10+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, p_10+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1305, 8, p_10+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1301, 8, p_10+1301, 8, temp);
	memset(p_11+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, p_11+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1305, 8, p_11+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1301, 8, p_11+1301, 8, temp);
	
	// Calculating left operands: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_01+1301);
	gf2x_add(40, f_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_01+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(40, f_sum+3897, 59);
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_11+1301);
	gf2x_add(40, g_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_11+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(40, g_sum+3897, 59);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_10+1301);
	gf2x_add(40, q_00+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_11+1301);
	gf2x_add(40, q_01+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_10+1301);
	gf2x_add(40, q_10+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_11+1301);
	gf2x_add(40, q_11+1252, 40, temp, 40, temp2);
	
	// Recombining results: n: 5355, depth: 4
	memset(q_00+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_01+1252);
	gf2x_add(80, q_00+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1204, 8, q_00+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1200, 8, q_00+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1196, 8, q_00+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1192, 8, q_00+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1188, 8, q_00+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1184, 8, q_00+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1180, 8, q_00+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1176, 8, q_00+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1172, 8, q_00+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1168, 8, q_00+1168, 8, temp);
	memset(q_01+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_01+1252);
	gf2x_add(80, q_01+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1204, 8, q_01+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1200, 8, q_01+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1196, 8, q_01+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1192, 8, q_01+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1188, 8, q_01+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1184, 8, q_01+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1180, 8, q_01+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1176, 8, q_01+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1172, 8, q_01+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1168, 8, q_01+1168, 8, temp);
	memset(q_10+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_11+1252);
	gf2x_add(80, q_10+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1204, 8, q_10+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1200, 8, q_10+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1196, 8, q_10+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1192, 8, q_10+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1188, 8, q_10+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1184, 8, q_10+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1180, 8, q_10+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1176, 8, q_10+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1172, 8, q_10+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1168, 8, q_10+1168, 8, temp);
	memset(q_11+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_11+1252);
	gf2x_add(80, q_11+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1204, 8, q_11+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1200, 8, q_11+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1196, 8, q_11+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1192, 8, q_11+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1188, 8, q_11+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1184, 8, q_11+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1180, 8, q_11+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1176, 8, q_11+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1172, 8, q_11+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1168, 8, q_11+1168, 8, temp);
	
	// Recombining results: n: 10710, depth: 3
	GF2X_MUL(168, temp, 84, q_00+1168, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, q_01+1168, 84, p_10+1173);
	gf2x_add(168, q_00+1000, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_00+1168, 84, p_01+1173);
	GF2X_MUL(168, temp2, 84, q_01+1168, 84, p_11+1173);
	gf2x_add(168, q_01+1000, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_10+1168, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, q_11+1168, 84, p_10+1173);
	gf2x_add(168, q_10+1000, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_10+1168, 84, p_01+1173);
	GF2X_MUL(168, temp2, 84, q_11+1168, 84, p_11+1173);
	gf2x_add(168, q_11+1000, 168, temp, 168, temp2);
	
	// Recombining results: n: 21420, depth: 2
	GF2X_MUL(336, temp, 168, q_00+1000, 168, p_00+1005);
	GF2X_MUL(336, temp2, 168, q_01+1000, 168, p_10+1005);
	gf2x_add(335, q_00+665, 335, temp+1, 335, temp2+1);
	GF2X_MUL(336, temp, 168, q_00+1000, 168, p_01+1005);
	GF2X_MUL(336, temp2, 168, q_01+1000, 168, p_11+1005);
	gf2x_add(335, q_01+665, 335, temp+1, 335, temp2+1);
	GF2X_MUL(336, temp, 168, q_10+1000, 168, p_00+1005);
	GF2X_MUL(336, temp2, 168, q_11+1000, 168, p_10+1005);
	gf2x_add(335, q_10+665, 335, temp+1, 335, temp2+1);
	GF2X_MUL(336, temp, 168, q_10+1000, 168, p_01+1005);
	GF2X_MUL(336, temp2, 168, q_11+1000, 168, p_11+1005);
	gf2x_add(335, q_11+665, 335, temp+1, 335, temp2+1);
	
	// Recombining results: n: 42840, depth: 1
	GF2X_MUL(670, temp, 335, q_00+665, 335, p_00+670);
	GF2X_MUL(670, temp2, 335, q_01+665, 335, p_10+670);
	gf2x_add(670, p_00+0, 670, temp, 670, temp2);
	GF2X_MUL(670, temp, 335, q_00+665, 335, p_01+670);
	GF2X_MUL(670, temp2, 335, q_01+665, 335, p_11+670);
	gf2x_add(670, p_01+0, 670, temp, 670, temp2);
	GF2X_MUL(670, temp, 335, q_10+665, 335, p_00+670);
	GF2X_MUL(670, temp2, 335, q_11+665, 335, p_10+670);
	gf2x_add(670, p_10+0, 670, temp, 670, temp2);
	GF2X_MUL(670, temp, 335, q_10+665, 335, p_01+670);
	GF2X_MUL(670, temp2, 335, q_11+665, 335, p_11+670);
	gf2x_add(670, p_11+0, 670, temp, 670, temp2);
	
	// Calculating left operands: n: 85353, depth: 0
	GF2X_MUL(1340, temp, 670, f+664, 670, p_00+0);
	GF2X_MUL(1340, temp2, 670, g+664, 670, p_01+0);
	gf2x_add(1335, f_sum+0, 1335, temp+5, 1335, temp2+5);
	GF2X_MUL(1328, temp, 664, p_00+6, 664, f+0);
	GF2X_MUL(1328, temp2, 664, p_01+6, 664, g+0);
	gf2x_add(1328, temp, 1328, temp, 1328, temp2);
	gf2x_add(665, f_sum+0, 665, f_sum+0, 665, temp+663);
	gf2x_mul_6_avx(temp, f+658, p_00+0);
	gf2x_mul_6_avx(temp2, g+658, p_01+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(1, f_sum+0, 1, f_sum+0, 1, temp+11);
	right_bit_shift_n(1334, f_sum+0, 24);
	GF2X_MUL(1340, temp, 670, f+664, 670, p_10+0);
	GF2X_MUL(1340, temp2, 670, g+664, 670, p_11+0);
	gf2x_add(1335, g_sum+0, 1335, temp+5, 1335, temp2+5);
	GF2X_MUL(1328, temp, 664, p_10+6, 664, f+0);
	GF2X_MUL(1328, temp2, 664, p_11+6, 664, g+0);
	gf2x_add(1328, temp, 1328, temp, 1328, temp2);
	gf2x_add(665, g_sum+0, 665, g_sum+0, 665, temp+663);
	gf2x_mul_6_avx(temp, f+658, p_10+0);
	gf2x_mul_6_avx(temp2, g+658, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(1, g_sum+0, 1, g_sum+0, 1, temp+11);
	right_bit_shift_n(1334, g_sum+0, 24);
	
	delta = divstepsx_256(255, delta, f_sum+662, g_sum+662, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+662, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+662, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+658, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+658, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+662, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+662, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+658, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+658, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+658, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+658, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+654);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+654);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+658, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+658, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+654);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+654);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+654, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+654, 12, p_01+1325);
	gf2x_add(24, f_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+642, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+642, 12, p_01+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+3966, 12, f_sum+3966, 12, temp+12);
	right_bit_shift_n(24, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+654, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+654, 12, p_11+1325);
	gf2x_add(24, g_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+642, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+642, 12, p_11+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+3966, 12, g_sum+3966, 12, temp+12);
	right_bit_shift_n(24, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3975, g_sum+3975, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3975, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3975, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(q_00+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, q_00+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1312, 8, q_00+1312, 8, temp);
	memset(q_01+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, q_01+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1312, 8, q_01+1312, 8, temp);
	memset(q_10+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, q_10+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1312, 8, q_10+1312, 8, temp);
	memset(q_11+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, q_11+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1312, 8, q_11+1312, 8, temp);
	
	// Recombining results: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_10+1325);
	gf2x_add(24, p_00+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_11+1325);
	gf2x_add(24, p_01+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_10+1325);
	gf2x_add(24, p_10+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_11+1325);
	gf2x_add(24, p_11+1301, 24, temp, 24, temp2);
	
	// Calculating left operands: n: 2805, depth: 5
	GF2X_MUL(48, temp, 24, f_sum+642, 24, p_00+1301);
	GF2X_MUL(48, temp2, 24, g_sum+642, 24, p_01+1301);
	gf2x_add(44, f_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, f_sum+622);
	GF2X_MUL(40, temp2, 20, p_01+1305, 20, g_sum+622);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(44, f_sum+3897, 58);
	GF2X_MUL(48, temp, 24, f_sum+642, 24, p_10+1301);
	GF2X_MUL(48, temp2, 24, g_sum+642, 24, p_11+1301);
	gf2x_add(44, g_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_10+1305, 20, f_sum+622);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, g_sum+622);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(44, g_sum+3897, 58);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2805, depth: 5
	memset(p_00+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_01+1292);
	gf2x_add(40, p_00+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1273, 8, p_00+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1269, 8, p_00+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1265, 8, p_00+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1261, 8, p_00+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1257, 8, p_00+1257, 8, temp);
	memset(p_01+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_01+1292);
	gf2x_add(40, p_01+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1273, 8, p_01+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1269, 8, p_01+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1265, 8, p_01+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1261, 8, p_01+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1257, 8, p_01+1257, 8, temp);
	memset(p_10+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_11+1292);
	gf2x_add(40, p_10+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1273, 8, p_10+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1269, 8, p_10+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1265, 8, p_10+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1261, 8, p_10+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1257, 8, p_10+1257, 8, temp);
	memset(p_11+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_11+1292);
	gf2x_add(40, p_11+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1273, 8, p_11+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1269, 8, p_11+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1265, 8, p_11+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1261, 8, p_11+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1257, 8, p_11+1257, 8, temp);
	
	// Calculating left operands: n: 5355, depth: 4
	GF2X_MUL(88, temp, 44, f_sum+622, 44, p_00+1257);
	GF2X_MUL(88, temp2, 44, g_sum+622, 44, p_01+1257);
	gf2x_add(84, f_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, f_sum+582);
	GF2X_MUL(80, temp2, 40, p_01+1261, 40, g_sum+582);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, f_sum+3768, 40, f_sum+3768, 40, temp+40);
	right_bit_shift_n(84, f_sum+3768, 53);
	GF2X_MUL(88, temp, 44, f_sum+622, 44, p_10+1257);
	GF2X_MUL(88, temp2, 44, g_sum+622, 44, p_11+1257);
	gf2x_add(84, g_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_10+1261, 40, f_sum+582);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, g_sum+582);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, g_sum+3768, 40, g_sum+3768, 40, temp+40);
	right_bit_shift_n(84, g_sum+3768, 53);
	
	delta = divstepsx_256(255, delta, f_sum+3805, g_sum+3805, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3805, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3805, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3801, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3801, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(p_00+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, p_00+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1305, 8, p_00+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1301, 8, p_00+1301, 8, temp);
	memset(p_01+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, p_01+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1305, 8, p_01+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1301, 8, p_01+1301, 8, temp);
	memset(p_10+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, p_10+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1305, 8, p_10+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1301, 8, p_10+1301, 8, temp);
	memset(p_11+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, p_11+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1305, 8, p_11+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1301, 8, p_11+1301, 8, temp);
	
	// Calculating left operands: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_01+1301);
	gf2x_add(40, f_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_01+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(40, f_sum+3897, 59);
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_11+1301);
	gf2x_add(40, g_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_11+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(40, g_sum+3897, 59);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_10+1301);
	gf2x_add(40, q_00+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_11+1301);
	gf2x_add(40, q_01+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_10+1301);
	gf2x_add(40, q_10+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_11+1301);
	gf2x_add(40, q_11+1252, 40, temp, 40, temp2);
	
	// Recombining results: n: 5355, depth: 4
	memset(p_00+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_01+1252);
	gf2x_add(80, p_00+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1209, 8, p_00+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1205, 8, p_00+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1201, 8, p_00+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1197, 8, p_00+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1193, 8, p_00+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1189, 8, p_00+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1185, 8, p_00+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1181, 8, p_00+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1177, 8, p_00+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1173, 8, p_00+1173, 8, temp);
	memset(p_01+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_01+1252);
	gf2x_add(80, p_01+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1209, 8, p_01+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1205, 8, p_01+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1201, 8, p_01+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1197, 8, p_01+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1193, 8, p_01+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1189, 8, p_01+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1185, 8, p_01+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1181, 8, p_01+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1177, 8, p_01+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1173, 8, p_01+1173, 8, temp);
	memset(p_10+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_11+1252);
	gf2x_add(80, p_10+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1209, 8, p_10+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1205, 8, p_10+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1201, 8, p_10+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1197, 8, p_10+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1193, 8, p_10+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1189, 8, p_10+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1185, 8, p_10+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1181, 8, p_10+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1177, 8, p_10+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1173, 8, p_10+1173, 8, temp);
	memset(p_11+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_11+1252);
	gf2x_add(80, p_11+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1209, 8, p_11+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1205, 8, p_11+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1201, 8, p_11+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1197, 8, p_11+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1193, 8, p_11+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1189, 8, p_11+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1185, 8, p_11+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1181, 8, p_11+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1177, 8, p_11+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1173, 8, p_11+1173, 8, temp);
	
	// Calculating left operands: n: 10710, depth: 3
	GF2X_MUL(168, temp, 84, f_sum+582, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, g_sum+582, 84, p_01+1173);
	gf2x_add(168, f_sum+3515, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, f_sum+498, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, g_sum+498, 84, p_01+1173);
	gf2x_add(168, temp, 168, temp, 168, temp2);
	gf2x_add(84, f_sum+3515, 84, f_sum+3515, 84, temp+84);
	right_bit_shift_n(168, f_sum+3515, 43);
	GF2X_MUL(168, temp, 84, f_sum+582, 84, p_10+1173);
	GF2X_MUL(168, temp2, 84, g_sum+582, 84, p_11+1173);
	gf2x_add(168, g_sum+3515, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, f_sum+498, 84, p_10+1173);
	GF2X_MUL(168, temp2, 84, g_sum+498, 84, p_11+1173);
	gf2x_add(168, temp, 168, temp, 168, temp2);
	gf2x_add(84, g_sum+3515, 84, g_sum+3515, 84, temp+84);
	right_bit_shift_n(168, g_sum+3515, 43);
	
	delta = divstepsx_256(255, delta, f_sum+3596, g_sum+3596, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3596, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3596, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3592, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3592, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3596, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3596, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3592, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3592, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3592, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3592, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3588);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3588);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3592, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3592, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3588);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3588);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3588, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3588, 12, p_01+1325);
	gf2x_add(24, f_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3576, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3576, 12, p_01+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+3966, 12, f_sum+3966, 12, temp+12);
	right_bit_shift_n(24, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3588, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3588, 12, p_11+1325);
	gf2x_add(24, g_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3576, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3576, 12, p_11+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+3966, 12, g_sum+3966, 12, temp+12);
	right_bit_shift_n(24, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3975, g_sum+3975, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3975, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3975, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(q_00+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, q_00+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1312, 8, q_00+1312, 8, temp);
	memset(q_01+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, q_01+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1312, 8, q_01+1312, 8, temp);
	memset(q_10+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, q_10+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1312, 8, q_10+1312, 8, temp);
	memset(q_11+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, q_11+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1312, 8, q_11+1312, 8, temp);
	
	// Recombining results: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_10+1325);
	gf2x_add(24, p_00+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_11+1325);
	gf2x_add(24, p_01+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_10+1325);
	gf2x_add(24, p_10+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_11+1325);
	gf2x_add(24, p_11+1301, 24, temp, 24, temp2);
	
	// Calculating left operands: n: 2805, depth: 5
	GF2X_MUL(48, temp, 24, f_sum+3576, 24, p_00+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3576, 24, p_01+1301);
	gf2x_add(44, f_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, f_sum+3556);
	GF2X_MUL(40, temp2, 20, p_01+1305, 20, g_sum+3556);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(44, f_sum+3897, 58);
	GF2X_MUL(48, temp, 24, f_sum+3576, 24, p_10+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3576, 24, p_11+1301);
	gf2x_add(44, g_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_10+1305, 20, f_sum+3556);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, g_sum+3556);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(44, g_sum+3897, 58);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2805, depth: 5
	memset(p_00+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_01+1292);
	gf2x_add(40, p_00+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1273, 8, p_00+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1269, 8, p_00+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1265, 8, p_00+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1261, 8, p_00+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1257, 8, p_00+1257, 8, temp);
	memset(p_01+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_01+1292);
	gf2x_add(40, p_01+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1273, 8, p_01+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1269, 8, p_01+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1265, 8, p_01+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1261, 8, p_01+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1257, 8, p_01+1257, 8, temp);
	memset(p_10+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_11+1292);
	gf2x_add(40, p_10+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1273, 8, p_10+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1269, 8, p_10+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1265, 8, p_10+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1261, 8, p_10+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1257, 8, p_10+1257, 8, temp);
	memset(p_11+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_11+1292);
	gf2x_add(40, p_11+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1273, 8, p_11+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1269, 8, p_11+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1265, 8, p_11+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1261, 8, p_11+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1257, 8, p_11+1257, 8, temp);
	
	// Calculating left operands: n: 5355, depth: 4
	GF2X_MUL(88, temp, 44, f_sum+3556, 44, p_00+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3556, 44, p_01+1257);
	gf2x_add(84, f_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, f_sum+3516);
	GF2X_MUL(80, temp2, 40, p_01+1261, 40, g_sum+3516);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, f_sum+3768, 40, f_sum+3768, 40, temp+40);
	right_bit_shift_n(84, f_sum+3768, 53);
	GF2X_MUL(88, temp, 44, f_sum+3556, 44, p_10+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3556, 44, p_11+1257);
	gf2x_add(84, g_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_10+1261, 40, f_sum+3516);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, g_sum+3516);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, g_sum+3768, 40, g_sum+3768, 40, temp+40);
	right_bit_shift_n(84, g_sum+3768, 53);
	
	delta = divstepsx_256(255, delta, f_sum+3805, g_sum+3805, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3805, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3805, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3801, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3801, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(p_00+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, p_00+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1305, 8, p_00+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1301, 8, p_00+1301, 8, temp);
	memset(p_01+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, p_01+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1305, 8, p_01+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1301, 8, p_01+1301, 8, temp);
	memset(p_10+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, p_10+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1305, 8, p_10+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1301, 8, p_10+1301, 8, temp);
	memset(p_11+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, p_11+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1305, 8, p_11+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1301, 8, p_11+1301, 8, temp);
	
	// Calculating left operands: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_01+1301);
	gf2x_add(40, f_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_01+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(40, f_sum+3897, 59);
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_11+1301);
	gf2x_add(40, g_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_11+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(40, g_sum+3897, 59);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_10+1301);
	gf2x_add(40, q_00+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_11+1301);
	gf2x_add(40, q_01+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_10+1301);
	gf2x_add(40, q_10+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_11+1301);
	gf2x_add(40, q_11+1252, 40, temp, 40, temp2);
	
	// Recombining results: n: 5355, depth: 4
	memset(q_00+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_01+1252);
	gf2x_add(80, q_00+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1204, 8, q_00+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1200, 8, q_00+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1196, 8, q_00+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1192, 8, q_00+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1188, 8, q_00+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1184, 8, q_00+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1180, 8, q_00+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1176, 8, q_00+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1172, 8, q_00+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1168, 8, q_00+1168, 8, temp);
	memset(q_01+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_01+1252);
	gf2x_add(80, q_01+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1204, 8, q_01+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1200, 8, q_01+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1196, 8, q_01+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1192, 8, q_01+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1188, 8, q_01+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1184, 8, q_01+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1180, 8, q_01+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1176, 8, q_01+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1172, 8, q_01+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1168, 8, q_01+1168, 8, temp);
	memset(q_10+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_11+1252);
	gf2x_add(80, q_10+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1204, 8, q_10+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1200, 8, q_10+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1196, 8, q_10+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1192, 8, q_10+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1188, 8, q_10+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1184, 8, q_10+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1180, 8, q_10+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1176, 8, q_10+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1172, 8, q_10+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1168, 8, q_10+1168, 8, temp);
	memset(q_11+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_11+1252);
	gf2x_add(80, q_11+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1204, 8, q_11+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1200, 8, q_11+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1196, 8, q_11+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1192, 8, q_11+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1188, 8, q_11+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1184, 8, q_11+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1180, 8, q_11+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1176, 8, q_11+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1172, 8, q_11+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1168, 8, q_11+1168, 8, temp);
	
	// Recombining results: n: 10710, depth: 3
	GF2X_MUL(168, temp, 84, q_00+1168, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, q_01+1168, 84, p_10+1173);
	gf2x_add(168, p_00+1005, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_00+1168, 84, p_01+1173);
	GF2X_MUL(168, temp2, 84, q_01+1168, 84, p_11+1173);
	gf2x_add(168, p_01+1005, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_10+1168, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, q_11+1168, 84, p_10+1173);
	gf2x_add(168, p_10+1005, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_10+1168, 84, p_01+1173);
	GF2X_MUL(168, temp2, 84, q_11+1168, 84, p_11+1173);
	gf2x_add(168, p_11+1005, 168, temp, 168, temp2);
	
	// Calculating left operands: n: 21420, depth: 2
	GF2X_MUL(336, temp, 168, f_sum+498, 168, p_00+1005);
	GF2X_MUL(336, temp2, 168, g_sum+498, 168, p_01+1005);
	gf2x_add(336, f_sum+3011, 336, temp, 336, temp2);
	GF2X_MUL(334, temp, 167, p_00+1006, 167, f_sum+331);
	GF2X_MUL(334, temp2, 167, p_01+1006, 167, g_sum+331);
	gf2x_add(334, temp, 334, temp, 334, temp2);
	gf2x_add(168, f_sum+3011, 168, f_sum+3011, 168, temp+166);
	gf2x_mul_1_avx(temp, f_sum+497, p_00+1005);
	gf2x_mul_1_avx(temp2, g_sum+497, p_01+1005);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, f_sum+3011, 1, f_sum+3011, 1, temp+1);
	right_bit_shift_n(335, f_sum+3011, 22);
	GF2X_MUL(336, temp, 168, f_sum+498, 168, p_10+1005);
	GF2X_MUL(336, temp2, 168, g_sum+498, 168, p_11+1005);
	gf2x_add(336, g_sum+3011, 336, temp, 336, temp2);
	GF2X_MUL(334, temp, 167, p_10+1006, 167, f_sum+331);
	GF2X_MUL(334, temp2, 167, p_11+1006, 167, g_sum+331);
	gf2x_add(334, temp, 334, temp, 334, temp2);
	gf2x_add(168, g_sum+3011, 168, g_sum+3011, 168, temp+166);
	gf2x_mul_1_avx(temp, f_sum+497, p_10+1005);
	gf2x_mul_1_avx(temp2, g_sum+497, p_11+1005);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, g_sum+3011, 1, g_sum+3011, 1, temp+1);
	right_bit_shift_n(335, g_sum+3011, 22);
	
	delta = divstepsx_256(255, delta, f_sum+3176, g_sum+3176, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3176, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3176, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3172, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3172, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3176, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3176, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3172, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3172, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3172, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3172, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3168);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3168);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3172, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3172, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3168);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3168);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3168, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3168, 12, p_01+1325);
	gf2x_add(24, f_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3156, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3156, 12, p_01+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+3966, 12, f_sum+3966, 12, temp+12);
	right_bit_shift_n(24, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3168, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3168, 12, p_11+1325);
	gf2x_add(24, g_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3156, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3156, 12, p_11+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+3966, 12, g_sum+3966, 12, temp+12);
	right_bit_shift_n(24, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3975, g_sum+3975, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3975, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3975, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(q_00+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, q_00+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1312, 8, q_00+1312, 8, temp);
	memset(q_01+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, q_01+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1312, 8, q_01+1312, 8, temp);
	memset(q_10+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, q_10+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1312, 8, q_10+1312, 8, temp);
	memset(q_11+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, q_11+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1312, 8, q_11+1312, 8, temp);
	
	// Recombining results: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_10+1325);
	gf2x_add(24, p_00+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_11+1325);
	gf2x_add(24, p_01+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_10+1325);
	gf2x_add(24, p_10+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_11+1325);
	gf2x_add(24, p_11+1301, 24, temp, 24, temp2);
	
	// Calculating left operands: n: 2805, depth: 5
	GF2X_MUL(48, temp, 24, f_sum+3156, 24, p_00+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3156, 24, p_01+1301);
	gf2x_add(44, f_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, f_sum+3136);
	GF2X_MUL(40, temp2, 20, p_01+1305, 20, g_sum+3136);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(44, f_sum+3897, 58);
	GF2X_MUL(48, temp, 24, f_sum+3156, 24, p_10+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3156, 24, p_11+1301);
	gf2x_add(44, g_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_10+1305, 20, f_sum+3136);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, g_sum+3136);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(44, g_sum+3897, 58);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2805, depth: 5
	memset(p_00+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_01+1292);
	gf2x_add(40, p_00+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1273, 8, p_00+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1269, 8, p_00+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1265, 8, p_00+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1261, 8, p_00+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1257, 8, p_00+1257, 8, temp);
	memset(p_01+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_01+1292);
	gf2x_add(40, p_01+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1273, 8, p_01+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1269, 8, p_01+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1265, 8, p_01+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1261, 8, p_01+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1257, 8, p_01+1257, 8, temp);
	memset(p_10+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_11+1292);
	gf2x_add(40, p_10+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1273, 8, p_10+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1269, 8, p_10+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1265, 8, p_10+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1261, 8, p_10+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1257, 8, p_10+1257, 8, temp);
	memset(p_11+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_11+1292);
	gf2x_add(40, p_11+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1273, 8, p_11+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1269, 8, p_11+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1265, 8, p_11+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1261, 8, p_11+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1257, 8, p_11+1257, 8, temp);
	
	// Calculating left operands: n: 5355, depth: 4
	GF2X_MUL(88, temp, 44, f_sum+3136, 44, p_00+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3136, 44, p_01+1257);
	gf2x_add(84, f_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, f_sum+3096);
	GF2X_MUL(80, temp2, 40, p_01+1261, 40, g_sum+3096);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, f_sum+3768, 40, f_sum+3768, 40, temp+40);
	right_bit_shift_n(84, f_sum+3768, 53);
	GF2X_MUL(88, temp, 44, f_sum+3136, 44, p_10+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3136, 44, p_11+1257);
	gf2x_add(84, g_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_10+1261, 40, f_sum+3096);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, g_sum+3096);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, g_sum+3768, 40, g_sum+3768, 40, temp+40);
	right_bit_shift_n(84, g_sum+3768, 53);
	
	delta = divstepsx_256(255, delta, f_sum+3805, g_sum+3805, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3805, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3805, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3801, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3801, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(p_00+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, p_00+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1305, 8, p_00+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1301, 8, p_00+1301, 8, temp);
	memset(p_01+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, p_01+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1305, 8, p_01+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1301, 8, p_01+1301, 8, temp);
	memset(p_10+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, p_10+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1305, 8, p_10+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1301, 8, p_10+1301, 8, temp);
	memset(p_11+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, p_11+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1305, 8, p_11+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1301, 8, p_11+1301, 8, temp);
	
	// Calculating left operands: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_01+1301);
	gf2x_add(40, f_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_01+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(40, f_sum+3897, 59);
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_11+1301);
	gf2x_add(40, g_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_11+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(40, g_sum+3897, 59);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_10+1301);
	gf2x_add(40, q_00+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_11+1301);
	gf2x_add(40, q_01+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_10+1301);
	gf2x_add(40, q_10+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_11+1301);
	gf2x_add(40, q_11+1252, 40, temp, 40, temp2);
	
	// Recombining results: n: 5355, depth: 4
	memset(p_00+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_01+1252);
	gf2x_add(80, p_00+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1209, 8, p_00+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1205, 8, p_00+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1201, 8, p_00+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1197, 8, p_00+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1193, 8, p_00+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1189, 8, p_00+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1185, 8, p_00+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1181, 8, p_00+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1177, 8, p_00+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1173, 8, p_00+1173, 8, temp);
	memset(p_01+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_01+1252);
	gf2x_add(80, p_01+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1209, 8, p_01+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1205, 8, p_01+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1201, 8, p_01+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1197, 8, p_01+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1193, 8, p_01+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1189, 8, p_01+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1185, 8, p_01+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1181, 8, p_01+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1177, 8, p_01+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1173, 8, p_01+1173, 8, temp);
	memset(p_10+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_11+1252);
	gf2x_add(80, p_10+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1209, 8, p_10+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1205, 8, p_10+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1201, 8, p_10+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1197, 8, p_10+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1193, 8, p_10+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1189, 8, p_10+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1185, 8, p_10+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1181, 8, p_10+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1177, 8, p_10+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1173, 8, p_10+1173, 8, temp);
	memset(p_11+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_11+1252);
	gf2x_add(80, p_11+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1209, 8, p_11+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1205, 8, p_11+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1201, 8, p_11+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1197, 8, p_11+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1193, 8, p_11+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1189, 8, p_11+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1185, 8, p_11+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1181, 8, p_11+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1177, 8, p_11+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1173, 8, p_11+1173, 8, temp);
	
	// Calculating left operands: n: 10710, depth: 3
	GF2X_MUL(168, temp, 84, f_sum+3096, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, g_sum+3096, 84, p_01+1173);
	gf2x_add(168, f_sum+3515, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, f_sum+3012, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, g_sum+3012, 84, p_01+1173);
	gf2x_add(168, temp, 168, temp, 168, temp2);
	gf2x_add(84, f_sum+3515, 84, f_sum+3515, 84, temp+84);
	right_bit_shift_n(168, f_sum+3515, 43);
	GF2X_MUL(168, temp, 84, f_sum+3096, 84, p_10+1173);
	GF2X_MUL(168, temp2, 84, g_sum+3096, 84, p_11+1173);
	gf2x_add(168, g_sum+3515, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, f_sum+3012, 84, p_10+1173);
	GF2X_MUL(168, temp2, 84, g_sum+3012, 84, p_11+1173);
	gf2x_add(168, temp, 168, temp, 168, temp2);
	gf2x_add(84, g_sum+3515, 84, g_sum+3515, 84, temp+84);
	right_bit_shift_n(168, g_sum+3515, 43);
	
	delta = divstepsx_256(255, delta, f_sum+3596, g_sum+3596, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3596, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3596, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3592, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3592, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3596, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3596, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3592, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3592, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3592, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3592, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3588);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3588);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3592, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3592, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3588);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3588);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3588, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3588, 12, p_01+1325);
	gf2x_add(24, f_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3576, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3576, 12, p_01+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+3966, 12, f_sum+3966, 12, temp+12);
	right_bit_shift_n(24, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3588, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3588, 12, p_11+1325);
	gf2x_add(24, g_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3576, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3576, 12, p_11+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+3966, 12, g_sum+3966, 12, temp+12);
	right_bit_shift_n(24, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3975, g_sum+3975, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3975, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3975, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(q_00+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, q_00+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1312, 8, q_00+1312, 8, temp);
	memset(q_01+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, q_01+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1312, 8, q_01+1312, 8, temp);
	memset(q_10+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, q_10+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1312, 8, q_10+1312, 8, temp);
	memset(q_11+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, q_11+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1312, 8, q_11+1312, 8, temp);
	
	// Recombining results: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_10+1325);
	gf2x_add(24, p_00+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_11+1325);
	gf2x_add(24, p_01+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_10+1325);
	gf2x_add(24, p_10+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_11+1325);
	gf2x_add(24, p_11+1301, 24, temp, 24, temp2);
	
	// Calculating left operands: n: 2805, depth: 5
	GF2X_MUL(48, temp, 24, f_sum+3576, 24, p_00+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3576, 24, p_01+1301);
	gf2x_add(44, f_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, f_sum+3556);
	GF2X_MUL(40, temp2, 20, p_01+1305, 20, g_sum+3556);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(44, f_sum+3897, 58);
	GF2X_MUL(48, temp, 24, f_sum+3576, 24, p_10+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3576, 24, p_11+1301);
	gf2x_add(44, g_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_10+1305, 20, f_sum+3556);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, g_sum+3556);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(44, g_sum+3897, 58);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2805, depth: 5
	memset(p_00+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_01+1292);
	gf2x_add(40, p_00+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1273, 8, p_00+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1269, 8, p_00+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1265, 8, p_00+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1261, 8, p_00+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1257, 8, p_00+1257, 8, temp);
	memset(p_01+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_01+1292);
	gf2x_add(40, p_01+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1273, 8, p_01+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1269, 8, p_01+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1265, 8, p_01+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1261, 8, p_01+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1257, 8, p_01+1257, 8, temp);
	memset(p_10+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_11+1292);
	gf2x_add(40, p_10+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1273, 8, p_10+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1269, 8, p_10+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1265, 8, p_10+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1261, 8, p_10+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1257, 8, p_10+1257, 8, temp);
	memset(p_11+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_11+1292);
	gf2x_add(40, p_11+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1273, 8, p_11+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1269, 8, p_11+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1265, 8, p_11+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1261, 8, p_11+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1257, 8, p_11+1257, 8, temp);
	
	// Calculating left operands: n: 5355, depth: 4
	GF2X_MUL(88, temp, 44, f_sum+3556, 44, p_00+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3556, 44, p_01+1257);
	gf2x_add(84, f_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, f_sum+3516);
	GF2X_MUL(80, temp2, 40, p_01+1261, 40, g_sum+3516);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, f_sum+3768, 40, f_sum+3768, 40, temp+40);
	right_bit_shift_n(84, f_sum+3768, 53);
	GF2X_MUL(88, temp, 44, f_sum+3556, 44, p_10+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3556, 44, p_11+1257);
	gf2x_add(84, g_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_10+1261, 40, f_sum+3516);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, g_sum+3516);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, g_sum+3768, 40, g_sum+3768, 40, temp+40);
	right_bit_shift_n(84, g_sum+3768, 53);
	
	delta = divstepsx_256(255, delta, f_sum+3805, g_sum+3805, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3805, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3805, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3801, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3801, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(p_00+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, p_00+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1305, 8, p_00+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1301, 8, p_00+1301, 8, temp);
	memset(p_01+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, p_01+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1305, 8, p_01+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1301, 8, p_01+1301, 8, temp);
	memset(p_10+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, p_10+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1305, 8, p_10+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1301, 8, p_10+1301, 8, temp);
	memset(p_11+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, p_11+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1305, 8, p_11+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1301, 8, p_11+1301, 8, temp);
	
	// Calculating left operands: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_01+1301);
	gf2x_add(40, f_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_01+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(40, f_sum+3897, 59);
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_11+1301);
	gf2x_add(40, g_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_11+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(40, g_sum+3897, 59);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_10+1301);
	gf2x_add(40, q_00+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_11+1301);
	gf2x_add(40, q_01+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_10+1301);
	gf2x_add(40, q_10+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_11+1301);
	gf2x_add(40, q_11+1252, 40, temp, 40, temp2);
	
	// Recombining results: n: 5355, depth: 4
	memset(q_00+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_01+1252);
	gf2x_add(80, q_00+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1204, 8, q_00+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1200, 8, q_00+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1196, 8, q_00+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1192, 8, q_00+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1188, 8, q_00+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1184, 8, q_00+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1180, 8, q_00+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1176, 8, q_00+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1172, 8, q_00+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1168, 8, q_00+1168, 8, temp);
	memset(q_01+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_01+1252);
	gf2x_add(80, q_01+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1204, 8, q_01+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1200, 8, q_01+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1196, 8, q_01+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1192, 8, q_01+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1188, 8, q_01+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1184, 8, q_01+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1180, 8, q_01+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1176, 8, q_01+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1172, 8, q_01+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1168, 8, q_01+1168, 8, temp);
	memset(q_10+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_11+1252);
	gf2x_add(80, q_10+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1204, 8, q_10+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1200, 8, q_10+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1196, 8, q_10+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1192, 8, q_10+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1188, 8, q_10+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1184, 8, q_10+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1180, 8, q_10+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1176, 8, q_10+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1172, 8, q_10+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1168, 8, q_10+1168, 8, temp);
	memset(q_11+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_11+1252);
	gf2x_add(80, q_11+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1204, 8, q_11+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1200, 8, q_11+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1196, 8, q_11+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1192, 8, q_11+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1188, 8, q_11+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1184, 8, q_11+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1180, 8, q_11+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1176, 8, q_11+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1172, 8, q_11+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1168, 8, q_11+1168, 8, temp);
	
	// Recombining results: n: 10710, depth: 3
	GF2X_MUL(168, temp, 84, q_00+1168, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, q_01+1168, 84, p_10+1173);
	gf2x_add(168, q_00+1000, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_00+1168, 84, p_01+1173);
	GF2X_MUL(168, temp2, 84, q_01+1168, 84, p_11+1173);
	gf2x_add(168, q_01+1000, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_10+1168, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, q_11+1168, 84, p_10+1173);
	gf2x_add(168, q_10+1000, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_10+1168, 84, p_01+1173);
	GF2X_MUL(168, temp2, 84, q_11+1168, 84, p_11+1173);
	gf2x_add(168, q_11+1000, 168, temp, 168, temp2);
	
	// Recombining results: n: 21420, depth: 2
	GF2X_MUL(336, temp, 168, q_00+1000, 168, p_00+1005);
	GF2X_MUL(336, temp2, 168, q_01+1000, 168, p_10+1005);
	gf2x_add(335, p_00+670, 335, temp+1, 335, temp2+1);
	GF2X_MUL(336, temp, 168, q_00+1000, 168, p_01+1005);
	GF2X_MUL(336, temp2, 168, q_01+1000, 168, p_11+1005);
	gf2x_add(335, p_01+670, 335, temp+1, 335, temp2+1);
	GF2X_MUL(336, temp, 168, q_10+1000, 168, p_00+1005);
	GF2X_MUL(336, temp2, 168, q_11+1000, 168, p_10+1005);
	gf2x_add(335, p_10+670, 335, temp+1, 335, temp2+1);
	GF2X_MUL(336, temp, 168, q_10+1000, 168, p_01+1005);
	GF2X_MUL(336, temp2, 168, q_11+1000, 168, p_11+1005);
	gf2x_add(335, p_11+670, 335, temp+1, 335, temp2+1);
	
	// Calculating left operands: n: 42513, depth: 1
	GF2X_MUL(670, temp, 335, f_sum+331, 335, p_00+670);
	GF2X_MUL(670, temp2, 335, g_sum+331, 335, p_01+670);
	gf2x_add(665, f_sum+2005, 665, temp+5, 665, temp2+5);
	GF2X_MUL(660, temp, 330, p_00+675, 330, f_sum+1);
	GF2X_MUL(660, temp2, 330, p_01+675, 330, g_sum+1);
	gf2x_add(660, temp, 660, temp, 660, temp2);
	gf2x_add(330, f_sum+2005, 330, f_sum+2005, 330, temp+330);
	right_bit_shift_n(665, f_sum+2005, 44);
	GF2X_MUL(670, temp, 335, f_sum+331, 335, p_10+670);
	GF2X_MUL(670, temp2, 335, g_sum+331, 335, p_11+670);
	gf2x_add(665, g_sum+2005, 665, temp+5, 665, temp2+5);
	GF2X_MUL(660, temp, 330, p_10+675, 330, f_sum+1);
	GF2X_MUL(660, temp2, 330, p_11+675, 330, g_sum+1);
	gf2x_add(660, temp, 660, temp, 660, temp2);
	gf2x_add(330, g_sum+2005, 330, g_sum+2005, 330, temp+330);
	right_bit_shift_n(665, g_sum+2005, 44);
	
	delta = divstepsx_256(255, delta, f_sum+2332, g_sum+2332, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+2332, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+2332, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2328, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+2328, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+2332, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+2332, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+2328, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+2328, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+2328, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+2328, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+2324);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+2324);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+2328, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+2328, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+2324);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+2324);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+2324, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+2324, 12, p_01+1325);
	gf2x_add(24, f_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+2312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+2312, 12, p_01+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+3966, 12, f_sum+3966, 12, temp+12);
	right_bit_shift_n(24, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+2324, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+2324, 12, p_11+1325);
	gf2x_add(24, g_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+2312, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+2312, 12, p_11+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+3966, 12, g_sum+3966, 12, temp+12);
	right_bit_shift_n(24, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3975, g_sum+3975, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3975, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3975, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(q_00+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, q_00+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1312, 8, q_00+1312, 8, temp);
	memset(q_01+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, q_01+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1312, 8, q_01+1312, 8, temp);
	memset(q_10+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, q_10+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1312, 8, q_10+1312, 8, temp);
	memset(q_11+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, q_11+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1312, 8, q_11+1312, 8, temp);
	
	// Recombining results: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_10+1325);
	gf2x_add(24, p_00+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_11+1325);
	gf2x_add(24, p_01+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_10+1325);
	gf2x_add(24, p_10+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_11+1325);
	gf2x_add(24, p_11+1301, 24, temp, 24, temp2);
	
	// Calculating left operands: n: 2805, depth: 5
	GF2X_MUL(48, temp, 24, f_sum+2312, 24, p_00+1301);
	GF2X_MUL(48, temp2, 24, g_sum+2312, 24, p_01+1301);
	gf2x_add(44, f_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, f_sum+2292);
	GF2X_MUL(40, temp2, 20, p_01+1305, 20, g_sum+2292);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(44, f_sum+3897, 58);
	GF2X_MUL(48, temp, 24, f_sum+2312, 24, p_10+1301);
	GF2X_MUL(48, temp2, 24, g_sum+2312, 24, p_11+1301);
	gf2x_add(44, g_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_10+1305, 20, f_sum+2292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, g_sum+2292);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(44, g_sum+3897, 58);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2805, depth: 5
	memset(p_00+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_01+1292);
	gf2x_add(40, p_00+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1273, 8, p_00+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1269, 8, p_00+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1265, 8, p_00+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1261, 8, p_00+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1257, 8, p_00+1257, 8, temp);
	memset(p_01+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_01+1292);
	gf2x_add(40, p_01+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1273, 8, p_01+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1269, 8, p_01+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1265, 8, p_01+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1261, 8, p_01+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1257, 8, p_01+1257, 8, temp);
	memset(p_10+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_11+1292);
	gf2x_add(40, p_10+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1273, 8, p_10+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1269, 8, p_10+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1265, 8, p_10+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1261, 8, p_10+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1257, 8, p_10+1257, 8, temp);
	memset(p_11+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_11+1292);
	gf2x_add(40, p_11+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1273, 8, p_11+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1269, 8, p_11+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1265, 8, p_11+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1261, 8, p_11+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1257, 8, p_11+1257, 8, temp);
	
	// Calculating left operands: n: 5355, depth: 4
	GF2X_MUL(88, temp, 44, f_sum+2292, 44, p_00+1257);
	GF2X_MUL(88, temp2, 44, g_sum+2292, 44, p_01+1257);
	gf2x_add(84, f_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, f_sum+2252);
	GF2X_MUL(80, temp2, 40, p_01+1261, 40, g_sum+2252);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, f_sum+3768, 40, f_sum+3768, 40, temp+40);
	right_bit_shift_n(84, f_sum+3768, 53);
	GF2X_MUL(88, temp, 44, f_sum+2292, 44, p_10+1257);
	GF2X_MUL(88, temp2, 44, g_sum+2292, 44, p_11+1257);
	gf2x_add(84, g_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_10+1261, 40, f_sum+2252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, g_sum+2252);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, g_sum+3768, 40, g_sum+3768, 40, temp+40);
	right_bit_shift_n(84, g_sum+3768, 53);
	
	delta = divstepsx_256(255, delta, f_sum+3805, g_sum+3805, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3805, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3805, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3801, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3801, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(p_00+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, p_00+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1305, 8, p_00+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1301, 8, p_00+1301, 8, temp);
	memset(p_01+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, p_01+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1305, 8, p_01+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1301, 8, p_01+1301, 8, temp);
	memset(p_10+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, p_10+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1305, 8, p_10+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1301, 8, p_10+1301, 8, temp);
	memset(p_11+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, p_11+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1305, 8, p_11+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1301, 8, p_11+1301, 8, temp);
	
	// Calculating left operands: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_01+1301);
	gf2x_add(40, f_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_01+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(40, f_sum+3897, 59);
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_11+1301);
	gf2x_add(40, g_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_11+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(40, g_sum+3897, 59);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_10+1301);
	gf2x_add(40, q_00+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_11+1301);
	gf2x_add(40, q_01+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_10+1301);
	gf2x_add(40, q_10+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_11+1301);
	gf2x_add(40, q_11+1252, 40, temp, 40, temp2);
	
	// Recombining results: n: 5355, depth: 4
	memset(p_00+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_01+1252);
	gf2x_add(80, p_00+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1209, 8, p_00+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1205, 8, p_00+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1201, 8, p_00+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1197, 8, p_00+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1193, 8, p_00+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1189, 8, p_00+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1185, 8, p_00+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1181, 8, p_00+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1177, 8, p_00+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1173, 8, p_00+1173, 8, temp);
	memset(p_01+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_01+1252);
	gf2x_add(80, p_01+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1209, 8, p_01+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1205, 8, p_01+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1201, 8, p_01+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1197, 8, p_01+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1193, 8, p_01+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1189, 8, p_01+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1185, 8, p_01+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1181, 8, p_01+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1177, 8, p_01+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1173, 8, p_01+1173, 8, temp);
	memset(p_10+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_11+1252);
	gf2x_add(80, p_10+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1209, 8, p_10+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1205, 8, p_10+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1201, 8, p_10+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1197, 8, p_10+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1193, 8, p_10+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1189, 8, p_10+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1185, 8, p_10+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1181, 8, p_10+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1177, 8, p_10+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1173, 8, p_10+1173, 8, temp);
	memset(p_11+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_11+1252);
	gf2x_add(80, p_11+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1209, 8, p_11+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1205, 8, p_11+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1201, 8, p_11+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1197, 8, p_11+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1193, 8, p_11+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1189, 8, p_11+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1185, 8, p_11+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1181, 8, p_11+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1177, 8, p_11+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1173, 8, p_11+1173, 8, temp);
	
	// Calculating left operands: n: 10710, depth: 3
	GF2X_MUL(168, temp, 84, f_sum+2252, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, g_sum+2252, 84, p_01+1173);
	gf2x_add(168, f_sum+3515, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, f_sum+2168, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, g_sum+2168, 84, p_01+1173);
	gf2x_add(168, temp, 168, temp, 168, temp2);
	gf2x_add(84, f_sum+3515, 84, f_sum+3515, 84, temp+84);
	right_bit_shift_n(168, f_sum+3515, 43);
	GF2X_MUL(168, temp, 84, f_sum+2252, 84, p_10+1173);
	GF2X_MUL(168, temp2, 84, g_sum+2252, 84, p_11+1173);
	gf2x_add(168, g_sum+3515, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, f_sum+2168, 84, p_10+1173);
	GF2X_MUL(168, temp2, 84, g_sum+2168, 84, p_11+1173);
	gf2x_add(168, temp, 168, temp, 168, temp2);
	gf2x_add(84, g_sum+3515, 84, g_sum+3515, 84, temp+84);
	right_bit_shift_n(168, g_sum+3515, 43);
	
	delta = divstepsx_256(255, delta, f_sum+3596, g_sum+3596, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3596, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3596, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3592, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3592, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3596, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3596, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3592, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3592, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3592, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3592, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3588);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3588);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3592, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3592, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3588);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3588);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3588, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3588, 12, p_01+1325);
	gf2x_add(24, f_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3576, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3576, 12, p_01+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+3966, 12, f_sum+3966, 12, temp+12);
	right_bit_shift_n(24, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3588, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3588, 12, p_11+1325);
	gf2x_add(24, g_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3576, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3576, 12, p_11+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+3966, 12, g_sum+3966, 12, temp+12);
	right_bit_shift_n(24, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3975, g_sum+3975, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3975, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3975, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(q_00+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, q_00+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1312, 8, q_00+1312, 8, temp);
	memset(q_01+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, q_01+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1312, 8, q_01+1312, 8, temp);
	memset(q_10+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, q_10+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1312, 8, q_10+1312, 8, temp);
	memset(q_11+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, q_11+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1312, 8, q_11+1312, 8, temp);
	
	// Recombining results: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_10+1325);
	gf2x_add(24, p_00+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_11+1325);
	gf2x_add(24, p_01+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_10+1325);
	gf2x_add(24, p_10+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_11+1325);
	gf2x_add(24, p_11+1301, 24, temp, 24, temp2);
	
	// Calculating left operands: n: 2805, depth: 5
	GF2X_MUL(48, temp, 24, f_sum+3576, 24, p_00+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3576, 24, p_01+1301);
	gf2x_add(44, f_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, f_sum+3556);
	GF2X_MUL(40, temp2, 20, p_01+1305, 20, g_sum+3556);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(44, f_sum+3897, 58);
	GF2X_MUL(48, temp, 24, f_sum+3576, 24, p_10+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3576, 24, p_11+1301);
	gf2x_add(44, g_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_10+1305, 20, f_sum+3556);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, g_sum+3556);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(44, g_sum+3897, 58);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2805, depth: 5
	memset(p_00+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_01+1292);
	gf2x_add(40, p_00+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1273, 8, p_00+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1269, 8, p_00+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1265, 8, p_00+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1261, 8, p_00+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1257, 8, p_00+1257, 8, temp);
	memset(p_01+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_01+1292);
	gf2x_add(40, p_01+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1273, 8, p_01+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1269, 8, p_01+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1265, 8, p_01+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1261, 8, p_01+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1257, 8, p_01+1257, 8, temp);
	memset(p_10+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_11+1292);
	gf2x_add(40, p_10+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1273, 8, p_10+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1269, 8, p_10+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1265, 8, p_10+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1261, 8, p_10+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1257, 8, p_10+1257, 8, temp);
	memset(p_11+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_11+1292);
	gf2x_add(40, p_11+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1273, 8, p_11+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1269, 8, p_11+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1265, 8, p_11+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1261, 8, p_11+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1257, 8, p_11+1257, 8, temp);
	
	// Calculating left operands: n: 5355, depth: 4
	GF2X_MUL(88, temp, 44, f_sum+3556, 44, p_00+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3556, 44, p_01+1257);
	gf2x_add(84, f_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, f_sum+3516);
	GF2X_MUL(80, temp2, 40, p_01+1261, 40, g_sum+3516);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, f_sum+3768, 40, f_sum+3768, 40, temp+40);
	right_bit_shift_n(84, f_sum+3768, 53);
	GF2X_MUL(88, temp, 44, f_sum+3556, 44, p_10+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3556, 44, p_11+1257);
	gf2x_add(84, g_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_10+1261, 40, f_sum+3516);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, g_sum+3516);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, g_sum+3768, 40, g_sum+3768, 40, temp+40);
	right_bit_shift_n(84, g_sum+3768, 53);
	
	delta = divstepsx_256(255, delta, f_sum+3805, g_sum+3805, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3805, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3805, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3801, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3801, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(p_00+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, p_00+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1305, 8, p_00+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1301, 8, p_00+1301, 8, temp);
	memset(p_01+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, p_01+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1305, 8, p_01+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1301, 8, p_01+1301, 8, temp);
	memset(p_10+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, p_10+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1305, 8, p_10+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1301, 8, p_10+1301, 8, temp);
	memset(p_11+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, p_11+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1305, 8, p_11+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1301, 8, p_11+1301, 8, temp);
	
	// Calculating left operands: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_01+1301);
	gf2x_add(40, f_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_01+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(40, f_sum+3897, 59);
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_11+1301);
	gf2x_add(40, g_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_11+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(40, g_sum+3897, 59);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_10+1301);
	gf2x_add(40, q_00+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_11+1301);
	gf2x_add(40, q_01+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_10+1301);
	gf2x_add(40, q_10+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_11+1301);
	gf2x_add(40, q_11+1252, 40, temp, 40, temp2);
	
	// Recombining results: n: 5355, depth: 4
	memset(q_00+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_01+1252);
	gf2x_add(80, q_00+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1204, 8, q_00+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1200, 8, q_00+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1196, 8, q_00+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1192, 8, q_00+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1188, 8, q_00+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1184, 8, q_00+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1180, 8, q_00+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1176, 8, q_00+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1172, 8, q_00+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1168, 8, q_00+1168, 8, temp);
	memset(q_01+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_01+1252);
	gf2x_add(80, q_01+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1204, 8, q_01+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1200, 8, q_01+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1196, 8, q_01+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1192, 8, q_01+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1188, 8, q_01+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1184, 8, q_01+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1180, 8, q_01+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1176, 8, q_01+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1172, 8, q_01+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1168, 8, q_01+1168, 8, temp);
	memset(q_10+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_11+1252);
	gf2x_add(80, q_10+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1204, 8, q_10+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1200, 8, q_10+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1196, 8, q_10+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1192, 8, q_10+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1188, 8, q_10+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1184, 8, q_10+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1180, 8, q_10+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1176, 8, q_10+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1172, 8, q_10+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1168, 8, q_10+1168, 8, temp);
	memset(q_11+1168, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_11+1252);
	gf2x_add(80, q_11+1172, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1204, 8, q_11+1204, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1200, 8, q_11+1200, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1196, 8, q_11+1196, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1192, 8, q_11+1192, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1188, 8, q_11+1188, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1184, 8, q_11+1184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1180, 8, q_11+1180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1176, 8, q_11+1176, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1172, 8, q_11+1172, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1168, 8, q_11+1168, 8, temp);
	
	// Recombining results: n: 10710, depth: 3
	GF2X_MUL(168, temp, 84, q_00+1168, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, q_01+1168, 84, p_10+1173);
	gf2x_add(168, p_00+1005, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_00+1168, 84, p_01+1173);
	GF2X_MUL(168, temp2, 84, q_01+1168, 84, p_11+1173);
	gf2x_add(168, p_01+1005, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_10+1168, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, q_11+1168, 84, p_10+1173);
	gf2x_add(168, p_10+1005, 168, temp, 168, temp2);
	GF2X_MUL(168, temp, 84, q_10+1168, 84, p_01+1173);
	GF2X_MUL(168, temp2, 84, q_11+1168, 84, p_11+1173);
	gf2x_add(168, p_11+1005, 168, temp, 168, temp2);
	
	// Calculating left operands: n: 21093, depth: 2
	GF2X_MUL(336, temp, 168, f_sum+2168, 168, p_00+1005);
	GF2X_MUL(336, temp2, 168, g_sum+2168, 168, p_01+1005);
	gf2x_add(331, f_sum+3011, 331, temp+5, 331, temp2+5);
	GF2X_MUL(324, temp, 162, p_00+1011, 162, f_sum+2006);
	GF2X_MUL(324, temp2, 162, p_01+1011, 162, g_sum+2006);
	gf2x_add(324, temp, 324, temp, 324, temp2);
	gf2x_add(163, f_sum+3011, 163, f_sum+3011, 163, temp+161);
	gf2x_mul_6_avx(temp, f_sum+2162, p_00+1005);
	gf2x_mul_6_avx(temp2, g_sum+2162, p_01+1005);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(1, f_sum+3011, 1, f_sum+3011, 1, temp+11);
	right_bit_shift_n(330, f_sum+3011, 22);
	GF2X_MUL(336, temp, 168, f_sum+2168, 168, p_10+1005);
	GF2X_MUL(336, temp2, 168, g_sum+2168, 168, p_11+1005);
	gf2x_add(331, g_sum+3011, 331, temp+5, 331, temp2+5);
	GF2X_MUL(324, temp, 162, p_10+1011, 162, f_sum+2006);
	GF2X_MUL(324, temp2, 162, p_11+1011, 162, g_sum+2006);
	gf2x_add(324, temp, 324, temp, 324, temp2);
	gf2x_add(163, g_sum+3011, 163, g_sum+3011, 163, temp+161);
	gf2x_mul_6_avx(temp, f_sum+2162, p_10+1005);
	gf2x_mul_6_avx(temp2, g_sum+2162, p_11+1005);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(1, g_sum+3011, 1, g_sum+3011, 1, temp+11);
	right_bit_shift_n(330, g_sum+3011, 22);
	
	delta = divstepsx_256(255, delta, f_sum+3171, g_sum+3171, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3171, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3171, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3167, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3167, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3171, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3171, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3167, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3167, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3167, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3167, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3163);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3163);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3167, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3167, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3163);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3163);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3163, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3163, 12, p_01+1325);
	gf2x_add(24, f_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3151, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3151, 12, p_01+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+3966, 12, f_sum+3966, 12, temp+12);
	right_bit_shift_n(24, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3163, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3163, 12, p_11+1325);
	gf2x_add(24, g_sum+3966, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, f_sum+3151, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3151, 12, p_11+1325);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+3966, 12, g_sum+3966, 12, temp+12);
	right_bit_shift_n(24, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3975, g_sum+3975, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3975, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3975, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3975, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3967);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3967);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(q_00+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, q_00+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1312, 8, q_00+1312, 8, temp);
	memset(q_01+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, q_01+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1312, 8, q_01+1312, 8, temp);
	memset(q_10+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, q_10+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1312, 8, q_10+1312, 8, temp);
	memset(q_11+1312, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, q_11+1316, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1312, 8, q_11+1312, 8, temp);
	
	// Recombining results: n: 1530, depth: 6
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_10+1325);
	gf2x_add(24, p_00+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_00+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_01+1312, 12, p_11+1325);
	gf2x_add(24, p_01+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_10+1325);
	gf2x_add(24, p_10+1301, 24, temp, 24, temp2);
	GF2X_MUL(24, temp, 12, q_10+1312, 12, p_01+1325);
	GF2X_MUL(24, temp2, 12, q_11+1312, 12, p_11+1325);
	gf2x_add(24, p_11+1301, 24, temp, 24, temp2);
	
	// Calculating left operands: n: 2805, depth: 5
	GF2X_MUL(48, temp, 24, f_sum+3151, 24, p_00+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3151, 24, p_01+1301);
	gf2x_add(44, f_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, f_sum+3131);
	GF2X_MUL(40, temp2, 20, p_01+1305, 20, g_sum+3131);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(44, f_sum+3897, 58);
	GF2X_MUL(48, temp, 24, f_sum+3151, 24, p_10+1301);
	GF2X_MUL(48, temp2, 24, g_sum+3151, 24, p_11+1301);
	gf2x_add(44, g_sum+3897, 44, temp+4, 44, temp2+4);
	GF2X_MUL(40, temp, 20, p_10+1305, 20, f_sum+3131);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, g_sum+3131);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(44, g_sum+3897, 58);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2805, depth: 5
	memset(p_00+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_01+1292);
	gf2x_add(40, p_00+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1273, 8, p_00+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1269, 8, p_00+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1265, 8, p_00+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1261, 8, p_00+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1257, 8, p_00+1257, 8, temp);
	memset(p_01+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_00+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_01+1292);
	gf2x_add(40, p_01+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_00+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1273, 8, p_01+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1269, 8, p_01+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1265, 8, p_01+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1261, 8, p_01+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_01+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1257, 8, p_01+1257, 8, temp);
	memset(p_10+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_00+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_10+1305, 20, q_11+1292);
	gf2x_add(40, p_10+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1273, 8, p_10+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1269, 8, p_10+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1265, 8, p_10+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1261, 8, p_10+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_00+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_10+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1257, 8, p_10+1257, 8, temp);
	memset(p_11+1257, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(40, temp, 20, p_01+1305, 20, q_10+1292);
	GF2X_MUL(40, temp2, 20, p_11+1305, 20, q_11+1292);
	gf2x_add(40, p_11+1261, 40, temp, 40, temp2);
	gf2x_mul_4_avx(temp, q_10+1308, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1308, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1273, 8, p_11+1273, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1304, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1304, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1269, 8, p_11+1269, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1300, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1300, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1265, 8, p_11+1265, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1296, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1296, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1261, 8, p_11+1261, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1292, p_01+1301);
	gf2x_mul_4_avx(temp2, q_11+1292, p_11+1301);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1257, 8, p_11+1257, 8, temp);
	
	// Calculating left operands: n: 5355, depth: 4
	GF2X_MUL(88, temp, 44, f_sum+3131, 44, p_00+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3131, 44, p_01+1257);
	gf2x_add(84, f_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, f_sum+3091);
	GF2X_MUL(80, temp2, 40, p_01+1261, 40, g_sum+3091);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, f_sum+3768, 40, f_sum+3768, 40, temp+40);
	right_bit_shift_n(84, f_sum+3768, 53);
	GF2X_MUL(88, temp, 44, f_sum+3131, 44, p_10+1257);
	GF2X_MUL(88, temp2, 44, g_sum+3131, 44, p_11+1257);
	gf2x_add(84, g_sum+3768, 84, temp+4, 84, temp2+4);
	GF2X_MUL(80, temp, 40, p_10+1261, 40, f_sum+3091);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, g_sum+3091);
	gf2x_add(80, temp, 80, temp, 80, temp2);
	gf2x_add(40, g_sum+3768, 40, g_sum+3768, 40, temp+40);
	right_bit_shift_n(84, g_sum+3768, 53);
	
	delta = divstepsx_256(255, delta, f_sum+3805, g_sum+3805, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3805, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3805, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3805, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3801, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3801, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3801, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3801, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3801, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3797);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3797);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3797, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3797, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3789);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3789);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(p_00+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, p_00+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1305, 8, p_00+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1301, 8, p_00+1301, 8, temp);
	memset(p_01+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, p_01+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1305, 8, p_01+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1301, 8, p_01+1301, 8, temp);
	memset(p_10+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, p_10+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1305, 8, p_10+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1301, 8, p_10+1301, 8, temp);
	memset(p_11+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, p_11+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1305, 8, p_11+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1301, 8, p_11+1301, 8, temp);
	
	// Calculating left operands: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_01+1301);
	gf2x_add(40, f_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_01+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(40, f_sum+3897, 59);
	GF2X_MUL(40, temp, 20, f_sum+3789, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3789, 20, p_11+1301);
	gf2x_add(40, g_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3769, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3769, 20, p_11+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(40, g_sum+3897, 59);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_10+1301);
	gf2x_add(40, q_00+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_11+1301);
	gf2x_add(40, q_01+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_10+1301);
	gf2x_add(40, q_10+1252, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_11+1301);
	gf2x_add(40, q_11+1252, 40, temp, 40, temp2);
	
	// Recombining results: n: 5355, depth: 4
	memset(p_00+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_01+1252);
	gf2x_add(80, p_00+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1209, 8, p_00+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1205, 8, p_00+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1201, 8, p_00+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1197, 8, p_00+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1193, 8, p_00+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1189, 8, p_00+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1185, 8, p_00+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1181, 8, p_00+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1177, 8, p_00+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1173, 8, p_00+1173, 8, temp);
	memset(p_01+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_00+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_01+1252);
	gf2x_add(80, p_01+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_00+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1209, 8, p_01+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1205, 8, p_01+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1201, 8, p_01+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1197, 8, p_01+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1193, 8, p_01+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1189, 8, p_01+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1185, 8, p_01+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1181, 8, p_01+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1177, 8, p_01+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_01+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1173, 8, p_01+1173, 8, temp);
	memset(p_10+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_00+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_10+1261, 40, q_11+1252);
	gf2x_add(80, p_10+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1209, 8, p_10+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1205, 8, p_10+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1201, 8, p_10+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1197, 8, p_10+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1193, 8, p_10+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1189, 8, p_10+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1185, 8, p_10+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1181, 8, p_10+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1177, 8, p_10+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_00+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_10+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1173, 8, p_10+1173, 8, temp);
	memset(p_11+1173, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(80, temp, 40, p_01+1261, 40, q_10+1252);
	GF2X_MUL(80, temp2, 40, p_11+1261, 40, q_11+1252);
	gf2x_add(80, p_11+1177, 80, temp, 80, temp2);
	gf2x_mul_4_avx(temp, q_10+1288, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1288, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1209, 8, p_11+1209, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1284, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1284, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1205, 8, p_11+1205, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1280, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1280, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1201, 8, p_11+1201, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1276, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1276, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1197, 8, p_11+1197, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1272, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1272, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1193, 8, p_11+1193, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1268, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1268, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1189, 8, p_11+1189, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1264, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1264, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1185, 8, p_11+1185, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1260, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1260, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1181, 8, p_11+1181, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1256, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1256, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1177, 8, p_11+1177, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1252, p_01+1257);
	gf2x_mul_4_avx(temp2, q_11+1252, p_11+1257);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1173, 8, p_11+1173, 8, temp);
	
	// Calculating left operands: n: 10383, depth: 3
	GF2X_MUL(168, temp, 84, f_sum+3091, 84, p_00+1173);
	GF2X_MUL(168, temp2, 84, g_sum+3091, 84, p_01+1173);
	gf2x_add(163, f_sum+3515, 163, temp+5, 163, temp2+5);
	GF2X_MUL(158, temp, 79, p_00+1178, 79, f_sum+3012);
	GF2X_MUL(158, temp2, 79, p_01+1178, 79, g_sum+3012);
	gf2x_add(158, temp, 158, temp, 158, temp2);
	gf2x_add(79, f_sum+3515, 79, f_sum+3515, 79, temp+79);
	right_bit_shift_n(163, f_sum+3515, 43);
	GF2X_MUL(168, temp, 84, f_sum+3091, 84, p_10+1173);
	GF2X_MUL(168, temp2, 84, g_sum+3091, 84, p_11+1173);
	gf2x_add(163, g_sum+3515, 163, temp+5, 163, temp2+5);
	GF2X_MUL(158, temp, 79, p_10+1178, 79, f_sum+3012);
	GF2X_MUL(158, temp2, 79, p_11+1178, 79, g_sum+3012);
	gf2x_add(158, temp, 158, temp, 158, temp2);
	gf2x_add(79, g_sum+3515, 79, g_sum+3515, 79, temp+79);
	right_bit_shift_n(163, g_sum+3515, 43);
	
	delta = divstepsx_256(255, delta, f_sum+3591, g_sum+3591, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3591, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3591, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3587, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3587, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3591, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3591, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3587, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3587, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3587, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3587, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3583);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3583);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3587, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3587, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3583);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3583);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3583, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3583, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3575);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3575);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3583, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3583, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3575);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3575);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(p_00+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, p_00+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1305, 8, p_00+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1301, 8, p_00+1301, 8, temp);
	memset(p_01+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, p_01+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1305, 8, p_01+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1301, 8, p_01+1301, 8, temp);
	memset(p_10+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, p_10+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1305, 8, p_10+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1301, 8, p_10+1301, 8, temp);
	memset(p_11+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, p_11+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1305, 8, p_11+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1301, 8, p_11+1301, 8, temp);
	
	// Calculating left operands: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, f_sum+3575, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3575, 20, p_01+1301);
	gf2x_add(40, f_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3555, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3555, 20, p_01+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, f_sum+3897, 20, f_sum+3897, 20, temp+20);
	right_bit_shift_n(40, f_sum+3897, 59);
	GF2X_MUL(40, temp, 20, f_sum+3575, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3575, 20, p_11+1301);
	gf2x_add(40, g_sum+3897, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, f_sum+3555, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3555, 20, p_11+1301);
	gf2x_add(40, temp, 40, temp, 40, temp2);
	gf2x_add(20, g_sum+3897, 20, g_sum+3897, 20, temp+20);
	right_bit_shift_n(40, g_sum+3897, 59);
	
	delta = divstepsx_256(255, delta, f_sum+3914, g_sum+3914, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3914, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3914, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3914, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3910, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3910, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3910, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3910, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3910, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3906);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3906);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3906, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3906, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3898);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3898);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(q_00+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, q_00+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1296, 8, q_00+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1292, 8, q_00+1292, 8, temp);
	memset(q_01+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, q_01+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1296, 8, q_01+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1292, 8, q_01+1292, 8, temp);
	memset(q_10+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, q_10+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1296, 8, q_10+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1292, 8, q_10+1292, 8, temp);
	memset(q_11+1292, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, q_11+1296, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1296, 8, q_11+1296, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1292, 8, q_11+1292, 8, temp);
	
	// Recombining results: n: 2550, depth: 5
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_10+1301);
	gf2x_add(40, p_00+1257, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_00+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_01+1292, 20, p_11+1301);
	gf2x_add(40, p_01+1257, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_10+1301);
	gf2x_add(40, p_10+1257, 40, temp, 40, temp2);
	GF2X_MUL(40, temp, 20, q_10+1292, 20, p_01+1301);
	GF2X_MUL(40, temp2, 20, q_11+1292, 20, p_11+1301);
	gf2x_add(40, p_11+1257, 40, temp, 40, temp2);
	
	// Calculating left operands: n: 5028, depth: 4
	GF2X_MUL(80, temp, 40, f_sum+3555, 40, p_00+1257);
	GF2X_MUL(80, temp2, 40, g_sum+3555, 40, p_01+1257);
	gf2x_add(79, f_sum+3768, 79, temp+1, 79, temp2+1);
	GF2X_MUL(78, temp, 39, p_00+1258, 39, f_sum+3516);
	GF2X_MUL(78, temp2, 39, p_01+1258, 39, g_sum+3516);
	gf2x_add(78, temp, 78, temp, 78, temp2);
	gf2x_add(39, f_sum+3768, 39, f_sum+3768, 39, temp+39);
	right_bit_shift_n(79, f_sum+3768, 54);
	GF2X_MUL(80, temp, 40, f_sum+3555, 40, p_10+1257);
	GF2X_MUL(80, temp2, 40, g_sum+3555, 40, p_11+1257);
	gf2x_add(79, g_sum+3768, 79, temp+1, 79, temp2+1);
	GF2X_MUL(78, temp, 39, p_10+1258, 39, f_sum+3516);
	GF2X_MUL(78, temp2, 39, p_11+1258, 39, g_sum+3516);
	gf2x_add(78, temp, 78, temp, 78, temp2);
	gf2x_add(39, g_sum+3768, 39, g_sum+3768, 39, temp+39);
	right_bit_shift_n(79, g_sum+3768, 54);
	
	delta = divstepsx_256(255, delta, f_sum+3804, g_sum+3804, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3804, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3804, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3800, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3800, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3804, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3804, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3800, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3800, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3800, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3800, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3796);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3796);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3800, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3800, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3796);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3796);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1275, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3796, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3796, 12, p_01+1325);
	gf2x_add(20, f_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_00+1329, f_sum+3788);
	gf2x_mul_8_avx(temp2, p_01+1329, g_sum+3788);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+3966, 8, f_sum+3966, 8, temp+8);
	right_bit_shift_n(20, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3796, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3796, 12, p_11+1325);
	gf2x_add(20, g_sum+3966, 20, temp+4, 20, temp2+4);
	gf2x_mul_8_avx(temp, p_10+1329, f_sum+3788);
	gf2x_mul_8_avx(temp2, p_11+1329, g_sum+3788);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+3966, 8, g_sum+3966, 8, temp+8);
	right_bit_shift_n(20, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3971, g_sum+3971, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 510, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3971, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_01+1337);
	gf2x_add(8, f_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_01+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(8, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3971, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3971, p_11+1337);
	gf2x_add(8, g_sum+4003, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3967, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3967, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(8, g_sum+4003, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 510, depth: 7
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, q_00+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, q_01+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, q_10+1312, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, q_11+1312, 8, temp, 8, temp2);
	
	// Recombining results: n: 1275, depth: 6
	memset(p_00+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_01+1312);
	gf2x_add(16, p_00+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1305, 8, p_00+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1301, 8, p_00+1301, 8, temp);
	memset(p_01+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_00+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_01+1312);
	gf2x_add(16, p_01+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_00+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1305, 8, p_01+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1301, 8, p_01+1301, 8, temp);
	memset(p_10+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_00+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_10+1329, q_11+1312);
	gf2x_add(16, p_10+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1305, 8, p_10+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1301, 8, p_10+1301, 8, temp);
	memset(p_11+1301, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_8_avx(temp, p_01+1329, q_10+1312);
	gf2x_mul_8_avx(temp2, p_11+1329, q_11+1312);
	gf2x_add(16, p_11+1305, 16, temp, 16, temp2);
	gf2x_mul_4_avx(temp, q_10+1316, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1316, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1305, 8, p_11+1305, 8, temp);
	gf2x_mul_4_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_4_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1301, 8, p_11+1301, 8, temp);
	
	// Calculating left operands: n: 2478, depth: 5
	GF2X_MUL(40, temp, 20, f_sum+3788, 20, p_00+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3788, 20, p_01+1301);
	gf2x_add(39, f_sum+3897, 39, temp+1, 39, temp2+1);
	GF2X_MUL(38, temp, 19, p_00+1302, 19, f_sum+3769);
	GF2X_MUL(38, temp2, 19, p_01+1302, 19, g_sum+3769);
	gf2x_add(38, temp, 38, temp, 38, temp2);
	gf2x_add(19, f_sum+3897, 19, f_sum+3897, 19, temp+19);
	right_bit_shift_n(39, f_sum+3897, 59);
	GF2X_MUL(40, temp, 20, f_sum+3788, 20, p_10+1301);
	GF2X_MUL(40, temp2, 20, g_sum+3788, 20, p_11+1301);
	gf2x_add(39, g_sum+3897, 39, temp+1, 39, temp2+1);
	GF2X_MUL(38, temp, 19, p_10+1302, 19, f_sum+3769);
	GF2X_MUL(38, temp2, 19, p_11+1302, 19, g_sum+3769);
	gf2x_add(38, temp, 38, temp, 38, temp2);
	gf2x_add(19, g_sum+3897, 19, g_sum+3897, 19, temp+19);
	right_bit_shift_n(39, g_sum+3897, 59);
	
	delta = divstepsx_256(255, delta, f_sum+3913, g_sum+3913, p_00+1345, p_01+1345, p_10+1345, p_11+1345);

	// Calculating left operands: n: 510, depth: 8
	gf2x_mul_4_avx(temp, f_sum+3913, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3913, p_01+1345);
	gf2x_add(8, f_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3909, p_00+1345);
	gf2x_mul_4_avx(temp2, g_sum+3909, p_01+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4024, 4, f_sum+4024, 4, temp+4);
	right_bit_shift_n(8, f_sum+4024, 63);
	gf2x_mul_4_avx(temp, f_sum+3913, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3913, p_11+1345);
	gf2x_add(8, g_sum+4024, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+3909, p_10+1345);
	gf2x_mul_4_avx(temp2, g_sum+3909, p_11+1345);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4024, 4, g_sum+4024, 4, temp+4);
	right_bit_shift_n(8, g_sum+4024, 63);
	
	delta = divstepsx_256(255, delta, f_sum+4025, g_sum+4025, q_00+1328, q_01+1328, q_10+1328, q_11+1328);

	// Recombining results: n: 510, depth: 8
	gf2x_mul_4_avx(temp, q_00+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_10+1345);
	gf2x_add(8, p_00+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_01+1328, p_11+1345);
	gf2x_add(8, p_01+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_00+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_10+1345);
	gf2x_add(8, p_10+1337, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1328, p_01+1345);
	gf2x_mul_4_avx(temp2, q_11+1328, p_11+1345);
	gf2x_add(8, p_11+1337, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 7
	gf2x_mul_8_avx(temp, f_sum+3909, p_00+1337);
	gf2x_mul_8_avx(temp2, g_sum+3909, p_01+1337);
	gf2x_add(12, f_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+1341, f_sum+3905);
	gf2x_mul_4_avx(temp2, p_01+1341, g_sum+3905);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+4003, 4, f_sum+4003, 4, temp+4);
	right_bit_shift_n(12, f_sum+4003, 62);
	gf2x_mul_8_avx(temp, f_sum+3909, p_10+1337);
	gf2x_mul_8_avx(temp2, g_sum+3909, p_11+1337);
	gf2x_add(12, g_sum+4003, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+1341, f_sum+3905);
	gf2x_mul_4_avx(temp2, p_11+1341, g_sum+3905);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+4003, 4, g_sum+4003, 4, temp+4);
	right_bit_shift_n(12, g_sum+4003, 62);
	
	delta = divstepsx_256(255, delta, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324);

	// Recombining results: n: 765, depth: 7
	memset(p_00+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_01+1324);
	gf2x_add(8, p_00+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+1325, 8, p_00+1325, 8, temp);
	memset(p_01+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_00+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_01+1324);
	gf2x_add(8, p_01+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+1325, 8, p_01+1325, 8, temp);
	memset(p_10+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_10+1341, q_11+1324);
	gf2x_add(8, p_10+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+1325, 8, p_10+1325, 8, temp);
	memset(p_11+1325, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+1341, q_10+1324);
	gf2x_mul_4_avx(temp2, p_11+1341, q_11+1324);
	gf2x_add(8, p_11+1329, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_4_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+1325, 8, p_11+1325, 8, temp);
	
	// Calculating left operands: n: 1203, depth: 6
	GF2X_MUL(24, temp, 12, f_sum+3905, 12, p_00+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3905, 12, p_01+1325);
	gf2x_add(19, f_sum+3966, 19, temp+5, 19, temp2+5);
	gf2x_mul_7_avx(temp, p_00+1330, f_sum+3898);
	gf2x_mul_7_avx(temp2, p_01+1330, g_sum+3898);
	gf2x_add(14, temp, 14, temp, 14, temp2);
	gf2x_add(7, f_sum+3966, 7, f_sum+3966, 7, temp+7);
	right_bit_shift_n(19, f_sum+3966, 61);
	GF2X_MUL(24, temp, 12, f_sum+3905, 12, p_10+1325);
	GF2X_MUL(24, temp2, 12, g_sum+3905, 12, p_11+1325);
	gf2x_add(19, g_sum+3966, 19, temp+5, 19, temp2+5);
	gf2x_mul_7_avx(temp, p_10+1330, f_sum+3898);
	gf2x_mul_7_avx(temp2, p_11+1330, g_sum+3898);
	gf2x_add(14, temp, 14, temp, 14, temp2);
	gf2x_add(7, g_sum+3966, 7, g_sum+3966, 7, temp+7);
	right_bit_shift_n(19, g_sum+3966, 61);
	
	delta = divstepsx_256(255, delta, f_sum+3970, g_sum+3970, p_00+1337, p_01+1337, p_10+1337, p_11+1337);

	// Calculating left operands: n: 438, depth: 7
	gf2x_mul_4_avx(temp, f_sum+3970, p_00+1337);
	gf2x_mul_4_avx(temp2, g_sum+3970, p_01+1337);
	gf2x_add(7, f_sum+4003, 7, temp+1, 7, temp2+1);
	gf2x_mul_3_avx(temp, p_00+1338, f_sum+3967);
	gf2x_mul_3_avx(temp2, p_01+1338, g_sum+3967);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(3, f_sum+4003, 3, f_sum+4003, 3, temp+3);
	right_bit_shift_n(7, f_sum+4003, 63);
	gf2x_mul_4_avx(temp, f_sum+3970, p_10+1337);
	gf2x_mul_4_avx(temp2, g_sum+3970, p_11+1337);
	gf2x_add(7, g_sum+4003, 7, temp+1, 7, temp2+1);
	gf2x_mul_3_avx(temp, p_10+1338, f_sum+3967);
	gf2x_mul_3_avx(temp2, p_11+1338, g_sum+3967);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(3, g_sum+4003, 3, g_sum+4003, 3, temp+3);
	right_bit_shift_n(7, g_sum+4003, 63);
	
	delta = support_jumpdivstep(183, delta, 3, f_sum+4004, g_sum+4004, q_00+1324, q_01+1324, q_10+1324, q_11+1324, 0.5);

	// Recombining results: n: 438, depth: 7
	memset(q_00+1312, 0x00, 1*DIGIT_SIZE_B);
	gf2x_mul_3_avx(temp, p_00+1338, q_00+1324);
	gf2x_mul_3_avx(temp2, p_10+1338, q_01+1324);
	gf2x_add(6, q_00+1313, 6, temp, 6, temp2);
	gf2x_mul_1_avx(temp, q_00+1326, p_00+1337);
	gf2x_mul_1_avx(temp2, q_01+1326, p_10+1337);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1314, 2, q_00+1314, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1325, p_00+1337);
	gf2x_mul_1_avx(temp2, q_01+1325, p_10+1337);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1313, 2, q_00+1313, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1324, p_00+1337);
	gf2x_mul_1_avx(temp2, q_01+1324, p_10+1337);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1312, 2, q_00+1312, 2, temp);
	memset(q_01+1312, 0x00, 1*DIGIT_SIZE_B);
	gf2x_mul_3_avx(temp, p_01+1338, q_00+1324);
	gf2x_mul_3_avx(temp2, p_11+1338, q_01+1324);
	gf2x_add(6, q_01+1313, 6, temp, 6, temp2);
	gf2x_mul_1_avx(temp, q_00+1326, p_01+1337);
	gf2x_mul_1_avx(temp2, q_01+1326, p_11+1337);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1314, 2, q_01+1314, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1325, p_01+1337);
	gf2x_mul_1_avx(temp2, q_01+1325, p_11+1337);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1313, 2, q_01+1313, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1324, p_01+1337);
	gf2x_mul_1_avx(temp2, q_01+1324, p_11+1337);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1312, 2, q_01+1312, 2, temp);
	memset(q_10+1312, 0x00, 1*DIGIT_SIZE_B);
	gf2x_mul_3_avx(temp, p_00+1338, q_10+1324);
	gf2x_mul_3_avx(temp2, p_10+1338, q_11+1324);
	gf2x_add(6, q_10+1313, 6, temp, 6, temp2);
	gf2x_mul_1_avx(temp, q_10+1326, p_00+1337);
	gf2x_mul_1_avx(temp2, q_11+1326, p_10+1337);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1314, 2, q_10+1314, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1325, p_00+1337);
	gf2x_mul_1_avx(temp2, q_11+1325, p_10+1337);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1313, 2, q_10+1313, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1324, p_00+1337);
	gf2x_mul_1_avx(temp2, q_11+1324, p_10+1337);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1312, 2, q_10+1312, 2, temp);
	memset(q_11+1312, 0x00, 1*DIGIT_SIZE_B);
	gf2x_mul_3_avx(temp, p_01+1338, q_10+1324);
	gf2x_mul_3_avx(temp2, p_11+1338, q_11+1324);
	gf2x_add(6, q_11+1313, 6, temp, 6, temp2);
	gf2x_mul_1_avx(temp, q_10+1326, p_01+1337);
	gf2x_mul_1_avx(temp2, q_11+1326, p_11+1337);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1314, 2, q_11+1314, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1325, p_01+1337);
	gf2x_mul_1_avx(temp2, q_11+1325, p_11+1337);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1313, 2, q_11+1313, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1324, p_01+1337);
	gf2x_mul_1_avx(temp2, q_11+1324, p_11+1337);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1312, 2, q_11+1312, 2, temp);
	
	// Recombining results: n: 1203, depth: 6
	memset(q_00+1292, 0x00, 5*DIGIT_SIZE_B);
	gf2x_mul_7_avx(temp, p_00+1330, q_00+1312);
	gf2x_mul_7_avx(temp2, p_10+1330, q_01+1312);
	gf2x_add(14, q_00+1297, 14, temp, 14, temp2);
	gf2x_mul_5_avx(temp, q_00+1314, p_00+1325);
	gf2x_mul_5_avx(temp2, q_01+1314, p_10+1325);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+1294, 10, q_00+1294, 10, temp);
	gf2x_mul_2_avx(temp, p_00+1328, q_00+1312);
	gf2x_mul_2_avx(temp2, p_10+1328, q_01+1312);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+1295, 4, q_00+1295, 4, temp);
	gf2x_mul_2_avx(temp, p_00+1326, q_00+1312);
	gf2x_mul_2_avx(temp2, p_10+1326, q_01+1312);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+1293, 4, q_00+1293, 4, temp);
	gf2x_mul_1_avx(temp, q_00+1313, p_00+1325);
	gf2x_mul_1_avx(temp2, q_01+1313, p_10+1325);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1293, 2, q_00+1293, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1312, p_00+1325);
	gf2x_mul_1_avx(temp2, q_01+1312, p_10+1325);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1292, 2, q_00+1292, 2, temp);
	memset(q_01+1292, 0x00, 5*DIGIT_SIZE_B);
	gf2x_mul_7_avx(temp, p_01+1330, q_00+1312);
	gf2x_mul_7_avx(temp2, p_11+1330, q_01+1312);
	gf2x_add(14, q_01+1297, 14, temp, 14, temp2);
	gf2x_mul_5_avx(temp, q_00+1314, p_01+1325);
	gf2x_mul_5_avx(temp2, q_01+1314, p_11+1325);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+1294, 10, q_01+1294, 10, temp);
	gf2x_mul_2_avx(temp, p_01+1328, q_00+1312);
	gf2x_mul_2_avx(temp2, p_11+1328, q_01+1312);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+1295, 4, q_01+1295, 4, temp);
	gf2x_mul_2_avx(temp, p_01+1326, q_00+1312);
	gf2x_mul_2_avx(temp2, p_11+1326, q_01+1312);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+1293, 4, q_01+1293, 4, temp);
	gf2x_mul_1_avx(temp, q_00+1313, p_01+1325);
	gf2x_mul_1_avx(temp2, q_01+1313, p_11+1325);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1293, 2, q_01+1293, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1312, p_01+1325);
	gf2x_mul_1_avx(temp2, q_01+1312, p_11+1325);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1292, 2, q_01+1292, 2, temp);
	memset(q_10+1292, 0x00, 5*DIGIT_SIZE_B);
	gf2x_mul_7_avx(temp, p_00+1330, q_10+1312);
	gf2x_mul_7_avx(temp2, p_10+1330, q_11+1312);
	gf2x_add(14, q_10+1297, 14, temp, 14, temp2);
	gf2x_mul_5_avx(temp, q_10+1314, p_00+1325);
	gf2x_mul_5_avx(temp2, q_11+1314, p_10+1325);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+1294, 10, q_10+1294, 10, temp);
	gf2x_mul_2_avx(temp, p_00+1328, q_10+1312);
	gf2x_mul_2_avx(temp2, p_10+1328, q_11+1312);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+1295, 4, q_10+1295, 4, temp);
	gf2x_mul_2_avx(temp, p_00+1326, q_10+1312);
	gf2x_mul_2_avx(temp2, p_10+1326, q_11+1312);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+1293, 4, q_10+1293, 4, temp);
	gf2x_mul_1_avx(temp, q_10+1313, p_00+1325);
	gf2x_mul_1_avx(temp2, q_11+1313, p_10+1325);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1293, 2, q_10+1293, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1312, p_00+1325);
	gf2x_mul_1_avx(temp2, q_11+1312, p_10+1325);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1292, 2, q_10+1292, 2, temp);
	memset(q_11+1292, 0x00, 5*DIGIT_SIZE_B);
	gf2x_mul_7_avx(temp, p_01+1330, q_10+1312);
	gf2x_mul_7_avx(temp2, p_11+1330, q_11+1312);
	gf2x_add(14, q_11+1297, 14, temp, 14, temp2);
	gf2x_mul_5_avx(temp, q_10+1314, p_01+1325);
	gf2x_mul_5_avx(temp2, q_11+1314, p_11+1325);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+1294, 10, q_11+1294, 10, temp);
	gf2x_mul_2_avx(temp, p_01+1328, q_10+1312);
	gf2x_mul_2_avx(temp2, p_11+1328, q_11+1312);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+1295, 4, q_11+1295, 4, temp);
	gf2x_mul_2_avx(temp, p_01+1326, q_10+1312);
	gf2x_mul_2_avx(temp2, p_11+1326, q_11+1312);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+1293, 4, q_11+1293, 4, temp);
	gf2x_mul_1_avx(temp, q_10+1313, p_01+1325);
	gf2x_mul_1_avx(temp2, q_11+1313, p_11+1325);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1293, 2, q_11+1293, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1312, p_01+1325);
	gf2x_mul_1_avx(temp2, q_11+1312, p_11+1325);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1292, 2, q_11+1292, 2, temp);
	
	// Recombining results: n: 2478, depth: 5
	memset(q_00+1252, 0x00, 1*DIGIT_SIZE_B);
	GF2X_MUL(38, temp, 19, p_00+1302, 19, q_00+1292);
	GF2X_MUL(38, temp2, 19, p_10+1302, 19, q_01+1292);
	gf2x_add(38, q_00+1253, 38, temp, 38, temp2);
	gf2x_mul_1_avx(temp, q_00+1310, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1310, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1270, 2, q_00+1270, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1309, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1309, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1269, 2, q_00+1269, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1308, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1308, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1268, 2, q_00+1268, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1307, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1307, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1267, 2, q_00+1267, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1306, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1306, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1266, 2, q_00+1266, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1305, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1305, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1265, 2, q_00+1265, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1304, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1304, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1264, 2, q_00+1264, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1303, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1303, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1263, 2, q_00+1263, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1302, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1302, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1262, 2, q_00+1262, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1301, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1301, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1261, 2, q_00+1261, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1300, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1300, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1260, 2, q_00+1260, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1299, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1299, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1259, 2, q_00+1259, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1298, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1298, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1258, 2, q_00+1258, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1297, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1297, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1257, 2, q_00+1257, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1296, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1296, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1256, 2, q_00+1256, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1295, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1295, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1255, 2, q_00+1255, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1294, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1294, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1254, 2, q_00+1254, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1293, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1293, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1253, 2, q_00+1253, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1292, p_00+1301);
	gf2x_mul_1_avx(temp2, q_01+1292, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1252, 2, q_00+1252, 2, temp);
	memset(q_01+1252, 0x00, 1*DIGIT_SIZE_B);
	GF2X_MUL(38, temp, 19, p_01+1302, 19, q_00+1292);
	GF2X_MUL(38, temp2, 19, p_11+1302, 19, q_01+1292);
	gf2x_add(38, q_01+1253, 38, temp, 38, temp2);
	gf2x_mul_1_avx(temp, q_00+1310, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1310, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1270, 2, q_01+1270, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1309, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1309, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1269, 2, q_01+1269, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1308, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1308, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1268, 2, q_01+1268, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1307, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1307, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1267, 2, q_01+1267, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1306, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1306, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1266, 2, q_01+1266, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1305, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1305, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1265, 2, q_01+1265, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1304, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1304, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1264, 2, q_01+1264, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1303, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1303, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1263, 2, q_01+1263, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1302, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1302, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1262, 2, q_01+1262, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1301, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1301, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1261, 2, q_01+1261, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1300, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1300, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1260, 2, q_01+1260, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1299, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1299, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1259, 2, q_01+1259, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1298, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1298, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1258, 2, q_01+1258, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1297, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1297, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1257, 2, q_01+1257, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1296, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1296, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1256, 2, q_01+1256, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1295, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1295, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1255, 2, q_01+1255, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1294, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1294, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1254, 2, q_01+1254, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1293, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1293, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1253, 2, q_01+1253, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1292, p_01+1301);
	gf2x_mul_1_avx(temp2, q_01+1292, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1252, 2, q_01+1252, 2, temp);
	memset(q_10+1252, 0x00, 1*DIGIT_SIZE_B);
	GF2X_MUL(38, temp, 19, p_00+1302, 19, q_10+1292);
	GF2X_MUL(38, temp2, 19, p_10+1302, 19, q_11+1292);
	gf2x_add(38, q_10+1253, 38, temp, 38, temp2);
	gf2x_mul_1_avx(temp, q_10+1310, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1310, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1270, 2, q_10+1270, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1309, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1309, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1269, 2, q_10+1269, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1308, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1308, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1268, 2, q_10+1268, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1307, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1307, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1267, 2, q_10+1267, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1306, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1306, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1266, 2, q_10+1266, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1305, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1305, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1265, 2, q_10+1265, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1304, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1304, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1264, 2, q_10+1264, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1303, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1303, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1263, 2, q_10+1263, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1302, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1302, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1262, 2, q_10+1262, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1301, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1301, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1261, 2, q_10+1261, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1300, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1300, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1260, 2, q_10+1260, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1299, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1299, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1259, 2, q_10+1259, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1298, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1298, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1258, 2, q_10+1258, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1297, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1297, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1257, 2, q_10+1257, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1296, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1296, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1256, 2, q_10+1256, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1295, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1295, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1255, 2, q_10+1255, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1294, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1294, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1254, 2, q_10+1254, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1293, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1293, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1253, 2, q_10+1253, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1292, p_00+1301);
	gf2x_mul_1_avx(temp2, q_11+1292, p_10+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1252, 2, q_10+1252, 2, temp);
	memset(q_11+1252, 0x00, 1*DIGIT_SIZE_B);
	GF2X_MUL(38, temp, 19, p_01+1302, 19, q_10+1292);
	GF2X_MUL(38, temp2, 19, p_11+1302, 19, q_11+1292);
	gf2x_add(38, q_11+1253, 38, temp, 38, temp2);
	gf2x_mul_1_avx(temp, q_10+1310, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1310, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1270, 2, q_11+1270, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1309, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1309, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1269, 2, q_11+1269, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1308, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1308, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1268, 2, q_11+1268, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1307, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1307, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1267, 2, q_11+1267, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1306, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1306, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1266, 2, q_11+1266, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1305, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1305, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1265, 2, q_11+1265, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1304, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1304, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1264, 2, q_11+1264, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1303, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1303, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1263, 2, q_11+1263, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1302, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1302, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1262, 2, q_11+1262, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1301, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1301, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1261, 2, q_11+1261, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1300, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1300, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1260, 2, q_11+1260, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1299, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1299, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1259, 2, q_11+1259, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1298, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1298, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1258, 2, q_11+1258, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1297, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1297, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1257, 2, q_11+1257, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1296, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1296, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1256, 2, q_11+1256, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1295, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1295, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1255, 2, q_11+1255, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1294, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1294, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1254, 2, q_11+1254, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1293, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1293, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1253, 2, q_11+1253, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1292, p_01+1301);
	gf2x_mul_1_avx(temp2, q_11+1292, p_11+1301);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1252, 2, q_11+1252, 2, temp);
	
	// Recombining results: n: 5028, depth: 4
	memset(q_00+1168, 0x00, 1*DIGIT_SIZE_B);
	GF2X_MUL(78, temp, 39, p_00+1258, 39, q_00+1252);
	GF2X_MUL(78, temp2, 39, p_10+1258, 39, q_01+1252);
	gf2x_add(78, q_00+1169, 78, temp, 78, temp2);
	gf2x_mul_1_avx(temp, q_00+1290, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1290, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1206, 2, q_00+1206, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1289, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1289, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1205, 2, q_00+1205, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1288, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1288, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1204, 2, q_00+1204, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1287, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1287, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1203, 2, q_00+1203, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1286, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1286, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1202, 2, q_00+1202, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1285, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1285, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1201, 2, q_00+1201, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1284, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1284, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1200, 2, q_00+1200, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1283, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1283, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1199, 2, q_00+1199, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1282, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1282, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1198, 2, q_00+1198, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1281, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1281, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1197, 2, q_00+1197, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1280, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1280, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1196, 2, q_00+1196, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1279, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1279, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1195, 2, q_00+1195, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1278, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1278, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1194, 2, q_00+1194, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1277, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1277, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1193, 2, q_00+1193, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1276, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1276, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1192, 2, q_00+1192, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1275, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1275, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1191, 2, q_00+1191, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1274, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1274, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1190, 2, q_00+1190, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1273, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1273, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1189, 2, q_00+1189, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1272, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1272, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1188, 2, q_00+1188, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1271, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1271, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1187, 2, q_00+1187, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1270, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1270, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1186, 2, q_00+1186, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1269, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1269, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1185, 2, q_00+1185, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1268, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1268, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1184, 2, q_00+1184, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1267, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1267, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1183, 2, q_00+1183, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1266, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1266, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1182, 2, q_00+1182, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1265, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1265, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1181, 2, q_00+1181, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1264, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1264, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1180, 2, q_00+1180, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1263, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1263, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1179, 2, q_00+1179, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1262, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1262, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1178, 2, q_00+1178, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1261, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1261, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1177, 2, q_00+1177, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1260, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1260, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1176, 2, q_00+1176, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1259, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1259, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1175, 2, q_00+1175, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1258, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1258, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1174, 2, q_00+1174, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1257, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1257, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1173, 2, q_00+1173, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1256, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1256, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1172, 2, q_00+1172, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1255, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1255, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1171, 2, q_00+1171, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1254, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1254, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1170, 2, q_00+1170, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1253, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1253, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1169, 2, q_00+1169, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1252, p_00+1257);
	gf2x_mul_1_avx(temp2, q_01+1252, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1168, 2, q_00+1168, 2, temp);
	memset(q_01+1168, 0x00, 1*DIGIT_SIZE_B);
	GF2X_MUL(78, temp, 39, p_01+1258, 39, q_00+1252);
	GF2X_MUL(78, temp2, 39, p_11+1258, 39, q_01+1252);
	gf2x_add(78, q_01+1169, 78, temp, 78, temp2);
	gf2x_mul_1_avx(temp, q_00+1290, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1290, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1206, 2, q_01+1206, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1289, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1289, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1205, 2, q_01+1205, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1288, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1288, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1204, 2, q_01+1204, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1287, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1287, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1203, 2, q_01+1203, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1286, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1286, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1202, 2, q_01+1202, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1285, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1285, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1201, 2, q_01+1201, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1284, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1284, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1200, 2, q_01+1200, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1283, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1283, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1199, 2, q_01+1199, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1282, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1282, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1198, 2, q_01+1198, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1281, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1281, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1197, 2, q_01+1197, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1280, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1280, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1196, 2, q_01+1196, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1279, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1279, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1195, 2, q_01+1195, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1278, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1278, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1194, 2, q_01+1194, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1277, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1277, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1193, 2, q_01+1193, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1276, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1276, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1192, 2, q_01+1192, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1275, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1275, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1191, 2, q_01+1191, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1274, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1274, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1190, 2, q_01+1190, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1273, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1273, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1189, 2, q_01+1189, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1272, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1272, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1188, 2, q_01+1188, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1271, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1271, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1187, 2, q_01+1187, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1270, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1270, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1186, 2, q_01+1186, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1269, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1269, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1185, 2, q_01+1185, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1268, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1268, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1184, 2, q_01+1184, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1267, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1267, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1183, 2, q_01+1183, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1266, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1266, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1182, 2, q_01+1182, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1265, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1265, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1181, 2, q_01+1181, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1264, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1264, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1180, 2, q_01+1180, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1263, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1263, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1179, 2, q_01+1179, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1262, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1262, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1178, 2, q_01+1178, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1261, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1261, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1177, 2, q_01+1177, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1260, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1260, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1176, 2, q_01+1176, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1259, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1259, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1175, 2, q_01+1175, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1258, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1258, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1174, 2, q_01+1174, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1257, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1257, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1173, 2, q_01+1173, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1256, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1256, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1172, 2, q_01+1172, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1255, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1255, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1171, 2, q_01+1171, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1254, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1254, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1170, 2, q_01+1170, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1253, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1253, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1169, 2, q_01+1169, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1252, p_01+1257);
	gf2x_mul_1_avx(temp2, q_01+1252, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1168, 2, q_01+1168, 2, temp);
	memset(q_10+1168, 0x00, 1*DIGIT_SIZE_B);
	GF2X_MUL(78, temp, 39, p_00+1258, 39, q_10+1252);
	GF2X_MUL(78, temp2, 39, p_10+1258, 39, q_11+1252);
	gf2x_add(78, q_10+1169, 78, temp, 78, temp2);
	gf2x_mul_1_avx(temp, q_10+1290, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1290, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1206, 2, q_10+1206, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1289, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1289, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1205, 2, q_10+1205, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1288, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1288, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1204, 2, q_10+1204, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1287, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1287, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1203, 2, q_10+1203, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1286, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1286, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1202, 2, q_10+1202, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1285, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1285, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1201, 2, q_10+1201, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1284, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1284, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1200, 2, q_10+1200, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1283, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1283, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1199, 2, q_10+1199, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1282, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1282, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1198, 2, q_10+1198, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1281, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1281, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1197, 2, q_10+1197, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1280, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1280, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1196, 2, q_10+1196, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1279, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1279, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1195, 2, q_10+1195, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1278, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1278, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1194, 2, q_10+1194, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1277, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1277, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1193, 2, q_10+1193, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1276, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1276, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1192, 2, q_10+1192, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1275, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1275, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1191, 2, q_10+1191, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1274, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1274, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1190, 2, q_10+1190, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1273, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1273, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1189, 2, q_10+1189, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1272, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1272, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1188, 2, q_10+1188, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1271, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1271, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1187, 2, q_10+1187, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1270, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1270, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1186, 2, q_10+1186, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1269, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1269, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1185, 2, q_10+1185, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1268, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1268, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1184, 2, q_10+1184, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1267, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1267, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1183, 2, q_10+1183, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1266, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1266, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1182, 2, q_10+1182, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1265, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1265, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1181, 2, q_10+1181, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1264, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1264, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1180, 2, q_10+1180, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1263, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1263, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1179, 2, q_10+1179, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1262, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1262, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1178, 2, q_10+1178, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1261, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1261, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1177, 2, q_10+1177, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1260, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1260, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1176, 2, q_10+1176, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1259, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1259, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1175, 2, q_10+1175, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1258, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1258, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1174, 2, q_10+1174, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1257, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1257, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1173, 2, q_10+1173, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1256, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1256, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1172, 2, q_10+1172, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1255, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1255, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1171, 2, q_10+1171, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1254, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1254, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1170, 2, q_10+1170, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1253, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1253, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1169, 2, q_10+1169, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1252, p_00+1257);
	gf2x_mul_1_avx(temp2, q_11+1252, p_10+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1168, 2, q_10+1168, 2, temp);
	memset(q_11+1168, 0x00, 1*DIGIT_SIZE_B);
	GF2X_MUL(78, temp, 39, p_01+1258, 39, q_10+1252);
	GF2X_MUL(78, temp2, 39, p_11+1258, 39, q_11+1252);
	gf2x_add(78, q_11+1169, 78, temp, 78, temp2);
	gf2x_mul_1_avx(temp, q_10+1290, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1290, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1206, 2, q_11+1206, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1289, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1289, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1205, 2, q_11+1205, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1288, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1288, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1204, 2, q_11+1204, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1287, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1287, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1203, 2, q_11+1203, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1286, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1286, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1202, 2, q_11+1202, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1285, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1285, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1201, 2, q_11+1201, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1284, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1284, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1200, 2, q_11+1200, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1283, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1283, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1199, 2, q_11+1199, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1282, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1282, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1198, 2, q_11+1198, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1281, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1281, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1197, 2, q_11+1197, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1280, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1280, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1196, 2, q_11+1196, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1279, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1279, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1195, 2, q_11+1195, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1278, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1278, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1194, 2, q_11+1194, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1277, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1277, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1193, 2, q_11+1193, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1276, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1276, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1192, 2, q_11+1192, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1275, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1275, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1191, 2, q_11+1191, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1274, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1274, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1190, 2, q_11+1190, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1273, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1273, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1189, 2, q_11+1189, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1272, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1272, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1188, 2, q_11+1188, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1271, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1271, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1187, 2, q_11+1187, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1270, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1270, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1186, 2, q_11+1186, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1269, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1269, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1185, 2, q_11+1185, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1268, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1268, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1184, 2, q_11+1184, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1267, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1267, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1183, 2, q_11+1183, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1266, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1266, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1182, 2, q_11+1182, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1265, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1265, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1181, 2, q_11+1181, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1264, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1264, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1180, 2, q_11+1180, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1263, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1263, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1179, 2, q_11+1179, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1262, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1262, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1178, 2, q_11+1178, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1261, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1261, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1177, 2, q_11+1177, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1260, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1260, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1176, 2, q_11+1176, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1259, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1259, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1175, 2, q_11+1175, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1258, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1258, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1174, 2, q_11+1174, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1257, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1257, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1173, 2, q_11+1173, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1256, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1256, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1172, 2, q_11+1172, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1255, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1255, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1171, 2, q_11+1171, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1254, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1254, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1170, 2, q_11+1170, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1253, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1253, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1169, 2, q_11+1169, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1252, p_01+1257);
	gf2x_mul_1_avx(temp2, q_11+1252, p_11+1257);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1168, 2, q_11+1168, 2, temp);
	
	// Recombining results: n: 10383, depth: 3
	memset(q_00+1000, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(158, temp, 79, p_00+1178, 79, q_00+1168);
	GF2X_MUL(158, temp2, 79, p_10+1178, 79, q_01+1168);
	gf2x_add(158, q_00+1005, 158, temp, 158, temp2);
	gf2x_mul_5_avx(temp, q_00+1242, p_00+1173);
	gf2x_mul_5_avx(temp2, q_01+1242, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+1074, 10, q_00+1074, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1237, p_00+1173);
	gf2x_mul_5_avx(temp2, q_01+1237, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+1069, 10, q_00+1069, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1232, p_00+1173);
	gf2x_mul_5_avx(temp2, q_01+1232, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+1064, 10, q_00+1064, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1227, p_00+1173);
	gf2x_mul_5_avx(temp2, q_01+1227, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+1059, 10, q_00+1059, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1222, p_00+1173);
	gf2x_mul_5_avx(temp2, q_01+1222, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+1054, 10, q_00+1054, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1217, p_00+1173);
	gf2x_mul_5_avx(temp2, q_01+1217, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+1049, 10, q_00+1049, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1212, p_00+1173);
	gf2x_mul_5_avx(temp2, q_01+1212, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+1044, 10, q_00+1044, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1207, p_00+1173);
	gf2x_mul_5_avx(temp2, q_01+1207, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+1039, 10, q_00+1039, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1202, p_00+1173);
	gf2x_mul_5_avx(temp2, q_01+1202, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+1034, 10, q_00+1034, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1197, p_00+1173);
	gf2x_mul_5_avx(temp2, q_01+1197, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+1029, 10, q_00+1029, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1192, p_00+1173);
	gf2x_mul_5_avx(temp2, q_01+1192, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+1024, 10, q_00+1024, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1187, p_00+1173);
	gf2x_mul_5_avx(temp2, q_01+1187, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+1019, 10, q_00+1019, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1182, p_00+1173);
	gf2x_mul_5_avx(temp2, q_01+1182, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+1014, 10, q_00+1014, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1177, p_00+1173);
	gf2x_mul_5_avx(temp2, q_01+1177, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+1009, 10, q_00+1009, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1172, p_00+1173);
	gf2x_mul_5_avx(temp2, q_01+1172, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+1004, 10, q_00+1004, 10, temp);
	gf2x_mul_4_avx(temp, p_00+1174, q_00+1168);
	gf2x_mul_4_avx(temp2, p_10+1174, q_01+1168);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+1001, 8, q_00+1001, 8, temp);
	gf2x_mul_1_avx(temp, q_00+1171, p_00+1173);
	gf2x_mul_1_avx(temp2, q_01+1171, p_10+1173);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1003, 2, q_00+1003, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1170, p_00+1173);
	gf2x_mul_1_avx(temp2, q_01+1170, p_10+1173);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1002, 2, q_00+1002, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1169, p_00+1173);
	gf2x_mul_1_avx(temp2, q_01+1169, p_10+1173);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1001, 2, q_00+1001, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1168, p_00+1173);
	gf2x_mul_1_avx(temp2, q_01+1168, p_10+1173);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1000, 2, q_00+1000, 2, temp);
	memset(q_01+1000, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(158, temp, 79, p_01+1178, 79, q_00+1168);
	GF2X_MUL(158, temp2, 79, p_11+1178, 79, q_01+1168);
	gf2x_add(158, q_01+1005, 158, temp, 158, temp2);
	gf2x_mul_5_avx(temp, q_00+1242, p_01+1173);
	gf2x_mul_5_avx(temp2, q_01+1242, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+1074, 10, q_01+1074, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1237, p_01+1173);
	gf2x_mul_5_avx(temp2, q_01+1237, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+1069, 10, q_01+1069, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1232, p_01+1173);
	gf2x_mul_5_avx(temp2, q_01+1232, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+1064, 10, q_01+1064, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1227, p_01+1173);
	gf2x_mul_5_avx(temp2, q_01+1227, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+1059, 10, q_01+1059, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1222, p_01+1173);
	gf2x_mul_5_avx(temp2, q_01+1222, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+1054, 10, q_01+1054, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1217, p_01+1173);
	gf2x_mul_5_avx(temp2, q_01+1217, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+1049, 10, q_01+1049, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1212, p_01+1173);
	gf2x_mul_5_avx(temp2, q_01+1212, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+1044, 10, q_01+1044, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1207, p_01+1173);
	gf2x_mul_5_avx(temp2, q_01+1207, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+1039, 10, q_01+1039, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1202, p_01+1173);
	gf2x_mul_5_avx(temp2, q_01+1202, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+1034, 10, q_01+1034, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1197, p_01+1173);
	gf2x_mul_5_avx(temp2, q_01+1197, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+1029, 10, q_01+1029, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1192, p_01+1173);
	gf2x_mul_5_avx(temp2, q_01+1192, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+1024, 10, q_01+1024, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1187, p_01+1173);
	gf2x_mul_5_avx(temp2, q_01+1187, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+1019, 10, q_01+1019, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1182, p_01+1173);
	gf2x_mul_5_avx(temp2, q_01+1182, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+1014, 10, q_01+1014, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1177, p_01+1173);
	gf2x_mul_5_avx(temp2, q_01+1177, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+1009, 10, q_01+1009, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1172, p_01+1173);
	gf2x_mul_5_avx(temp2, q_01+1172, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+1004, 10, q_01+1004, 10, temp);
	gf2x_mul_4_avx(temp, p_01+1174, q_00+1168);
	gf2x_mul_4_avx(temp2, p_11+1174, q_01+1168);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+1001, 8, q_01+1001, 8, temp);
	gf2x_mul_1_avx(temp, q_00+1171, p_01+1173);
	gf2x_mul_1_avx(temp2, q_01+1171, p_11+1173);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1003, 2, q_01+1003, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1170, p_01+1173);
	gf2x_mul_1_avx(temp2, q_01+1170, p_11+1173);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1002, 2, q_01+1002, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1169, p_01+1173);
	gf2x_mul_1_avx(temp2, q_01+1169, p_11+1173);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1001, 2, q_01+1001, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1168, p_01+1173);
	gf2x_mul_1_avx(temp2, q_01+1168, p_11+1173);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1000, 2, q_01+1000, 2, temp);
	memset(q_10+1000, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(158, temp, 79, p_00+1178, 79, q_10+1168);
	GF2X_MUL(158, temp2, 79, p_10+1178, 79, q_11+1168);
	gf2x_add(158, q_10+1005, 158, temp, 158, temp2);
	gf2x_mul_5_avx(temp, q_10+1242, p_00+1173);
	gf2x_mul_5_avx(temp2, q_11+1242, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+1074, 10, q_10+1074, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1237, p_00+1173);
	gf2x_mul_5_avx(temp2, q_11+1237, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+1069, 10, q_10+1069, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1232, p_00+1173);
	gf2x_mul_5_avx(temp2, q_11+1232, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+1064, 10, q_10+1064, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1227, p_00+1173);
	gf2x_mul_5_avx(temp2, q_11+1227, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+1059, 10, q_10+1059, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1222, p_00+1173);
	gf2x_mul_5_avx(temp2, q_11+1222, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+1054, 10, q_10+1054, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1217, p_00+1173);
	gf2x_mul_5_avx(temp2, q_11+1217, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+1049, 10, q_10+1049, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1212, p_00+1173);
	gf2x_mul_5_avx(temp2, q_11+1212, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+1044, 10, q_10+1044, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1207, p_00+1173);
	gf2x_mul_5_avx(temp2, q_11+1207, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+1039, 10, q_10+1039, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1202, p_00+1173);
	gf2x_mul_5_avx(temp2, q_11+1202, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+1034, 10, q_10+1034, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1197, p_00+1173);
	gf2x_mul_5_avx(temp2, q_11+1197, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+1029, 10, q_10+1029, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1192, p_00+1173);
	gf2x_mul_5_avx(temp2, q_11+1192, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+1024, 10, q_10+1024, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1187, p_00+1173);
	gf2x_mul_5_avx(temp2, q_11+1187, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+1019, 10, q_10+1019, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1182, p_00+1173);
	gf2x_mul_5_avx(temp2, q_11+1182, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+1014, 10, q_10+1014, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1177, p_00+1173);
	gf2x_mul_5_avx(temp2, q_11+1177, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+1009, 10, q_10+1009, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1172, p_00+1173);
	gf2x_mul_5_avx(temp2, q_11+1172, p_10+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+1004, 10, q_10+1004, 10, temp);
	gf2x_mul_4_avx(temp, p_00+1174, q_10+1168);
	gf2x_mul_4_avx(temp2, p_10+1174, q_11+1168);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+1001, 8, q_10+1001, 8, temp);
	gf2x_mul_1_avx(temp, q_10+1171, p_00+1173);
	gf2x_mul_1_avx(temp2, q_11+1171, p_10+1173);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1003, 2, q_10+1003, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1170, p_00+1173);
	gf2x_mul_1_avx(temp2, q_11+1170, p_10+1173);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1002, 2, q_10+1002, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1169, p_00+1173);
	gf2x_mul_1_avx(temp2, q_11+1169, p_10+1173);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1001, 2, q_10+1001, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1168, p_00+1173);
	gf2x_mul_1_avx(temp2, q_11+1168, p_10+1173);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1000, 2, q_10+1000, 2, temp);
	memset(q_11+1000, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(158, temp, 79, p_01+1178, 79, q_10+1168);
	GF2X_MUL(158, temp2, 79, p_11+1178, 79, q_11+1168);
	gf2x_add(158, q_11+1005, 158, temp, 158, temp2);
	gf2x_mul_5_avx(temp, q_10+1242, p_01+1173);
	gf2x_mul_5_avx(temp2, q_11+1242, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+1074, 10, q_11+1074, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1237, p_01+1173);
	gf2x_mul_5_avx(temp2, q_11+1237, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+1069, 10, q_11+1069, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1232, p_01+1173);
	gf2x_mul_5_avx(temp2, q_11+1232, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+1064, 10, q_11+1064, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1227, p_01+1173);
	gf2x_mul_5_avx(temp2, q_11+1227, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+1059, 10, q_11+1059, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1222, p_01+1173);
	gf2x_mul_5_avx(temp2, q_11+1222, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+1054, 10, q_11+1054, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1217, p_01+1173);
	gf2x_mul_5_avx(temp2, q_11+1217, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+1049, 10, q_11+1049, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1212, p_01+1173);
	gf2x_mul_5_avx(temp2, q_11+1212, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+1044, 10, q_11+1044, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1207, p_01+1173);
	gf2x_mul_5_avx(temp2, q_11+1207, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+1039, 10, q_11+1039, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1202, p_01+1173);
	gf2x_mul_5_avx(temp2, q_11+1202, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+1034, 10, q_11+1034, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1197, p_01+1173);
	gf2x_mul_5_avx(temp2, q_11+1197, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+1029, 10, q_11+1029, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1192, p_01+1173);
	gf2x_mul_5_avx(temp2, q_11+1192, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+1024, 10, q_11+1024, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1187, p_01+1173);
	gf2x_mul_5_avx(temp2, q_11+1187, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+1019, 10, q_11+1019, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1182, p_01+1173);
	gf2x_mul_5_avx(temp2, q_11+1182, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+1014, 10, q_11+1014, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1177, p_01+1173);
	gf2x_mul_5_avx(temp2, q_11+1177, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+1009, 10, q_11+1009, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1172, p_01+1173);
	gf2x_mul_5_avx(temp2, q_11+1172, p_11+1173);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+1004, 10, q_11+1004, 10, temp);
	gf2x_mul_4_avx(temp, p_01+1174, q_10+1168);
	gf2x_mul_4_avx(temp2, p_11+1174, q_11+1168);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+1001, 8, q_11+1001, 8, temp);
	gf2x_mul_1_avx(temp, q_10+1171, p_01+1173);
	gf2x_mul_1_avx(temp2, q_11+1171, p_11+1173);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1003, 2, q_11+1003, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1170, p_01+1173);
	gf2x_mul_1_avx(temp2, q_11+1170, p_11+1173);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1002, 2, q_11+1002, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1169, p_01+1173);
	gf2x_mul_1_avx(temp2, q_11+1169, p_11+1173);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1001, 2, q_11+1001, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1168, p_01+1173);
	gf2x_mul_1_avx(temp2, q_11+1168, p_11+1173);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1000, 2, q_11+1000, 2, temp);
	
	// Recombining results: n: 21093, depth: 2
	memset(q_00+665, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(326, temp, 163, p_00+1010, 163, q_00+1000);
	GF2X_MUL(326, temp2, 163, p_10+1010, 163, q_01+1000);
	gf2x_add(326, q_00+669, 326, temp, 326, temp2);
	gf2x_mul_5_avx(temp, q_00+1158, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1158, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+822, 10, q_00+822, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1153, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1153, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+817, 10, q_00+817, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1148, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1148, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+812, 10, q_00+812, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1143, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1143, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+807, 10, q_00+807, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1138, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1138, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+802, 10, q_00+802, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1133, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1133, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+797, 10, q_00+797, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1128, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1128, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+792, 10, q_00+792, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1123, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1123, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+787, 10, q_00+787, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1118, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1118, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+782, 10, q_00+782, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1113, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1113, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+777, 10, q_00+777, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1108, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1108, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+772, 10, q_00+772, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1103, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1103, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+767, 10, q_00+767, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1098, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1098, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+762, 10, q_00+762, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1093, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1093, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+757, 10, q_00+757, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1088, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1088, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+752, 10, q_00+752, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1083, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1083, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+747, 10, q_00+747, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1078, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1078, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+742, 10, q_00+742, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1073, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1073, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+737, 10, q_00+737, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1068, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1068, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+732, 10, q_00+732, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1063, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1063, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+727, 10, q_00+727, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1058, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1058, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+722, 10, q_00+722, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1053, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1053, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+717, 10, q_00+717, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1048, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1048, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+712, 10, q_00+712, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1043, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1043, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+707, 10, q_00+707, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1038, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1038, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+702, 10, q_00+702, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1033, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1033, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+697, 10, q_00+697, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1028, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1028, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+692, 10, q_00+692, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1023, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1023, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+687, 10, q_00+687, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1018, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1018, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+682, 10, q_00+682, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1013, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1013, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+677, 10, q_00+677, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1008, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1008, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+672, 10, q_00+672, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1003, p_00+1005);
	gf2x_mul_5_avx(temp2, q_01+1003, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+667, 10, q_00+667, 10, temp);
	gf2x_mul_3_avx(temp, p_00+1007, q_00+1000);
	gf2x_mul_3_avx(temp2, p_10+1007, q_01+1000);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+666, 6, q_00+666, 6, temp);
	gf2x_mul_2_avx(temp, q_00+1001, p_00+1005);
	gf2x_mul_2_avx(temp2, q_01+1001, p_10+1005);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+665, 4, q_00+665, 4, temp);
	gf2x_mul_1_avx(temp, p_00+1006, q_00+1000);
	gf2x_mul_1_avx(temp2, p_10+1006, q_01+1000);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+665, 2, q_00+665, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1000, p_00+1005);
	gf2x_mul_1_avx(temp2, q_01+1000, p_10+1005);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, q_00+665, 1, q_00+665, 1, temp+1);
	memset(q_01+665, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(326, temp, 163, p_01+1010, 163, q_00+1000);
	GF2X_MUL(326, temp2, 163, p_11+1010, 163, q_01+1000);
	gf2x_add(326, q_01+669, 326, temp, 326, temp2);
	gf2x_mul_5_avx(temp, q_00+1158, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1158, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+822, 10, q_01+822, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1153, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1153, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+817, 10, q_01+817, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1148, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1148, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+812, 10, q_01+812, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1143, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1143, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+807, 10, q_01+807, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1138, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1138, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+802, 10, q_01+802, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1133, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1133, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+797, 10, q_01+797, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1128, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1128, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+792, 10, q_01+792, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1123, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1123, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+787, 10, q_01+787, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1118, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1118, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+782, 10, q_01+782, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1113, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1113, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+777, 10, q_01+777, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1108, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1108, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+772, 10, q_01+772, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1103, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1103, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+767, 10, q_01+767, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1098, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1098, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+762, 10, q_01+762, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1093, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1093, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+757, 10, q_01+757, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1088, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1088, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+752, 10, q_01+752, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1083, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1083, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+747, 10, q_01+747, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1078, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1078, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+742, 10, q_01+742, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1073, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1073, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+737, 10, q_01+737, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1068, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1068, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+732, 10, q_01+732, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1063, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1063, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+727, 10, q_01+727, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1058, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1058, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+722, 10, q_01+722, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1053, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1053, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+717, 10, q_01+717, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1048, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1048, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+712, 10, q_01+712, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1043, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1043, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+707, 10, q_01+707, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1038, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1038, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+702, 10, q_01+702, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1033, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1033, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+697, 10, q_01+697, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1028, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1028, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+692, 10, q_01+692, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1023, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1023, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+687, 10, q_01+687, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1018, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1018, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+682, 10, q_01+682, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1013, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1013, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+677, 10, q_01+677, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1008, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1008, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+672, 10, q_01+672, 10, temp);
	gf2x_mul_5_avx(temp, q_00+1003, p_01+1005);
	gf2x_mul_5_avx(temp2, q_01+1003, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+667, 10, q_01+667, 10, temp);
	gf2x_mul_3_avx(temp, p_01+1007, q_00+1000);
	gf2x_mul_3_avx(temp2, p_11+1007, q_01+1000);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+666, 6, q_01+666, 6, temp);
	gf2x_mul_2_avx(temp, q_00+1001, p_01+1005);
	gf2x_mul_2_avx(temp2, q_01+1001, p_11+1005);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+665, 4, q_01+665, 4, temp);
	gf2x_mul_1_avx(temp, p_01+1006, q_00+1000);
	gf2x_mul_1_avx(temp2, p_11+1006, q_01+1000);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+665, 2, q_01+665, 2, temp);
	gf2x_mul_1_avx(temp, q_00+1000, p_01+1005);
	gf2x_mul_1_avx(temp2, q_01+1000, p_11+1005);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, q_01+665, 1, q_01+665, 1, temp+1);
	memset(q_10+665, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(326, temp, 163, p_00+1010, 163, q_10+1000);
	GF2X_MUL(326, temp2, 163, p_10+1010, 163, q_11+1000);
	gf2x_add(326, q_10+669, 326, temp, 326, temp2);
	gf2x_mul_5_avx(temp, q_10+1158, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1158, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+822, 10, q_10+822, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1153, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1153, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+817, 10, q_10+817, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1148, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1148, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+812, 10, q_10+812, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1143, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1143, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+807, 10, q_10+807, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1138, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1138, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+802, 10, q_10+802, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1133, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1133, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+797, 10, q_10+797, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1128, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1128, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+792, 10, q_10+792, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1123, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1123, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+787, 10, q_10+787, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1118, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1118, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+782, 10, q_10+782, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1113, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1113, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+777, 10, q_10+777, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1108, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1108, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+772, 10, q_10+772, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1103, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1103, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+767, 10, q_10+767, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1098, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1098, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+762, 10, q_10+762, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1093, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1093, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+757, 10, q_10+757, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1088, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1088, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+752, 10, q_10+752, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1083, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1083, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+747, 10, q_10+747, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1078, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1078, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+742, 10, q_10+742, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1073, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1073, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+737, 10, q_10+737, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1068, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1068, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+732, 10, q_10+732, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1063, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1063, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+727, 10, q_10+727, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1058, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1058, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+722, 10, q_10+722, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1053, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1053, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+717, 10, q_10+717, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1048, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1048, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+712, 10, q_10+712, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1043, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1043, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+707, 10, q_10+707, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1038, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1038, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+702, 10, q_10+702, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1033, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1033, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+697, 10, q_10+697, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1028, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1028, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+692, 10, q_10+692, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1023, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1023, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+687, 10, q_10+687, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1018, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1018, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+682, 10, q_10+682, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1013, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1013, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+677, 10, q_10+677, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1008, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1008, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+672, 10, q_10+672, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1003, p_00+1005);
	gf2x_mul_5_avx(temp2, q_11+1003, p_10+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+667, 10, q_10+667, 10, temp);
	gf2x_mul_3_avx(temp, p_00+1007, q_10+1000);
	gf2x_mul_3_avx(temp2, p_10+1007, q_11+1000);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+666, 6, q_10+666, 6, temp);
	gf2x_mul_2_avx(temp, q_10+1001, p_00+1005);
	gf2x_mul_2_avx(temp2, q_11+1001, p_10+1005);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+665, 4, q_10+665, 4, temp);
	gf2x_mul_1_avx(temp, p_00+1006, q_10+1000);
	gf2x_mul_1_avx(temp2, p_10+1006, q_11+1000);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+665, 2, q_10+665, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1000, p_00+1005);
	gf2x_mul_1_avx(temp2, q_11+1000, p_10+1005);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, q_10+665, 1, q_10+665, 1, temp+1);
	memset(q_11+665, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(326, temp, 163, p_01+1010, 163, q_10+1000);
	GF2X_MUL(326, temp2, 163, p_11+1010, 163, q_11+1000);
	gf2x_add(326, q_11+669, 326, temp, 326, temp2);
	gf2x_mul_5_avx(temp, q_10+1158, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1158, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+822, 10, q_11+822, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1153, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1153, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+817, 10, q_11+817, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1148, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1148, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+812, 10, q_11+812, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1143, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1143, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+807, 10, q_11+807, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1138, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1138, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+802, 10, q_11+802, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1133, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1133, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+797, 10, q_11+797, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1128, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1128, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+792, 10, q_11+792, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1123, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1123, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+787, 10, q_11+787, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1118, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1118, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+782, 10, q_11+782, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1113, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1113, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+777, 10, q_11+777, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1108, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1108, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+772, 10, q_11+772, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1103, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1103, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+767, 10, q_11+767, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1098, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1098, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+762, 10, q_11+762, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1093, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1093, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+757, 10, q_11+757, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1088, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1088, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+752, 10, q_11+752, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1083, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1083, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+747, 10, q_11+747, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1078, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1078, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+742, 10, q_11+742, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1073, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1073, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+737, 10, q_11+737, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1068, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1068, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+732, 10, q_11+732, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1063, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1063, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+727, 10, q_11+727, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1058, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1058, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+722, 10, q_11+722, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1053, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1053, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+717, 10, q_11+717, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1048, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1048, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+712, 10, q_11+712, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1043, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1043, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+707, 10, q_11+707, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1038, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1038, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+702, 10, q_11+702, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1033, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1033, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+697, 10, q_11+697, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1028, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1028, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+692, 10, q_11+692, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1023, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1023, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+687, 10, q_11+687, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1018, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1018, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+682, 10, q_11+682, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1013, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1013, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+677, 10, q_11+677, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1008, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1008, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+672, 10, q_11+672, 10, temp);
	gf2x_mul_5_avx(temp, q_10+1003, p_01+1005);
	gf2x_mul_5_avx(temp2, q_11+1003, p_11+1005);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+667, 10, q_11+667, 10, temp);
	gf2x_mul_3_avx(temp, p_01+1007, q_10+1000);
	gf2x_mul_3_avx(temp2, p_11+1007, q_11+1000);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+666, 6, q_11+666, 6, temp);
	gf2x_mul_2_avx(temp, q_10+1001, p_01+1005);
	gf2x_mul_2_avx(temp2, q_11+1001, p_11+1005);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+665, 4, q_11+665, 4, temp);
	gf2x_mul_1_avx(temp, p_01+1006, q_10+1000);
	gf2x_mul_1_avx(temp2, p_11+1006, q_11+1000);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+665, 2, q_11+665, 2, temp);
	gf2x_mul_1_avx(temp, q_10+1000, p_01+1005);
	gf2x_mul_1_avx(temp2, q_11+1000, p_11+1005);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, q_11+665, 1, q_11+665, 1, temp+1);
	
	// Recombining results: n: 42513, depth: 1
	memset(q_00+0, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(660, temp, 330, p_00+675, 330, q_00+665);
	GF2X_MUL(660, temp2, 330, p_10+675, 330, q_01+665);
	gf2x_add(660, q_00+5, 660, temp, 660, temp2);
	gf2x_mul_5_avx(temp, q_00+990, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+990, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+325, 10, q_00+325, 10, temp);
	gf2x_mul_5_avx(temp, q_00+985, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+985, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+320, 10, q_00+320, 10, temp);
	gf2x_mul_5_avx(temp, q_00+980, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+980, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+315, 10, q_00+315, 10, temp);
	gf2x_mul_5_avx(temp, q_00+975, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+975, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+310, 10, q_00+310, 10, temp);
	gf2x_mul_5_avx(temp, q_00+970, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+970, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+305, 10, q_00+305, 10, temp);
	gf2x_mul_5_avx(temp, q_00+965, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+965, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+300, 10, q_00+300, 10, temp);
	gf2x_mul_5_avx(temp, q_00+960, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+960, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+295, 10, q_00+295, 10, temp);
	gf2x_mul_5_avx(temp, q_00+955, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+955, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+290, 10, q_00+290, 10, temp);
	gf2x_mul_5_avx(temp, q_00+950, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+950, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+285, 10, q_00+285, 10, temp);
	gf2x_mul_5_avx(temp, q_00+945, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+945, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+280, 10, q_00+280, 10, temp);
	gf2x_mul_5_avx(temp, q_00+940, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+940, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+275, 10, q_00+275, 10, temp);
	gf2x_mul_5_avx(temp, q_00+935, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+935, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+270, 10, q_00+270, 10, temp);
	gf2x_mul_5_avx(temp, q_00+930, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+930, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+265, 10, q_00+265, 10, temp);
	gf2x_mul_5_avx(temp, q_00+925, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+925, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+260, 10, q_00+260, 10, temp);
	gf2x_mul_5_avx(temp, q_00+920, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+920, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+255, 10, q_00+255, 10, temp);
	gf2x_mul_5_avx(temp, q_00+915, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+915, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+250, 10, q_00+250, 10, temp);
	gf2x_mul_5_avx(temp, q_00+910, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+910, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+245, 10, q_00+245, 10, temp);
	gf2x_mul_5_avx(temp, q_00+905, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+905, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+240, 10, q_00+240, 10, temp);
	gf2x_mul_5_avx(temp, q_00+900, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+900, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+235, 10, q_00+235, 10, temp);
	gf2x_mul_5_avx(temp, q_00+895, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+895, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+230, 10, q_00+230, 10, temp);
	gf2x_mul_5_avx(temp, q_00+890, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+890, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+225, 10, q_00+225, 10, temp);
	gf2x_mul_5_avx(temp, q_00+885, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+885, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+220, 10, q_00+220, 10, temp);
	gf2x_mul_5_avx(temp, q_00+880, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+880, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+215, 10, q_00+215, 10, temp);
	gf2x_mul_5_avx(temp, q_00+875, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+875, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+210, 10, q_00+210, 10, temp);
	gf2x_mul_5_avx(temp, q_00+870, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+870, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+205, 10, q_00+205, 10, temp);
	gf2x_mul_5_avx(temp, q_00+865, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+865, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+200, 10, q_00+200, 10, temp);
	gf2x_mul_5_avx(temp, q_00+860, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+860, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+195, 10, q_00+195, 10, temp);
	gf2x_mul_5_avx(temp, q_00+855, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+855, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+190, 10, q_00+190, 10, temp);
	gf2x_mul_5_avx(temp, q_00+850, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+850, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+185, 10, q_00+185, 10, temp);
	gf2x_mul_5_avx(temp, q_00+845, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+845, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+180, 10, q_00+180, 10, temp);
	gf2x_mul_5_avx(temp, q_00+840, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+840, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+175, 10, q_00+175, 10, temp);
	gf2x_mul_5_avx(temp, q_00+835, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+835, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+170, 10, q_00+170, 10, temp);
	gf2x_mul_5_avx(temp, q_00+830, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+830, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+165, 10, q_00+165, 10, temp);
	gf2x_mul_5_avx(temp, q_00+825, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+825, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+160, 10, q_00+160, 10, temp);
	gf2x_mul_5_avx(temp, q_00+820, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+820, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+155, 10, q_00+155, 10, temp);
	gf2x_mul_5_avx(temp, q_00+815, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+815, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+150, 10, q_00+150, 10, temp);
	gf2x_mul_5_avx(temp, q_00+810, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+810, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+145, 10, q_00+145, 10, temp);
	gf2x_mul_5_avx(temp, q_00+805, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+805, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+140, 10, q_00+140, 10, temp);
	gf2x_mul_5_avx(temp, q_00+800, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+800, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+135, 10, q_00+135, 10, temp);
	gf2x_mul_5_avx(temp, q_00+795, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+795, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+130, 10, q_00+130, 10, temp);
	gf2x_mul_5_avx(temp, q_00+790, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+790, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+125, 10, q_00+125, 10, temp);
	gf2x_mul_5_avx(temp, q_00+785, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+785, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+120, 10, q_00+120, 10, temp);
	gf2x_mul_5_avx(temp, q_00+780, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+780, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+115, 10, q_00+115, 10, temp);
	gf2x_mul_5_avx(temp, q_00+775, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+775, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+110, 10, q_00+110, 10, temp);
	gf2x_mul_5_avx(temp, q_00+770, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+770, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+105, 10, q_00+105, 10, temp);
	gf2x_mul_5_avx(temp, q_00+765, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+765, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+100, 10, q_00+100, 10, temp);
	gf2x_mul_5_avx(temp, q_00+760, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+760, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+95, 10, q_00+95, 10, temp);
	gf2x_mul_5_avx(temp, q_00+755, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+755, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+90, 10, q_00+90, 10, temp);
	gf2x_mul_5_avx(temp, q_00+750, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+750, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+85, 10, q_00+85, 10, temp);
	gf2x_mul_5_avx(temp, q_00+745, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+745, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+80, 10, q_00+80, 10, temp);
	gf2x_mul_5_avx(temp, q_00+740, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+740, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+75, 10, q_00+75, 10, temp);
	gf2x_mul_5_avx(temp, q_00+735, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+735, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+70, 10, q_00+70, 10, temp);
	gf2x_mul_5_avx(temp, q_00+730, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+730, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+65, 10, q_00+65, 10, temp);
	gf2x_mul_5_avx(temp, q_00+725, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+725, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+60, 10, q_00+60, 10, temp);
	gf2x_mul_5_avx(temp, q_00+720, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+720, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+55, 10, q_00+55, 10, temp);
	gf2x_mul_5_avx(temp, q_00+715, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+715, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+50, 10, q_00+50, 10, temp);
	gf2x_mul_5_avx(temp, q_00+710, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+710, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+45, 10, q_00+45, 10, temp);
	gf2x_mul_5_avx(temp, q_00+705, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+705, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+40, 10, q_00+40, 10, temp);
	gf2x_mul_5_avx(temp, q_00+700, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+700, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+35, 10, q_00+35, 10, temp);
	gf2x_mul_5_avx(temp, q_00+695, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+695, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+30, 10, q_00+30, 10, temp);
	gf2x_mul_5_avx(temp, q_00+690, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+690, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+25, 10, q_00+25, 10, temp);
	gf2x_mul_5_avx(temp, q_00+685, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+685, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+20, 10, q_00+20, 10, temp);
	gf2x_mul_5_avx(temp, q_00+680, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+680, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+15, 10, q_00+15, 10, temp);
	gf2x_mul_5_avx(temp, q_00+675, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+675, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+10, 10, q_00+10, 10, temp);
	gf2x_mul_5_avx(temp, q_00+670, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+670, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+5, 10, q_00+5, 10, temp);
	gf2x_mul_5_avx(temp, q_00+665, p_00+670);
	gf2x_mul_5_avx(temp2, q_01+665, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_00+0, 10, q_00+0, 10, temp);
	memset(q_01+0, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(660, temp, 330, p_01+675, 330, q_00+665);
	GF2X_MUL(660, temp2, 330, p_11+675, 330, q_01+665);
	gf2x_add(660, q_01+5, 660, temp, 660, temp2);
	gf2x_mul_5_avx(temp, q_00+990, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+990, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+325, 10, q_01+325, 10, temp);
	gf2x_mul_5_avx(temp, q_00+985, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+985, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+320, 10, q_01+320, 10, temp);
	gf2x_mul_5_avx(temp, q_00+980, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+980, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+315, 10, q_01+315, 10, temp);
	gf2x_mul_5_avx(temp, q_00+975, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+975, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+310, 10, q_01+310, 10, temp);
	gf2x_mul_5_avx(temp, q_00+970, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+970, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+305, 10, q_01+305, 10, temp);
	gf2x_mul_5_avx(temp, q_00+965, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+965, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+300, 10, q_01+300, 10, temp);
	gf2x_mul_5_avx(temp, q_00+960, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+960, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+295, 10, q_01+295, 10, temp);
	gf2x_mul_5_avx(temp, q_00+955, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+955, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+290, 10, q_01+290, 10, temp);
	gf2x_mul_5_avx(temp, q_00+950, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+950, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+285, 10, q_01+285, 10, temp);
	gf2x_mul_5_avx(temp, q_00+945, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+945, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+280, 10, q_01+280, 10, temp);
	gf2x_mul_5_avx(temp, q_00+940, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+940, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+275, 10, q_01+275, 10, temp);
	gf2x_mul_5_avx(temp, q_00+935, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+935, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+270, 10, q_01+270, 10, temp);
	gf2x_mul_5_avx(temp, q_00+930, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+930, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+265, 10, q_01+265, 10, temp);
	gf2x_mul_5_avx(temp, q_00+925, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+925, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+260, 10, q_01+260, 10, temp);
	gf2x_mul_5_avx(temp, q_00+920, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+920, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+255, 10, q_01+255, 10, temp);
	gf2x_mul_5_avx(temp, q_00+915, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+915, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+250, 10, q_01+250, 10, temp);
	gf2x_mul_5_avx(temp, q_00+910, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+910, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+245, 10, q_01+245, 10, temp);
	gf2x_mul_5_avx(temp, q_00+905, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+905, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+240, 10, q_01+240, 10, temp);
	gf2x_mul_5_avx(temp, q_00+900, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+900, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+235, 10, q_01+235, 10, temp);
	gf2x_mul_5_avx(temp, q_00+895, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+895, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+230, 10, q_01+230, 10, temp);
	gf2x_mul_5_avx(temp, q_00+890, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+890, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+225, 10, q_01+225, 10, temp);
	gf2x_mul_5_avx(temp, q_00+885, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+885, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+220, 10, q_01+220, 10, temp);
	gf2x_mul_5_avx(temp, q_00+880, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+880, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+215, 10, q_01+215, 10, temp);
	gf2x_mul_5_avx(temp, q_00+875, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+875, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+210, 10, q_01+210, 10, temp);
	gf2x_mul_5_avx(temp, q_00+870, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+870, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+205, 10, q_01+205, 10, temp);
	gf2x_mul_5_avx(temp, q_00+865, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+865, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+200, 10, q_01+200, 10, temp);
	gf2x_mul_5_avx(temp, q_00+860, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+860, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+195, 10, q_01+195, 10, temp);
	gf2x_mul_5_avx(temp, q_00+855, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+855, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+190, 10, q_01+190, 10, temp);
	gf2x_mul_5_avx(temp, q_00+850, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+850, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+185, 10, q_01+185, 10, temp);
	gf2x_mul_5_avx(temp, q_00+845, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+845, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+180, 10, q_01+180, 10, temp);
	gf2x_mul_5_avx(temp, q_00+840, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+840, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+175, 10, q_01+175, 10, temp);
	gf2x_mul_5_avx(temp, q_00+835, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+835, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+170, 10, q_01+170, 10, temp);
	gf2x_mul_5_avx(temp, q_00+830, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+830, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+165, 10, q_01+165, 10, temp);
	gf2x_mul_5_avx(temp, q_00+825, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+825, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+160, 10, q_01+160, 10, temp);
	gf2x_mul_5_avx(temp, q_00+820, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+820, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+155, 10, q_01+155, 10, temp);
	gf2x_mul_5_avx(temp, q_00+815, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+815, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+150, 10, q_01+150, 10, temp);
	gf2x_mul_5_avx(temp, q_00+810, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+810, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+145, 10, q_01+145, 10, temp);
	gf2x_mul_5_avx(temp, q_00+805, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+805, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+140, 10, q_01+140, 10, temp);
	gf2x_mul_5_avx(temp, q_00+800, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+800, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+135, 10, q_01+135, 10, temp);
	gf2x_mul_5_avx(temp, q_00+795, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+795, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+130, 10, q_01+130, 10, temp);
	gf2x_mul_5_avx(temp, q_00+790, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+790, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+125, 10, q_01+125, 10, temp);
	gf2x_mul_5_avx(temp, q_00+785, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+785, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+120, 10, q_01+120, 10, temp);
	gf2x_mul_5_avx(temp, q_00+780, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+780, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+115, 10, q_01+115, 10, temp);
	gf2x_mul_5_avx(temp, q_00+775, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+775, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+110, 10, q_01+110, 10, temp);
	gf2x_mul_5_avx(temp, q_00+770, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+770, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+105, 10, q_01+105, 10, temp);
	gf2x_mul_5_avx(temp, q_00+765, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+765, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+100, 10, q_01+100, 10, temp);
	gf2x_mul_5_avx(temp, q_00+760, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+760, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+95, 10, q_01+95, 10, temp);
	gf2x_mul_5_avx(temp, q_00+755, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+755, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+90, 10, q_01+90, 10, temp);
	gf2x_mul_5_avx(temp, q_00+750, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+750, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+85, 10, q_01+85, 10, temp);
	gf2x_mul_5_avx(temp, q_00+745, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+745, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+80, 10, q_01+80, 10, temp);
	gf2x_mul_5_avx(temp, q_00+740, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+740, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+75, 10, q_01+75, 10, temp);
	gf2x_mul_5_avx(temp, q_00+735, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+735, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+70, 10, q_01+70, 10, temp);
	gf2x_mul_5_avx(temp, q_00+730, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+730, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+65, 10, q_01+65, 10, temp);
	gf2x_mul_5_avx(temp, q_00+725, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+725, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+60, 10, q_01+60, 10, temp);
	gf2x_mul_5_avx(temp, q_00+720, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+720, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+55, 10, q_01+55, 10, temp);
	gf2x_mul_5_avx(temp, q_00+715, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+715, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+50, 10, q_01+50, 10, temp);
	gf2x_mul_5_avx(temp, q_00+710, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+710, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+45, 10, q_01+45, 10, temp);
	gf2x_mul_5_avx(temp, q_00+705, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+705, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+40, 10, q_01+40, 10, temp);
	gf2x_mul_5_avx(temp, q_00+700, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+700, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+35, 10, q_01+35, 10, temp);
	gf2x_mul_5_avx(temp, q_00+695, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+695, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+30, 10, q_01+30, 10, temp);
	gf2x_mul_5_avx(temp, q_00+690, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+690, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+25, 10, q_01+25, 10, temp);
	gf2x_mul_5_avx(temp, q_00+685, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+685, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+20, 10, q_01+20, 10, temp);
	gf2x_mul_5_avx(temp, q_00+680, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+680, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+15, 10, q_01+15, 10, temp);
	gf2x_mul_5_avx(temp, q_00+675, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+675, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+10, 10, q_01+10, 10, temp);
	gf2x_mul_5_avx(temp, q_00+670, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+670, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+5, 10, q_01+5, 10, temp);
	gf2x_mul_5_avx(temp, q_00+665, p_01+670);
	gf2x_mul_5_avx(temp2, q_01+665, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_01+0, 10, q_01+0, 10, temp);
	memset(q_10+0, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(660, temp, 330, p_00+675, 330, q_10+665);
	GF2X_MUL(660, temp2, 330, p_10+675, 330, q_11+665);
	gf2x_add(660, q_10+5, 660, temp, 660, temp2);
	gf2x_mul_5_avx(temp, q_10+990, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+990, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+325, 10, q_10+325, 10, temp);
	gf2x_mul_5_avx(temp, q_10+985, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+985, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+320, 10, q_10+320, 10, temp);
	gf2x_mul_5_avx(temp, q_10+980, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+980, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+315, 10, q_10+315, 10, temp);
	gf2x_mul_5_avx(temp, q_10+975, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+975, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+310, 10, q_10+310, 10, temp);
	gf2x_mul_5_avx(temp, q_10+970, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+970, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+305, 10, q_10+305, 10, temp);
	gf2x_mul_5_avx(temp, q_10+965, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+965, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+300, 10, q_10+300, 10, temp);
	gf2x_mul_5_avx(temp, q_10+960, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+960, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+295, 10, q_10+295, 10, temp);
	gf2x_mul_5_avx(temp, q_10+955, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+955, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+290, 10, q_10+290, 10, temp);
	gf2x_mul_5_avx(temp, q_10+950, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+950, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+285, 10, q_10+285, 10, temp);
	gf2x_mul_5_avx(temp, q_10+945, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+945, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+280, 10, q_10+280, 10, temp);
	gf2x_mul_5_avx(temp, q_10+940, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+940, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+275, 10, q_10+275, 10, temp);
	gf2x_mul_5_avx(temp, q_10+935, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+935, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+270, 10, q_10+270, 10, temp);
	gf2x_mul_5_avx(temp, q_10+930, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+930, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+265, 10, q_10+265, 10, temp);
	gf2x_mul_5_avx(temp, q_10+925, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+925, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+260, 10, q_10+260, 10, temp);
	gf2x_mul_5_avx(temp, q_10+920, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+920, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+255, 10, q_10+255, 10, temp);
	gf2x_mul_5_avx(temp, q_10+915, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+915, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+250, 10, q_10+250, 10, temp);
	gf2x_mul_5_avx(temp, q_10+910, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+910, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+245, 10, q_10+245, 10, temp);
	gf2x_mul_5_avx(temp, q_10+905, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+905, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+240, 10, q_10+240, 10, temp);
	gf2x_mul_5_avx(temp, q_10+900, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+900, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+235, 10, q_10+235, 10, temp);
	gf2x_mul_5_avx(temp, q_10+895, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+895, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+230, 10, q_10+230, 10, temp);
	gf2x_mul_5_avx(temp, q_10+890, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+890, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+225, 10, q_10+225, 10, temp);
	gf2x_mul_5_avx(temp, q_10+885, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+885, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+220, 10, q_10+220, 10, temp);
	gf2x_mul_5_avx(temp, q_10+880, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+880, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+215, 10, q_10+215, 10, temp);
	gf2x_mul_5_avx(temp, q_10+875, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+875, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+210, 10, q_10+210, 10, temp);
	gf2x_mul_5_avx(temp, q_10+870, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+870, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+205, 10, q_10+205, 10, temp);
	gf2x_mul_5_avx(temp, q_10+865, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+865, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+200, 10, q_10+200, 10, temp);
	gf2x_mul_5_avx(temp, q_10+860, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+860, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+195, 10, q_10+195, 10, temp);
	gf2x_mul_5_avx(temp, q_10+855, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+855, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+190, 10, q_10+190, 10, temp);
	gf2x_mul_5_avx(temp, q_10+850, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+850, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+185, 10, q_10+185, 10, temp);
	gf2x_mul_5_avx(temp, q_10+845, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+845, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+180, 10, q_10+180, 10, temp);
	gf2x_mul_5_avx(temp, q_10+840, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+840, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+175, 10, q_10+175, 10, temp);
	gf2x_mul_5_avx(temp, q_10+835, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+835, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+170, 10, q_10+170, 10, temp);
	gf2x_mul_5_avx(temp, q_10+830, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+830, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+165, 10, q_10+165, 10, temp);
	gf2x_mul_5_avx(temp, q_10+825, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+825, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+160, 10, q_10+160, 10, temp);
	gf2x_mul_5_avx(temp, q_10+820, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+820, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+155, 10, q_10+155, 10, temp);
	gf2x_mul_5_avx(temp, q_10+815, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+815, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+150, 10, q_10+150, 10, temp);
	gf2x_mul_5_avx(temp, q_10+810, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+810, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+145, 10, q_10+145, 10, temp);
	gf2x_mul_5_avx(temp, q_10+805, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+805, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+140, 10, q_10+140, 10, temp);
	gf2x_mul_5_avx(temp, q_10+800, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+800, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+135, 10, q_10+135, 10, temp);
	gf2x_mul_5_avx(temp, q_10+795, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+795, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+130, 10, q_10+130, 10, temp);
	gf2x_mul_5_avx(temp, q_10+790, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+790, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+125, 10, q_10+125, 10, temp);
	gf2x_mul_5_avx(temp, q_10+785, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+785, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+120, 10, q_10+120, 10, temp);
	gf2x_mul_5_avx(temp, q_10+780, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+780, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+115, 10, q_10+115, 10, temp);
	gf2x_mul_5_avx(temp, q_10+775, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+775, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+110, 10, q_10+110, 10, temp);
	gf2x_mul_5_avx(temp, q_10+770, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+770, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+105, 10, q_10+105, 10, temp);
	gf2x_mul_5_avx(temp, q_10+765, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+765, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+100, 10, q_10+100, 10, temp);
	gf2x_mul_5_avx(temp, q_10+760, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+760, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+95, 10, q_10+95, 10, temp);
	gf2x_mul_5_avx(temp, q_10+755, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+755, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+90, 10, q_10+90, 10, temp);
	gf2x_mul_5_avx(temp, q_10+750, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+750, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+85, 10, q_10+85, 10, temp);
	gf2x_mul_5_avx(temp, q_10+745, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+745, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+80, 10, q_10+80, 10, temp);
	gf2x_mul_5_avx(temp, q_10+740, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+740, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+75, 10, q_10+75, 10, temp);
	gf2x_mul_5_avx(temp, q_10+735, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+735, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+70, 10, q_10+70, 10, temp);
	gf2x_mul_5_avx(temp, q_10+730, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+730, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+65, 10, q_10+65, 10, temp);
	gf2x_mul_5_avx(temp, q_10+725, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+725, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+60, 10, q_10+60, 10, temp);
	gf2x_mul_5_avx(temp, q_10+720, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+720, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+55, 10, q_10+55, 10, temp);
	gf2x_mul_5_avx(temp, q_10+715, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+715, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+50, 10, q_10+50, 10, temp);
	gf2x_mul_5_avx(temp, q_10+710, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+710, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+45, 10, q_10+45, 10, temp);
	gf2x_mul_5_avx(temp, q_10+705, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+705, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+40, 10, q_10+40, 10, temp);
	gf2x_mul_5_avx(temp, q_10+700, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+700, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+35, 10, q_10+35, 10, temp);
	gf2x_mul_5_avx(temp, q_10+695, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+695, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+30, 10, q_10+30, 10, temp);
	gf2x_mul_5_avx(temp, q_10+690, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+690, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+25, 10, q_10+25, 10, temp);
	gf2x_mul_5_avx(temp, q_10+685, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+685, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+20, 10, q_10+20, 10, temp);
	gf2x_mul_5_avx(temp, q_10+680, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+680, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+15, 10, q_10+15, 10, temp);
	gf2x_mul_5_avx(temp, q_10+675, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+675, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+10, 10, q_10+10, 10, temp);
	gf2x_mul_5_avx(temp, q_10+670, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+670, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+5, 10, q_10+5, 10, temp);
	gf2x_mul_5_avx(temp, q_10+665, p_00+670);
	gf2x_mul_5_avx(temp2, q_11+665, p_10+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_10+0, 10, q_10+0, 10, temp);
	memset(q_11+0, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(660, temp, 330, p_01+675, 330, q_10+665);
	GF2X_MUL(660, temp2, 330, p_11+675, 330, q_11+665);
	gf2x_add(660, q_11+5, 660, temp, 660, temp2);
	gf2x_mul_5_avx(temp, q_10+990, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+990, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+325, 10, q_11+325, 10, temp);
	gf2x_mul_5_avx(temp, q_10+985, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+985, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+320, 10, q_11+320, 10, temp);
	gf2x_mul_5_avx(temp, q_10+980, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+980, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+315, 10, q_11+315, 10, temp);
	gf2x_mul_5_avx(temp, q_10+975, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+975, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+310, 10, q_11+310, 10, temp);
	gf2x_mul_5_avx(temp, q_10+970, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+970, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+305, 10, q_11+305, 10, temp);
	gf2x_mul_5_avx(temp, q_10+965, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+965, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+300, 10, q_11+300, 10, temp);
	gf2x_mul_5_avx(temp, q_10+960, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+960, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+295, 10, q_11+295, 10, temp);
	gf2x_mul_5_avx(temp, q_10+955, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+955, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+290, 10, q_11+290, 10, temp);
	gf2x_mul_5_avx(temp, q_10+950, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+950, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+285, 10, q_11+285, 10, temp);
	gf2x_mul_5_avx(temp, q_10+945, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+945, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+280, 10, q_11+280, 10, temp);
	gf2x_mul_5_avx(temp, q_10+940, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+940, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+275, 10, q_11+275, 10, temp);
	gf2x_mul_5_avx(temp, q_10+935, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+935, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+270, 10, q_11+270, 10, temp);
	gf2x_mul_5_avx(temp, q_10+930, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+930, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+265, 10, q_11+265, 10, temp);
	gf2x_mul_5_avx(temp, q_10+925, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+925, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+260, 10, q_11+260, 10, temp);
	gf2x_mul_5_avx(temp, q_10+920, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+920, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+255, 10, q_11+255, 10, temp);
	gf2x_mul_5_avx(temp, q_10+915, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+915, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+250, 10, q_11+250, 10, temp);
	gf2x_mul_5_avx(temp, q_10+910, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+910, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+245, 10, q_11+245, 10, temp);
	gf2x_mul_5_avx(temp, q_10+905, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+905, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+240, 10, q_11+240, 10, temp);
	gf2x_mul_5_avx(temp, q_10+900, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+900, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+235, 10, q_11+235, 10, temp);
	gf2x_mul_5_avx(temp, q_10+895, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+895, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+230, 10, q_11+230, 10, temp);
	gf2x_mul_5_avx(temp, q_10+890, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+890, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+225, 10, q_11+225, 10, temp);
	gf2x_mul_5_avx(temp, q_10+885, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+885, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+220, 10, q_11+220, 10, temp);
	gf2x_mul_5_avx(temp, q_10+880, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+880, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+215, 10, q_11+215, 10, temp);
	gf2x_mul_5_avx(temp, q_10+875, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+875, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+210, 10, q_11+210, 10, temp);
	gf2x_mul_5_avx(temp, q_10+870, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+870, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+205, 10, q_11+205, 10, temp);
	gf2x_mul_5_avx(temp, q_10+865, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+865, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+200, 10, q_11+200, 10, temp);
	gf2x_mul_5_avx(temp, q_10+860, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+860, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+195, 10, q_11+195, 10, temp);
	gf2x_mul_5_avx(temp, q_10+855, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+855, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+190, 10, q_11+190, 10, temp);
	gf2x_mul_5_avx(temp, q_10+850, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+850, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+185, 10, q_11+185, 10, temp);
	gf2x_mul_5_avx(temp, q_10+845, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+845, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+180, 10, q_11+180, 10, temp);
	gf2x_mul_5_avx(temp, q_10+840, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+840, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+175, 10, q_11+175, 10, temp);
	gf2x_mul_5_avx(temp, q_10+835, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+835, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+170, 10, q_11+170, 10, temp);
	gf2x_mul_5_avx(temp, q_10+830, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+830, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+165, 10, q_11+165, 10, temp);
	gf2x_mul_5_avx(temp, q_10+825, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+825, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+160, 10, q_11+160, 10, temp);
	gf2x_mul_5_avx(temp, q_10+820, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+820, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+155, 10, q_11+155, 10, temp);
	gf2x_mul_5_avx(temp, q_10+815, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+815, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+150, 10, q_11+150, 10, temp);
	gf2x_mul_5_avx(temp, q_10+810, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+810, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+145, 10, q_11+145, 10, temp);
	gf2x_mul_5_avx(temp, q_10+805, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+805, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+140, 10, q_11+140, 10, temp);
	gf2x_mul_5_avx(temp, q_10+800, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+800, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+135, 10, q_11+135, 10, temp);
	gf2x_mul_5_avx(temp, q_10+795, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+795, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+130, 10, q_11+130, 10, temp);
	gf2x_mul_5_avx(temp, q_10+790, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+790, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+125, 10, q_11+125, 10, temp);
	gf2x_mul_5_avx(temp, q_10+785, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+785, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+120, 10, q_11+120, 10, temp);
	gf2x_mul_5_avx(temp, q_10+780, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+780, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+115, 10, q_11+115, 10, temp);
	gf2x_mul_5_avx(temp, q_10+775, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+775, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+110, 10, q_11+110, 10, temp);
	gf2x_mul_5_avx(temp, q_10+770, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+770, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+105, 10, q_11+105, 10, temp);
	gf2x_mul_5_avx(temp, q_10+765, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+765, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+100, 10, q_11+100, 10, temp);
	gf2x_mul_5_avx(temp, q_10+760, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+760, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+95, 10, q_11+95, 10, temp);
	gf2x_mul_5_avx(temp, q_10+755, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+755, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+90, 10, q_11+90, 10, temp);
	gf2x_mul_5_avx(temp, q_10+750, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+750, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+85, 10, q_11+85, 10, temp);
	gf2x_mul_5_avx(temp, q_10+745, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+745, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+80, 10, q_11+80, 10, temp);
	gf2x_mul_5_avx(temp, q_10+740, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+740, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+75, 10, q_11+75, 10, temp);
	gf2x_mul_5_avx(temp, q_10+735, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+735, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+70, 10, q_11+70, 10, temp);
	gf2x_mul_5_avx(temp, q_10+730, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+730, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+65, 10, q_11+65, 10, temp);
	gf2x_mul_5_avx(temp, q_10+725, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+725, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+60, 10, q_11+60, 10, temp);
	gf2x_mul_5_avx(temp, q_10+720, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+720, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+55, 10, q_11+55, 10, temp);
	gf2x_mul_5_avx(temp, q_10+715, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+715, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+50, 10, q_11+50, 10, temp);
	gf2x_mul_5_avx(temp, q_10+710, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+710, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+45, 10, q_11+45, 10, temp);
	gf2x_mul_5_avx(temp, q_10+705, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+705, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+40, 10, q_11+40, 10, temp);
	gf2x_mul_5_avx(temp, q_10+700, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+700, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+35, 10, q_11+35, 10, temp);
	gf2x_mul_5_avx(temp, q_10+695, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+695, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+30, 10, q_11+30, 10, temp);
	gf2x_mul_5_avx(temp, q_10+690, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+690, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+25, 10, q_11+25, 10, temp);
	gf2x_mul_5_avx(temp, q_10+685, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+685, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+20, 10, q_11+20, 10, temp);
	gf2x_mul_5_avx(temp, q_10+680, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+680, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+15, 10, q_11+15, 10, temp);
	gf2x_mul_5_avx(temp, q_10+675, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+675, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+10, 10, q_11+10, 10, temp);
	gf2x_mul_5_avx(temp, q_10+670, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+670, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+5, 10, q_11+5, 10, temp);
	gf2x_mul_5_avx(temp, q_10+665, p_01+670);
	gf2x_mul_5_avx(temp2, q_11+665, p_11+670);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, q_11+0, 10, q_11+0, 10, temp);
	
	// Recombining results: n: 85353, depth: 0
	memset(t_00+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(1330, temp, 665, p_00+5, 665, q_00+0);
	GF2X_MUL(1330, temp2, 665, p_10+5, 665, q_01+0);
	gf2x_add(1330, t_00+4, 1330, temp, 1330, temp2);
	gf2x_mul_5_avx(temp, q_00+660, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+660, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+659, 10, t_00+659, 10, temp);
	gf2x_mul_5_avx(temp, q_00+655, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+655, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+654, 10, t_00+654, 10, temp);
	gf2x_mul_5_avx(temp, q_00+650, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+650, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+649, 10, t_00+649, 10, temp);
	gf2x_mul_5_avx(temp, q_00+645, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+645, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+644, 10, t_00+644, 10, temp);
	gf2x_mul_5_avx(temp, q_00+640, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+640, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+639, 10, t_00+639, 10, temp);
	gf2x_mul_5_avx(temp, q_00+635, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+635, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+634, 10, t_00+634, 10, temp);
	gf2x_mul_5_avx(temp, q_00+630, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+630, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+629, 10, t_00+629, 10, temp);
	gf2x_mul_5_avx(temp, q_00+625, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+625, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+624, 10, t_00+624, 10, temp);
	gf2x_mul_5_avx(temp, q_00+620, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+620, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+619, 10, t_00+619, 10, temp);
	gf2x_mul_5_avx(temp, q_00+615, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+615, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+614, 10, t_00+614, 10, temp);
	gf2x_mul_5_avx(temp, q_00+610, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+610, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+609, 10, t_00+609, 10, temp);
	gf2x_mul_5_avx(temp, q_00+605, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+605, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+604, 10, t_00+604, 10, temp);
	gf2x_mul_5_avx(temp, q_00+600, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+600, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+599, 10, t_00+599, 10, temp);
	gf2x_mul_5_avx(temp, q_00+595, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+595, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+594, 10, t_00+594, 10, temp);
	gf2x_mul_5_avx(temp, q_00+590, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+590, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+589, 10, t_00+589, 10, temp);
	gf2x_mul_5_avx(temp, q_00+585, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+585, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+584, 10, t_00+584, 10, temp);
	gf2x_mul_5_avx(temp, q_00+580, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+580, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+579, 10, t_00+579, 10, temp);
	gf2x_mul_5_avx(temp, q_00+575, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+575, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+574, 10, t_00+574, 10, temp);
	gf2x_mul_5_avx(temp, q_00+570, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+570, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+569, 10, t_00+569, 10, temp);
	gf2x_mul_5_avx(temp, q_00+565, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+565, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+564, 10, t_00+564, 10, temp);
	gf2x_mul_5_avx(temp, q_00+560, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+560, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+559, 10, t_00+559, 10, temp);
	gf2x_mul_5_avx(temp, q_00+555, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+555, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+554, 10, t_00+554, 10, temp);
	gf2x_mul_5_avx(temp, q_00+550, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+550, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+549, 10, t_00+549, 10, temp);
	gf2x_mul_5_avx(temp, q_00+545, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+545, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+544, 10, t_00+544, 10, temp);
	gf2x_mul_5_avx(temp, q_00+540, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+540, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+539, 10, t_00+539, 10, temp);
	gf2x_mul_5_avx(temp, q_00+535, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+535, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+534, 10, t_00+534, 10, temp);
	gf2x_mul_5_avx(temp, q_00+530, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+530, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+529, 10, t_00+529, 10, temp);
	gf2x_mul_5_avx(temp, q_00+525, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+525, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+524, 10, t_00+524, 10, temp);
	gf2x_mul_5_avx(temp, q_00+520, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+520, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+519, 10, t_00+519, 10, temp);
	gf2x_mul_5_avx(temp, q_00+515, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+515, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+514, 10, t_00+514, 10, temp);
	gf2x_mul_5_avx(temp, q_00+510, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+510, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+509, 10, t_00+509, 10, temp);
	gf2x_mul_5_avx(temp, q_00+505, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+505, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+504, 10, t_00+504, 10, temp);
	gf2x_mul_5_avx(temp, q_00+500, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+500, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+499, 10, t_00+499, 10, temp);
	gf2x_mul_5_avx(temp, q_00+495, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+495, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+494, 10, t_00+494, 10, temp);
	gf2x_mul_5_avx(temp, q_00+490, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+490, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+489, 10, t_00+489, 10, temp);
	gf2x_mul_5_avx(temp, q_00+485, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+485, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+484, 10, t_00+484, 10, temp);
	gf2x_mul_5_avx(temp, q_00+480, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+480, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+479, 10, t_00+479, 10, temp);
	gf2x_mul_5_avx(temp, q_00+475, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+475, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+474, 10, t_00+474, 10, temp);
	gf2x_mul_5_avx(temp, q_00+470, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+470, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+469, 10, t_00+469, 10, temp);
	gf2x_mul_5_avx(temp, q_00+465, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+465, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+464, 10, t_00+464, 10, temp);
	gf2x_mul_5_avx(temp, q_00+460, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+460, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+459, 10, t_00+459, 10, temp);
	gf2x_mul_5_avx(temp, q_00+455, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+455, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+454, 10, t_00+454, 10, temp);
	gf2x_mul_5_avx(temp, q_00+450, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+450, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+449, 10, t_00+449, 10, temp);
	gf2x_mul_5_avx(temp, q_00+445, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+445, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+444, 10, t_00+444, 10, temp);
	gf2x_mul_5_avx(temp, q_00+440, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+440, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+439, 10, t_00+439, 10, temp);
	gf2x_mul_5_avx(temp, q_00+435, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+435, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+434, 10, t_00+434, 10, temp);
	gf2x_mul_5_avx(temp, q_00+430, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+430, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+429, 10, t_00+429, 10, temp);
	gf2x_mul_5_avx(temp, q_00+425, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+425, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+424, 10, t_00+424, 10, temp);
	gf2x_mul_5_avx(temp, q_00+420, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+420, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+419, 10, t_00+419, 10, temp);
	gf2x_mul_5_avx(temp, q_00+415, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+415, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+414, 10, t_00+414, 10, temp);
	gf2x_mul_5_avx(temp, q_00+410, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+410, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+409, 10, t_00+409, 10, temp);
	gf2x_mul_5_avx(temp, q_00+405, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+405, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+404, 10, t_00+404, 10, temp);
	gf2x_mul_5_avx(temp, q_00+400, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+400, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+399, 10, t_00+399, 10, temp);
	gf2x_mul_5_avx(temp, q_00+395, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+395, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+394, 10, t_00+394, 10, temp);
	gf2x_mul_5_avx(temp, q_00+390, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+390, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+389, 10, t_00+389, 10, temp);
	gf2x_mul_5_avx(temp, q_00+385, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+385, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+384, 10, t_00+384, 10, temp);
	gf2x_mul_5_avx(temp, q_00+380, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+380, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+379, 10, t_00+379, 10, temp);
	gf2x_mul_5_avx(temp, q_00+375, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+375, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+374, 10, t_00+374, 10, temp);
	gf2x_mul_5_avx(temp, q_00+370, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+370, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+369, 10, t_00+369, 10, temp);
	gf2x_mul_5_avx(temp, q_00+365, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+365, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+364, 10, t_00+364, 10, temp);
	gf2x_mul_5_avx(temp, q_00+360, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+360, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+359, 10, t_00+359, 10, temp);
	gf2x_mul_5_avx(temp, q_00+355, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+355, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+354, 10, t_00+354, 10, temp);
	gf2x_mul_5_avx(temp, q_00+350, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+350, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+349, 10, t_00+349, 10, temp);
	gf2x_mul_5_avx(temp, q_00+345, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+345, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+344, 10, t_00+344, 10, temp);
	gf2x_mul_5_avx(temp, q_00+340, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+340, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+339, 10, t_00+339, 10, temp);
	gf2x_mul_5_avx(temp, q_00+335, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+335, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+334, 10, t_00+334, 10, temp);
	gf2x_mul_5_avx(temp, q_00+330, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+330, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+329, 10, t_00+329, 10, temp);
	gf2x_mul_5_avx(temp, q_00+325, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+325, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+324, 10, t_00+324, 10, temp);
	gf2x_mul_5_avx(temp, q_00+320, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+320, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+319, 10, t_00+319, 10, temp);
	gf2x_mul_5_avx(temp, q_00+315, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+315, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+314, 10, t_00+314, 10, temp);
	gf2x_mul_5_avx(temp, q_00+310, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+310, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+309, 10, t_00+309, 10, temp);
	gf2x_mul_5_avx(temp, q_00+305, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+305, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+304, 10, t_00+304, 10, temp);
	gf2x_mul_5_avx(temp, q_00+300, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+300, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+299, 10, t_00+299, 10, temp);
	gf2x_mul_5_avx(temp, q_00+295, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+295, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+294, 10, t_00+294, 10, temp);
	gf2x_mul_5_avx(temp, q_00+290, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+290, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+289, 10, t_00+289, 10, temp);
	gf2x_mul_5_avx(temp, q_00+285, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+285, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+284, 10, t_00+284, 10, temp);
	gf2x_mul_5_avx(temp, q_00+280, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+280, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+279, 10, t_00+279, 10, temp);
	gf2x_mul_5_avx(temp, q_00+275, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+275, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+274, 10, t_00+274, 10, temp);
	gf2x_mul_5_avx(temp, q_00+270, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+270, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+269, 10, t_00+269, 10, temp);
	gf2x_mul_5_avx(temp, q_00+265, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+265, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+264, 10, t_00+264, 10, temp);
	gf2x_mul_5_avx(temp, q_00+260, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+260, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+259, 10, t_00+259, 10, temp);
	gf2x_mul_5_avx(temp, q_00+255, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+255, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+254, 10, t_00+254, 10, temp);
	gf2x_mul_5_avx(temp, q_00+250, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+250, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+249, 10, t_00+249, 10, temp);
	gf2x_mul_5_avx(temp, q_00+245, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+245, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+244, 10, t_00+244, 10, temp);
	gf2x_mul_5_avx(temp, q_00+240, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+240, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+239, 10, t_00+239, 10, temp);
	gf2x_mul_5_avx(temp, q_00+235, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+235, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+234, 10, t_00+234, 10, temp);
	gf2x_mul_5_avx(temp, q_00+230, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+230, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+229, 10, t_00+229, 10, temp);
	gf2x_mul_5_avx(temp, q_00+225, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+225, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+224, 10, t_00+224, 10, temp);
	gf2x_mul_5_avx(temp, q_00+220, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+220, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+219, 10, t_00+219, 10, temp);
	gf2x_mul_5_avx(temp, q_00+215, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+215, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+214, 10, t_00+214, 10, temp);
	gf2x_mul_5_avx(temp, q_00+210, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+210, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+209, 10, t_00+209, 10, temp);
	gf2x_mul_5_avx(temp, q_00+205, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+205, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+204, 10, t_00+204, 10, temp);
	gf2x_mul_5_avx(temp, q_00+200, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+200, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+199, 10, t_00+199, 10, temp);
	gf2x_mul_5_avx(temp, q_00+195, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+195, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+194, 10, t_00+194, 10, temp);
	gf2x_mul_5_avx(temp, q_00+190, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+190, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+189, 10, t_00+189, 10, temp);
	gf2x_mul_5_avx(temp, q_00+185, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+185, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+184, 10, t_00+184, 10, temp);
	gf2x_mul_5_avx(temp, q_00+180, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+180, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+179, 10, t_00+179, 10, temp);
	gf2x_mul_5_avx(temp, q_00+175, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+175, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+174, 10, t_00+174, 10, temp);
	gf2x_mul_5_avx(temp, q_00+170, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+170, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+169, 10, t_00+169, 10, temp);
	gf2x_mul_5_avx(temp, q_00+165, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+165, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+164, 10, t_00+164, 10, temp);
	gf2x_mul_5_avx(temp, q_00+160, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+160, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+159, 10, t_00+159, 10, temp);
	gf2x_mul_5_avx(temp, q_00+155, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+155, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+154, 10, t_00+154, 10, temp);
	gf2x_mul_5_avx(temp, q_00+150, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+150, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+149, 10, t_00+149, 10, temp);
	gf2x_mul_5_avx(temp, q_00+145, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+145, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+144, 10, t_00+144, 10, temp);
	gf2x_mul_5_avx(temp, q_00+140, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+140, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+139, 10, t_00+139, 10, temp);
	gf2x_mul_5_avx(temp, q_00+135, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+135, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+134, 10, t_00+134, 10, temp);
	gf2x_mul_5_avx(temp, q_00+130, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+130, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+129, 10, t_00+129, 10, temp);
	gf2x_mul_5_avx(temp, q_00+125, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+125, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+124, 10, t_00+124, 10, temp);
	gf2x_mul_5_avx(temp, q_00+120, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+120, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+119, 10, t_00+119, 10, temp);
	gf2x_mul_5_avx(temp, q_00+115, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+115, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+114, 10, t_00+114, 10, temp);
	gf2x_mul_5_avx(temp, q_00+110, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+110, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+109, 10, t_00+109, 10, temp);
	gf2x_mul_5_avx(temp, q_00+105, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+105, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+104, 10, t_00+104, 10, temp);
	gf2x_mul_5_avx(temp, q_00+100, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+100, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+99, 10, t_00+99, 10, temp);
	gf2x_mul_5_avx(temp, q_00+95, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+95, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+94, 10, t_00+94, 10, temp);
	gf2x_mul_5_avx(temp, q_00+90, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+90, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+89, 10, t_00+89, 10, temp);
	gf2x_mul_5_avx(temp, q_00+85, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+85, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+84, 10, t_00+84, 10, temp);
	gf2x_mul_5_avx(temp, q_00+80, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+80, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+79, 10, t_00+79, 10, temp);
	gf2x_mul_5_avx(temp, q_00+75, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+75, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+74, 10, t_00+74, 10, temp);
	gf2x_mul_5_avx(temp, q_00+70, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+70, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+69, 10, t_00+69, 10, temp);
	gf2x_mul_5_avx(temp, q_00+65, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+65, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+64, 10, t_00+64, 10, temp);
	gf2x_mul_5_avx(temp, q_00+60, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+60, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+59, 10, t_00+59, 10, temp);
	gf2x_mul_5_avx(temp, q_00+55, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+55, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+54, 10, t_00+54, 10, temp);
	gf2x_mul_5_avx(temp, q_00+50, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+50, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+49, 10, t_00+49, 10, temp);
	gf2x_mul_5_avx(temp, q_00+45, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+45, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+44, 10, t_00+44, 10, temp);
	gf2x_mul_5_avx(temp, q_00+40, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+40, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+39, 10, t_00+39, 10, temp);
	gf2x_mul_5_avx(temp, q_00+35, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+35, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+34, 10, t_00+34, 10, temp);
	gf2x_mul_5_avx(temp, q_00+30, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+30, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+29, 10, t_00+29, 10, temp);
	gf2x_mul_5_avx(temp, q_00+25, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+25, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+24, 10, t_00+24, 10, temp);
	gf2x_mul_5_avx(temp, q_00+20, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+20, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+19, 10, t_00+19, 10, temp);
	gf2x_mul_5_avx(temp, q_00+15, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+15, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+14, 10, t_00+14, 10, temp);
	gf2x_mul_5_avx(temp, q_00+10, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+10, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+9, 10, t_00+9, 10, temp);
	gf2x_mul_5_avx(temp, q_00+5, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+5, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_00+4, 10, t_00+4, 10, temp);
	gf2x_mul_5_avx(temp, q_00+0, p_00+0);
	gf2x_mul_5_avx(temp2, q_01+0, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(9, t_00+0, 9, t_00+0, 9, temp+1);
	memset(t_01+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(1330, temp, 665, p_01+5, 665, q_00+0);
	GF2X_MUL(1330, temp2, 665, p_11+5, 665, q_01+0);
	gf2x_add(1330, t_01+4, 1330, temp, 1330, temp2);
	gf2x_mul_5_avx(temp, q_00+660, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+660, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+659, 10, t_01+659, 10, temp);
	gf2x_mul_5_avx(temp, q_00+655, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+655, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+654, 10, t_01+654, 10, temp);
	gf2x_mul_5_avx(temp, q_00+650, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+650, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+649, 10, t_01+649, 10, temp);
	gf2x_mul_5_avx(temp, q_00+645, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+645, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+644, 10, t_01+644, 10, temp);
	gf2x_mul_5_avx(temp, q_00+640, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+640, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+639, 10, t_01+639, 10, temp);
	gf2x_mul_5_avx(temp, q_00+635, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+635, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+634, 10, t_01+634, 10, temp);
	gf2x_mul_5_avx(temp, q_00+630, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+630, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+629, 10, t_01+629, 10, temp);
	gf2x_mul_5_avx(temp, q_00+625, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+625, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+624, 10, t_01+624, 10, temp);
	gf2x_mul_5_avx(temp, q_00+620, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+620, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+619, 10, t_01+619, 10, temp);
	gf2x_mul_5_avx(temp, q_00+615, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+615, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+614, 10, t_01+614, 10, temp);
	gf2x_mul_5_avx(temp, q_00+610, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+610, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+609, 10, t_01+609, 10, temp);
	gf2x_mul_5_avx(temp, q_00+605, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+605, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+604, 10, t_01+604, 10, temp);
	gf2x_mul_5_avx(temp, q_00+600, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+600, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+599, 10, t_01+599, 10, temp);
	gf2x_mul_5_avx(temp, q_00+595, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+595, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+594, 10, t_01+594, 10, temp);
	gf2x_mul_5_avx(temp, q_00+590, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+590, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+589, 10, t_01+589, 10, temp);
	gf2x_mul_5_avx(temp, q_00+585, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+585, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+584, 10, t_01+584, 10, temp);
	gf2x_mul_5_avx(temp, q_00+580, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+580, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+579, 10, t_01+579, 10, temp);
	gf2x_mul_5_avx(temp, q_00+575, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+575, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+574, 10, t_01+574, 10, temp);
	gf2x_mul_5_avx(temp, q_00+570, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+570, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+569, 10, t_01+569, 10, temp);
	gf2x_mul_5_avx(temp, q_00+565, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+565, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+564, 10, t_01+564, 10, temp);
	gf2x_mul_5_avx(temp, q_00+560, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+560, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+559, 10, t_01+559, 10, temp);
	gf2x_mul_5_avx(temp, q_00+555, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+555, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+554, 10, t_01+554, 10, temp);
	gf2x_mul_5_avx(temp, q_00+550, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+550, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+549, 10, t_01+549, 10, temp);
	gf2x_mul_5_avx(temp, q_00+545, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+545, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+544, 10, t_01+544, 10, temp);
	gf2x_mul_5_avx(temp, q_00+540, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+540, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+539, 10, t_01+539, 10, temp);
	gf2x_mul_5_avx(temp, q_00+535, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+535, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+534, 10, t_01+534, 10, temp);
	gf2x_mul_5_avx(temp, q_00+530, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+530, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+529, 10, t_01+529, 10, temp);
	gf2x_mul_5_avx(temp, q_00+525, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+525, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+524, 10, t_01+524, 10, temp);
	gf2x_mul_5_avx(temp, q_00+520, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+520, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+519, 10, t_01+519, 10, temp);
	gf2x_mul_5_avx(temp, q_00+515, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+515, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+514, 10, t_01+514, 10, temp);
	gf2x_mul_5_avx(temp, q_00+510, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+510, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+509, 10, t_01+509, 10, temp);
	gf2x_mul_5_avx(temp, q_00+505, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+505, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+504, 10, t_01+504, 10, temp);
	gf2x_mul_5_avx(temp, q_00+500, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+500, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+499, 10, t_01+499, 10, temp);
	gf2x_mul_5_avx(temp, q_00+495, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+495, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+494, 10, t_01+494, 10, temp);
	gf2x_mul_5_avx(temp, q_00+490, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+490, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+489, 10, t_01+489, 10, temp);
	gf2x_mul_5_avx(temp, q_00+485, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+485, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+484, 10, t_01+484, 10, temp);
	gf2x_mul_5_avx(temp, q_00+480, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+480, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+479, 10, t_01+479, 10, temp);
	gf2x_mul_5_avx(temp, q_00+475, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+475, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+474, 10, t_01+474, 10, temp);
	gf2x_mul_5_avx(temp, q_00+470, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+470, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+469, 10, t_01+469, 10, temp);
	gf2x_mul_5_avx(temp, q_00+465, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+465, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+464, 10, t_01+464, 10, temp);
	gf2x_mul_5_avx(temp, q_00+460, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+460, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+459, 10, t_01+459, 10, temp);
	gf2x_mul_5_avx(temp, q_00+455, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+455, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+454, 10, t_01+454, 10, temp);
	gf2x_mul_5_avx(temp, q_00+450, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+450, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+449, 10, t_01+449, 10, temp);
	gf2x_mul_5_avx(temp, q_00+445, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+445, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+444, 10, t_01+444, 10, temp);
	gf2x_mul_5_avx(temp, q_00+440, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+440, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+439, 10, t_01+439, 10, temp);
	gf2x_mul_5_avx(temp, q_00+435, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+435, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+434, 10, t_01+434, 10, temp);
	gf2x_mul_5_avx(temp, q_00+430, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+430, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+429, 10, t_01+429, 10, temp);
	gf2x_mul_5_avx(temp, q_00+425, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+425, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+424, 10, t_01+424, 10, temp);
	gf2x_mul_5_avx(temp, q_00+420, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+420, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+419, 10, t_01+419, 10, temp);
	gf2x_mul_5_avx(temp, q_00+415, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+415, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+414, 10, t_01+414, 10, temp);
	gf2x_mul_5_avx(temp, q_00+410, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+410, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+409, 10, t_01+409, 10, temp);
	gf2x_mul_5_avx(temp, q_00+405, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+405, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+404, 10, t_01+404, 10, temp);
	gf2x_mul_5_avx(temp, q_00+400, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+400, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+399, 10, t_01+399, 10, temp);
	gf2x_mul_5_avx(temp, q_00+395, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+395, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+394, 10, t_01+394, 10, temp);
	gf2x_mul_5_avx(temp, q_00+390, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+390, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+389, 10, t_01+389, 10, temp);
	gf2x_mul_5_avx(temp, q_00+385, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+385, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+384, 10, t_01+384, 10, temp);
	gf2x_mul_5_avx(temp, q_00+380, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+380, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+379, 10, t_01+379, 10, temp);
	gf2x_mul_5_avx(temp, q_00+375, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+375, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+374, 10, t_01+374, 10, temp);
	gf2x_mul_5_avx(temp, q_00+370, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+370, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+369, 10, t_01+369, 10, temp);
	gf2x_mul_5_avx(temp, q_00+365, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+365, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+364, 10, t_01+364, 10, temp);
	gf2x_mul_5_avx(temp, q_00+360, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+360, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+359, 10, t_01+359, 10, temp);
	gf2x_mul_5_avx(temp, q_00+355, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+355, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+354, 10, t_01+354, 10, temp);
	gf2x_mul_5_avx(temp, q_00+350, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+350, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+349, 10, t_01+349, 10, temp);
	gf2x_mul_5_avx(temp, q_00+345, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+345, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+344, 10, t_01+344, 10, temp);
	gf2x_mul_5_avx(temp, q_00+340, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+340, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+339, 10, t_01+339, 10, temp);
	gf2x_mul_5_avx(temp, q_00+335, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+335, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+334, 10, t_01+334, 10, temp);
	gf2x_mul_5_avx(temp, q_00+330, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+330, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+329, 10, t_01+329, 10, temp);
	gf2x_mul_5_avx(temp, q_00+325, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+325, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+324, 10, t_01+324, 10, temp);
	gf2x_mul_5_avx(temp, q_00+320, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+320, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+319, 10, t_01+319, 10, temp);
	gf2x_mul_5_avx(temp, q_00+315, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+315, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+314, 10, t_01+314, 10, temp);
	gf2x_mul_5_avx(temp, q_00+310, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+310, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+309, 10, t_01+309, 10, temp);
	gf2x_mul_5_avx(temp, q_00+305, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+305, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+304, 10, t_01+304, 10, temp);
	gf2x_mul_5_avx(temp, q_00+300, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+300, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+299, 10, t_01+299, 10, temp);
	gf2x_mul_5_avx(temp, q_00+295, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+295, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+294, 10, t_01+294, 10, temp);
	gf2x_mul_5_avx(temp, q_00+290, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+290, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+289, 10, t_01+289, 10, temp);
	gf2x_mul_5_avx(temp, q_00+285, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+285, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+284, 10, t_01+284, 10, temp);
	gf2x_mul_5_avx(temp, q_00+280, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+280, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+279, 10, t_01+279, 10, temp);
	gf2x_mul_5_avx(temp, q_00+275, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+275, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+274, 10, t_01+274, 10, temp);
	gf2x_mul_5_avx(temp, q_00+270, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+270, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+269, 10, t_01+269, 10, temp);
	gf2x_mul_5_avx(temp, q_00+265, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+265, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+264, 10, t_01+264, 10, temp);
	gf2x_mul_5_avx(temp, q_00+260, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+260, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+259, 10, t_01+259, 10, temp);
	gf2x_mul_5_avx(temp, q_00+255, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+255, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+254, 10, t_01+254, 10, temp);
	gf2x_mul_5_avx(temp, q_00+250, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+250, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+249, 10, t_01+249, 10, temp);
	gf2x_mul_5_avx(temp, q_00+245, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+245, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+244, 10, t_01+244, 10, temp);
	gf2x_mul_5_avx(temp, q_00+240, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+240, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+239, 10, t_01+239, 10, temp);
	gf2x_mul_5_avx(temp, q_00+235, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+235, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+234, 10, t_01+234, 10, temp);
	gf2x_mul_5_avx(temp, q_00+230, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+230, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+229, 10, t_01+229, 10, temp);
	gf2x_mul_5_avx(temp, q_00+225, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+225, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+224, 10, t_01+224, 10, temp);
	gf2x_mul_5_avx(temp, q_00+220, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+220, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+219, 10, t_01+219, 10, temp);
	gf2x_mul_5_avx(temp, q_00+215, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+215, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+214, 10, t_01+214, 10, temp);
	gf2x_mul_5_avx(temp, q_00+210, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+210, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+209, 10, t_01+209, 10, temp);
	gf2x_mul_5_avx(temp, q_00+205, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+205, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+204, 10, t_01+204, 10, temp);
	gf2x_mul_5_avx(temp, q_00+200, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+200, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+199, 10, t_01+199, 10, temp);
	gf2x_mul_5_avx(temp, q_00+195, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+195, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+194, 10, t_01+194, 10, temp);
	gf2x_mul_5_avx(temp, q_00+190, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+190, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+189, 10, t_01+189, 10, temp);
	gf2x_mul_5_avx(temp, q_00+185, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+185, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+184, 10, t_01+184, 10, temp);
	gf2x_mul_5_avx(temp, q_00+180, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+180, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+179, 10, t_01+179, 10, temp);
	gf2x_mul_5_avx(temp, q_00+175, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+175, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+174, 10, t_01+174, 10, temp);
	gf2x_mul_5_avx(temp, q_00+170, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+170, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+169, 10, t_01+169, 10, temp);
	gf2x_mul_5_avx(temp, q_00+165, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+165, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+164, 10, t_01+164, 10, temp);
	gf2x_mul_5_avx(temp, q_00+160, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+160, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+159, 10, t_01+159, 10, temp);
	gf2x_mul_5_avx(temp, q_00+155, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+155, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+154, 10, t_01+154, 10, temp);
	gf2x_mul_5_avx(temp, q_00+150, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+150, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+149, 10, t_01+149, 10, temp);
	gf2x_mul_5_avx(temp, q_00+145, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+145, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+144, 10, t_01+144, 10, temp);
	gf2x_mul_5_avx(temp, q_00+140, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+140, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+139, 10, t_01+139, 10, temp);
	gf2x_mul_5_avx(temp, q_00+135, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+135, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+134, 10, t_01+134, 10, temp);
	gf2x_mul_5_avx(temp, q_00+130, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+130, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+129, 10, t_01+129, 10, temp);
	gf2x_mul_5_avx(temp, q_00+125, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+125, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+124, 10, t_01+124, 10, temp);
	gf2x_mul_5_avx(temp, q_00+120, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+120, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+119, 10, t_01+119, 10, temp);
	gf2x_mul_5_avx(temp, q_00+115, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+115, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+114, 10, t_01+114, 10, temp);
	gf2x_mul_5_avx(temp, q_00+110, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+110, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+109, 10, t_01+109, 10, temp);
	gf2x_mul_5_avx(temp, q_00+105, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+105, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+104, 10, t_01+104, 10, temp);
	gf2x_mul_5_avx(temp, q_00+100, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+100, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+99, 10, t_01+99, 10, temp);
	gf2x_mul_5_avx(temp, q_00+95, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+95, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+94, 10, t_01+94, 10, temp);
	gf2x_mul_5_avx(temp, q_00+90, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+90, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+89, 10, t_01+89, 10, temp);
	gf2x_mul_5_avx(temp, q_00+85, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+85, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+84, 10, t_01+84, 10, temp);
	gf2x_mul_5_avx(temp, q_00+80, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+80, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+79, 10, t_01+79, 10, temp);
	gf2x_mul_5_avx(temp, q_00+75, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+75, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+74, 10, t_01+74, 10, temp);
	gf2x_mul_5_avx(temp, q_00+70, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+70, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+69, 10, t_01+69, 10, temp);
	gf2x_mul_5_avx(temp, q_00+65, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+65, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+64, 10, t_01+64, 10, temp);
	gf2x_mul_5_avx(temp, q_00+60, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+60, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+59, 10, t_01+59, 10, temp);
	gf2x_mul_5_avx(temp, q_00+55, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+55, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+54, 10, t_01+54, 10, temp);
	gf2x_mul_5_avx(temp, q_00+50, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+50, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+49, 10, t_01+49, 10, temp);
	gf2x_mul_5_avx(temp, q_00+45, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+45, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+44, 10, t_01+44, 10, temp);
	gf2x_mul_5_avx(temp, q_00+40, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+40, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+39, 10, t_01+39, 10, temp);
	gf2x_mul_5_avx(temp, q_00+35, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+35, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+34, 10, t_01+34, 10, temp);
	gf2x_mul_5_avx(temp, q_00+30, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+30, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+29, 10, t_01+29, 10, temp);
	gf2x_mul_5_avx(temp, q_00+25, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+25, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+24, 10, t_01+24, 10, temp);
	gf2x_mul_5_avx(temp, q_00+20, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+20, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+19, 10, t_01+19, 10, temp);
	gf2x_mul_5_avx(temp, q_00+15, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+15, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+14, 10, t_01+14, 10, temp);
	gf2x_mul_5_avx(temp, q_00+10, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+10, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+9, 10, t_01+9, 10, temp);
	gf2x_mul_5_avx(temp, q_00+5, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+5, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_01+4, 10, t_01+4, 10, temp);
	gf2x_mul_5_avx(temp, q_00+0, p_01+0);
	gf2x_mul_5_avx(temp2, q_01+0, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(9, t_01+0, 9, t_01+0, 9, temp+1);
	memset(t_10+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(1330, temp, 665, p_00+5, 665, q_10+0);
	GF2X_MUL(1330, temp2, 665, p_10+5, 665, q_11+0);
	gf2x_add(1330, t_10+4, 1330, temp, 1330, temp2);
	gf2x_mul_5_avx(temp, q_10+660, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+660, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+659, 10, t_10+659, 10, temp);
	gf2x_mul_5_avx(temp, q_10+655, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+655, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+654, 10, t_10+654, 10, temp);
	gf2x_mul_5_avx(temp, q_10+650, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+650, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+649, 10, t_10+649, 10, temp);
	gf2x_mul_5_avx(temp, q_10+645, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+645, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+644, 10, t_10+644, 10, temp);
	gf2x_mul_5_avx(temp, q_10+640, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+640, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+639, 10, t_10+639, 10, temp);
	gf2x_mul_5_avx(temp, q_10+635, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+635, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+634, 10, t_10+634, 10, temp);
	gf2x_mul_5_avx(temp, q_10+630, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+630, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+629, 10, t_10+629, 10, temp);
	gf2x_mul_5_avx(temp, q_10+625, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+625, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+624, 10, t_10+624, 10, temp);
	gf2x_mul_5_avx(temp, q_10+620, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+620, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+619, 10, t_10+619, 10, temp);
	gf2x_mul_5_avx(temp, q_10+615, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+615, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+614, 10, t_10+614, 10, temp);
	gf2x_mul_5_avx(temp, q_10+610, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+610, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+609, 10, t_10+609, 10, temp);
	gf2x_mul_5_avx(temp, q_10+605, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+605, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+604, 10, t_10+604, 10, temp);
	gf2x_mul_5_avx(temp, q_10+600, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+600, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+599, 10, t_10+599, 10, temp);
	gf2x_mul_5_avx(temp, q_10+595, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+595, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+594, 10, t_10+594, 10, temp);
	gf2x_mul_5_avx(temp, q_10+590, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+590, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+589, 10, t_10+589, 10, temp);
	gf2x_mul_5_avx(temp, q_10+585, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+585, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+584, 10, t_10+584, 10, temp);
	gf2x_mul_5_avx(temp, q_10+580, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+580, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+579, 10, t_10+579, 10, temp);
	gf2x_mul_5_avx(temp, q_10+575, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+575, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+574, 10, t_10+574, 10, temp);
	gf2x_mul_5_avx(temp, q_10+570, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+570, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+569, 10, t_10+569, 10, temp);
	gf2x_mul_5_avx(temp, q_10+565, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+565, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+564, 10, t_10+564, 10, temp);
	gf2x_mul_5_avx(temp, q_10+560, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+560, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+559, 10, t_10+559, 10, temp);
	gf2x_mul_5_avx(temp, q_10+555, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+555, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+554, 10, t_10+554, 10, temp);
	gf2x_mul_5_avx(temp, q_10+550, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+550, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+549, 10, t_10+549, 10, temp);
	gf2x_mul_5_avx(temp, q_10+545, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+545, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+544, 10, t_10+544, 10, temp);
	gf2x_mul_5_avx(temp, q_10+540, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+540, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+539, 10, t_10+539, 10, temp);
	gf2x_mul_5_avx(temp, q_10+535, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+535, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+534, 10, t_10+534, 10, temp);
	gf2x_mul_5_avx(temp, q_10+530, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+530, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+529, 10, t_10+529, 10, temp);
	gf2x_mul_5_avx(temp, q_10+525, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+525, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+524, 10, t_10+524, 10, temp);
	gf2x_mul_5_avx(temp, q_10+520, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+520, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+519, 10, t_10+519, 10, temp);
	gf2x_mul_5_avx(temp, q_10+515, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+515, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+514, 10, t_10+514, 10, temp);
	gf2x_mul_5_avx(temp, q_10+510, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+510, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+509, 10, t_10+509, 10, temp);
	gf2x_mul_5_avx(temp, q_10+505, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+505, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+504, 10, t_10+504, 10, temp);
	gf2x_mul_5_avx(temp, q_10+500, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+500, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+499, 10, t_10+499, 10, temp);
	gf2x_mul_5_avx(temp, q_10+495, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+495, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+494, 10, t_10+494, 10, temp);
	gf2x_mul_5_avx(temp, q_10+490, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+490, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+489, 10, t_10+489, 10, temp);
	gf2x_mul_5_avx(temp, q_10+485, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+485, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+484, 10, t_10+484, 10, temp);
	gf2x_mul_5_avx(temp, q_10+480, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+480, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+479, 10, t_10+479, 10, temp);
	gf2x_mul_5_avx(temp, q_10+475, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+475, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+474, 10, t_10+474, 10, temp);
	gf2x_mul_5_avx(temp, q_10+470, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+470, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+469, 10, t_10+469, 10, temp);
	gf2x_mul_5_avx(temp, q_10+465, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+465, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+464, 10, t_10+464, 10, temp);
	gf2x_mul_5_avx(temp, q_10+460, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+460, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+459, 10, t_10+459, 10, temp);
	gf2x_mul_5_avx(temp, q_10+455, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+455, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+454, 10, t_10+454, 10, temp);
	gf2x_mul_5_avx(temp, q_10+450, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+450, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+449, 10, t_10+449, 10, temp);
	gf2x_mul_5_avx(temp, q_10+445, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+445, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+444, 10, t_10+444, 10, temp);
	gf2x_mul_5_avx(temp, q_10+440, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+440, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+439, 10, t_10+439, 10, temp);
	gf2x_mul_5_avx(temp, q_10+435, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+435, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+434, 10, t_10+434, 10, temp);
	gf2x_mul_5_avx(temp, q_10+430, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+430, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+429, 10, t_10+429, 10, temp);
	gf2x_mul_5_avx(temp, q_10+425, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+425, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+424, 10, t_10+424, 10, temp);
	gf2x_mul_5_avx(temp, q_10+420, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+420, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+419, 10, t_10+419, 10, temp);
	gf2x_mul_5_avx(temp, q_10+415, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+415, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+414, 10, t_10+414, 10, temp);
	gf2x_mul_5_avx(temp, q_10+410, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+410, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+409, 10, t_10+409, 10, temp);
	gf2x_mul_5_avx(temp, q_10+405, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+405, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+404, 10, t_10+404, 10, temp);
	gf2x_mul_5_avx(temp, q_10+400, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+400, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+399, 10, t_10+399, 10, temp);
	gf2x_mul_5_avx(temp, q_10+395, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+395, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+394, 10, t_10+394, 10, temp);
	gf2x_mul_5_avx(temp, q_10+390, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+390, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+389, 10, t_10+389, 10, temp);
	gf2x_mul_5_avx(temp, q_10+385, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+385, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+384, 10, t_10+384, 10, temp);
	gf2x_mul_5_avx(temp, q_10+380, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+380, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+379, 10, t_10+379, 10, temp);
	gf2x_mul_5_avx(temp, q_10+375, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+375, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+374, 10, t_10+374, 10, temp);
	gf2x_mul_5_avx(temp, q_10+370, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+370, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+369, 10, t_10+369, 10, temp);
	gf2x_mul_5_avx(temp, q_10+365, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+365, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+364, 10, t_10+364, 10, temp);
	gf2x_mul_5_avx(temp, q_10+360, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+360, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+359, 10, t_10+359, 10, temp);
	gf2x_mul_5_avx(temp, q_10+355, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+355, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+354, 10, t_10+354, 10, temp);
	gf2x_mul_5_avx(temp, q_10+350, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+350, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+349, 10, t_10+349, 10, temp);
	gf2x_mul_5_avx(temp, q_10+345, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+345, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+344, 10, t_10+344, 10, temp);
	gf2x_mul_5_avx(temp, q_10+340, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+340, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+339, 10, t_10+339, 10, temp);
	gf2x_mul_5_avx(temp, q_10+335, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+335, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+334, 10, t_10+334, 10, temp);
	gf2x_mul_5_avx(temp, q_10+330, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+330, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+329, 10, t_10+329, 10, temp);
	gf2x_mul_5_avx(temp, q_10+325, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+325, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+324, 10, t_10+324, 10, temp);
	gf2x_mul_5_avx(temp, q_10+320, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+320, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+319, 10, t_10+319, 10, temp);
	gf2x_mul_5_avx(temp, q_10+315, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+315, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+314, 10, t_10+314, 10, temp);
	gf2x_mul_5_avx(temp, q_10+310, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+310, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+309, 10, t_10+309, 10, temp);
	gf2x_mul_5_avx(temp, q_10+305, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+305, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+304, 10, t_10+304, 10, temp);
	gf2x_mul_5_avx(temp, q_10+300, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+300, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+299, 10, t_10+299, 10, temp);
	gf2x_mul_5_avx(temp, q_10+295, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+295, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+294, 10, t_10+294, 10, temp);
	gf2x_mul_5_avx(temp, q_10+290, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+290, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+289, 10, t_10+289, 10, temp);
	gf2x_mul_5_avx(temp, q_10+285, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+285, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+284, 10, t_10+284, 10, temp);
	gf2x_mul_5_avx(temp, q_10+280, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+280, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+279, 10, t_10+279, 10, temp);
	gf2x_mul_5_avx(temp, q_10+275, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+275, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+274, 10, t_10+274, 10, temp);
	gf2x_mul_5_avx(temp, q_10+270, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+270, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+269, 10, t_10+269, 10, temp);
	gf2x_mul_5_avx(temp, q_10+265, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+265, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+264, 10, t_10+264, 10, temp);
	gf2x_mul_5_avx(temp, q_10+260, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+260, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+259, 10, t_10+259, 10, temp);
	gf2x_mul_5_avx(temp, q_10+255, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+255, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+254, 10, t_10+254, 10, temp);
	gf2x_mul_5_avx(temp, q_10+250, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+250, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+249, 10, t_10+249, 10, temp);
	gf2x_mul_5_avx(temp, q_10+245, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+245, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+244, 10, t_10+244, 10, temp);
	gf2x_mul_5_avx(temp, q_10+240, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+240, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+239, 10, t_10+239, 10, temp);
	gf2x_mul_5_avx(temp, q_10+235, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+235, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+234, 10, t_10+234, 10, temp);
	gf2x_mul_5_avx(temp, q_10+230, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+230, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+229, 10, t_10+229, 10, temp);
	gf2x_mul_5_avx(temp, q_10+225, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+225, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+224, 10, t_10+224, 10, temp);
	gf2x_mul_5_avx(temp, q_10+220, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+220, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+219, 10, t_10+219, 10, temp);
	gf2x_mul_5_avx(temp, q_10+215, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+215, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+214, 10, t_10+214, 10, temp);
	gf2x_mul_5_avx(temp, q_10+210, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+210, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+209, 10, t_10+209, 10, temp);
	gf2x_mul_5_avx(temp, q_10+205, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+205, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+204, 10, t_10+204, 10, temp);
	gf2x_mul_5_avx(temp, q_10+200, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+200, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+199, 10, t_10+199, 10, temp);
	gf2x_mul_5_avx(temp, q_10+195, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+195, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+194, 10, t_10+194, 10, temp);
	gf2x_mul_5_avx(temp, q_10+190, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+190, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+189, 10, t_10+189, 10, temp);
	gf2x_mul_5_avx(temp, q_10+185, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+185, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+184, 10, t_10+184, 10, temp);
	gf2x_mul_5_avx(temp, q_10+180, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+180, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+179, 10, t_10+179, 10, temp);
	gf2x_mul_5_avx(temp, q_10+175, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+175, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+174, 10, t_10+174, 10, temp);
	gf2x_mul_5_avx(temp, q_10+170, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+170, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+169, 10, t_10+169, 10, temp);
	gf2x_mul_5_avx(temp, q_10+165, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+165, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+164, 10, t_10+164, 10, temp);
	gf2x_mul_5_avx(temp, q_10+160, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+160, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+159, 10, t_10+159, 10, temp);
	gf2x_mul_5_avx(temp, q_10+155, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+155, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+154, 10, t_10+154, 10, temp);
	gf2x_mul_5_avx(temp, q_10+150, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+150, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+149, 10, t_10+149, 10, temp);
	gf2x_mul_5_avx(temp, q_10+145, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+145, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+144, 10, t_10+144, 10, temp);
	gf2x_mul_5_avx(temp, q_10+140, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+140, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+139, 10, t_10+139, 10, temp);
	gf2x_mul_5_avx(temp, q_10+135, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+135, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+134, 10, t_10+134, 10, temp);
	gf2x_mul_5_avx(temp, q_10+130, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+130, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+129, 10, t_10+129, 10, temp);
	gf2x_mul_5_avx(temp, q_10+125, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+125, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+124, 10, t_10+124, 10, temp);
	gf2x_mul_5_avx(temp, q_10+120, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+120, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+119, 10, t_10+119, 10, temp);
	gf2x_mul_5_avx(temp, q_10+115, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+115, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+114, 10, t_10+114, 10, temp);
	gf2x_mul_5_avx(temp, q_10+110, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+110, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+109, 10, t_10+109, 10, temp);
	gf2x_mul_5_avx(temp, q_10+105, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+105, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+104, 10, t_10+104, 10, temp);
	gf2x_mul_5_avx(temp, q_10+100, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+100, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+99, 10, t_10+99, 10, temp);
	gf2x_mul_5_avx(temp, q_10+95, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+95, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+94, 10, t_10+94, 10, temp);
	gf2x_mul_5_avx(temp, q_10+90, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+90, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+89, 10, t_10+89, 10, temp);
	gf2x_mul_5_avx(temp, q_10+85, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+85, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+84, 10, t_10+84, 10, temp);
	gf2x_mul_5_avx(temp, q_10+80, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+80, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+79, 10, t_10+79, 10, temp);
	gf2x_mul_5_avx(temp, q_10+75, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+75, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+74, 10, t_10+74, 10, temp);
	gf2x_mul_5_avx(temp, q_10+70, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+70, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+69, 10, t_10+69, 10, temp);
	gf2x_mul_5_avx(temp, q_10+65, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+65, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+64, 10, t_10+64, 10, temp);
	gf2x_mul_5_avx(temp, q_10+60, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+60, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+59, 10, t_10+59, 10, temp);
	gf2x_mul_5_avx(temp, q_10+55, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+55, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+54, 10, t_10+54, 10, temp);
	gf2x_mul_5_avx(temp, q_10+50, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+50, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+49, 10, t_10+49, 10, temp);
	gf2x_mul_5_avx(temp, q_10+45, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+45, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+44, 10, t_10+44, 10, temp);
	gf2x_mul_5_avx(temp, q_10+40, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+40, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+39, 10, t_10+39, 10, temp);
	gf2x_mul_5_avx(temp, q_10+35, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+35, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+34, 10, t_10+34, 10, temp);
	gf2x_mul_5_avx(temp, q_10+30, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+30, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+29, 10, t_10+29, 10, temp);
	gf2x_mul_5_avx(temp, q_10+25, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+25, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+24, 10, t_10+24, 10, temp);
	gf2x_mul_5_avx(temp, q_10+20, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+20, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+19, 10, t_10+19, 10, temp);
	gf2x_mul_5_avx(temp, q_10+15, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+15, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+14, 10, t_10+14, 10, temp);
	gf2x_mul_5_avx(temp, q_10+10, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+10, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+9, 10, t_10+9, 10, temp);
	gf2x_mul_5_avx(temp, q_10+5, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+5, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_10+4, 10, t_10+4, 10, temp);
	gf2x_mul_5_avx(temp, q_10+0, p_00+0);
	gf2x_mul_5_avx(temp2, q_11+0, p_10+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(9, t_10+0, 9, t_10+0, 9, temp+1);
	memset(t_11+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(1330, temp, 665, p_01+5, 665, q_10+0);
	GF2X_MUL(1330, temp2, 665, p_11+5, 665, q_11+0);
	gf2x_add(1330, t_11+4, 1330, temp, 1330, temp2);
	gf2x_mul_5_avx(temp, q_10+660, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+660, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+659, 10, t_11+659, 10, temp);
	gf2x_mul_5_avx(temp, q_10+655, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+655, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+654, 10, t_11+654, 10, temp);
	gf2x_mul_5_avx(temp, q_10+650, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+650, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+649, 10, t_11+649, 10, temp);
	gf2x_mul_5_avx(temp, q_10+645, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+645, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+644, 10, t_11+644, 10, temp);
	gf2x_mul_5_avx(temp, q_10+640, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+640, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+639, 10, t_11+639, 10, temp);
	gf2x_mul_5_avx(temp, q_10+635, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+635, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+634, 10, t_11+634, 10, temp);
	gf2x_mul_5_avx(temp, q_10+630, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+630, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+629, 10, t_11+629, 10, temp);
	gf2x_mul_5_avx(temp, q_10+625, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+625, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+624, 10, t_11+624, 10, temp);
	gf2x_mul_5_avx(temp, q_10+620, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+620, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+619, 10, t_11+619, 10, temp);
	gf2x_mul_5_avx(temp, q_10+615, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+615, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+614, 10, t_11+614, 10, temp);
	gf2x_mul_5_avx(temp, q_10+610, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+610, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+609, 10, t_11+609, 10, temp);
	gf2x_mul_5_avx(temp, q_10+605, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+605, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+604, 10, t_11+604, 10, temp);
	gf2x_mul_5_avx(temp, q_10+600, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+600, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+599, 10, t_11+599, 10, temp);
	gf2x_mul_5_avx(temp, q_10+595, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+595, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+594, 10, t_11+594, 10, temp);
	gf2x_mul_5_avx(temp, q_10+590, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+590, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+589, 10, t_11+589, 10, temp);
	gf2x_mul_5_avx(temp, q_10+585, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+585, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+584, 10, t_11+584, 10, temp);
	gf2x_mul_5_avx(temp, q_10+580, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+580, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+579, 10, t_11+579, 10, temp);
	gf2x_mul_5_avx(temp, q_10+575, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+575, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+574, 10, t_11+574, 10, temp);
	gf2x_mul_5_avx(temp, q_10+570, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+570, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+569, 10, t_11+569, 10, temp);
	gf2x_mul_5_avx(temp, q_10+565, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+565, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+564, 10, t_11+564, 10, temp);
	gf2x_mul_5_avx(temp, q_10+560, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+560, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+559, 10, t_11+559, 10, temp);
	gf2x_mul_5_avx(temp, q_10+555, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+555, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+554, 10, t_11+554, 10, temp);
	gf2x_mul_5_avx(temp, q_10+550, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+550, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+549, 10, t_11+549, 10, temp);
	gf2x_mul_5_avx(temp, q_10+545, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+545, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+544, 10, t_11+544, 10, temp);
	gf2x_mul_5_avx(temp, q_10+540, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+540, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+539, 10, t_11+539, 10, temp);
	gf2x_mul_5_avx(temp, q_10+535, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+535, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+534, 10, t_11+534, 10, temp);
	gf2x_mul_5_avx(temp, q_10+530, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+530, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+529, 10, t_11+529, 10, temp);
	gf2x_mul_5_avx(temp, q_10+525, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+525, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+524, 10, t_11+524, 10, temp);
	gf2x_mul_5_avx(temp, q_10+520, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+520, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+519, 10, t_11+519, 10, temp);
	gf2x_mul_5_avx(temp, q_10+515, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+515, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+514, 10, t_11+514, 10, temp);
	gf2x_mul_5_avx(temp, q_10+510, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+510, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+509, 10, t_11+509, 10, temp);
	gf2x_mul_5_avx(temp, q_10+505, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+505, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+504, 10, t_11+504, 10, temp);
	gf2x_mul_5_avx(temp, q_10+500, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+500, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+499, 10, t_11+499, 10, temp);
	gf2x_mul_5_avx(temp, q_10+495, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+495, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+494, 10, t_11+494, 10, temp);
	gf2x_mul_5_avx(temp, q_10+490, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+490, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+489, 10, t_11+489, 10, temp);
	gf2x_mul_5_avx(temp, q_10+485, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+485, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+484, 10, t_11+484, 10, temp);
	gf2x_mul_5_avx(temp, q_10+480, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+480, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+479, 10, t_11+479, 10, temp);
	gf2x_mul_5_avx(temp, q_10+475, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+475, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+474, 10, t_11+474, 10, temp);
	gf2x_mul_5_avx(temp, q_10+470, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+470, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+469, 10, t_11+469, 10, temp);
	gf2x_mul_5_avx(temp, q_10+465, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+465, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+464, 10, t_11+464, 10, temp);
	gf2x_mul_5_avx(temp, q_10+460, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+460, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+459, 10, t_11+459, 10, temp);
	gf2x_mul_5_avx(temp, q_10+455, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+455, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+454, 10, t_11+454, 10, temp);
	gf2x_mul_5_avx(temp, q_10+450, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+450, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+449, 10, t_11+449, 10, temp);
	gf2x_mul_5_avx(temp, q_10+445, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+445, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+444, 10, t_11+444, 10, temp);
	gf2x_mul_5_avx(temp, q_10+440, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+440, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+439, 10, t_11+439, 10, temp);
	gf2x_mul_5_avx(temp, q_10+435, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+435, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+434, 10, t_11+434, 10, temp);
	gf2x_mul_5_avx(temp, q_10+430, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+430, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+429, 10, t_11+429, 10, temp);
	gf2x_mul_5_avx(temp, q_10+425, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+425, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+424, 10, t_11+424, 10, temp);
	gf2x_mul_5_avx(temp, q_10+420, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+420, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+419, 10, t_11+419, 10, temp);
	gf2x_mul_5_avx(temp, q_10+415, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+415, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+414, 10, t_11+414, 10, temp);
	gf2x_mul_5_avx(temp, q_10+410, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+410, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+409, 10, t_11+409, 10, temp);
	gf2x_mul_5_avx(temp, q_10+405, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+405, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+404, 10, t_11+404, 10, temp);
	gf2x_mul_5_avx(temp, q_10+400, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+400, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+399, 10, t_11+399, 10, temp);
	gf2x_mul_5_avx(temp, q_10+395, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+395, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+394, 10, t_11+394, 10, temp);
	gf2x_mul_5_avx(temp, q_10+390, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+390, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+389, 10, t_11+389, 10, temp);
	gf2x_mul_5_avx(temp, q_10+385, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+385, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+384, 10, t_11+384, 10, temp);
	gf2x_mul_5_avx(temp, q_10+380, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+380, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+379, 10, t_11+379, 10, temp);
	gf2x_mul_5_avx(temp, q_10+375, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+375, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+374, 10, t_11+374, 10, temp);
	gf2x_mul_5_avx(temp, q_10+370, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+370, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+369, 10, t_11+369, 10, temp);
	gf2x_mul_5_avx(temp, q_10+365, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+365, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+364, 10, t_11+364, 10, temp);
	gf2x_mul_5_avx(temp, q_10+360, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+360, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+359, 10, t_11+359, 10, temp);
	gf2x_mul_5_avx(temp, q_10+355, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+355, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+354, 10, t_11+354, 10, temp);
	gf2x_mul_5_avx(temp, q_10+350, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+350, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+349, 10, t_11+349, 10, temp);
	gf2x_mul_5_avx(temp, q_10+345, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+345, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+344, 10, t_11+344, 10, temp);
	gf2x_mul_5_avx(temp, q_10+340, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+340, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+339, 10, t_11+339, 10, temp);
	gf2x_mul_5_avx(temp, q_10+335, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+335, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+334, 10, t_11+334, 10, temp);
	gf2x_mul_5_avx(temp, q_10+330, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+330, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+329, 10, t_11+329, 10, temp);
	gf2x_mul_5_avx(temp, q_10+325, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+325, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+324, 10, t_11+324, 10, temp);
	gf2x_mul_5_avx(temp, q_10+320, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+320, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+319, 10, t_11+319, 10, temp);
	gf2x_mul_5_avx(temp, q_10+315, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+315, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+314, 10, t_11+314, 10, temp);
	gf2x_mul_5_avx(temp, q_10+310, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+310, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+309, 10, t_11+309, 10, temp);
	gf2x_mul_5_avx(temp, q_10+305, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+305, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+304, 10, t_11+304, 10, temp);
	gf2x_mul_5_avx(temp, q_10+300, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+300, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+299, 10, t_11+299, 10, temp);
	gf2x_mul_5_avx(temp, q_10+295, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+295, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+294, 10, t_11+294, 10, temp);
	gf2x_mul_5_avx(temp, q_10+290, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+290, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+289, 10, t_11+289, 10, temp);
	gf2x_mul_5_avx(temp, q_10+285, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+285, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+284, 10, t_11+284, 10, temp);
	gf2x_mul_5_avx(temp, q_10+280, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+280, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+279, 10, t_11+279, 10, temp);
	gf2x_mul_5_avx(temp, q_10+275, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+275, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+274, 10, t_11+274, 10, temp);
	gf2x_mul_5_avx(temp, q_10+270, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+270, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+269, 10, t_11+269, 10, temp);
	gf2x_mul_5_avx(temp, q_10+265, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+265, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+264, 10, t_11+264, 10, temp);
	gf2x_mul_5_avx(temp, q_10+260, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+260, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+259, 10, t_11+259, 10, temp);
	gf2x_mul_5_avx(temp, q_10+255, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+255, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+254, 10, t_11+254, 10, temp);
	gf2x_mul_5_avx(temp, q_10+250, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+250, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+249, 10, t_11+249, 10, temp);
	gf2x_mul_5_avx(temp, q_10+245, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+245, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+244, 10, t_11+244, 10, temp);
	gf2x_mul_5_avx(temp, q_10+240, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+240, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+239, 10, t_11+239, 10, temp);
	gf2x_mul_5_avx(temp, q_10+235, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+235, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+234, 10, t_11+234, 10, temp);
	gf2x_mul_5_avx(temp, q_10+230, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+230, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+229, 10, t_11+229, 10, temp);
	gf2x_mul_5_avx(temp, q_10+225, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+225, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+224, 10, t_11+224, 10, temp);
	gf2x_mul_5_avx(temp, q_10+220, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+220, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+219, 10, t_11+219, 10, temp);
	gf2x_mul_5_avx(temp, q_10+215, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+215, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+214, 10, t_11+214, 10, temp);
	gf2x_mul_5_avx(temp, q_10+210, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+210, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+209, 10, t_11+209, 10, temp);
	gf2x_mul_5_avx(temp, q_10+205, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+205, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+204, 10, t_11+204, 10, temp);
	gf2x_mul_5_avx(temp, q_10+200, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+200, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+199, 10, t_11+199, 10, temp);
	gf2x_mul_5_avx(temp, q_10+195, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+195, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+194, 10, t_11+194, 10, temp);
	gf2x_mul_5_avx(temp, q_10+190, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+190, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+189, 10, t_11+189, 10, temp);
	gf2x_mul_5_avx(temp, q_10+185, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+185, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+184, 10, t_11+184, 10, temp);
	gf2x_mul_5_avx(temp, q_10+180, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+180, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+179, 10, t_11+179, 10, temp);
	gf2x_mul_5_avx(temp, q_10+175, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+175, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+174, 10, t_11+174, 10, temp);
	gf2x_mul_5_avx(temp, q_10+170, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+170, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+169, 10, t_11+169, 10, temp);
	gf2x_mul_5_avx(temp, q_10+165, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+165, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+164, 10, t_11+164, 10, temp);
	gf2x_mul_5_avx(temp, q_10+160, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+160, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+159, 10, t_11+159, 10, temp);
	gf2x_mul_5_avx(temp, q_10+155, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+155, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+154, 10, t_11+154, 10, temp);
	gf2x_mul_5_avx(temp, q_10+150, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+150, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+149, 10, t_11+149, 10, temp);
	gf2x_mul_5_avx(temp, q_10+145, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+145, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+144, 10, t_11+144, 10, temp);
	gf2x_mul_5_avx(temp, q_10+140, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+140, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+139, 10, t_11+139, 10, temp);
	gf2x_mul_5_avx(temp, q_10+135, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+135, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+134, 10, t_11+134, 10, temp);
	gf2x_mul_5_avx(temp, q_10+130, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+130, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+129, 10, t_11+129, 10, temp);
	gf2x_mul_5_avx(temp, q_10+125, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+125, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+124, 10, t_11+124, 10, temp);
	gf2x_mul_5_avx(temp, q_10+120, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+120, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+119, 10, t_11+119, 10, temp);
	gf2x_mul_5_avx(temp, q_10+115, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+115, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+114, 10, t_11+114, 10, temp);
	gf2x_mul_5_avx(temp, q_10+110, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+110, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+109, 10, t_11+109, 10, temp);
	gf2x_mul_5_avx(temp, q_10+105, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+105, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+104, 10, t_11+104, 10, temp);
	gf2x_mul_5_avx(temp, q_10+100, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+100, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+99, 10, t_11+99, 10, temp);
	gf2x_mul_5_avx(temp, q_10+95, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+95, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+94, 10, t_11+94, 10, temp);
	gf2x_mul_5_avx(temp, q_10+90, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+90, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+89, 10, t_11+89, 10, temp);
	gf2x_mul_5_avx(temp, q_10+85, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+85, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+84, 10, t_11+84, 10, temp);
	gf2x_mul_5_avx(temp, q_10+80, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+80, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+79, 10, t_11+79, 10, temp);
	gf2x_mul_5_avx(temp, q_10+75, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+75, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+74, 10, t_11+74, 10, temp);
	gf2x_mul_5_avx(temp, q_10+70, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+70, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+69, 10, t_11+69, 10, temp);
	gf2x_mul_5_avx(temp, q_10+65, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+65, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+64, 10, t_11+64, 10, temp);
	gf2x_mul_5_avx(temp, q_10+60, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+60, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+59, 10, t_11+59, 10, temp);
	gf2x_mul_5_avx(temp, q_10+55, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+55, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+54, 10, t_11+54, 10, temp);
	gf2x_mul_5_avx(temp, q_10+50, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+50, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+49, 10, t_11+49, 10, temp);
	gf2x_mul_5_avx(temp, q_10+45, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+45, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+44, 10, t_11+44, 10, temp);
	gf2x_mul_5_avx(temp, q_10+40, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+40, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+39, 10, t_11+39, 10, temp);
	gf2x_mul_5_avx(temp, q_10+35, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+35, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+34, 10, t_11+34, 10, temp);
	gf2x_mul_5_avx(temp, q_10+30, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+30, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+29, 10, t_11+29, 10, temp);
	gf2x_mul_5_avx(temp, q_10+25, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+25, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+24, 10, t_11+24, 10, temp);
	gf2x_mul_5_avx(temp, q_10+20, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+20, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+19, 10, t_11+19, 10, temp);
	gf2x_mul_5_avx(temp, q_10+15, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+15, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+14, 10, t_11+14, 10, temp);
	gf2x_mul_5_avx(temp, q_10+10, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+10, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+9, 10, t_11+9, 10, temp);
	gf2x_mul_5_avx(temp, q_10+5, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+5, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(10, t_11+4, 10, t_11+4, 10, temp);
	gf2x_mul_5_avx(temp, q_10+0, p_01+0);
	gf2x_mul_5_avx(temp2, q_11+0, p_11+0);
	gf2x_add(10, temp, 10, temp, 10, temp2);
	gf2x_add(9, t_11+0, 9, t_11+0, 9, temp+1);
	
	return delta;
}