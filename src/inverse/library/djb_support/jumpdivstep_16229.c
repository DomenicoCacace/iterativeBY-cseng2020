/**
  * @author Domenico Cacace <domenico.cacace@mail.polimi.it>
  * 
  *
  * This code is hereby placed in the public domain.
  *
  * THIS SOFTWARE IS PROVIDED BY THE AUTHORS ''AS IS'' AND ANY EXPRESS
  * OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
  * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHORS OR CONTRIBUTORS BE
  * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
  * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
  * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
  * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
  * EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **/

#include "../../include/inverse_DJB_facilities.h"

int jumpdivstep_16229(int delta, DIGIT *f, DIGIT *g, DIGIT *t_00, DIGIT *t_01, DIGIT *t_10, DIGIT *t_11) {
	DIGIT p_00[508];
	DIGIT p_01[508];
	DIGIT p_10[508];
	DIGIT p_11[508];
	
	DIGIT q_00[505];
	DIGIT q_01[505];
	DIGIT q_10[505];
	DIGIT q_11[505];
	
	DIGIT f_sum[1528];
	DIGIT g_sum[1528];
	
	DIGIT temp[512];
	DIGIT temp2[512];
	

	delta = divstepsx_256(255, delta, f+504, g+504, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f+504, p_00+504);
	gf2x_mul_4_avx(temp2, g+504, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f+500, p_00+504);
	gf2x_mul_4_avx(temp2, g+500, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f+504, p_10+504);
	gf2x_mul_4_avx(temp2, g+504, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f+500, p_10+504);
	gf2x_mul_4_avx(temp2, g+500, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f+500, p_00+496);
	gf2x_mul_8_avx(temp2, g+500, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f+492, p_00+496);
	gf2x_mul_8_avx(temp2, g+492, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f+500, p_10+496);
	gf2x_mul_8_avx(temp2, g+500, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f+492, p_10+496);
	gf2x_mul_8_avx(temp2, g+492, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, p_00+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, p_01+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, p_10+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, p_11+480, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, f+492, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g+492, 16, p_01+480);
	gf2x_add(32, f_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f+476, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g+476, 16, p_01+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, f_sum+1440, 16, f_sum+1440, 16, temp+16);
	right_bit_shift_n(32, f_sum+1440, 60);
	GF2X_MUL(32, temp, 16, f+492, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g+492, 16, p_11+480);
	gf2x_add(32, g_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f+476, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g+476, 16, p_11+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, g_sum+1440, 16, g_sum+1440, 16, temp+16);
	right_bit_shift_n(32, g_sum+1440, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1453, g_sum+1453, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1453, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1453, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1449, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1449, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, q_00+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, q_01+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, q_10+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, q_11+477, 16, temp, 16, temp2);
	
	// Recombining results: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_10+480);
	gf2x_add(32, p_00+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_11+480);
	gf2x_add(32, p_01+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_10+480);
	gf2x_add(32, p_10+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_11+480);
	gf2x_add(32, p_11+448, 32, temp, 32, temp2);
	
	// Calculating left operands: n: 4080, depth: 3
	GF2X_MUL(64, temp, 32, f+476, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, g+476, 32, p_01+448);
	gf2x_add(64, f_sum+1343, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, f+444, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, g+444, 32, p_01+448);
	gf2x_add(64, temp, 64, temp, 64, temp2);
	gf2x_add(32, f_sum+1343, 32, f_sum+1343, 32, temp+32);
	right_bit_shift_n(64, f_sum+1343, 56);
	GF2X_MUL(64, temp, 32, f+476, 32, p_10+448);
	GF2X_MUL(64, temp2, 32, g+476, 32, p_11+448);
	gf2x_add(64, g_sum+1343, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, f+444, 32, p_10+448);
	GF2X_MUL(64, temp2, 32, g+444, 32, p_11+448);
	gf2x_add(64, temp, 64, temp, 64, temp2);
	gf2x_add(32, g_sum+1343, 32, g_sum+1343, 32, temp+32);
	right_bit_shift_n(64, g_sum+1343, 56);
	
	delta = divstepsx_256(255, delta, f_sum+1372, g_sum+1372, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1372, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1372, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1368, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1368, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1372, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1372, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1368, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1368, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1368, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1368, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1360, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1360, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1368, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1368, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1360, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1360, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, p_00+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, p_01+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, p_10+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, p_11+480, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+1360, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1360, 16, p_01+480);
	gf2x_add(32, f_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1344, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1344, 16, p_01+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, f_sum+1440, 16, f_sum+1440, 16, temp+16);
	right_bit_shift_n(32, f_sum+1440, 60);
	GF2X_MUL(32, temp, 16, f_sum+1360, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1360, 16, p_11+480);
	gf2x_add(32, g_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1344, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1344, 16, p_11+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, g_sum+1440, 16, g_sum+1440, 16, temp+16);
	right_bit_shift_n(32, g_sum+1440, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1453, g_sum+1453, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1453, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1453, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1449, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1449, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, q_00+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, q_01+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, q_10+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, q_11+477, 16, temp, 16, temp2);
	
	// Recombining results: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_10+480);
	gf2x_add(32, q_00+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_11+480);
	gf2x_add(32, q_01+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_10+480);
	gf2x_add(32, q_10+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_11+480);
	gf2x_add(32, q_11+445, 32, temp, 32, temp2);
	
	// Recombining results: n: 4080, depth: 3
	GF2X_MUL(64, temp, 32, q_00+445, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, q_01+445, 32, p_10+448);
	gf2x_add(64, p_00+384, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_00+445, 32, p_01+448);
	GF2X_MUL(64, temp2, 32, q_01+445, 32, p_11+448);
	gf2x_add(64, p_01+384, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_10+445, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, q_11+445, 32, p_10+448);
	gf2x_add(64, p_10+384, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_10+445, 32, p_01+448);
	GF2X_MUL(64, temp2, 32, q_11+445, 32, p_11+448);
	gf2x_add(64, p_11+384, 64, temp, 64, temp2);
	
	// Calculating left operands: n: 8160, depth: 2
	GF2X_MUL(128, temp, 64, f+444, 64, p_00+384);
	GF2X_MUL(128, temp2, 64, g+444, 64, p_01+384);
	gf2x_add(128, f_sum+1150, 128, temp, 128, temp2);
	GF2X_MUL(128, temp, 64, f+380, 64, p_00+384);
	GF2X_MUL(128, temp2, 64, g+380, 64, p_01+384);
	gf2x_add(128, temp, 128, temp, 128, temp2);
	gf2x_add(64, f_sum+1150, 64, f_sum+1150, 64, temp+64);
	right_bit_shift_n(128, f_sum+1150, 48);
	GF2X_MUL(128, temp, 64, f+444, 64, p_10+384);
	GF2X_MUL(128, temp2, 64, g+444, 64, p_11+384);
	gf2x_add(128, g_sum+1150, 128, temp, 128, temp2);
	GF2X_MUL(128, temp, 64, f+380, 64, p_10+384);
	GF2X_MUL(128, temp2, 64, g+380, 64, p_11+384);
	gf2x_add(128, temp, 128, temp, 128, temp2);
	gf2x_add(64, g_sum+1150, 64, g_sum+1150, 64, temp+64);
	right_bit_shift_n(128, g_sum+1150, 48);
	
	delta = divstepsx_256(255, delta, f_sum+1211, g_sum+1211, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1211, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1211, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1207, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1207, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1211, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1211, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1207, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1207, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1207, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1207, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1199, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1199, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1207, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1207, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1199, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1199, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, p_00+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, p_01+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, p_10+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, p_11+480, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+1199, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1199, 16, p_01+480);
	gf2x_add(32, f_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1183, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1183, 16, p_01+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, f_sum+1440, 16, f_sum+1440, 16, temp+16);
	right_bit_shift_n(32, f_sum+1440, 60);
	GF2X_MUL(32, temp, 16, f_sum+1199, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1199, 16, p_11+480);
	gf2x_add(32, g_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1183, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1183, 16, p_11+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, g_sum+1440, 16, g_sum+1440, 16, temp+16);
	right_bit_shift_n(32, g_sum+1440, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1453, g_sum+1453, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1453, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1453, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1449, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1449, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, q_00+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, q_01+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, q_10+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, q_11+477, 16, temp, 16, temp2);
	
	// Recombining results: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_10+480);
	gf2x_add(32, p_00+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_11+480);
	gf2x_add(32, p_01+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_10+480);
	gf2x_add(32, p_10+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_11+480);
	gf2x_add(32, p_11+448, 32, temp, 32, temp2);
	
	// Calculating left operands: n: 4080, depth: 3
	GF2X_MUL(64, temp, 32, f_sum+1183, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, g_sum+1183, 32, p_01+448);
	gf2x_add(64, f_sum+1343, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, f_sum+1151, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, g_sum+1151, 32, p_01+448);
	gf2x_add(64, temp, 64, temp, 64, temp2);
	gf2x_add(32, f_sum+1343, 32, f_sum+1343, 32, temp+32);
	right_bit_shift_n(64, f_sum+1343, 56);
	GF2X_MUL(64, temp, 32, f_sum+1183, 32, p_10+448);
	GF2X_MUL(64, temp2, 32, g_sum+1183, 32, p_11+448);
	gf2x_add(64, g_sum+1343, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, f_sum+1151, 32, p_10+448);
	GF2X_MUL(64, temp2, 32, g_sum+1151, 32, p_11+448);
	gf2x_add(64, temp, 64, temp, 64, temp2);
	gf2x_add(32, g_sum+1343, 32, g_sum+1343, 32, temp+32);
	right_bit_shift_n(64, g_sum+1343, 56);
	
	delta = divstepsx_256(255, delta, f_sum+1372, g_sum+1372, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1372, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1372, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1368, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1368, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1372, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1372, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1368, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1368, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1368, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1368, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1360, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1360, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1368, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1368, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1360, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1360, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, p_00+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, p_01+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, p_10+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, p_11+480, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+1360, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1360, 16, p_01+480);
	gf2x_add(32, f_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1344, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1344, 16, p_01+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, f_sum+1440, 16, f_sum+1440, 16, temp+16);
	right_bit_shift_n(32, f_sum+1440, 60);
	GF2X_MUL(32, temp, 16, f_sum+1360, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1360, 16, p_11+480);
	gf2x_add(32, g_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1344, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1344, 16, p_11+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, g_sum+1440, 16, g_sum+1440, 16, temp+16);
	right_bit_shift_n(32, g_sum+1440, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1453, g_sum+1453, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1453, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1453, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1449, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1449, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, q_00+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, q_01+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, q_10+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, q_11+477, 16, temp, 16, temp2);
	
	// Recombining results: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_10+480);
	gf2x_add(32, q_00+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_11+480);
	gf2x_add(32, q_01+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_10+480);
	gf2x_add(32, q_10+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_11+480);
	gf2x_add(32, q_11+445, 32, temp, 32, temp2);
	
	// Recombining results: n: 4080, depth: 3
	GF2X_MUL(64, temp, 32, q_00+445, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, q_01+445, 32, p_10+448);
	gf2x_add(64, q_00+381, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_00+445, 32, p_01+448);
	GF2X_MUL(64, temp2, 32, q_01+445, 32, p_11+448);
	gf2x_add(64, q_01+381, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_10+445, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, q_11+445, 32, p_10+448);
	gf2x_add(64, q_10+381, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_10+445, 32, p_01+448);
	GF2X_MUL(64, temp2, 32, q_11+445, 32, p_11+448);
	gf2x_add(64, q_11+381, 64, temp, 64, temp2);
	
	// Recombining results: n: 8160, depth: 2
	GF2X_MUL(128, temp, 64, q_00+381, 64, p_00+384);
	GF2X_MUL(128, temp2, 64, q_01+381, 64, p_10+384);
	gf2x_add(128, p_00+256, 128, temp, 128, temp2);
	GF2X_MUL(128, temp, 64, q_00+381, 64, p_01+384);
	GF2X_MUL(128, temp2, 64, q_01+381, 64, p_11+384);
	gf2x_add(128, p_01+256, 128, temp, 128, temp2);
	GF2X_MUL(128, temp, 64, q_10+381, 64, p_00+384);
	GF2X_MUL(128, temp2, 64, q_11+381, 64, p_10+384);
	gf2x_add(128, p_10+256, 128, temp, 128, temp2);
	GF2X_MUL(128, temp, 64, q_10+381, 64, p_01+384);
	GF2X_MUL(128, temp2, 64, q_11+381, 64, p_11+384);
	gf2x_add(128, p_11+256, 128, temp, 128, temp2);
	
	// Calculating left operands: n: 16320, depth: 1
	GF2X_MUL(256, temp, 128, f+380, 128, p_00+256);
	GF2X_MUL(256, temp2, 128, g+380, 128, p_01+256);
	gf2x_add(256, f_sum+765, 256, temp, 256, temp2);
	GF2X_MUL(256, temp, 128, f+252, 128, p_00+256);
	GF2X_MUL(256, temp2, 128, g+252, 128, p_01+256);
	gf2x_add(256, temp, 256, temp, 256, temp2);
	gf2x_add(128, f_sum+765, 128, f_sum+765, 128, temp+128);
	right_bit_shift_n(256, f_sum+765, 32);
	GF2X_MUL(256, temp, 128, f+380, 128, p_10+256);
	GF2X_MUL(256, temp2, 128, g+380, 128, p_11+256);
	gf2x_add(256, g_sum+765, 256, temp, 256, temp2);
	GF2X_MUL(256, temp, 128, f+252, 128, p_10+256);
	GF2X_MUL(256, temp2, 128, g+252, 128, p_11+256);
	gf2x_add(256, temp, 256, temp, 256, temp2);
	gf2x_add(128, g_sum+765, 128, g_sum+765, 128, temp+128);
	right_bit_shift_n(256, g_sum+765, 32);
	
	delta = divstepsx_256(255, delta, f_sum+890, g_sum+890, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+890, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+890, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+886, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+886, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+890, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+890, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+886, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+886, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+886, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+886, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+878, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+878, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+886, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+886, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+878, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+878, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, p_00+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, p_01+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, p_10+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, p_11+480, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+878, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+878, 16, p_01+480);
	gf2x_add(32, f_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+862, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+862, 16, p_01+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, f_sum+1440, 16, f_sum+1440, 16, temp+16);
	right_bit_shift_n(32, f_sum+1440, 60);
	GF2X_MUL(32, temp, 16, f_sum+878, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+878, 16, p_11+480);
	gf2x_add(32, g_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+862, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+862, 16, p_11+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, g_sum+1440, 16, g_sum+1440, 16, temp+16);
	right_bit_shift_n(32, g_sum+1440, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1453, g_sum+1453, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1453, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1453, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1449, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1449, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, q_00+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, q_01+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, q_10+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, q_11+477, 16, temp, 16, temp2);
	
	// Recombining results: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_10+480);
	gf2x_add(32, p_00+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_11+480);
	gf2x_add(32, p_01+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_10+480);
	gf2x_add(32, p_10+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_11+480);
	gf2x_add(32, p_11+448, 32, temp, 32, temp2);
	
	// Calculating left operands: n: 4080, depth: 3
	GF2X_MUL(64, temp, 32, f_sum+862, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, g_sum+862, 32, p_01+448);
	gf2x_add(64, f_sum+1343, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, f_sum+830, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, g_sum+830, 32, p_01+448);
	gf2x_add(64, temp, 64, temp, 64, temp2);
	gf2x_add(32, f_sum+1343, 32, f_sum+1343, 32, temp+32);
	right_bit_shift_n(64, f_sum+1343, 56);
	GF2X_MUL(64, temp, 32, f_sum+862, 32, p_10+448);
	GF2X_MUL(64, temp2, 32, g_sum+862, 32, p_11+448);
	gf2x_add(64, g_sum+1343, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, f_sum+830, 32, p_10+448);
	GF2X_MUL(64, temp2, 32, g_sum+830, 32, p_11+448);
	gf2x_add(64, temp, 64, temp, 64, temp2);
	gf2x_add(32, g_sum+1343, 32, g_sum+1343, 32, temp+32);
	right_bit_shift_n(64, g_sum+1343, 56);
	
	delta = divstepsx_256(255, delta, f_sum+1372, g_sum+1372, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1372, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1372, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1368, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1368, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1372, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1372, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1368, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1368, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1368, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1368, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1360, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1360, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1368, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1368, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1360, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1360, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, p_00+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, p_01+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, p_10+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, p_11+480, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+1360, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1360, 16, p_01+480);
	gf2x_add(32, f_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1344, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1344, 16, p_01+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, f_sum+1440, 16, f_sum+1440, 16, temp+16);
	right_bit_shift_n(32, f_sum+1440, 60);
	GF2X_MUL(32, temp, 16, f_sum+1360, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1360, 16, p_11+480);
	gf2x_add(32, g_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1344, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1344, 16, p_11+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, g_sum+1440, 16, g_sum+1440, 16, temp+16);
	right_bit_shift_n(32, g_sum+1440, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1453, g_sum+1453, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1453, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1453, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1449, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1449, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, q_00+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, q_01+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, q_10+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, q_11+477, 16, temp, 16, temp2);
	
	// Recombining results: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_10+480);
	gf2x_add(32, q_00+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_11+480);
	gf2x_add(32, q_01+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_10+480);
	gf2x_add(32, q_10+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_11+480);
	gf2x_add(32, q_11+445, 32, temp, 32, temp2);
	
	// Recombining results: n: 4080, depth: 3
	GF2X_MUL(64, temp, 32, q_00+445, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, q_01+445, 32, p_10+448);
	gf2x_add(64, p_00+384, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_00+445, 32, p_01+448);
	GF2X_MUL(64, temp2, 32, q_01+445, 32, p_11+448);
	gf2x_add(64, p_01+384, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_10+445, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, q_11+445, 32, p_10+448);
	gf2x_add(64, p_10+384, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_10+445, 32, p_01+448);
	GF2X_MUL(64, temp2, 32, q_11+445, 32, p_11+448);
	gf2x_add(64, p_11+384, 64, temp, 64, temp2);
	
	// Calculating left operands: n: 8160, depth: 2
	GF2X_MUL(128, temp, 64, f_sum+830, 64, p_00+384);
	GF2X_MUL(128, temp2, 64, g_sum+830, 64, p_01+384);
	gf2x_add(128, f_sum+1150, 128, temp, 128, temp2);
	GF2X_MUL(128, temp, 64, f_sum+766, 64, p_00+384);
	GF2X_MUL(128, temp2, 64, g_sum+766, 64, p_01+384);
	gf2x_add(128, temp, 128, temp, 128, temp2);
	gf2x_add(64, f_sum+1150, 64, f_sum+1150, 64, temp+64);
	right_bit_shift_n(128, f_sum+1150, 48);
	GF2X_MUL(128, temp, 64, f_sum+830, 64, p_10+384);
	GF2X_MUL(128, temp2, 64, g_sum+830, 64, p_11+384);
	gf2x_add(128, g_sum+1150, 128, temp, 128, temp2);
	GF2X_MUL(128, temp, 64, f_sum+766, 64, p_10+384);
	GF2X_MUL(128, temp2, 64, g_sum+766, 64, p_11+384);
	gf2x_add(128, temp, 128, temp, 128, temp2);
	gf2x_add(64, g_sum+1150, 64, g_sum+1150, 64, temp+64);
	right_bit_shift_n(128, g_sum+1150, 48);
	
	delta = divstepsx_256(255, delta, f_sum+1211, g_sum+1211, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1211, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1211, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1207, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1207, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1211, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1211, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1207, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1207, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1207, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1207, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1199, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1199, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1207, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1207, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1199, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1199, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, p_00+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, p_01+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, p_10+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, p_11+480, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+1199, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1199, 16, p_01+480);
	gf2x_add(32, f_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1183, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1183, 16, p_01+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, f_sum+1440, 16, f_sum+1440, 16, temp+16);
	right_bit_shift_n(32, f_sum+1440, 60);
	GF2X_MUL(32, temp, 16, f_sum+1199, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1199, 16, p_11+480);
	gf2x_add(32, g_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1183, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1183, 16, p_11+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, g_sum+1440, 16, g_sum+1440, 16, temp+16);
	right_bit_shift_n(32, g_sum+1440, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1453, g_sum+1453, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1453, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1453, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1449, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1449, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, q_00+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, q_01+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, q_10+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, q_11+477, 16, temp, 16, temp2);
	
	// Recombining results: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_10+480);
	gf2x_add(32, p_00+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_11+480);
	gf2x_add(32, p_01+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_10+480);
	gf2x_add(32, p_10+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_11+480);
	gf2x_add(32, p_11+448, 32, temp, 32, temp2);
	
	// Calculating left operands: n: 4080, depth: 3
	GF2X_MUL(64, temp, 32, f_sum+1183, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, g_sum+1183, 32, p_01+448);
	gf2x_add(64, f_sum+1343, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, f_sum+1151, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, g_sum+1151, 32, p_01+448);
	gf2x_add(64, temp, 64, temp, 64, temp2);
	gf2x_add(32, f_sum+1343, 32, f_sum+1343, 32, temp+32);
	right_bit_shift_n(64, f_sum+1343, 56);
	GF2X_MUL(64, temp, 32, f_sum+1183, 32, p_10+448);
	GF2X_MUL(64, temp2, 32, g_sum+1183, 32, p_11+448);
	gf2x_add(64, g_sum+1343, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, f_sum+1151, 32, p_10+448);
	GF2X_MUL(64, temp2, 32, g_sum+1151, 32, p_11+448);
	gf2x_add(64, temp, 64, temp, 64, temp2);
	gf2x_add(32, g_sum+1343, 32, g_sum+1343, 32, temp+32);
	right_bit_shift_n(64, g_sum+1343, 56);
	
	delta = divstepsx_256(255, delta, f_sum+1372, g_sum+1372, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1372, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1372, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1368, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1368, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1372, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1372, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1368, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1368, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1368, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1368, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1360, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1360, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1368, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1368, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1360, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1360, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, p_00+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, p_01+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, p_10+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, p_11+480, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+1360, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1360, 16, p_01+480);
	gf2x_add(32, f_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1344, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1344, 16, p_01+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, f_sum+1440, 16, f_sum+1440, 16, temp+16);
	right_bit_shift_n(32, f_sum+1440, 60);
	GF2X_MUL(32, temp, 16, f_sum+1360, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1360, 16, p_11+480);
	gf2x_add(32, g_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1344, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1344, 16, p_11+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, g_sum+1440, 16, g_sum+1440, 16, temp+16);
	right_bit_shift_n(32, g_sum+1440, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1453, g_sum+1453, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1453, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1453, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1449, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1449, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, q_00+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, q_01+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, q_10+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, q_11+477, 16, temp, 16, temp2);
	
	// Recombining results: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_10+480);
	gf2x_add(32, q_00+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_11+480);
	gf2x_add(32, q_01+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_10+480);
	gf2x_add(32, q_10+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_11+480);
	gf2x_add(32, q_11+445, 32, temp, 32, temp2);
	
	// Recombining results: n: 4080, depth: 3
	GF2X_MUL(64, temp, 32, q_00+445, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, q_01+445, 32, p_10+448);
	gf2x_add(64, q_00+381, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_00+445, 32, p_01+448);
	GF2X_MUL(64, temp2, 32, q_01+445, 32, p_11+448);
	gf2x_add(64, q_01+381, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_10+445, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, q_11+445, 32, p_10+448);
	gf2x_add(64, q_10+381, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_10+445, 32, p_01+448);
	GF2X_MUL(64, temp2, 32, q_11+445, 32, p_11+448);
	gf2x_add(64, q_11+381, 64, temp, 64, temp2);
	
	// Recombining results: n: 8160, depth: 2
	GF2X_MUL(128, temp, 64, q_00+381, 64, p_00+384);
	GF2X_MUL(128, temp2, 64, q_01+381, 64, p_10+384);
	gf2x_add(128, q_00+253, 128, temp, 128, temp2);
	GF2X_MUL(128, temp, 64, q_00+381, 64, p_01+384);
	GF2X_MUL(128, temp2, 64, q_01+381, 64, p_11+384);
	gf2x_add(128, q_01+253, 128, temp, 128, temp2);
	GF2X_MUL(128, temp, 64, q_10+381, 64, p_00+384);
	GF2X_MUL(128, temp2, 64, q_11+381, 64, p_10+384);
	gf2x_add(128, q_10+253, 128, temp, 128, temp2);
	GF2X_MUL(128, temp, 64, q_10+381, 64, p_01+384);
	GF2X_MUL(128, temp2, 64, q_11+381, 64, p_11+384);
	gf2x_add(128, q_11+253, 128, temp, 128, temp2);
	
	// Recombining results: n: 16320, depth: 1
	GF2X_MUL(256, temp, 128, q_00+253, 128, p_00+256);
	GF2X_MUL(256, temp2, 128, q_01+253, 128, p_10+256);
	gf2x_add(256, p_00+0, 256, temp, 256, temp2);
	GF2X_MUL(256, temp, 128, q_00+253, 128, p_01+256);
	GF2X_MUL(256, temp2, 128, q_01+253, 128, p_11+256);
	gf2x_add(256, p_01+0, 256, temp, 256, temp2);
	GF2X_MUL(256, temp, 128, q_10+253, 128, p_00+256);
	GF2X_MUL(256, temp2, 128, q_11+253, 128, p_10+256);
	gf2x_add(256, p_10+0, 256, temp, 256, temp2);
	GF2X_MUL(256, temp, 128, q_10+253, 128, p_01+256);
	GF2X_MUL(256, temp2, 128, q_11+253, 128, p_11+256);
	gf2x_add(256, p_11+0, 256, temp, 256, temp2);
	
	// Calculating left operands: n: 32457, depth: 0
	GF2X_MUL(512, temp, 256, f+252, 256, p_00+0);
	GF2X_MUL(512, temp2, 256, g+252, 256, p_01+0);
	gf2x_add(509, f_sum+0, 509, temp+3, 509, temp2+3);
	GF2X_MUL(504, temp, 252, p_00+4, 252, f+0);
	GF2X_MUL(504, temp2, 252, p_01+4, 252, g+0);
	gf2x_add(504, temp, 504, temp, 504, temp2);
	gf2x_add(253, f_sum+0, 253, f_sum+0, 253, temp+251);
	gf2x_mul_4_avx(temp, f+248, p_00+0);
	gf2x_mul_4_avx(temp2, g+248, p_01+0);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(1, f_sum+0, 1, f_sum+0, 1, temp+7);
	right_bit_shift_n(508, f_sum+0, 0);
	GF2X_MUL(512, temp, 256, f+252, 256, p_10+0);
	GF2X_MUL(512, temp2, 256, g+252, 256, p_11+0);
	gf2x_add(509, g_sum+0, 509, temp+3, 509, temp2+3);
	GF2X_MUL(504, temp, 252, p_10+4, 252, f+0);
	GF2X_MUL(504, temp2, 252, p_11+4, 252, g+0);
	gf2x_add(504, temp, 504, temp, 504, temp2);
	gf2x_add(253, g_sum+0, 253, g_sum+0, 253, temp+251);
	gf2x_mul_4_avx(temp, f+248, p_10+0);
	gf2x_mul_4_avx(temp2, g+248, p_11+0);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(1, g_sum+0, 1, g_sum+0, 1, temp+7);
	right_bit_shift_n(508, g_sum+0, 0);
	
	delta = divstepsx_256(255, delta, f_sum+250, g_sum+250, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+250, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+250, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+246, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+246, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+250, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+250, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+246, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+246, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+246, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+246, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+238, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+238, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+246, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+246, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+238, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+238, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, p_00+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, p_01+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, p_10+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, p_11+480, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+238, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+238, 16, p_01+480);
	gf2x_add(32, f_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+222, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+222, 16, p_01+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, f_sum+1440, 16, f_sum+1440, 16, temp+16);
	right_bit_shift_n(32, f_sum+1440, 60);
	GF2X_MUL(32, temp, 16, f_sum+238, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+238, 16, p_11+480);
	gf2x_add(32, g_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+222, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+222, 16, p_11+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, g_sum+1440, 16, g_sum+1440, 16, temp+16);
	right_bit_shift_n(32, g_sum+1440, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1453, g_sum+1453, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1453, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1453, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1449, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1449, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, q_00+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, q_01+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, q_10+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, q_11+477, 16, temp, 16, temp2);
	
	// Recombining results: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_10+480);
	gf2x_add(32, p_00+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_11+480);
	gf2x_add(32, p_01+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_10+480);
	gf2x_add(32, p_10+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_11+480);
	gf2x_add(32, p_11+448, 32, temp, 32, temp2);
	
	// Calculating left operands: n: 4080, depth: 3
	GF2X_MUL(64, temp, 32, f_sum+222, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, g_sum+222, 32, p_01+448);
	gf2x_add(64, f_sum+1343, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, f_sum+190, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, g_sum+190, 32, p_01+448);
	gf2x_add(64, temp, 64, temp, 64, temp2);
	gf2x_add(32, f_sum+1343, 32, f_sum+1343, 32, temp+32);
	right_bit_shift_n(64, f_sum+1343, 56);
	GF2X_MUL(64, temp, 32, f_sum+222, 32, p_10+448);
	GF2X_MUL(64, temp2, 32, g_sum+222, 32, p_11+448);
	gf2x_add(64, g_sum+1343, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, f_sum+190, 32, p_10+448);
	GF2X_MUL(64, temp2, 32, g_sum+190, 32, p_11+448);
	gf2x_add(64, temp, 64, temp, 64, temp2);
	gf2x_add(32, g_sum+1343, 32, g_sum+1343, 32, temp+32);
	right_bit_shift_n(64, g_sum+1343, 56);
	
	delta = divstepsx_256(255, delta, f_sum+1372, g_sum+1372, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1372, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1372, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1368, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1368, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1372, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1372, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1368, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1368, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1368, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1368, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1360, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1360, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1368, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1368, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1360, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1360, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, p_00+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, p_01+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, p_10+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, p_11+480, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+1360, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1360, 16, p_01+480);
	gf2x_add(32, f_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1344, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1344, 16, p_01+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, f_sum+1440, 16, f_sum+1440, 16, temp+16);
	right_bit_shift_n(32, f_sum+1440, 60);
	GF2X_MUL(32, temp, 16, f_sum+1360, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1360, 16, p_11+480);
	gf2x_add(32, g_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1344, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1344, 16, p_11+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, g_sum+1440, 16, g_sum+1440, 16, temp+16);
	right_bit_shift_n(32, g_sum+1440, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1453, g_sum+1453, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1453, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1453, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1449, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1449, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, q_00+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, q_01+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, q_10+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, q_11+477, 16, temp, 16, temp2);
	
	// Recombining results: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_10+480);
	gf2x_add(32, q_00+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_11+480);
	gf2x_add(32, q_01+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_10+480);
	gf2x_add(32, q_10+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_11+480);
	gf2x_add(32, q_11+445, 32, temp, 32, temp2);
	
	// Recombining results: n: 4080, depth: 3
	GF2X_MUL(64, temp, 32, q_00+445, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, q_01+445, 32, p_10+448);
	gf2x_add(64, p_00+384, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_00+445, 32, p_01+448);
	GF2X_MUL(64, temp2, 32, q_01+445, 32, p_11+448);
	gf2x_add(64, p_01+384, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_10+445, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, q_11+445, 32, p_10+448);
	gf2x_add(64, p_10+384, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_10+445, 32, p_01+448);
	GF2X_MUL(64, temp2, 32, q_11+445, 32, p_11+448);
	gf2x_add(64, p_11+384, 64, temp, 64, temp2);
	
	// Calculating left operands: n: 8160, depth: 2
	GF2X_MUL(128, temp, 64, f_sum+190, 64, p_00+384);
	GF2X_MUL(128, temp2, 64, g_sum+190, 64, p_01+384);
	gf2x_add(128, f_sum+1150, 128, temp, 128, temp2);
	GF2X_MUL(128, temp, 64, f_sum+126, 64, p_00+384);
	GF2X_MUL(128, temp2, 64, g_sum+126, 64, p_01+384);
	gf2x_add(128, temp, 128, temp, 128, temp2);
	gf2x_add(64, f_sum+1150, 64, f_sum+1150, 64, temp+64);
	right_bit_shift_n(128, f_sum+1150, 48);
	GF2X_MUL(128, temp, 64, f_sum+190, 64, p_10+384);
	GF2X_MUL(128, temp2, 64, g_sum+190, 64, p_11+384);
	gf2x_add(128, g_sum+1150, 128, temp, 128, temp2);
	GF2X_MUL(128, temp, 64, f_sum+126, 64, p_10+384);
	GF2X_MUL(128, temp2, 64, g_sum+126, 64, p_11+384);
	gf2x_add(128, temp, 128, temp, 128, temp2);
	gf2x_add(64, g_sum+1150, 64, g_sum+1150, 64, temp+64);
	right_bit_shift_n(128, g_sum+1150, 48);
	
	delta = divstepsx_256(255, delta, f_sum+1211, g_sum+1211, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1211, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1211, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1207, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1207, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1211, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1211, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1207, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1207, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1207, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1207, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1199, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1199, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1207, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1207, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1199, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1199, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, p_00+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, p_01+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, p_10+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, p_11+480, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+1199, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1199, 16, p_01+480);
	gf2x_add(32, f_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1183, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1183, 16, p_01+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, f_sum+1440, 16, f_sum+1440, 16, temp+16);
	right_bit_shift_n(32, f_sum+1440, 60);
	GF2X_MUL(32, temp, 16, f_sum+1199, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1199, 16, p_11+480);
	gf2x_add(32, g_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1183, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1183, 16, p_11+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, g_sum+1440, 16, g_sum+1440, 16, temp+16);
	right_bit_shift_n(32, g_sum+1440, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1453, g_sum+1453, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1453, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1453, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1449, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1449, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, q_00+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, q_01+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, q_10+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, q_11+477, 16, temp, 16, temp2);
	
	// Recombining results: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_10+480);
	gf2x_add(32, p_00+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_11+480);
	gf2x_add(32, p_01+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_10+480);
	gf2x_add(32, p_10+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_11+480);
	gf2x_add(32, p_11+448, 32, temp, 32, temp2);
	
	// Calculating left operands: n: 4080, depth: 3
	GF2X_MUL(64, temp, 32, f_sum+1183, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, g_sum+1183, 32, p_01+448);
	gf2x_add(64, f_sum+1343, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, f_sum+1151, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, g_sum+1151, 32, p_01+448);
	gf2x_add(64, temp, 64, temp, 64, temp2);
	gf2x_add(32, f_sum+1343, 32, f_sum+1343, 32, temp+32);
	right_bit_shift_n(64, f_sum+1343, 56);
	GF2X_MUL(64, temp, 32, f_sum+1183, 32, p_10+448);
	GF2X_MUL(64, temp2, 32, g_sum+1183, 32, p_11+448);
	gf2x_add(64, g_sum+1343, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, f_sum+1151, 32, p_10+448);
	GF2X_MUL(64, temp2, 32, g_sum+1151, 32, p_11+448);
	gf2x_add(64, temp, 64, temp, 64, temp2);
	gf2x_add(32, g_sum+1343, 32, g_sum+1343, 32, temp+32);
	right_bit_shift_n(64, g_sum+1343, 56);
	
	delta = divstepsx_256(255, delta, f_sum+1372, g_sum+1372, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1372, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1372, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1368, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1368, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1372, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1372, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1368, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1368, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1368, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1368, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1360, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1360, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1368, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1368, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1360, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1360, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, p_00+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, p_01+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, p_10+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, p_11+480, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+1360, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1360, 16, p_01+480);
	gf2x_add(32, f_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1344, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1344, 16, p_01+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, f_sum+1440, 16, f_sum+1440, 16, temp+16);
	right_bit_shift_n(32, f_sum+1440, 60);
	GF2X_MUL(32, temp, 16, f_sum+1360, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1360, 16, p_11+480);
	gf2x_add(32, g_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1344, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1344, 16, p_11+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, g_sum+1440, 16, g_sum+1440, 16, temp+16);
	right_bit_shift_n(32, g_sum+1440, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1453, g_sum+1453, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1453, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1453, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1449, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1449, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, q_00+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, q_01+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, q_10+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, q_11+477, 16, temp, 16, temp2);
	
	// Recombining results: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_10+480);
	gf2x_add(32, q_00+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_11+480);
	gf2x_add(32, q_01+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_10+480);
	gf2x_add(32, q_10+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_11+480);
	gf2x_add(32, q_11+445, 32, temp, 32, temp2);
	
	// Recombining results: n: 4080, depth: 3
	GF2X_MUL(64, temp, 32, q_00+445, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, q_01+445, 32, p_10+448);
	gf2x_add(64, q_00+381, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_00+445, 32, p_01+448);
	GF2X_MUL(64, temp2, 32, q_01+445, 32, p_11+448);
	gf2x_add(64, q_01+381, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_10+445, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, q_11+445, 32, p_10+448);
	gf2x_add(64, q_10+381, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_10+445, 32, p_01+448);
	GF2X_MUL(64, temp2, 32, q_11+445, 32, p_11+448);
	gf2x_add(64, q_11+381, 64, temp, 64, temp2);
	
	// Recombining results: n: 8160, depth: 2
	GF2X_MUL(128, temp, 64, q_00+381, 64, p_00+384);
	GF2X_MUL(128, temp2, 64, q_01+381, 64, p_10+384);
	gf2x_add(128, p_00+256, 128, temp, 128, temp2);
	GF2X_MUL(128, temp, 64, q_00+381, 64, p_01+384);
	GF2X_MUL(128, temp2, 64, q_01+381, 64, p_11+384);
	gf2x_add(128, p_01+256, 128, temp, 128, temp2);
	GF2X_MUL(128, temp, 64, q_10+381, 64, p_00+384);
	GF2X_MUL(128, temp2, 64, q_11+381, 64, p_10+384);
	gf2x_add(128, p_10+256, 128, temp, 128, temp2);
	GF2X_MUL(128, temp, 64, q_10+381, 64, p_01+384);
	GF2X_MUL(128, temp2, 64, q_11+381, 64, p_11+384);
	gf2x_add(128, p_11+256, 128, temp, 128, temp2);
	
	// Calculating left operands: n: 16137, depth: 1
	GF2X_MUL(256, temp, 128, f_sum+126, 128, p_00+256);
	GF2X_MUL(256, temp2, 128, g_sum+126, 128, p_01+256);
	gf2x_add(253, f_sum+765, 253, temp+3, 253, temp2+3);
	GF2X_MUL(250, temp, 125, p_00+259, 125, f_sum+1);
	GF2X_MUL(250, temp2, 125, p_01+259, 125, g_sum+1);
	gf2x_add(250, temp, 250, temp, 250, temp2);
	gf2x_add(125, f_sum+765, 125, f_sum+765, 125, temp+125);
	right_bit_shift_n(253, f_sum+765, 32);
	GF2X_MUL(256, temp, 128, f_sum+126, 128, p_10+256);
	GF2X_MUL(256, temp2, 128, g_sum+126, 128, p_11+256);
	gf2x_add(253, g_sum+765, 253, temp+3, 253, temp2+3);
	GF2X_MUL(250, temp, 125, p_10+259, 125, f_sum+1);
	GF2X_MUL(250, temp2, 125, p_11+259, 125, g_sum+1);
	gf2x_add(250, temp, 250, temp, 250, temp2);
	gf2x_add(125, g_sum+765, 125, g_sum+765, 125, temp+125);
	right_bit_shift_n(253, g_sum+765, 32);
	
	delta = divstepsx_256(255, delta, f_sum+887, g_sum+887, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+887, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+887, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+883, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+883, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+887, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+887, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+883, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+883, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+883, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+883, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+875, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+875, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+883, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+883, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+875, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+875, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, p_00+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, p_01+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, p_10+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, p_11+480, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+875, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+875, 16, p_01+480);
	gf2x_add(32, f_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+859, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+859, 16, p_01+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, f_sum+1440, 16, f_sum+1440, 16, temp+16);
	right_bit_shift_n(32, f_sum+1440, 60);
	GF2X_MUL(32, temp, 16, f_sum+875, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+875, 16, p_11+480);
	gf2x_add(32, g_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+859, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+859, 16, p_11+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, g_sum+1440, 16, g_sum+1440, 16, temp+16);
	right_bit_shift_n(32, g_sum+1440, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1453, g_sum+1453, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1453, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1453, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1449, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1449, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, q_00+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, q_01+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, q_10+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, q_11+477, 16, temp, 16, temp2);
	
	// Recombining results: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_10+480);
	gf2x_add(32, p_00+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_11+480);
	gf2x_add(32, p_01+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_10+480);
	gf2x_add(32, p_10+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_11+480);
	gf2x_add(32, p_11+448, 32, temp, 32, temp2);
	
	// Calculating left operands: n: 4080, depth: 3
	GF2X_MUL(64, temp, 32, f_sum+859, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, g_sum+859, 32, p_01+448);
	gf2x_add(64, f_sum+1343, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, f_sum+827, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, g_sum+827, 32, p_01+448);
	gf2x_add(64, temp, 64, temp, 64, temp2);
	gf2x_add(32, f_sum+1343, 32, f_sum+1343, 32, temp+32);
	right_bit_shift_n(64, f_sum+1343, 56);
	GF2X_MUL(64, temp, 32, f_sum+859, 32, p_10+448);
	GF2X_MUL(64, temp2, 32, g_sum+859, 32, p_11+448);
	gf2x_add(64, g_sum+1343, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, f_sum+827, 32, p_10+448);
	GF2X_MUL(64, temp2, 32, g_sum+827, 32, p_11+448);
	gf2x_add(64, temp, 64, temp, 64, temp2);
	gf2x_add(32, g_sum+1343, 32, g_sum+1343, 32, temp+32);
	right_bit_shift_n(64, g_sum+1343, 56);
	
	delta = divstepsx_256(255, delta, f_sum+1372, g_sum+1372, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1372, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1372, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1368, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1368, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1372, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1372, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1368, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1368, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1368, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1368, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1360, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1360, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1368, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1368, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1360, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1360, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, p_00+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, p_01+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, p_10+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, p_11+480, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+1360, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1360, 16, p_01+480);
	gf2x_add(32, f_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1344, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1344, 16, p_01+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, f_sum+1440, 16, f_sum+1440, 16, temp+16);
	right_bit_shift_n(32, f_sum+1440, 60);
	GF2X_MUL(32, temp, 16, f_sum+1360, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1360, 16, p_11+480);
	gf2x_add(32, g_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1344, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1344, 16, p_11+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, g_sum+1440, 16, g_sum+1440, 16, temp+16);
	right_bit_shift_n(32, g_sum+1440, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1453, g_sum+1453, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1453, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1453, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1449, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1449, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, q_00+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, q_01+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, q_10+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, q_11+477, 16, temp, 16, temp2);
	
	// Recombining results: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_10+480);
	gf2x_add(32, q_00+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_11+480);
	gf2x_add(32, q_01+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_10+480);
	gf2x_add(32, q_10+445, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_11+480);
	gf2x_add(32, q_11+445, 32, temp, 32, temp2);
	
	// Recombining results: n: 4080, depth: 3
	GF2X_MUL(64, temp, 32, q_00+445, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, q_01+445, 32, p_10+448);
	gf2x_add(64, p_00+384, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_00+445, 32, p_01+448);
	GF2X_MUL(64, temp2, 32, q_01+445, 32, p_11+448);
	gf2x_add(64, p_01+384, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_10+445, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, q_11+445, 32, p_10+448);
	gf2x_add(64, p_10+384, 64, temp, 64, temp2);
	GF2X_MUL(64, temp, 32, q_10+445, 32, p_01+448);
	GF2X_MUL(64, temp2, 32, q_11+445, 32, p_11+448);
	gf2x_add(64, p_11+384, 64, temp, 64, temp2);
	
	// Calculating left operands: n: 7977, depth: 2
	GF2X_MUL(128, temp, 64, f_sum+827, 64, p_00+384);
	GF2X_MUL(128, temp2, 64, g_sum+827, 64, p_01+384);
	gf2x_add(125, f_sum+1150, 125, temp+3, 125, temp2+3);
	GF2X_MUL(122, temp, 61, p_00+387, 61, f_sum+766);
	GF2X_MUL(122, temp2, 61, p_01+387, 61, g_sum+766);
	gf2x_add(122, temp, 122, temp, 122, temp2);
	gf2x_add(61, f_sum+1150, 61, f_sum+1150, 61, temp+61);
	right_bit_shift_n(125, f_sum+1150, 48);
	GF2X_MUL(128, temp, 64, f_sum+827, 64, p_10+384);
	GF2X_MUL(128, temp2, 64, g_sum+827, 64, p_11+384);
	gf2x_add(125, g_sum+1150, 125, temp+3, 125, temp2+3);
	GF2X_MUL(122, temp, 61, p_10+387, 61, f_sum+766);
	GF2X_MUL(122, temp2, 61, p_11+387, 61, g_sum+766);
	gf2x_add(122, temp, 122, temp, 122, temp2);
	gf2x_add(61, g_sum+1150, 61, g_sum+1150, 61, temp+61);
	right_bit_shift_n(125, g_sum+1150, 48);
	
	delta = divstepsx_256(255, delta, f_sum+1208, g_sum+1208, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1208, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1208, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1204, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1204, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1208, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1208, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1204, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1204, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1204, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1204, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1196, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1196, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1204, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1204, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1196, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1196, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, p_00+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, p_01+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, p_10+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, p_11+480, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+1196, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1196, 16, p_01+480);
	gf2x_add(32, f_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1180, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1180, 16, p_01+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, f_sum+1440, 16, f_sum+1440, 16, temp+16);
	right_bit_shift_n(32, f_sum+1440, 60);
	GF2X_MUL(32, temp, 16, f_sum+1196, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1196, 16, p_11+480);
	gf2x_add(32, g_sum+1440, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f_sum+1180, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1180, 16, p_11+480);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, g_sum+1440, 16, g_sum+1440, 16, temp+16);
	right_bit_shift_n(32, g_sum+1440, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1453, g_sum+1453, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1453, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1453, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1453, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1449, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1449, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1449, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1449, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1449, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1441, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1441, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, q_00+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, q_01+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, q_10+477, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, q_11+477, 16, temp, 16, temp2);
	
	// Recombining results: n: 2040, depth: 4
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_10+480);
	gf2x_add(32, p_00+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_00+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_01+477, 16, p_11+480);
	gf2x_add(32, p_01+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_10+480);
	gf2x_add(32, p_10+448, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+477, 16, p_01+480);
	GF2X_MUL(32, temp2, 16, q_11+477, 16, p_11+480);
	gf2x_add(32, p_11+448, 32, temp, 32, temp2);
	
	// Calculating left operands: n: 3897, depth: 3
	GF2X_MUL(64, temp, 32, f_sum+1180, 32, p_00+448);
	GF2X_MUL(64, temp2, 32, g_sum+1180, 32, p_01+448);
	gf2x_add(62, f_sum+1343, 62, temp+2, 62, temp2+2);
	GF2X_MUL(58, temp, 29, p_00+451, 29, f_sum+1151);
	GF2X_MUL(58, temp2, 29, p_01+451, 29, g_sum+1151);
	gf2x_add(58, temp, 58, temp, 58, temp2);
	gf2x_add(30, f_sum+1343, 30, f_sum+1343, 30, temp+28);
	gf2x_mul_3_avx(temp, f_sum+1177, p_00+448);
	gf2x_mul_3_avx(temp2, g_sum+1177, p_01+448);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(1, f_sum+1343, 1, f_sum+1343, 1, temp+5);
	right_bit_shift_n(61, f_sum+1343, 56);
	GF2X_MUL(64, temp, 32, f_sum+1180, 32, p_10+448);
	GF2X_MUL(64, temp2, 32, g_sum+1180, 32, p_11+448);
	gf2x_add(62, g_sum+1343, 62, temp+2, 62, temp2+2);
	GF2X_MUL(58, temp, 29, p_10+451, 29, f_sum+1151);
	GF2X_MUL(58, temp2, 29, p_11+451, 29, g_sum+1151);
	gf2x_add(58, temp, 58, temp, 58, temp2);
	gf2x_add(30, g_sum+1343, 30, g_sum+1343, 30, temp+28);
	gf2x_mul_3_avx(temp, f_sum+1177, p_10+448);
	gf2x_mul_3_avx(temp2, g_sum+1177, p_11+448);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(1, g_sum+1343, 1, g_sum+1343, 1, temp+5);
	right_bit_shift_n(61, g_sum+1343, 56);
	
	delta = divstepsx_256(255, delta, f_sum+1370, g_sum+1370, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1370, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1370, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1366, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1366, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1370, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1370, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1366, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1366, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1366, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1366, p_01+496);
	gf2x_add(16, f_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1358, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1358, p_01+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+1489, 8, f_sum+1489, 8, temp+8);
	right_bit_shift_n(16, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1366, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1366, p_11+496);
	gf2x_add(16, g_sum+1489, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+1358, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1358, p_11+496);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+1489, 8, g_sum+1489, 8, temp+8);
	right_bit_shift_n(16, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1494, g_sum+1494, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1494, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1494, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1494, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1490, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1490, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, q_00+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, q_01+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, q_10+493, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, q_11+493, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 5
	gf2x_mul_8_avx(temp, q_00+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_10+496);
	gf2x_add(16, p_00+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_01+493, p_11+496);
	gf2x_add(16, p_01+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_00+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_10+496);
	gf2x_add(16, p_10+480, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+493, p_01+496);
	gf2x_mul_8_avx(temp2, q_11+493, p_11+496);
	gf2x_add(16, p_11+480, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1857, depth: 4
	GF2X_MUL(32, temp, 16, f_sum+1358, 16, p_00+480);
	GF2X_MUL(32, temp2, 16, g_sum+1358, 16, p_01+480);
	gf2x_add(30, f_sum+1440, 30, temp+2, 30, temp2+2);
	GF2X_MUL(28, temp, 14, p_00+482, 14, f_sum+1344);
	GF2X_MUL(28, temp2, 14, p_01+482, 14, g_sum+1344);
	gf2x_add(28, temp, 28, temp, 28, temp2);
	gf2x_add(14, f_sum+1440, 14, f_sum+1440, 14, temp+14);
	right_bit_shift_n(30, f_sum+1440, 60);
	GF2X_MUL(32, temp, 16, f_sum+1358, 16, p_10+480);
	GF2X_MUL(32, temp2, 16, g_sum+1358, 16, p_11+480);
	gf2x_add(30, g_sum+1440, 30, temp+2, 30, temp2+2);
	GF2X_MUL(28, temp, 14, p_10+482, 14, f_sum+1344);
	GF2X_MUL(28, temp2, 14, p_11+482, 14, g_sum+1344);
	gf2x_add(28, temp, 28, temp, 28, temp2);
	gf2x_add(14, g_sum+1440, 14, g_sum+1440, 14, temp+14);
	right_bit_shift_n(30, g_sum+1440, 60);
	
	delta = divstepsx_256(255, delta, f_sum+1451, g_sum+1451, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 510, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1451, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1451, p_01+504);
	gf2x_add(8, f_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1447, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1447, p_01+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+1514, 4, f_sum+1514, 4, temp+4);
	right_bit_shift_n(8, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1451, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1451, p_11+504);
	gf2x_add(8, g_sum+1514, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+1447, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1447, p_11+504);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+1514, 4, g_sum+1514, 4, temp+4);
	right_bit_shift_n(8, g_sum+1514, 63);
	
	delta = divstepsx_256(255, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 510, depth: 6
	gf2x_mul_4_avx(temp, q_00+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_10+504);
	gf2x_add(8, p_00+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_01+501, p_11+504);
	gf2x_add(8, p_01+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_00+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_10+504);
	gf2x_add(8, p_10+496, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+501, p_01+504);
	gf2x_mul_4_avx(temp2, q_11+501, p_11+504);
	gf2x_add(8, p_11+496, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 837, depth: 5
	gf2x_mul_8_avx(temp, f_sum+1447, p_00+496);
	gf2x_mul_8_avx(temp2, g_sum+1447, p_01+496);
	gf2x_add(14, f_sum+1489, 14, temp+2, 14, temp2+2);
	gf2x_mul_6_avx(temp, p_00+498, f_sum+1441);
	gf2x_mul_6_avx(temp2, p_01+498, g_sum+1441);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(6, f_sum+1489, 6, f_sum+1489, 6, temp+6);
	right_bit_shift_n(14, f_sum+1489, 62);
	gf2x_mul_8_avx(temp, f_sum+1447, p_10+496);
	gf2x_mul_8_avx(temp2, g_sum+1447, p_11+496);
	gf2x_add(14, g_sum+1489, 14, temp+2, 14, temp2+2);
	gf2x_mul_6_avx(temp, p_10+498, f_sum+1441);
	gf2x_mul_6_avx(temp2, p_11+498, g_sum+1441);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(6, g_sum+1489, 6, g_sum+1489, 6, temp+6);
	right_bit_shift_n(14, g_sum+1489, 62);
	
	delta = divstepsx_256(255, delta, f_sum+1492, g_sum+1492, p_00+504, p_01+504, p_10+504, p_11+504);

	// Calculating left operands: n: 327, depth: 6
	gf2x_mul_4_avx(temp, f_sum+1492, p_00+504);
	gf2x_mul_4_avx(temp2, g_sum+1492, p_01+504);
	gf2x_add(6, f_sum+1514, 6, temp+2, 6, temp2+2);
	gf2x_mul_2_avx(temp, p_00+506, f_sum+1490);
	gf2x_mul_2_avx(temp2, p_01+506, g_sum+1490);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(2, f_sum+1514, 2, f_sum+1514, 2, temp+2);
	right_bit_shift_n(6, f_sum+1514, 63);
	gf2x_mul_4_avx(temp, f_sum+1492, p_10+504);
	gf2x_mul_4_avx(temp2, g_sum+1492, p_11+504);
	gf2x_add(6, g_sum+1514, 6, temp+2, 6, temp2+2);
	gf2x_mul_2_avx(temp, p_10+506, f_sum+1490);
	gf2x_mul_2_avx(temp2, p_11+506, g_sum+1490);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(2, g_sum+1514, 2, g_sum+1514, 2, temp+2);
	right_bit_shift_n(6, g_sum+1514, 63);
	
	delta = divstepsx_128(72, delta, f_sum+1515, g_sum+1515, q_00+501, q_01+501, q_10+501, q_11+501);

	// Recombining results: n: 327, depth: 6
	memset(q_00+493, 0x00, 2*DIGIT_SIZE_B);
	gf2x_mul_2_avx(temp, p_00+506, q_00+501);
	gf2x_mul_2_avx(temp2, p_10+506, q_01+501);
	gf2x_add(4, q_00+495, 4, temp, 4, temp2);
	gf2x_mul_2_avx(temp, q_00+501, p_00+504);
	gf2x_mul_2_avx(temp2, q_01+501, p_10+504);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+493, 4, q_00+493, 4, temp);
	memset(q_01+493, 0x00, 2*DIGIT_SIZE_B);
	gf2x_mul_2_avx(temp, p_01+506, q_00+501);
	gf2x_mul_2_avx(temp2, p_11+506, q_01+501);
	gf2x_add(4, q_01+495, 4, temp, 4, temp2);
	gf2x_mul_2_avx(temp, q_00+501, p_01+504);
	gf2x_mul_2_avx(temp2, q_01+501, p_11+504);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+493, 4, q_01+493, 4, temp);
	memset(q_10+493, 0x00, 2*DIGIT_SIZE_B);
	gf2x_mul_2_avx(temp, p_00+506, q_10+501);
	gf2x_mul_2_avx(temp2, p_10+506, q_11+501);
	gf2x_add(4, q_10+495, 4, temp, 4, temp2);
	gf2x_mul_2_avx(temp, q_10+501, p_00+504);
	gf2x_mul_2_avx(temp2, q_11+501, p_10+504);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+493, 4, q_10+493, 4, temp);
	memset(q_11+493, 0x00, 2*DIGIT_SIZE_B);
	gf2x_mul_2_avx(temp, p_01+506, q_10+501);
	gf2x_mul_2_avx(temp2, p_11+506, q_11+501);
	gf2x_add(4, q_11+495, 4, temp, 4, temp2);
	gf2x_mul_2_avx(temp, q_10+501, p_01+504);
	gf2x_mul_2_avx(temp2, q_11+501, p_11+504);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+493, 4, q_11+493, 4, temp);
	
	// Recombining results: n: 837, depth: 5
	memset(q_00+477, 0x00, 2*DIGIT_SIZE_B);
	gf2x_mul_6_avx(temp, p_00+498, q_00+493);
	gf2x_mul_6_avx(temp2, p_10+498, q_01+493);
	gf2x_add(12, q_00+479, 12, temp, 12, temp2);
	gf2x_mul_2_avx(temp, q_00+497, p_00+496);
	gf2x_mul_2_avx(temp2, q_01+497, p_10+496);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+481, 4, q_00+481, 4, temp);
	gf2x_mul_2_avx(temp, q_00+495, p_00+496);
	gf2x_mul_2_avx(temp2, q_01+495, p_10+496);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+479, 4, q_00+479, 4, temp);
	gf2x_mul_2_avx(temp, q_00+493, p_00+496);
	gf2x_mul_2_avx(temp2, q_01+493, p_10+496);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+477, 4, q_00+477, 4, temp);
	memset(q_01+477, 0x00, 2*DIGIT_SIZE_B);
	gf2x_mul_6_avx(temp, p_01+498, q_00+493);
	gf2x_mul_6_avx(temp2, p_11+498, q_01+493);
	gf2x_add(12, q_01+479, 12, temp, 12, temp2);
	gf2x_mul_2_avx(temp, q_00+497, p_01+496);
	gf2x_mul_2_avx(temp2, q_01+497, p_11+496);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+481, 4, q_01+481, 4, temp);
	gf2x_mul_2_avx(temp, q_00+495, p_01+496);
	gf2x_mul_2_avx(temp2, q_01+495, p_11+496);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+479, 4, q_01+479, 4, temp);
	gf2x_mul_2_avx(temp, q_00+493, p_01+496);
	gf2x_mul_2_avx(temp2, q_01+493, p_11+496);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+477, 4, q_01+477, 4, temp);
	memset(q_10+477, 0x00, 2*DIGIT_SIZE_B);
	gf2x_mul_6_avx(temp, p_00+498, q_10+493);
	gf2x_mul_6_avx(temp2, p_10+498, q_11+493);
	gf2x_add(12, q_10+479, 12, temp, 12, temp2);
	gf2x_mul_2_avx(temp, q_10+497, p_00+496);
	gf2x_mul_2_avx(temp2, q_11+497, p_10+496);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+481, 4, q_10+481, 4, temp);
	gf2x_mul_2_avx(temp, q_10+495, p_00+496);
	gf2x_mul_2_avx(temp2, q_11+495, p_10+496);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+479, 4, q_10+479, 4, temp);
	gf2x_mul_2_avx(temp, q_10+493, p_00+496);
	gf2x_mul_2_avx(temp2, q_11+493, p_10+496);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+477, 4, q_10+477, 4, temp);
	memset(q_11+477, 0x00, 2*DIGIT_SIZE_B);
	gf2x_mul_6_avx(temp, p_01+498, q_10+493);
	gf2x_mul_6_avx(temp2, p_11+498, q_11+493);
	gf2x_add(12, q_11+479, 12, temp, 12, temp2);
	gf2x_mul_2_avx(temp, q_10+497, p_01+496);
	gf2x_mul_2_avx(temp2, q_11+497, p_11+496);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+481, 4, q_11+481, 4, temp);
	gf2x_mul_2_avx(temp, q_10+495, p_01+496);
	gf2x_mul_2_avx(temp2, q_11+495, p_11+496);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+479, 4, q_11+479, 4, temp);
	gf2x_mul_2_avx(temp, q_10+493, p_01+496);
	gf2x_mul_2_avx(temp2, q_11+493, p_11+496);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+477, 4, q_11+477, 4, temp);
	
	// Recombining results: n: 1857, depth: 4
	memset(q_00+445, 0x00, 2*DIGIT_SIZE_B);
	GF2X_MUL(28, temp, 14, p_00+482, 14, q_00+477);
	GF2X_MUL(28, temp2, 14, p_10+482, 14, q_01+477);
	gf2x_add(28, q_00+447, 28, temp, 28, temp2);
	gf2x_mul_2_avx(temp, q_00+489, p_00+480);
	gf2x_mul_2_avx(temp2, q_01+489, p_10+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+457, 4, q_00+457, 4, temp);
	gf2x_mul_2_avx(temp, q_00+487, p_00+480);
	gf2x_mul_2_avx(temp2, q_01+487, p_10+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+455, 4, q_00+455, 4, temp);
	gf2x_mul_2_avx(temp, q_00+485, p_00+480);
	gf2x_mul_2_avx(temp2, q_01+485, p_10+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+453, 4, q_00+453, 4, temp);
	gf2x_mul_2_avx(temp, q_00+483, p_00+480);
	gf2x_mul_2_avx(temp2, q_01+483, p_10+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+451, 4, q_00+451, 4, temp);
	gf2x_mul_2_avx(temp, q_00+481, p_00+480);
	gf2x_mul_2_avx(temp2, q_01+481, p_10+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+449, 4, q_00+449, 4, temp);
	gf2x_mul_2_avx(temp, q_00+479, p_00+480);
	gf2x_mul_2_avx(temp2, q_01+479, p_10+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+447, 4, q_00+447, 4, temp);
	gf2x_mul_2_avx(temp, q_00+477, p_00+480);
	gf2x_mul_2_avx(temp2, q_01+477, p_10+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+445, 4, q_00+445, 4, temp);
	memset(q_01+445, 0x00, 2*DIGIT_SIZE_B);
	GF2X_MUL(28, temp, 14, p_01+482, 14, q_00+477);
	GF2X_MUL(28, temp2, 14, p_11+482, 14, q_01+477);
	gf2x_add(28, q_01+447, 28, temp, 28, temp2);
	gf2x_mul_2_avx(temp, q_00+489, p_01+480);
	gf2x_mul_2_avx(temp2, q_01+489, p_11+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+457, 4, q_01+457, 4, temp);
	gf2x_mul_2_avx(temp, q_00+487, p_01+480);
	gf2x_mul_2_avx(temp2, q_01+487, p_11+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+455, 4, q_01+455, 4, temp);
	gf2x_mul_2_avx(temp, q_00+485, p_01+480);
	gf2x_mul_2_avx(temp2, q_01+485, p_11+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+453, 4, q_01+453, 4, temp);
	gf2x_mul_2_avx(temp, q_00+483, p_01+480);
	gf2x_mul_2_avx(temp2, q_01+483, p_11+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+451, 4, q_01+451, 4, temp);
	gf2x_mul_2_avx(temp, q_00+481, p_01+480);
	gf2x_mul_2_avx(temp2, q_01+481, p_11+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+449, 4, q_01+449, 4, temp);
	gf2x_mul_2_avx(temp, q_00+479, p_01+480);
	gf2x_mul_2_avx(temp2, q_01+479, p_11+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+447, 4, q_01+447, 4, temp);
	gf2x_mul_2_avx(temp, q_00+477, p_01+480);
	gf2x_mul_2_avx(temp2, q_01+477, p_11+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+445, 4, q_01+445, 4, temp);
	memset(q_10+445, 0x00, 2*DIGIT_SIZE_B);
	GF2X_MUL(28, temp, 14, p_00+482, 14, q_10+477);
	GF2X_MUL(28, temp2, 14, p_10+482, 14, q_11+477);
	gf2x_add(28, q_10+447, 28, temp, 28, temp2);
	gf2x_mul_2_avx(temp, q_10+489, p_00+480);
	gf2x_mul_2_avx(temp2, q_11+489, p_10+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+457, 4, q_10+457, 4, temp);
	gf2x_mul_2_avx(temp, q_10+487, p_00+480);
	gf2x_mul_2_avx(temp2, q_11+487, p_10+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+455, 4, q_10+455, 4, temp);
	gf2x_mul_2_avx(temp, q_10+485, p_00+480);
	gf2x_mul_2_avx(temp2, q_11+485, p_10+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+453, 4, q_10+453, 4, temp);
	gf2x_mul_2_avx(temp, q_10+483, p_00+480);
	gf2x_mul_2_avx(temp2, q_11+483, p_10+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+451, 4, q_10+451, 4, temp);
	gf2x_mul_2_avx(temp, q_10+481, p_00+480);
	gf2x_mul_2_avx(temp2, q_11+481, p_10+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+449, 4, q_10+449, 4, temp);
	gf2x_mul_2_avx(temp, q_10+479, p_00+480);
	gf2x_mul_2_avx(temp2, q_11+479, p_10+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+447, 4, q_10+447, 4, temp);
	gf2x_mul_2_avx(temp, q_10+477, p_00+480);
	gf2x_mul_2_avx(temp2, q_11+477, p_10+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+445, 4, q_10+445, 4, temp);
	memset(q_11+445, 0x00, 2*DIGIT_SIZE_B);
	GF2X_MUL(28, temp, 14, p_01+482, 14, q_10+477);
	GF2X_MUL(28, temp2, 14, p_11+482, 14, q_11+477);
	gf2x_add(28, q_11+447, 28, temp, 28, temp2);
	gf2x_mul_2_avx(temp, q_10+489, p_01+480);
	gf2x_mul_2_avx(temp2, q_11+489, p_11+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+457, 4, q_11+457, 4, temp);
	gf2x_mul_2_avx(temp, q_10+487, p_01+480);
	gf2x_mul_2_avx(temp2, q_11+487, p_11+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+455, 4, q_11+455, 4, temp);
	gf2x_mul_2_avx(temp, q_10+485, p_01+480);
	gf2x_mul_2_avx(temp2, q_11+485, p_11+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+453, 4, q_11+453, 4, temp);
	gf2x_mul_2_avx(temp, q_10+483, p_01+480);
	gf2x_mul_2_avx(temp2, q_11+483, p_11+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+451, 4, q_11+451, 4, temp);
	gf2x_mul_2_avx(temp, q_10+481, p_01+480);
	gf2x_mul_2_avx(temp2, q_11+481, p_11+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+449, 4, q_11+449, 4, temp);
	gf2x_mul_2_avx(temp, q_10+479, p_01+480);
	gf2x_mul_2_avx(temp2, q_11+479, p_11+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+447, 4, q_11+447, 4, temp);
	gf2x_mul_2_avx(temp, q_10+477, p_01+480);
	gf2x_mul_2_avx(temp2, q_11+477, p_11+480);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+445, 4, q_11+445, 4, temp);
	
	// Recombining results: n: 3897, depth: 3
	memset(q_00+381, 0x00, 1*DIGIT_SIZE_B);
	GF2X_MUL(60, temp, 30, p_00+450, 30, q_00+445);
	GF2X_MUL(60, temp2, 30, p_10+450, 30, q_01+445);
	gf2x_add(60, q_00+382, 60, temp, 60, temp2);
	gf2x_mul_2_avx(temp, q_00+473, p_00+448);
	gf2x_mul_2_avx(temp2, q_01+473, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+408, 4, q_00+408, 4, temp);
	gf2x_mul_2_avx(temp, q_00+471, p_00+448);
	gf2x_mul_2_avx(temp2, q_01+471, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+406, 4, q_00+406, 4, temp);
	gf2x_mul_2_avx(temp, q_00+469, p_00+448);
	gf2x_mul_2_avx(temp2, q_01+469, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+404, 4, q_00+404, 4, temp);
	gf2x_mul_2_avx(temp, q_00+467, p_00+448);
	gf2x_mul_2_avx(temp2, q_01+467, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+402, 4, q_00+402, 4, temp);
	gf2x_mul_2_avx(temp, q_00+465, p_00+448);
	gf2x_mul_2_avx(temp2, q_01+465, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+400, 4, q_00+400, 4, temp);
	gf2x_mul_2_avx(temp, q_00+463, p_00+448);
	gf2x_mul_2_avx(temp2, q_01+463, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+398, 4, q_00+398, 4, temp);
	gf2x_mul_2_avx(temp, q_00+461, p_00+448);
	gf2x_mul_2_avx(temp2, q_01+461, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+396, 4, q_00+396, 4, temp);
	gf2x_mul_2_avx(temp, q_00+459, p_00+448);
	gf2x_mul_2_avx(temp2, q_01+459, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+394, 4, q_00+394, 4, temp);
	gf2x_mul_2_avx(temp, q_00+457, p_00+448);
	gf2x_mul_2_avx(temp2, q_01+457, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+392, 4, q_00+392, 4, temp);
	gf2x_mul_2_avx(temp, q_00+455, p_00+448);
	gf2x_mul_2_avx(temp2, q_01+455, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+390, 4, q_00+390, 4, temp);
	gf2x_mul_2_avx(temp, q_00+453, p_00+448);
	gf2x_mul_2_avx(temp2, q_01+453, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+388, 4, q_00+388, 4, temp);
	gf2x_mul_2_avx(temp, q_00+451, p_00+448);
	gf2x_mul_2_avx(temp2, q_01+451, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+386, 4, q_00+386, 4, temp);
	gf2x_mul_2_avx(temp, q_00+449, p_00+448);
	gf2x_mul_2_avx(temp2, q_01+449, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+384, 4, q_00+384, 4, temp);
	gf2x_mul_2_avx(temp, q_00+447, p_00+448);
	gf2x_mul_2_avx(temp2, q_01+447, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+382, 4, q_00+382, 4, temp);
	gf2x_mul_2_avx(temp, q_00+445, p_00+448);
	gf2x_mul_2_avx(temp2, q_01+445, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(3, q_00+381, 3, q_00+381, 3, temp+1);
	memset(q_01+381, 0x00, 1*DIGIT_SIZE_B);
	GF2X_MUL(60, temp, 30, p_01+450, 30, q_00+445);
	GF2X_MUL(60, temp2, 30, p_11+450, 30, q_01+445);
	gf2x_add(60, q_01+382, 60, temp, 60, temp2);
	gf2x_mul_2_avx(temp, q_00+473, p_01+448);
	gf2x_mul_2_avx(temp2, q_01+473, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+408, 4, q_01+408, 4, temp);
	gf2x_mul_2_avx(temp, q_00+471, p_01+448);
	gf2x_mul_2_avx(temp2, q_01+471, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+406, 4, q_01+406, 4, temp);
	gf2x_mul_2_avx(temp, q_00+469, p_01+448);
	gf2x_mul_2_avx(temp2, q_01+469, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+404, 4, q_01+404, 4, temp);
	gf2x_mul_2_avx(temp, q_00+467, p_01+448);
	gf2x_mul_2_avx(temp2, q_01+467, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+402, 4, q_01+402, 4, temp);
	gf2x_mul_2_avx(temp, q_00+465, p_01+448);
	gf2x_mul_2_avx(temp2, q_01+465, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+400, 4, q_01+400, 4, temp);
	gf2x_mul_2_avx(temp, q_00+463, p_01+448);
	gf2x_mul_2_avx(temp2, q_01+463, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+398, 4, q_01+398, 4, temp);
	gf2x_mul_2_avx(temp, q_00+461, p_01+448);
	gf2x_mul_2_avx(temp2, q_01+461, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+396, 4, q_01+396, 4, temp);
	gf2x_mul_2_avx(temp, q_00+459, p_01+448);
	gf2x_mul_2_avx(temp2, q_01+459, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+394, 4, q_01+394, 4, temp);
	gf2x_mul_2_avx(temp, q_00+457, p_01+448);
	gf2x_mul_2_avx(temp2, q_01+457, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+392, 4, q_01+392, 4, temp);
	gf2x_mul_2_avx(temp, q_00+455, p_01+448);
	gf2x_mul_2_avx(temp2, q_01+455, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+390, 4, q_01+390, 4, temp);
	gf2x_mul_2_avx(temp, q_00+453, p_01+448);
	gf2x_mul_2_avx(temp2, q_01+453, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+388, 4, q_01+388, 4, temp);
	gf2x_mul_2_avx(temp, q_00+451, p_01+448);
	gf2x_mul_2_avx(temp2, q_01+451, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+386, 4, q_01+386, 4, temp);
	gf2x_mul_2_avx(temp, q_00+449, p_01+448);
	gf2x_mul_2_avx(temp2, q_01+449, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+384, 4, q_01+384, 4, temp);
	gf2x_mul_2_avx(temp, q_00+447, p_01+448);
	gf2x_mul_2_avx(temp2, q_01+447, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+382, 4, q_01+382, 4, temp);
	gf2x_mul_2_avx(temp, q_00+445, p_01+448);
	gf2x_mul_2_avx(temp2, q_01+445, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(3, q_01+381, 3, q_01+381, 3, temp+1);
	memset(q_10+381, 0x00, 1*DIGIT_SIZE_B);
	GF2X_MUL(60, temp, 30, p_00+450, 30, q_10+445);
	GF2X_MUL(60, temp2, 30, p_10+450, 30, q_11+445);
	gf2x_add(60, q_10+382, 60, temp, 60, temp2);
	gf2x_mul_2_avx(temp, q_10+473, p_00+448);
	gf2x_mul_2_avx(temp2, q_11+473, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+408, 4, q_10+408, 4, temp);
	gf2x_mul_2_avx(temp, q_10+471, p_00+448);
	gf2x_mul_2_avx(temp2, q_11+471, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+406, 4, q_10+406, 4, temp);
	gf2x_mul_2_avx(temp, q_10+469, p_00+448);
	gf2x_mul_2_avx(temp2, q_11+469, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+404, 4, q_10+404, 4, temp);
	gf2x_mul_2_avx(temp, q_10+467, p_00+448);
	gf2x_mul_2_avx(temp2, q_11+467, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+402, 4, q_10+402, 4, temp);
	gf2x_mul_2_avx(temp, q_10+465, p_00+448);
	gf2x_mul_2_avx(temp2, q_11+465, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+400, 4, q_10+400, 4, temp);
	gf2x_mul_2_avx(temp, q_10+463, p_00+448);
	gf2x_mul_2_avx(temp2, q_11+463, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+398, 4, q_10+398, 4, temp);
	gf2x_mul_2_avx(temp, q_10+461, p_00+448);
	gf2x_mul_2_avx(temp2, q_11+461, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+396, 4, q_10+396, 4, temp);
	gf2x_mul_2_avx(temp, q_10+459, p_00+448);
	gf2x_mul_2_avx(temp2, q_11+459, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+394, 4, q_10+394, 4, temp);
	gf2x_mul_2_avx(temp, q_10+457, p_00+448);
	gf2x_mul_2_avx(temp2, q_11+457, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+392, 4, q_10+392, 4, temp);
	gf2x_mul_2_avx(temp, q_10+455, p_00+448);
	gf2x_mul_2_avx(temp2, q_11+455, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+390, 4, q_10+390, 4, temp);
	gf2x_mul_2_avx(temp, q_10+453, p_00+448);
	gf2x_mul_2_avx(temp2, q_11+453, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+388, 4, q_10+388, 4, temp);
	gf2x_mul_2_avx(temp, q_10+451, p_00+448);
	gf2x_mul_2_avx(temp2, q_11+451, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+386, 4, q_10+386, 4, temp);
	gf2x_mul_2_avx(temp, q_10+449, p_00+448);
	gf2x_mul_2_avx(temp2, q_11+449, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+384, 4, q_10+384, 4, temp);
	gf2x_mul_2_avx(temp, q_10+447, p_00+448);
	gf2x_mul_2_avx(temp2, q_11+447, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+382, 4, q_10+382, 4, temp);
	gf2x_mul_2_avx(temp, q_10+445, p_00+448);
	gf2x_mul_2_avx(temp2, q_11+445, p_10+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(3, q_10+381, 3, q_10+381, 3, temp+1);
	memset(q_11+381, 0x00, 1*DIGIT_SIZE_B);
	GF2X_MUL(60, temp, 30, p_01+450, 30, q_10+445);
	GF2X_MUL(60, temp2, 30, p_11+450, 30, q_11+445);
	gf2x_add(60, q_11+382, 60, temp, 60, temp2);
	gf2x_mul_2_avx(temp, q_10+473, p_01+448);
	gf2x_mul_2_avx(temp2, q_11+473, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+408, 4, q_11+408, 4, temp);
	gf2x_mul_2_avx(temp, q_10+471, p_01+448);
	gf2x_mul_2_avx(temp2, q_11+471, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+406, 4, q_11+406, 4, temp);
	gf2x_mul_2_avx(temp, q_10+469, p_01+448);
	gf2x_mul_2_avx(temp2, q_11+469, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+404, 4, q_11+404, 4, temp);
	gf2x_mul_2_avx(temp, q_10+467, p_01+448);
	gf2x_mul_2_avx(temp2, q_11+467, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+402, 4, q_11+402, 4, temp);
	gf2x_mul_2_avx(temp, q_10+465, p_01+448);
	gf2x_mul_2_avx(temp2, q_11+465, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+400, 4, q_11+400, 4, temp);
	gf2x_mul_2_avx(temp, q_10+463, p_01+448);
	gf2x_mul_2_avx(temp2, q_11+463, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+398, 4, q_11+398, 4, temp);
	gf2x_mul_2_avx(temp, q_10+461, p_01+448);
	gf2x_mul_2_avx(temp2, q_11+461, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+396, 4, q_11+396, 4, temp);
	gf2x_mul_2_avx(temp, q_10+459, p_01+448);
	gf2x_mul_2_avx(temp2, q_11+459, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+394, 4, q_11+394, 4, temp);
	gf2x_mul_2_avx(temp, q_10+457, p_01+448);
	gf2x_mul_2_avx(temp2, q_11+457, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+392, 4, q_11+392, 4, temp);
	gf2x_mul_2_avx(temp, q_10+455, p_01+448);
	gf2x_mul_2_avx(temp2, q_11+455, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+390, 4, q_11+390, 4, temp);
	gf2x_mul_2_avx(temp, q_10+453, p_01+448);
	gf2x_mul_2_avx(temp2, q_11+453, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+388, 4, q_11+388, 4, temp);
	gf2x_mul_2_avx(temp, q_10+451, p_01+448);
	gf2x_mul_2_avx(temp2, q_11+451, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+386, 4, q_11+386, 4, temp);
	gf2x_mul_2_avx(temp, q_10+449, p_01+448);
	gf2x_mul_2_avx(temp2, q_11+449, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+384, 4, q_11+384, 4, temp);
	gf2x_mul_2_avx(temp, q_10+447, p_01+448);
	gf2x_mul_2_avx(temp2, q_11+447, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+382, 4, q_11+382, 4, temp);
	gf2x_mul_2_avx(temp, q_10+445, p_01+448);
	gf2x_mul_2_avx(temp2, q_11+445, p_11+448);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(3, q_11+381, 3, q_11+381, 3, temp+1);
	
	// Recombining results: n: 7977, depth: 2
	memset(q_00+253, 0x00, 3*DIGIT_SIZE_B);
	GF2X_MUL(122, temp, 61, p_00+387, 61, q_00+381);
	GF2X_MUL(122, temp2, 61, p_10+387, 61, q_01+381);
	gf2x_add(122, q_00+256, 122, temp, 122, temp2);
	gf2x_mul_3_avx(temp, q_00+439, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+439, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+311, 6, q_00+311, 6, temp);
	gf2x_mul_3_avx(temp, q_00+436, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+436, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+308, 6, q_00+308, 6, temp);
	gf2x_mul_3_avx(temp, q_00+433, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+433, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+305, 6, q_00+305, 6, temp);
	gf2x_mul_3_avx(temp, q_00+430, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+430, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+302, 6, q_00+302, 6, temp);
	gf2x_mul_3_avx(temp, q_00+427, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+427, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+299, 6, q_00+299, 6, temp);
	gf2x_mul_3_avx(temp, q_00+424, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+424, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+296, 6, q_00+296, 6, temp);
	gf2x_mul_3_avx(temp, q_00+421, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+421, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+293, 6, q_00+293, 6, temp);
	gf2x_mul_3_avx(temp, q_00+418, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+418, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+290, 6, q_00+290, 6, temp);
	gf2x_mul_3_avx(temp, q_00+415, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+415, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+287, 6, q_00+287, 6, temp);
	gf2x_mul_3_avx(temp, q_00+412, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+412, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+284, 6, q_00+284, 6, temp);
	gf2x_mul_3_avx(temp, q_00+409, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+409, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+281, 6, q_00+281, 6, temp);
	gf2x_mul_3_avx(temp, q_00+406, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+406, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+278, 6, q_00+278, 6, temp);
	gf2x_mul_3_avx(temp, q_00+403, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+403, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+275, 6, q_00+275, 6, temp);
	gf2x_mul_3_avx(temp, q_00+400, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+400, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+272, 6, q_00+272, 6, temp);
	gf2x_mul_3_avx(temp, q_00+397, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+397, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+269, 6, q_00+269, 6, temp);
	gf2x_mul_3_avx(temp, q_00+394, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+394, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+266, 6, q_00+266, 6, temp);
	gf2x_mul_3_avx(temp, q_00+391, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+391, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+263, 6, q_00+263, 6, temp);
	gf2x_mul_3_avx(temp, q_00+388, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+388, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+260, 6, q_00+260, 6, temp);
	gf2x_mul_3_avx(temp, q_00+385, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+385, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+257, 6, q_00+257, 6, temp);
	gf2x_mul_3_avx(temp, q_00+382, p_00+384);
	gf2x_mul_3_avx(temp2, q_01+382, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+254, 6, q_00+254, 6, temp);
	gf2x_mul_1_avx(temp, p_00+386, q_00+381);
	gf2x_mul_1_avx(temp2, p_10+386, q_01+381);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+255, 2, q_00+255, 2, temp);
	gf2x_mul_1_avx(temp, p_00+385, q_00+381);
	gf2x_mul_1_avx(temp2, p_10+385, q_01+381);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+254, 2, q_00+254, 2, temp);
	gf2x_mul_1_avx(temp, q_00+381, p_00+384);
	gf2x_mul_1_avx(temp2, q_01+381, p_10+384);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+253, 2, q_00+253, 2, temp);
	memset(q_01+253, 0x00, 3*DIGIT_SIZE_B);
	GF2X_MUL(122, temp, 61, p_01+387, 61, q_00+381);
	GF2X_MUL(122, temp2, 61, p_11+387, 61, q_01+381);
	gf2x_add(122, q_01+256, 122, temp, 122, temp2);
	gf2x_mul_3_avx(temp, q_00+439, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+439, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+311, 6, q_01+311, 6, temp);
	gf2x_mul_3_avx(temp, q_00+436, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+436, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+308, 6, q_01+308, 6, temp);
	gf2x_mul_3_avx(temp, q_00+433, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+433, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+305, 6, q_01+305, 6, temp);
	gf2x_mul_3_avx(temp, q_00+430, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+430, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+302, 6, q_01+302, 6, temp);
	gf2x_mul_3_avx(temp, q_00+427, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+427, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+299, 6, q_01+299, 6, temp);
	gf2x_mul_3_avx(temp, q_00+424, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+424, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+296, 6, q_01+296, 6, temp);
	gf2x_mul_3_avx(temp, q_00+421, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+421, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+293, 6, q_01+293, 6, temp);
	gf2x_mul_3_avx(temp, q_00+418, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+418, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+290, 6, q_01+290, 6, temp);
	gf2x_mul_3_avx(temp, q_00+415, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+415, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+287, 6, q_01+287, 6, temp);
	gf2x_mul_3_avx(temp, q_00+412, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+412, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+284, 6, q_01+284, 6, temp);
	gf2x_mul_3_avx(temp, q_00+409, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+409, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+281, 6, q_01+281, 6, temp);
	gf2x_mul_3_avx(temp, q_00+406, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+406, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+278, 6, q_01+278, 6, temp);
	gf2x_mul_3_avx(temp, q_00+403, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+403, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+275, 6, q_01+275, 6, temp);
	gf2x_mul_3_avx(temp, q_00+400, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+400, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+272, 6, q_01+272, 6, temp);
	gf2x_mul_3_avx(temp, q_00+397, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+397, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+269, 6, q_01+269, 6, temp);
	gf2x_mul_3_avx(temp, q_00+394, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+394, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+266, 6, q_01+266, 6, temp);
	gf2x_mul_3_avx(temp, q_00+391, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+391, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+263, 6, q_01+263, 6, temp);
	gf2x_mul_3_avx(temp, q_00+388, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+388, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+260, 6, q_01+260, 6, temp);
	gf2x_mul_3_avx(temp, q_00+385, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+385, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+257, 6, q_01+257, 6, temp);
	gf2x_mul_3_avx(temp, q_00+382, p_01+384);
	gf2x_mul_3_avx(temp2, q_01+382, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+254, 6, q_01+254, 6, temp);
	gf2x_mul_1_avx(temp, p_01+386, q_00+381);
	gf2x_mul_1_avx(temp2, p_11+386, q_01+381);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+255, 2, q_01+255, 2, temp);
	gf2x_mul_1_avx(temp, p_01+385, q_00+381);
	gf2x_mul_1_avx(temp2, p_11+385, q_01+381);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+254, 2, q_01+254, 2, temp);
	gf2x_mul_1_avx(temp, q_00+381, p_01+384);
	gf2x_mul_1_avx(temp2, q_01+381, p_11+384);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+253, 2, q_01+253, 2, temp);
	memset(q_10+253, 0x00, 3*DIGIT_SIZE_B);
	GF2X_MUL(122, temp, 61, p_00+387, 61, q_10+381);
	GF2X_MUL(122, temp2, 61, p_10+387, 61, q_11+381);
	gf2x_add(122, q_10+256, 122, temp, 122, temp2);
	gf2x_mul_3_avx(temp, q_10+439, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+439, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+311, 6, q_10+311, 6, temp);
	gf2x_mul_3_avx(temp, q_10+436, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+436, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+308, 6, q_10+308, 6, temp);
	gf2x_mul_3_avx(temp, q_10+433, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+433, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+305, 6, q_10+305, 6, temp);
	gf2x_mul_3_avx(temp, q_10+430, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+430, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+302, 6, q_10+302, 6, temp);
	gf2x_mul_3_avx(temp, q_10+427, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+427, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+299, 6, q_10+299, 6, temp);
	gf2x_mul_3_avx(temp, q_10+424, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+424, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+296, 6, q_10+296, 6, temp);
	gf2x_mul_3_avx(temp, q_10+421, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+421, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+293, 6, q_10+293, 6, temp);
	gf2x_mul_3_avx(temp, q_10+418, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+418, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+290, 6, q_10+290, 6, temp);
	gf2x_mul_3_avx(temp, q_10+415, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+415, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+287, 6, q_10+287, 6, temp);
	gf2x_mul_3_avx(temp, q_10+412, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+412, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+284, 6, q_10+284, 6, temp);
	gf2x_mul_3_avx(temp, q_10+409, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+409, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+281, 6, q_10+281, 6, temp);
	gf2x_mul_3_avx(temp, q_10+406, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+406, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+278, 6, q_10+278, 6, temp);
	gf2x_mul_3_avx(temp, q_10+403, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+403, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+275, 6, q_10+275, 6, temp);
	gf2x_mul_3_avx(temp, q_10+400, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+400, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+272, 6, q_10+272, 6, temp);
	gf2x_mul_3_avx(temp, q_10+397, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+397, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+269, 6, q_10+269, 6, temp);
	gf2x_mul_3_avx(temp, q_10+394, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+394, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+266, 6, q_10+266, 6, temp);
	gf2x_mul_3_avx(temp, q_10+391, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+391, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+263, 6, q_10+263, 6, temp);
	gf2x_mul_3_avx(temp, q_10+388, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+388, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+260, 6, q_10+260, 6, temp);
	gf2x_mul_3_avx(temp, q_10+385, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+385, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+257, 6, q_10+257, 6, temp);
	gf2x_mul_3_avx(temp, q_10+382, p_00+384);
	gf2x_mul_3_avx(temp2, q_11+382, p_10+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+254, 6, q_10+254, 6, temp);
	gf2x_mul_1_avx(temp, p_00+386, q_10+381);
	gf2x_mul_1_avx(temp2, p_10+386, q_11+381);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+255, 2, q_10+255, 2, temp);
	gf2x_mul_1_avx(temp, p_00+385, q_10+381);
	gf2x_mul_1_avx(temp2, p_10+385, q_11+381);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+254, 2, q_10+254, 2, temp);
	gf2x_mul_1_avx(temp, q_10+381, p_00+384);
	gf2x_mul_1_avx(temp2, q_11+381, p_10+384);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+253, 2, q_10+253, 2, temp);
	memset(q_11+253, 0x00, 3*DIGIT_SIZE_B);
	GF2X_MUL(122, temp, 61, p_01+387, 61, q_10+381);
	GF2X_MUL(122, temp2, 61, p_11+387, 61, q_11+381);
	gf2x_add(122, q_11+256, 122, temp, 122, temp2);
	gf2x_mul_3_avx(temp, q_10+439, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+439, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+311, 6, q_11+311, 6, temp);
	gf2x_mul_3_avx(temp, q_10+436, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+436, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+308, 6, q_11+308, 6, temp);
	gf2x_mul_3_avx(temp, q_10+433, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+433, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+305, 6, q_11+305, 6, temp);
	gf2x_mul_3_avx(temp, q_10+430, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+430, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+302, 6, q_11+302, 6, temp);
	gf2x_mul_3_avx(temp, q_10+427, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+427, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+299, 6, q_11+299, 6, temp);
	gf2x_mul_3_avx(temp, q_10+424, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+424, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+296, 6, q_11+296, 6, temp);
	gf2x_mul_3_avx(temp, q_10+421, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+421, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+293, 6, q_11+293, 6, temp);
	gf2x_mul_3_avx(temp, q_10+418, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+418, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+290, 6, q_11+290, 6, temp);
	gf2x_mul_3_avx(temp, q_10+415, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+415, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+287, 6, q_11+287, 6, temp);
	gf2x_mul_3_avx(temp, q_10+412, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+412, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+284, 6, q_11+284, 6, temp);
	gf2x_mul_3_avx(temp, q_10+409, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+409, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+281, 6, q_11+281, 6, temp);
	gf2x_mul_3_avx(temp, q_10+406, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+406, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+278, 6, q_11+278, 6, temp);
	gf2x_mul_3_avx(temp, q_10+403, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+403, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+275, 6, q_11+275, 6, temp);
	gf2x_mul_3_avx(temp, q_10+400, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+400, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+272, 6, q_11+272, 6, temp);
	gf2x_mul_3_avx(temp, q_10+397, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+397, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+269, 6, q_11+269, 6, temp);
	gf2x_mul_3_avx(temp, q_10+394, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+394, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+266, 6, q_11+266, 6, temp);
	gf2x_mul_3_avx(temp, q_10+391, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+391, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+263, 6, q_11+263, 6, temp);
	gf2x_mul_3_avx(temp, q_10+388, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+388, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+260, 6, q_11+260, 6, temp);
	gf2x_mul_3_avx(temp, q_10+385, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+385, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+257, 6, q_11+257, 6, temp);
	gf2x_mul_3_avx(temp, q_10+382, p_01+384);
	gf2x_mul_3_avx(temp2, q_11+382, p_11+384);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+254, 6, q_11+254, 6, temp);
	gf2x_mul_1_avx(temp, p_01+386, q_10+381);
	gf2x_mul_1_avx(temp2, p_11+386, q_11+381);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+255, 2, q_11+255, 2, temp);
	gf2x_mul_1_avx(temp, p_01+385, q_10+381);
	gf2x_mul_1_avx(temp2, p_11+385, q_11+381);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+254, 2, q_11+254, 2, temp);
	gf2x_mul_1_avx(temp, q_10+381, p_01+384);
	gf2x_mul_1_avx(temp2, q_11+381, p_11+384);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+253, 2, q_11+253, 2, temp);
	
	// Recombining results: n: 16137, depth: 1
	memset(q_00+0, 0x00, 3*DIGIT_SIZE_B);
	GF2X_MUL(250, temp, 125, p_00+259, 125, q_00+253);
	GF2X_MUL(250, temp2, 125, p_10+259, 125, q_01+253);
	gf2x_add(250, q_00+3, 250, temp, 250, temp2);
	gf2x_mul_3_avx(temp, q_00+375, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+375, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+122, 6, q_00+122, 6, temp);
	gf2x_mul_3_avx(temp, q_00+372, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+372, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+119, 6, q_00+119, 6, temp);
	gf2x_mul_3_avx(temp, q_00+369, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+369, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+116, 6, q_00+116, 6, temp);
	gf2x_mul_3_avx(temp, q_00+366, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+366, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+113, 6, q_00+113, 6, temp);
	gf2x_mul_3_avx(temp, q_00+363, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+363, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+110, 6, q_00+110, 6, temp);
	gf2x_mul_3_avx(temp, q_00+360, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+360, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+107, 6, q_00+107, 6, temp);
	gf2x_mul_3_avx(temp, q_00+357, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+357, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+104, 6, q_00+104, 6, temp);
	gf2x_mul_3_avx(temp, q_00+354, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+354, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+101, 6, q_00+101, 6, temp);
	gf2x_mul_3_avx(temp, q_00+351, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+351, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+98, 6, q_00+98, 6, temp);
	gf2x_mul_3_avx(temp, q_00+348, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+348, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+95, 6, q_00+95, 6, temp);
	gf2x_mul_3_avx(temp, q_00+345, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+345, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+92, 6, q_00+92, 6, temp);
	gf2x_mul_3_avx(temp, q_00+342, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+342, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+89, 6, q_00+89, 6, temp);
	gf2x_mul_3_avx(temp, q_00+339, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+339, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+86, 6, q_00+86, 6, temp);
	gf2x_mul_3_avx(temp, q_00+336, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+336, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+83, 6, q_00+83, 6, temp);
	gf2x_mul_3_avx(temp, q_00+333, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+333, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+80, 6, q_00+80, 6, temp);
	gf2x_mul_3_avx(temp, q_00+330, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+330, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+77, 6, q_00+77, 6, temp);
	gf2x_mul_3_avx(temp, q_00+327, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+327, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+74, 6, q_00+74, 6, temp);
	gf2x_mul_3_avx(temp, q_00+324, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+324, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+71, 6, q_00+71, 6, temp);
	gf2x_mul_3_avx(temp, q_00+321, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+321, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+68, 6, q_00+68, 6, temp);
	gf2x_mul_3_avx(temp, q_00+318, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+318, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+65, 6, q_00+65, 6, temp);
	gf2x_mul_3_avx(temp, q_00+315, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+315, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+62, 6, q_00+62, 6, temp);
	gf2x_mul_3_avx(temp, q_00+312, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+312, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+59, 6, q_00+59, 6, temp);
	gf2x_mul_3_avx(temp, q_00+309, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+309, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+56, 6, q_00+56, 6, temp);
	gf2x_mul_3_avx(temp, q_00+306, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+306, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+53, 6, q_00+53, 6, temp);
	gf2x_mul_3_avx(temp, q_00+303, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+303, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+50, 6, q_00+50, 6, temp);
	gf2x_mul_3_avx(temp, q_00+300, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+300, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+47, 6, q_00+47, 6, temp);
	gf2x_mul_3_avx(temp, q_00+297, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+297, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+44, 6, q_00+44, 6, temp);
	gf2x_mul_3_avx(temp, q_00+294, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+294, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+41, 6, q_00+41, 6, temp);
	gf2x_mul_3_avx(temp, q_00+291, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+291, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+38, 6, q_00+38, 6, temp);
	gf2x_mul_3_avx(temp, q_00+288, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+288, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+35, 6, q_00+35, 6, temp);
	gf2x_mul_3_avx(temp, q_00+285, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+285, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+32, 6, q_00+32, 6, temp);
	gf2x_mul_3_avx(temp, q_00+282, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+282, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+29, 6, q_00+29, 6, temp);
	gf2x_mul_3_avx(temp, q_00+279, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+279, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+26, 6, q_00+26, 6, temp);
	gf2x_mul_3_avx(temp, q_00+276, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+276, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+23, 6, q_00+23, 6, temp);
	gf2x_mul_3_avx(temp, q_00+273, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+273, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+20, 6, q_00+20, 6, temp);
	gf2x_mul_3_avx(temp, q_00+270, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+270, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+17, 6, q_00+17, 6, temp);
	gf2x_mul_3_avx(temp, q_00+267, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+267, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+14, 6, q_00+14, 6, temp);
	gf2x_mul_3_avx(temp, q_00+264, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+264, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+11, 6, q_00+11, 6, temp);
	gf2x_mul_3_avx(temp, q_00+261, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+261, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+8, 6, q_00+8, 6, temp);
	gf2x_mul_3_avx(temp, q_00+258, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+258, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+5, 6, q_00+5, 6, temp);
	gf2x_mul_3_avx(temp, q_00+255, p_00+256);
	gf2x_mul_3_avx(temp2, q_01+255, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_00+2, 6, q_00+2, 6, temp);
	gf2x_mul_2_avx(temp, p_00+257, q_00+253);
	gf2x_mul_2_avx(temp2, p_10+257, q_01+253);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+1, 4, q_00+1, 4, temp);
	gf2x_mul_1_avx(temp, q_00+254, p_00+256);
	gf2x_mul_1_avx(temp2, q_01+254, p_10+256);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+1, 2, q_00+1, 2, temp);
	gf2x_mul_1_avx(temp, q_00+253, p_00+256);
	gf2x_mul_1_avx(temp2, q_01+253, p_10+256);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_00+0, 2, q_00+0, 2, temp);
	memset(q_01+0, 0x00, 3*DIGIT_SIZE_B);
	GF2X_MUL(250, temp, 125, p_01+259, 125, q_00+253);
	GF2X_MUL(250, temp2, 125, p_11+259, 125, q_01+253);
	gf2x_add(250, q_01+3, 250, temp, 250, temp2);
	gf2x_mul_3_avx(temp, q_00+375, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+375, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+122, 6, q_01+122, 6, temp);
	gf2x_mul_3_avx(temp, q_00+372, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+372, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+119, 6, q_01+119, 6, temp);
	gf2x_mul_3_avx(temp, q_00+369, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+369, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+116, 6, q_01+116, 6, temp);
	gf2x_mul_3_avx(temp, q_00+366, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+366, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+113, 6, q_01+113, 6, temp);
	gf2x_mul_3_avx(temp, q_00+363, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+363, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+110, 6, q_01+110, 6, temp);
	gf2x_mul_3_avx(temp, q_00+360, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+360, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+107, 6, q_01+107, 6, temp);
	gf2x_mul_3_avx(temp, q_00+357, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+357, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+104, 6, q_01+104, 6, temp);
	gf2x_mul_3_avx(temp, q_00+354, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+354, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+101, 6, q_01+101, 6, temp);
	gf2x_mul_3_avx(temp, q_00+351, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+351, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+98, 6, q_01+98, 6, temp);
	gf2x_mul_3_avx(temp, q_00+348, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+348, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+95, 6, q_01+95, 6, temp);
	gf2x_mul_3_avx(temp, q_00+345, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+345, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+92, 6, q_01+92, 6, temp);
	gf2x_mul_3_avx(temp, q_00+342, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+342, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+89, 6, q_01+89, 6, temp);
	gf2x_mul_3_avx(temp, q_00+339, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+339, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+86, 6, q_01+86, 6, temp);
	gf2x_mul_3_avx(temp, q_00+336, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+336, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+83, 6, q_01+83, 6, temp);
	gf2x_mul_3_avx(temp, q_00+333, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+333, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+80, 6, q_01+80, 6, temp);
	gf2x_mul_3_avx(temp, q_00+330, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+330, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+77, 6, q_01+77, 6, temp);
	gf2x_mul_3_avx(temp, q_00+327, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+327, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+74, 6, q_01+74, 6, temp);
	gf2x_mul_3_avx(temp, q_00+324, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+324, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+71, 6, q_01+71, 6, temp);
	gf2x_mul_3_avx(temp, q_00+321, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+321, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+68, 6, q_01+68, 6, temp);
	gf2x_mul_3_avx(temp, q_00+318, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+318, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+65, 6, q_01+65, 6, temp);
	gf2x_mul_3_avx(temp, q_00+315, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+315, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+62, 6, q_01+62, 6, temp);
	gf2x_mul_3_avx(temp, q_00+312, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+312, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+59, 6, q_01+59, 6, temp);
	gf2x_mul_3_avx(temp, q_00+309, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+309, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+56, 6, q_01+56, 6, temp);
	gf2x_mul_3_avx(temp, q_00+306, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+306, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+53, 6, q_01+53, 6, temp);
	gf2x_mul_3_avx(temp, q_00+303, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+303, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+50, 6, q_01+50, 6, temp);
	gf2x_mul_3_avx(temp, q_00+300, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+300, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+47, 6, q_01+47, 6, temp);
	gf2x_mul_3_avx(temp, q_00+297, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+297, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+44, 6, q_01+44, 6, temp);
	gf2x_mul_3_avx(temp, q_00+294, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+294, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+41, 6, q_01+41, 6, temp);
	gf2x_mul_3_avx(temp, q_00+291, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+291, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+38, 6, q_01+38, 6, temp);
	gf2x_mul_3_avx(temp, q_00+288, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+288, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+35, 6, q_01+35, 6, temp);
	gf2x_mul_3_avx(temp, q_00+285, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+285, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+32, 6, q_01+32, 6, temp);
	gf2x_mul_3_avx(temp, q_00+282, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+282, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+29, 6, q_01+29, 6, temp);
	gf2x_mul_3_avx(temp, q_00+279, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+279, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+26, 6, q_01+26, 6, temp);
	gf2x_mul_3_avx(temp, q_00+276, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+276, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+23, 6, q_01+23, 6, temp);
	gf2x_mul_3_avx(temp, q_00+273, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+273, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+20, 6, q_01+20, 6, temp);
	gf2x_mul_3_avx(temp, q_00+270, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+270, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+17, 6, q_01+17, 6, temp);
	gf2x_mul_3_avx(temp, q_00+267, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+267, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+14, 6, q_01+14, 6, temp);
	gf2x_mul_3_avx(temp, q_00+264, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+264, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+11, 6, q_01+11, 6, temp);
	gf2x_mul_3_avx(temp, q_00+261, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+261, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+8, 6, q_01+8, 6, temp);
	gf2x_mul_3_avx(temp, q_00+258, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+258, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+5, 6, q_01+5, 6, temp);
	gf2x_mul_3_avx(temp, q_00+255, p_01+256);
	gf2x_mul_3_avx(temp2, q_01+255, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_01+2, 6, q_01+2, 6, temp);
	gf2x_mul_2_avx(temp, p_01+257, q_00+253);
	gf2x_mul_2_avx(temp2, p_11+257, q_01+253);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+1, 4, q_01+1, 4, temp);
	gf2x_mul_1_avx(temp, q_00+254, p_01+256);
	gf2x_mul_1_avx(temp2, q_01+254, p_11+256);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+1, 2, q_01+1, 2, temp);
	gf2x_mul_1_avx(temp, q_00+253, p_01+256);
	gf2x_mul_1_avx(temp2, q_01+253, p_11+256);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_01+0, 2, q_01+0, 2, temp);
	memset(q_10+0, 0x00, 3*DIGIT_SIZE_B);
	GF2X_MUL(250, temp, 125, p_00+259, 125, q_10+253);
	GF2X_MUL(250, temp2, 125, p_10+259, 125, q_11+253);
	gf2x_add(250, q_10+3, 250, temp, 250, temp2);
	gf2x_mul_3_avx(temp, q_10+375, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+375, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+122, 6, q_10+122, 6, temp);
	gf2x_mul_3_avx(temp, q_10+372, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+372, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+119, 6, q_10+119, 6, temp);
	gf2x_mul_3_avx(temp, q_10+369, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+369, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+116, 6, q_10+116, 6, temp);
	gf2x_mul_3_avx(temp, q_10+366, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+366, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+113, 6, q_10+113, 6, temp);
	gf2x_mul_3_avx(temp, q_10+363, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+363, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+110, 6, q_10+110, 6, temp);
	gf2x_mul_3_avx(temp, q_10+360, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+360, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+107, 6, q_10+107, 6, temp);
	gf2x_mul_3_avx(temp, q_10+357, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+357, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+104, 6, q_10+104, 6, temp);
	gf2x_mul_3_avx(temp, q_10+354, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+354, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+101, 6, q_10+101, 6, temp);
	gf2x_mul_3_avx(temp, q_10+351, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+351, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+98, 6, q_10+98, 6, temp);
	gf2x_mul_3_avx(temp, q_10+348, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+348, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+95, 6, q_10+95, 6, temp);
	gf2x_mul_3_avx(temp, q_10+345, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+345, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+92, 6, q_10+92, 6, temp);
	gf2x_mul_3_avx(temp, q_10+342, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+342, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+89, 6, q_10+89, 6, temp);
	gf2x_mul_3_avx(temp, q_10+339, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+339, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+86, 6, q_10+86, 6, temp);
	gf2x_mul_3_avx(temp, q_10+336, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+336, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+83, 6, q_10+83, 6, temp);
	gf2x_mul_3_avx(temp, q_10+333, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+333, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+80, 6, q_10+80, 6, temp);
	gf2x_mul_3_avx(temp, q_10+330, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+330, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+77, 6, q_10+77, 6, temp);
	gf2x_mul_3_avx(temp, q_10+327, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+327, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+74, 6, q_10+74, 6, temp);
	gf2x_mul_3_avx(temp, q_10+324, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+324, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+71, 6, q_10+71, 6, temp);
	gf2x_mul_3_avx(temp, q_10+321, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+321, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+68, 6, q_10+68, 6, temp);
	gf2x_mul_3_avx(temp, q_10+318, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+318, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+65, 6, q_10+65, 6, temp);
	gf2x_mul_3_avx(temp, q_10+315, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+315, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+62, 6, q_10+62, 6, temp);
	gf2x_mul_3_avx(temp, q_10+312, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+312, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+59, 6, q_10+59, 6, temp);
	gf2x_mul_3_avx(temp, q_10+309, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+309, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+56, 6, q_10+56, 6, temp);
	gf2x_mul_3_avx(temp, q_10+306, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+306, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+53, 6, q_10+53, 6, temp);
	gf2x_mul_3_avx(temp, q_10+303, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+303, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+50, 6, q_10+50, 6, temp);
	gf2x_mul_3_avx(temp, q_10+300, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+300, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+47, 6, q_10+47, 6, temp);
	gf2x_mul_3_avx(temp, q_10+297, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+297, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+44, 6, q_10+44, 6, temp);
	gf2x_mul_3_avx(temp, q_10+294, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+294, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+41, 6, q_10+41, 6, temp);
	gf2x_mul_3_avx(temp, q_10+291, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+291, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+38, 6, q_10+38, 6, temp);
	gf2x_mul_3_avx(temp, q_10+288, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+288, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+35, 6, q_10+35, 6, temp);
	gf2x_mul_3_avx(temp, q_10+285, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+285, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+32, 6, q_10+32, 6, temp);
	gf2x_mul_3_avx(temp, q_10+282, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+282, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+29, 6, q_10+29, 6, temp);
	gf2x_mul_3_avx(temp, q_10+279, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+279, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+26, 6, q_10+26, 6, temp);
	gf2x_mul_3_avx(temp, q_10+276, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+276, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+23, 6, q_10+23, 6, temp);
	gf2x_mul_3_avx(temp, q_10+273, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+273, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+20, 6, q_10+20, 6, temp);
	gf2x_mul_3_avx(temp, q_10+270, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+270, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+17, 6, q_10+17, 6, temp);
	gf2x_mul_3_avx(temp, q_10+267, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+267, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+14, 6, q_10+14, 6, temp);
	gf2x_mul_3_avx(temp, q_10+264, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+264, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+11, 6, q_10+11, 6, temp);
	gf2x_mul_3_avx(temp, q_10+261, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+261, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+8, 6, q_10+8, 6, temp);
	gf2x_mul_3_avx(temp, q_10+258, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+258, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+5, 6, q_10+5, 6, temp);
	gf2x_mul_3_avx(temp, q_10+255, p_00+256);
	gf2x_mul_3_avx(temp2, q_11+255, p_10+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_10+2, 6, q_10+2, 6, temp);
	gf2x_mul_2_avx(temp, p_00+257, q_10+253);
	gf2x_mul_2_avx(temp2, p_10+257, q_11+253);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+1, 4, q_10+1, 4, temp);
	gf2x_mul_1_avx(temp, q_10+254, p_00+256);
	gf2x_mul_1_avx(temp2, q_11+254, p_10+256);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+1, 2, q_10+1, 2, temp);
	gf2x_mul_1_avx(temp, q_10+253, p_00+256);
	gf2x_mul_1_avx(temp2, q_11+253, p_10+256);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_10+0, 2, q_10+0, 2, temp);
	memset(q_11+0, 0x00, 3*DIGIT_SIZE_B);
	GF2X_MUL(250, temp, 125, p_01+259, 125, q_10+253);
	GF2X_MUL(250, temp2, 125, p_11+259, 125, q_11+253);
	gf2x_add(250, q_11+3, 250, temp, 250, temp2);
	gf2x_mul_3_avx(temp, q_10+375, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+375, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+122, 6, q_11+122, 6, temp);
	gf2x_mul_3_avx(temp, q_10+372, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+372, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+119, 6, q_11+119, 6, temp);
	gf2x_mul_3_avx(temp, q_10+369, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+369, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+116, 6, q_11+116, 6, temp);
	gf2x_mul_3_avx(temp, q_10+366, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+366, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+113, 6, q_11+113, 6, temp);
	gf2x_mul_3_avx(temp, q_10+363, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+363, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+110, 6, q_11+110, 6, temp);
	gf2x_mul_3_avx(temp, q_10+360, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+360, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+107, 6, q_11+107, 6, temp);
	gf2x_mul_3_avx(temp, q_10+357, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+357, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+104, 6, q_11+104, 6, temp);
	gf2x_mul_3_avx(temp, q_10+354, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+354, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+101, 6, q_11+101, 6, temp);
	gf2x_mul_3_avx(temp, q_10+351, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+351, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+98, 6, q_11+98, 6, temp);
	gf2x_mul_3_avx(temp, q_10+348, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+348, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+95, 6, q_11+95, 6, temp);
	gf2x_mul_3_avx(temp, q_10+345, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+345, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+92, 6, q_11+92, 6, temp);
	gf2x_mul_3_avx(temp, q_10+342, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+342, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+89, 6, q_11+89, 6, temp);
	gf2x_mul_3_avx(temp, q_10+339, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+339, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+86, 6, q_11+86, 6, temp);
	gf2x_mul_3_avx(temp, q_10+336, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+336, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+83, 6, q_11+83, 6, temp);
	gf2x_mul_3_avx(temp, q_10+333, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+333, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+80, 6, q_11+80, 6, temp);
	gf2x_mul_3_avx(temp, q_10+330, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+330, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+77, 6, q_11+77, 6, temp);
	gf2x_mul_3_avx(temp, q_10+327, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+327, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+74, 6, q_11+74, 6, temp);
	gf2x_mul_3_avx(temp, q_10+324, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+324, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+71, 6, q_11+71, 6, temp);
	gf2x_mul_3_avx(temp, q_10+321, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+321, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+68, 6, q_11+68, 6, temp);
	gf2x_mul_3_avx(temp, q_10+318, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+318, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+65, 6, q_11+65, 6, temp);
	gf2x_mul_3_avx(temp, q_10+315, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+315, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+62, 6, q_11+62, 6, temp);
	gf2x_mul_3_avx(temp, q_10+312, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+312, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+59, 6, q_11+59, 6, temp);
	gf2x_mul_3_avx(temp, q_10+309, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+309, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+56, 6, q_11+56, 6, temp);
	gf2x_mul_3_avx(temp, q_10+306, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+306, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+53, 6, q_11+53, 6, temp);
	gf2x_mul_3_avx(temp, q_10+303, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+303, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+50, 6, q_11+50, 6, temp);
	gf2x_mul_3_avx(temp, q_10+300, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+300, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+47, 6, q_11+47, 6, temp);
	gf2x_mul_3_avx(temp, q_10+297, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+297, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+44, 6, q_11+44, 6, temp);
	gf2x_mul_3_avx(temp, q_10+294, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+294, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+41, 6, q_11+41, 6, temp);
	gf2x_mul_3_avx(temp, q_10+291, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+291, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+38, 6, q_11+38, 6, temp);
	gf2x_mul_3_avx(temp, q_10+288, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+288, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+35, 6, q_11+35, 6, temp);
	gf2x_mul_3_avx(temp, q_10+285, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+285, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+32, 6, q_11+32, 6, temp);
	gf2x_mul_3_avx(temp, q_10+282, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+282, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+29, 6, q_11+29, 6, temp);
	gf2x_mul_3_avx(temp, q_10+279, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+279, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+26, 6, q_11+26, 6, temp);
	gf2x_mul_3_avx(temp, q_10+276, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+276, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+23, 6, q_11+23, 6, temp);
	gf2x_mul_3_avx(temp, q_10+273, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+273, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+20, 6, q_11+20, 6, temp);
	gf2x_mul_3_avx(temp, q_10+270, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+270, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+17, 6, q_11+17, 6, temp);
	gf2x_mul_3_avx(temp, q_10+267, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+267, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+14, 6, q_11+14, 6, temp);
	gf2x_mul_3_avx(temp, q_10+264, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+264, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+11, 6, q_11+11, 6, temp);
	gf2x_mul_3_avx(temp, q_10+261, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+261, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+8, 6, q_11+8, 6, temp);
	gf2x_mul_3_avx(temp, q_10+258, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+258, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+5, 6, q_11+5, 6, temp);
	gf2x_mul_3_avx(temp, q_10+255, p_01+256);
	gf2x_mul_3_avx(temp2, q_11+255, p_11+256);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, q_11+2, 6, q_11+2, 6, temp);
	gf2x_mul_2_avx(temp, p_01+257, q_10+253);
	gf2x_mul_2_avx(temp2, p_11+257, q_11+253);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+1, 4, q_11+1, 4, temp);
	gf2x_mul_1_avx(temp, q_10+254, p_01+256);
	gf2x_mul_1_avx(temp2, q_11+254, p_11+256);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+1, 2, q_11+1, 2, temp);
	gf2x_mul_1_avx(temp, q_10+253, p_01+256);
	gf2x_mul_1_avx(temp2, q_11+253, p_11+256);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, q_11+0, 2, q_11+0, 2, temp);
	
	// Recombining results: n: 32457, depth: 0
	memset(t_00+0, 0x00, 2*DIGIT_SIZE_B);
	GF2X_MUL(506, temp, 253, p_00+3, 253, q_00+0);
	GF2X_MUL(506, temp2, 253, p_10+3, 253, q_01+0);
	gf2x_add(506, t_00+2, 506, temp, 506, temp2);
	gf2x_mul_3_avx(temp, q_00+250, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+250, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+249, 6, t_00+249, 6, temp);
	gf2x_mul_3_avx(temp, q_00+247, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+247, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+246, 6, t_00+246, 6, temp);
	gf2x_mul_3_avx(temp, q_00+244, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+244, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+243, 6, t_00+243, 6, temp);
	gf2x_mul_3_avx(temp, q_00+241, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+241, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+240, 6, t_00+240, 6, temp);
	gf2x_mul_3_avx(temp, q_00+238, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+238, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+237, 6, t_00+237, 6, temp);
	gf2x_mul_3_avx(temp, q_00+235, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+235, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+234, 6, t_00+234, 6, temp);
	gf2x_mul_3_avx(temp, q_00+232, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+232, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+231, 6, t_00+231, 6, temp);
	gf2x_mul_3_avx(temp, q_00+229, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+229, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+228, 6, t_00+228, 6, temp);
	gf2x_mul_3_avx(temp, q_00+226, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+226, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+225, 6, t_00+225, 6, temp);
	gf2x_mul_3_avx(temp, q_00+223, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+223, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+222, 6, t_00+222, 6, temp);
	gf2x_mul_3_avx(temp, q_00+220, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+220, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+219, 6, t_00+219, 6, temp);
	gf2x_mul_3_avx(temp, q_00+217, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+217, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+216, 6, t_00+216, 6, temp);
	gf2x_mul_3_avx(temp, q_00+214, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+214, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+213, 6, t_00+213, 6, temp);
	gf2x_mul_3_avx(temp, q_00+211, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+211, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+210, 6, t_00+210, 6, temp);
	gf2x_mul_3_avx(temp, q_00+208, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+208, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+207, 6, t_00+207, 6, temp);
	gf2x_mul_3_avx(temp, q_00+205, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+205, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+204, 6, t_00+204, 6, temp);
	gf2x_mul_3_avx(temp, q_00+202, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+202, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+201, 6, t_00+201, 6, temp);
	gf2x_mul_3_avx(temp, q_00+199, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+199, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+198, 6, t_00+198, 6, temp);
	gf2x_mul_3_avx(temp, q_00+196, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+196, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+195, 6, t_00+195, 6, temp);
	gf2x_mul_3_avx(temp, q_00+193, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+193, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+192, 6, t_00+192, 6, temp);
	gf2x_mul_3_avx(temp, q_00+190, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+190, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+189, 6, t_00+189, 6, temp);
	gf2x_mul_3_avx(temp, q_00+187, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+187, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+186, 6, t_00+186, 6, temp);
	gf2x_mul_3_avx(temp, q_00+184, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+184, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+183, 6, t_00+183, 6, temp);
	gf2x_mul_3_avx(temp, q_00+181, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+181, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+180, 6, t_00+180, 6, temp);
	gf2x_mul_3_avx(temp, q_00+178, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+178, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+177, 6, t_00+177, 6, temp);
	gf2x_mul_3_avx(temp, q_00+175, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+175, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+174, 6, t_00+174, 6, temp);
	gf2x_mul_3_avx(temp, q_00+172, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+172, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+171, 6, t_00+171, 6, temp);
	gf2x_mul_3_avx(temp, q_00+169, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+169, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+168, 6, t_00+168, 6, temp);
	gf2x_mul_3_avx(temp, q_00+166, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+166, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+165, 6, t_00+165, 6, temp);
	gf2x_mul_3_avx(temp, q_00+163, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+163, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+162, 6, t_00+162, 6, temp);
	gf2x_mul_3_avx(temp, q_00+160, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+160, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+159, 6, t_00+159, 6, temp);
	gf2x_mul_3_avx(temp, q_00+157, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+157, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+156, 6, t_00+156, 6, temp);
	gf2x_mul_3_avx(temp, q_00+154, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+154, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+153, 6, t_00+153, 6, temp);
	gf2x_mul_3_avx(temp, q_00+151, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+151, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+150, 6, t_00+150, 6, temp);
	gf2x_mul_3_avx(temp, q_00+148, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+148, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+147, 6, t_00+147, 6, temp);
	gf2x_mul_3_avx(temp, q_00+145, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+145, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+144, 6, t_00+144, 6, temp);
	gf2x_mul_3_avx(temp, q_00+142, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+142, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+141, 6, t_00+141, 6, temp);
	gf2x_mul_3_avx(temp, q_00+139, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+139, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+138, 6, t_00+138, 6, temp);
	gf2x_mul_3_avx(temp, q_00+136, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+136, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+135, 6, t_00+135, 6, temp);
	gf2x_mul_3_avx(temp, q_00+133, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+133, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+132, 6, t_00+132, 6, temp);
	gf2x_mul_3_avx(temp, q_00+130, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+130, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+129, 6, t_00+129, 6, temp);
	gf2x_mul_3_avx(temp, q_00+127, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+127, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+126, 6, t_00+126, 6, temp);
	gf2x_mul_3_avx(temp, q_00+124, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+124, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+123, 6, t_00+123, 6, temp);
	gf2x_mul_3_avx(temp, q_00+121, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+121, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+120, 6, t_00+120, 6, temp);
	gf2x_mul_3_avx(temp, q_00+118, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+118, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+117, 6, t_00+117, 6, temp);
	gf2x_mul_3_avx(temp, q_00+115, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+115, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+114, 6, t_00+114, 6, temp);
	gf2x_mul_3_avx(temp, q_00+112, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+112, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+111, 6, t_00+111, 6, temp);
	gf2x_mul_3_avx(temp, q_00+109, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+109, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+108, 6, t_00+108, 6, temp);
	gf2x_mul_3_avx(temp, q_00+106, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+106, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+105, 6, t_00+105, 6, temp);
	gf2x_mul_3_avx(temp, q_00+103, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+103, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+102, 6, t_00+102, 6, temp);
	gf2x_mul_3_avx(temp, q_00+100, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+100, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+99, 6, t_00+99, 6, temp);
	gf2x_mul_3_avx(temp, q_00+97, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+97, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+96, 6, t_00+96, 6, temp);
	gf2x_mul_3_avx(temp, q_00+94, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+94, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+93, 6, t_00+93, 6, temp);
	gf2x_mul_3_avx(temp, q_00+91, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+91, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+90, 6, t_00+90, 6, temp);
	gf2x_mul_3_avx(temp, q_00+88, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+88, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+87, 6, t_00+87, 6, temp);
	gf2x_mul_3_avx(temp, q_00+85, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+85, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+84, 6, t_00+84, 6, temp);
	gf2x_mul_3_avx(temp, q_00+82, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+82, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+81, 6, t_00+81, 6, temp);
	gf2x_mul_3_avx(temp, q_00+79, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+79, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+78, 6, t_00+78, 6, temp);
	gf2x_mul_3_avx(temp, q_00+76, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+76, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+75, 6, t_00+75, 6, temp);
	gf2x_mul_3_avx(temp, q_00+73, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+73, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+72, 6, t_00+72, 6, temp);
	gf2x_mul_3_avx(temp, q_00+70, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+70, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+69, 6, t_00+69, 6, temp);
	gf2x_mul_3_avx(temp, q_00+67, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+67, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+66, 6, t_00+66, 6, temp);
	gf2x_mul_3_avx(temp, q_00+64, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+64, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+63, 6, t_00+63, 6, temp);
	gf2x_mul_3_avx(temp, q_00+61, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+61, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+60, 6, t_00+60, 6, temp);
	gf2x_mul_3_avx(temp, q_00+58, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+58, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+57, 6, t_00+57, 6, temp);
	gf2x_mul_3_avx(temp, q_00+55, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+55, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+54, 6, t_00+54, 6, temp);
	gf2x_mul_3_avx(temp, q_00+52, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+52, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+51, 6, t_00+51, 6, temp);
	gf2x_mul_3_avx(temp, q_00+49, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+49, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+48, 6, t_00+48, 6, temp);
	gf2x_mul_3_avx(temp, q_00+46, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+46, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+45, 6, t_00+45, 6, temp);
	gf2x_mul_3_avx(temp, q_00+43, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+43, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+42, 6, t_00+42, 6, temp);
	gf2x_mul_3_avx(temp, q_00+40, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+40, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+39, 6, t_00+39, 6, temp);
	gf2x_mul_3_avx(temp, q_00+37, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+37, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+36, 6, t_00+36, 6, temp);
	gf2x_mul_3_avx(temp, q_00+34, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+34, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+33, 6, t_00+33, 6, temp);
	gf2x_mul_3_avx(temp, q_00+31, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+31, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+30, 6, t_00+30, 6, temp);
	gf2x_mul_3_avx(temp, q_00+28, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+28, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+27, 6, t_00+27, 6, temp);
	gf2x_mul_3_avx(temp, q_00+25, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+25, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+24, 6, t_00+24, 6, temp);
	gf2x_mul_3_avx(temp, q_00+22, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+22, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+21, 6, t_00+21, 6, temp);
	gf2x_mul_3_avx(temp, q_00+19, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+19, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+18, 6, t_00+18, 6, temp);
	gf2x_mul_3_avx(temp, q_00+16, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+16, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+15, 6, t_00+15, 6, temp);
	gf2x_mul_3_avx(temp, q_00+13, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+13, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+12, 6, t_00+12, 6, temp);
	gf2x_mul_3_avx(temp, q_00+10, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+10, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+9, 6, t_00+9, 6, temp);
	gf2x_mul_3_avx(temp, q_00+7, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+7, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+6, 6, t_00+6, 6, temp);
	gf2x_mul_3_avx(temp, q_00+4, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+4, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+3, 6, t_00+3, 6, temp);
	gf2x_mul_3_avx(temp, q_00+1, p_00+0);
	gf2x_mul_3_avx(temp2, q_01+1, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_00+0, 6, t_00+0, 6, temp);
	gf2x_mul_1_avx(temp, p_00+2, q_00+0);
	gf2x_mul_1_avx(temp2, p_10+2, q_01+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, t_00+1, 2, t_00+1, 2, temp);
	gf2x_mul_1_avx(temp, p_00+1, q_00+0);
	gf2x_mul_1_avx(temp2, p_10+1, q_01+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, t_00+0, 2, t_00+0, 2, temp);
	gf2x_mul_1_avx(temp, q_00+0, p_00+0);
	gf2x_mul_1_avx(temp2, q_01+0, p_10+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, t_00+0, 1, t_00+0, 1, temp+1);
	memset(t_01+0, 0x00, 2*DIGIT_SIZE_B);
	GF2X_MUL(506, temp, 253, p_01+3, 253, q_00+0);
	GF2X_MUL(506, temp2, 253, p_11+3, 253, q_01+0);
	gf2x_add(506, t_01+2, 506, temp, 506, temp2);
	gf2x_mul_3_avx(temp, q_00+250, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+250, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+249, 6, t_01+249, 6, temp);
	gf2x_mul_3_avx(temp, q_00+247, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+247, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+246, 6, t_01+246, 6, temp);
	gf2x_mul_3_avx(temp, q_00+244, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+244, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+243, 6, t_01+243, 6, temp);
	gf2x_mul_3_avx(temp, q_00+241, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+241, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+240, 6, t_01+240, 6, temp);
	gf2x_mul_3_avx(temp, q_00+238, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+238, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+237, 6, t_01+237, 6, temp);
	gf2x_mul_3_avx(temp, q_00+235, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+235, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+234, 6, t_01+234, 6, temp);
	gf2x_mul_3_avx(temp, q_00+232, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+232, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+231, 6, t_01+231, 6, temp);
	gf2x_mul_3_avx(temp, q_00+229, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+229, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+228, 6, t_01+228, 6, temp);
	gf2x_mul_3_avx(temp, q_00+226, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+226, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+225, 6, t_01+225, 6, temp);
	gf2x_mul_3_avx(temp, q_00+223, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+223, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+222, 6, t_01+222, 6, temp);
	gf2x_mul_3_avx(temp, q_00+220, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+220, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+219, 6, t_01+219, 6, temp);
	gf2x_mul_3_avx(temp, q_00+217, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+217, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+216, 6, t_01+216, 6, temp);
	gf2x_mul_3_avx(temp, q_00+214, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+214, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+213, 6, t_01+213, 6, temp);
	gf2x_mul_3_avx(temp, q_00+211, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+211, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+210, 6, t_01+210, 6, temp);
	gf2x_mul_3_avx(temp, q_00+208, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+208, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+207, 6, t_01+207, 6, temp);
	gf2x_mul_3_avx(temp, q_00+205, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+205, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+204, 6, t_01+204, 6, temp);
	gf2x_mul_3_avx(temp, q_00+202, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+202, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+201, 6, t_01+201, 6, temp);
	gf2x_mul_3_avx(temp, q_00+199, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+199, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+198, 6, t_01+198, 6, temp);
	gf2x_mul_3_avx(temp, q_00+196, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+196, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+195, 6, t_01+195, 6, temp);
	gf2x_mul_3_avx(temp, q_00+193, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+193, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+192, 6, t_01+192, 6, temp);
	gf2x_mul_3_avx(temp, q_00+190, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+190, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+189, 6, t_01+189, 6, temp);
	gf2x_mul_3_avx(temp, q_00+187, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+187, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+186, 6, t_01+186, 6, temp);
	gf2x_mul_3_avx(temp, q_00+184, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+184, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+183, 6, t_01+183, 6, temp);
	gf2x_mul_3_avx(temp, q_00+181, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+181, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+180, 6, t_01+180, 6, temp);
	gf2x_mul_3_avx(temp, q_00+178, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+178, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+177, 6, t_01+177, 6, temp);
	gf2x_mul_3_avx(temp, q_00+175, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+175, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+174, 6, t_01+174, 6, temp);
	gf2x_mul_3_avx(temp, q_00+172, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+172, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+171, 6, t_01+171, 6, temp);
	gf2x_mul_3_avx(temp, q_00+169, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+169, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+168, 6, t_01+168, 6, temp);
	gf2x_mul_3_avx(temp, q_00+166, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+166, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+165, 6, t_01+165, 6, temp);
	gf2x_mul_3_avx(temp, q_00+163, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+163, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+162, 6, t_01+162, 6, temp);
	gf2x_mul_3_avx(temp, q_00+160, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+160, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+159, 6, t_01+159, 6, temp);
	gf2x_mul_3_avx(temp, q_00+157, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+157, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+156, 6, t_01+156, 6, temp);
	gf2x_mul_3_avx(temp, q_00+154, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+154, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+153, 6, t_01+153, 6, temp);
	gf2x_mul_3_avx(temp, q_00+151, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+151, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+150, 6, t_01+150, 6, temp);
	gf2x_mul_3_avx(temp, q_00+148, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+148, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+147, 6, t_01+147, 6, temp);
	gf2x_mul_3_avx(temp, q_00+145, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+145, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+144, 6, t_01+144, 6, temp);
	gf2x_mul_3_avx(temp, q_00+142, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+142, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+141, 6, t_01+141, 6, temp);
	gf2x_mul_3_avx(temp, q_00+139, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+139, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+138, 6, t_01+138, 6, temp);
	gf2x_mul_3_avx(temp, q_00+136, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+136, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+135, 6, t_01+135, 6, temp);
	gf2x_mul_3_avx(temp, q_00+133, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+133, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+132, 6, t_01+132, 6, temp);
	gf2x_mul_3_avx(temp, q_00+130, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+130, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+129, 6, t_01+129, 6, temp);
	gf2x_mul_3_avx(temp, q_00+127, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+127, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+126, 6, t_01+126, 6, temp);
	gf2x_mul_3_avx(temp, q_00+124, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+124, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+123, 6, t_01+123, 6, temp);
	gf2x_mul_3_avx(temp, q_00+121, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+121, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+120, 6, t_01+120, 6, temp);
	gf2x_mul_3_avx(temp, q_00+118, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+118, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+117, 6, t_01+117, 6, temp);
	gf2x_mul_3_avx(temp, q_00+115, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+115, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+114, 6, t_01+114, 6, temp);
	gf2x_mul_3_avx(temp, q_00+112, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+112, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+111, 6, t_01+111, 6, temp);
	gf2x_mul_3_avx(temp, q_00+109, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+109, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+108, 6, t_01+108, 6, temp);
	gf2x_mul_3_avx(temp, q_00+106, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+106, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+105, 6, t_01+105, 6, temp);
	gf2x_mul_3_avx(temp, q_00+103, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+103, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+102, 6, t_01+102, 6, temp);
	gf2x_mul_3_avx(temp, q_00+100, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+100, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+99, 6, t_01+99, 6, temp);
	gf2x_mul_3_avx(temp, q_00+97, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+97, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+96, 6, t_01+96, 6, temp);
	gf2x_mul_3_avx(temp, q_00+94, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+94, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+93, 6, t_01+93, 6, temp);
	gf2x_mul_3_avx(temp, q_00+91, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+91, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+90, 6, t_01+90, 6, temp);
	gf2x_mul_3_avx(temp, q_00+88, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+88, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+87, 6, t_01+87, 6, temp);
	gf2x_mul_3_avx(temp, q_00+85, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+85, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+84, 6, t_01+84, 6, temp);
	gf2x_mul_3_avx(temp, q_00+82, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+82, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+81, 6, t_01+81, 6, temp);
	gf2x_mul_3_avx(temp, q_00+79, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+79, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+78, 6, t_01+78, 6, temp);
	gf2x_mul_3_avx(temp, q_00+76, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+76, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+75, 6, t_01+75, 6, temp);
	gf2x_mul_3_avx(temp, q_00+73, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+73, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+72, 6, t_01+72, 6, temp);
	gf2x_mul_3_avx(temp, q_00+70, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+70, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+69, 6, t_01+69, 6, temp);
	gf2x_mul_3_avx(temp, q_00+67, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+67, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+66, 6, t_01+66, 6, temp);
	gf2x_mul_3_avx(temp, q_00+64, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+64, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+63, 6, t_01+63, 6, temp);
	gf2x_mul_3_avx(temp, q_00+61, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+61, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+60, 6, t_01+60, 6, temp);
	gf2x_mul_3_avx(temp, q_00+58, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+58, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+57, 6, t_01+57, 6, temp);
	gf2x_mul_3_avx(temp, q_00+55, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+55, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+54, 6, t_01+54, 6, temp);
	gf2x_mul_3_avx(temp, q_00+52, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+52, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+51, 6, t_01+51, 6, temp);
	gf2x_mul_3_avx(temp, q_00+49, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+49, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+48, 6, t_01+48, 6, temp);
	gf2x_mul_3_avx(temp, q_00+46, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+46, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+45, 6, t_01+45, 6, temp);
	gf2x_mul_3_avx(temp, q_00+43, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+43, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+42, 6, t_01+42, 6, temp);
	gf2x_mul_3_avx(temp, q_00+40, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+40, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+39, 6, t_01+39, 6, temp);
	gf2x_mul_3_avx(temp, q_00+37, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+37, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+36, 6, t_01+36, 6, temp);
	gf2x_mul_3_avx(temp, q_00+34, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+34, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+33, 6, t_01+33, 6, temp);
	gf2x_mul_3_avx(temp, q_00+31, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+31, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+30, 6, t_01+30, 6, temp);
	gf2x_mul_3_avx(temp, q_00+28, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+28, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+27, 6, t_01+27, 6, temp);
	gf2x_mul_3_avx(temp, q_00+25, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+25, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+24, 6, t_01+24, 6, temp);
	gf2x_mul_3_avx(temp, q_00+22, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+22, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+21, 6, t_01+21, 6, temp);
	gf2x_mul_3_avx(temp, q_00+19, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+19, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+18, 6, t_01+18, 6, temp);
	gf2x_mul_3_avx(temp, q_00+16, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+16, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+15, 6, t_01+15, 6, temp);
	gf2x_mul_3_avx(temp, q_00+13, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+13, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+12, 6, t_01+12, 6, temp);
	gf2x_mul_3_avx(temp, q_00+10, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+10, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+9, 6, t_01+9, 6, temp);
	gf2x_mul_3_avx(temp, q_00+7, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+7, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+6, 6, t_01+6, 6, temp);
	gf2x_mul_3_avx(temp, q_00+4, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+4, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+3, 6, t_01+3, 6, temp);
	gf2x_mul_3_avx(temp, q_00+1, p_01+0);
	gf2x_mul_3_avx(temp2, q_01+1, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_01+0, 6, t_01+0, 6, temp);
	gf2x_mul_1_avx(temp, p_01+2, q_00+0);
	gf2x_mul_1_avx(temp2, p_11+2, q_01+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, t_01+1, 2, t_01+1, 2, temp);
	gf2x_mul_1_avx(temp, p_01+1, q_00+0);
	gf2x_mul_1_avx(temp2, p_11+1, q_01+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, t_01+0, 2, t_01+0, 2, temp);
	gf2x_mul_1_avx(temp, q_00+0, p_01+0);
	gf2x_mul_1_avx(temp2, q_01+0, p_11+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, t_01+0, 1, t_01+0, 1, temp+1);
	memset(t_10+0, 0x00, 2*DIGIT_SIZE_B);
	GF2X_MUL(506, temp, 253, p_00+3, 253, q_10+0);
	GF2X_MUL(506, temp2, 253, p_10+3, 253, q_11+0);
	gf2x_add(506, t_10+2, 506, temp, 506, temp2);
	gf2x_mul_3_avx(temp, q_10+250, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+250, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+249, 6, t_10+249, 6, temp);
	gf2x_mul_3_avx(temp, q_10+247, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+247, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+246, 6, t_10+246, 6, temp);
	gf2x_mul_3_avx(temp, q_10+244, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+244, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+243, 6, t_10+243, 6, temp);
	gf2x_mul_3_avx(temp, q_10+241, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+241, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+240, 6, t_10+240, 6, temp);
	gf2x_mul_3_avx(temp, q_10+238, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+238, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+237, 6, t_10+237, 6, temp);
	gf2x_mul_3_avx(temp, q_10+235, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+235, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+234, 6, t_10+234, 6, temp);
	gf2x_mul_3_avx(temp, q_10+232, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+232, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+231, 6, t_10+231, 6, temp);
	gf2x_mul_3_avx(temp, q_10+229, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+229, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+228, 6, t_10+228, 6, temp);
	gf2x_mul_3_avx(temp, q_10+226, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+226, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+225, 6, t_10+225, 6, temp);
	gf2x_mul_3_avx(temp, q_10+223, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+223, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+222, 6, t_10+222, 6, temp);
	gf2x_mul_3_avx(temp, q_10+220, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+220, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+219, 6, t_10+219, 6, temp);
	gf2x_mul_3_avx(temp, q_10+217, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+217, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+216, 6, t_10+216, 6, temp);
	gf2x_mul_3_avx(temp, q_10+214, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+214, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+213, 6, t_10+213, 6, temp);
	gf2x_mul_3_avx(temp, q_10+211, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+211, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+210, 6, t_10+210, 6, temp);
	gf2x_mul_3_avx(temp, q_10+208, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+208, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+207, 6, t_10+207, 6, temp);
	gf2x_mul_3_avx(temp, q_10+205, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+205, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+204, 6, t_10+204, 6, temp);
	gf2x_mul_3_avx(temp, q_10+202, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+202, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+201, 6, t_10+201, 6, temp);
	gf2x_mul_3_avx(temp, q_10+199, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+199, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+198, 6, t_10+198, 6, temp);
	gf2x_mul_3_avx(temp, q_10+196, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+196, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+195, 6, t_10+195, 6, temp);
	gf2x_mul_3_avx(temp, q_10+193, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+193, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+192, 6, t_10+192, 6, temp);
	gf2x_mul_3_avx(temp, q_10+190, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+190, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+189, 6, t_10+189, 6, temp);
	gf2x_mul_3_avx(temp, q_10+187, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+187, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+186, 6, t_10+186, 6, temp);
	gf2x_mul_3_avx(temp, q_10+184, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+184, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+183, 6, t_10+183, 6, temp);
	gf2x_mul_3_avx(temp, q_10+181, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+181, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+180, 6, t_10+180, 6, temp);
	gf2x_mul_3_avx(temp, q_10+178, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+178, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+177, 6, t_10+177, 6, temp);
	gf2x_mul_3_avx(temp, q_10+175, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+175, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+174, 6, t_10+174, 6, temp);
	gf2x_mul_3_avx(temp, q_10+172, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+172, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+171, 6, t_10+171, 6, temp);
	gf2x_mul_3_avx(temp, q_10+169, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+169, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+168, 6, t_10+168, 6, temp);
	gf2x_mul_3_avx(temp, q_10+166, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+166, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+165, 6, t_10+165, 6, temp);
	gf2x_mul_3_avx(temp, q_10+163, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+163, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+162, 6, t_10+162, 6, temp);
	gf2x_mul_3_avx(temp, q_10+160, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+160, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+159, 6, t_10+159, 6, temp);
	gf2x_mul_3_avx(temp, q_10+157, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+157, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+156, 6, t_10+156, 6, temp);
	gf2x_mul_3_avx(temp, q_10+154, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+154, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+153, 6, t_10+153, 6, temp);
	gf2x_mul_3_avx(temp, q_10+151, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+151, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+150, 6, t_10+150, 6, temp);
	gf2x_mul_3_avx(temp, q_10+148, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+148, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+147, 6, t_10+147, 6, temp);
	gf2x_mul_3_avx(temp, q_10+145, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+145, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+144, 6, t_10+144, 6, temp);
	gf2x_mul_3_avx(temp, q_10+142, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+142, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+141, 6, t_10+141, 6, temp);
	gf2x_mul_3_avx(temp, q_10+139, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+139, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+138, 6, t_10+138, 6, temp);
	gf2x_mul_3_avx(temp, q_10+136, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+136, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+135, 6, t_10+135, 6, temp);
	gf2x_mul_3_avx(temp, q_10+133, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+133, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+132, 6, t_10+132, 6, temp);
	gf2x_mul_3_avx(temp, q_10+130, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+130, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+129, 6, t_10+129, 6, temp);
	gf2x_mul_3_avx(temp, q_10+127, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+127, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+126, 6, t_10+126, 6, temp);
	gf2x_mul_3_avx(temp, q_10+124, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+124, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+123, 6, t_10+123, 6, temp);
	gf2x_mul_3_avx(temp, q_10+121, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+121, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+120, 6, t_10+120, 6, temp);
	gf2x_mul_3_avx(temp, q_10+118, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+118, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+117, 6, t_10+117, 6, temp);
	gf2x_mul_3_avx(temp, q_10+115, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+115, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+114, 6, t_10+114, 6, temp);
	gf2x_mul_3_avx(temp, q_10+112, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+112, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+111, 6, t_10+111, 6, temp);
	gf2x_mul_3_avx(temp, q_10+109, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+109, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+108, 6, t_10+108, 6, temp);
	gf2x_mul_3_avx(temp, q_10+106, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+106, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+105, 6, t_10+105, 6, temp);
	gf2x_mul_3_avx(temp, q_10+103, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+103, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+102, 6, t_10+102, 6, temp);
	gf2x_mul_3_avx(temp, q_10+100, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+100, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+99, 6, t_10+99, 6, temp);
	gf2x_mul_3_avx(temp, q_10+97, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+97, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+96, 6, t_10+96, 6, temp);
	gf2x_mul_3_avx(temp, q_10+94, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+94, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+93, 6, t_10+93, 6, temp);
	gf2x_mul_3_avx(temp, q_10+91, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+91, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+90, 6, t_10+90, 6, temp);
	gf2x_mul_3_avx(temp, q_10+88, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+88, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+87, 6, t_10+87, 6, temp);
	gf2x_mul_3_avx(temp, q_10+85, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+85, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+84, 6, t_10+84, 6, temp);
	gf2x_mul_3_avx(temp, q_10+82, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+82, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+81, 6, t_10+81, 6, temp);
	gf2x_mul_3_avx(temp, q_10+79, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+79, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+78, 6, t_10+78, 6, temp);
	gf2x_mul_3_avx(temp, q_10+76, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+76, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+75, 6, t_10+75, 6, temp);
	gf2x_mul_3_avx(temp, q_10+73, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+73, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+72, 6, t_10+72, 6, temp);
	gf2x_mul_3_avx(temp, q_10+70, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+70, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+69, 6, t_10+69, 6, temp);
	gf2x_mul_3_avx(temp, q_10+67, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+67, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+66, 6, t_10+66, 6, temp);
	gf2x_mul_3_avx(temp, q_10+64, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+64, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+63, 6, t_10+63, 6, temp);
	gf2x_mul_3_avx(temp, q_10+61, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+61, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+60, 6, t_10+60, 6, temp);
	gf2x_mul_3_avx(temp, q_10+58, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+58, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+57, 6, t_10+57, 6, temp);
	gf2x_mul_3_avx(temp, q_10+55, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+55, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+54, 6, t_10+54, 6, temp);
	gf2x_mul_3_avx(temp, q_10+52, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+52, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+51, 6, t_10+51, 6, temp);
	gf2x_mul_3_avx(temp, q_10+49, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+49, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+48, 6, t_10+48, 6, temp);
	gf2x_mul_3_avx(temp, q_10+46, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+46, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+45, 6, t_10+45, 6, temp);
	gf2x_mul_3_avx(temp, q_10+43, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+43, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+42, 6, t_10+42, 6, temp);
	gf2x_mul_3_avx(temp, q_10+40, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+40, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+39, 6, t_10+39, 6, temp);
	gf2x_mul_3_avx(temp, q_10+37, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+37, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+36, 6, t_10+36, 6, temp);
	gf2x_mul_3_avx(temp, q_10+34, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+34, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+33, 6, t_10+33, 6, temp);
	gf2x_mul_3_avx(temp, q_10+31, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+31, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+30, 6, t_10+30, 6, temp);
	gf2x_mul_3_avx(temp, q_10+28, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+28, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+27, 6, t_10+27, 6, temp);
	gf2x_mul_3_avx(temp, q_10+25, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+25, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+24, 6, t_10+24, 6, temp);
	gf2x_mul_3_avx(temp, q_10+22, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+22, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+21, 6, t_10+21, 6, temp);
	gf2x_mul_3_avx(temp, q_10+19, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+19, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+18, 6, t_10+18, 6, temp);
	gf2x_mul_3_avx(temp, q_10+16, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+16, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+15, 6, t_10+15, 6, temp);
	gf2x_mul_3_avx(temp, q_10+13, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+13, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+12, 6, t_10+12, 6, temp);
	gf2x_mul_3_avx(temp, q_10+10, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+10, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+9, 6, t_10+9, 6, temp);
	gf2x_mul_3_avx(temp, q_10+7, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+7, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+6, 6, t_10+6, 6, temp);
	gf2x_mul_3_avx(temp, q_10+4, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+4, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+3, 6, t_10+3, 6, temp);
	gf2x_mul_3_avx(temp, q_10+1, p_00+0);
	gf2x_mul_3_avx(temp2, q_11+1, p_10+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_10+0, 6, t_10+0, 6, temp);
	gf2x_mul_1_avx(temp, p_00+2, q_10+0);
	gf2x_mul_1_avx(temp2, p_10+2, q_11+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, t_10+1, 2, t_10+1, 2, temp);
	gf2x_mul_1_avx(temp, p_00+1, q_10+0);
	gf2x_mul_1_avx(temp2, p_10+1, q_11+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, t_10+0, 2, t_10+0, 2, temp);
	gf2x_mul_1_avx(temp, q_10+0, p_00+0);
	gf2x_mul_1_avx(temp2, q_11+0, p_10+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, t_10+0, 1, t_10+0, 1, temp+1);
	memset(t_11+0, 0x00, 2*DIGIT_SIZE_B);
	GF2X_MUL(506, temp, 253, p_01+3, 253, q_10+0);
	GF2X_MUL(506, temp2, 253, p_11+3, 253, q_11+0);
	gf2x_add(506, t_11+2, 506, temp, 506, temp2);
	gf2x_mul_3_avx(temp, q_10+250, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+250, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+249, 6, t_11+249, 6, temp);
	gf2x_mul_3_avx(temp, q_10+247, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+247, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+246, 6, t_11+246, 6, temp);
	gf2x_mul_3_avx(temp, q_10+244, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+244, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+243, 6, t_11+243, 6, temp);
	gf2x_mul_3_avx(temp, q_10+241, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+241, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+240, 6, t_11+240, 6, temp);
	gf2x_mul_3_avx(temp, q_10+238, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+238, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+237, 6, t_11+237, 6, temp);
	gf2x_mul_3_avx(temp, q_10+235, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+235, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+234, 6, t_11+234, 6, temp);
	gf2x_mul_3_avx(temp, q_10+232, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+232, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+231, 6, t_11+231, 6, temp);
	gf2x_mul_3_avx(temp, q_10+229, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+229, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+228, 6, t_11+228, 6, temp);
	gf2x_mul_3_avx(temp, q_10+226, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+226, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+225, 6, t_11+225, 6, temp);
	gf2x_mul_3_avx(temp, q_10+223, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+223, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+222, 6, t_11+222, 6, temp);
	gf2x_mul_3_avx(temp, q_10+220, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+220, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+219, 6, t_11+219, 6, temp);
	gf2x_mul_3_avx(temp, q_10+217, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+217, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+216, 6, t_11+216, 6, temp);
	gf2x_mul_3_avx(temp, q_10+214, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+214, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+213, 6, t_11+213, 6, temp);
	gf2x_mul_3_avx(temp, q_10+211, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+211, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+210, 6, t_11+210, 6, temp);
	gf2x_mul_3_avx(temp, q_10+208, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+208, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+207, 6, t_11+207, 6, temp);
	gf2x_mul_3_avx(temp, q_10+205, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+205, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+204, 6, t_11+204, 6, temp);
	gf2x_mul_3_avx(temp, q_10+202, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+202, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+201, 6, t_11+201, 6, temp);
	gf2x_mul_3_avx(temp, q_10+199, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+199, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+198, 6, t_11+198, 6, temp);
	gf2x_mul_3_avx(temp, q_10+196, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+196, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+195, 6, t_11+195, 6, temp);
	gf2x_mul_3_avx(temp, q_10+193, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+193, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+192, 6, t_11+192, 6, temp);
	gf2x_mul_3_avx(temp, q_10+190, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+190, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+189, 6, t_11+189, 6, temp);
	gf2x_mul_3_avx(temp, q_10+187, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+187, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+186, 6, t_11+186, 6, temp);
	gf2x_mul_3_avx(temp, q_10+184, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+184, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+183, 6, t_11+183, 6, temp);
	gf2x_mul_3_avx(temp, q_10+181, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+181, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+180, 6, t_11+180, 6, temp);
	gf2x_mul_3_avx(temp, q_10+178, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+178, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+177, 6, t_11+177, 6, temp);
	gf2x_mul_3_avx(temp, q_10+175, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+175, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+174, 6, t_11+174, 6, temp);
	gf2x_mul_3_avx(temp, q_10+172, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+172, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+171, 6, t_11+171, 6, temp);
	gf2x_mul_3_avx(temp, q_10+169, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+169, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+168, 6, t_11+168, 6, temp);
	gf2x_mul_3_avx(temp, q_10+166, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+166, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+165, 6, t_11+165, 6, temp);
	gf2x_mul_3_avx(temp, q_10+163, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+163, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+162, 6, t_11+162, 6, temp);
	gf2x_mul_3_avx(temp, q_10+160, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+160, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+159, 6, t_11+159, 6, temp);
	gf2x_mul_3_avx(temp, q_10+157, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+157, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+156, 6, t_11+156, 6, temp);
	gf2x_mul_3_avx(temp, q_10+154, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+154, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+153, 6, t_11+153, 6, temp);
	gf2x_mul_3_avx(temp, q_10+151, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+151, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+150, 6, t_11+150, 6, temp);
	gf2x_mul_3_avx(temp, q_10+148, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+148, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+147, 6, t_11+147, 6, temp);
	gf2x_mul_3_avx(temp, q_10+145, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+145, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+144, 6, t_11+144, 6, temp);
	gf2x_mul_3_avx(temp, q_10+142, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+142, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+141, 6, t_11+141, 6, temp);
	gf2x_mul_3_avx(temp, q_10+139, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+139, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+138, 6, t_11+138, 6, temp);
	gf2x_mul_3_avx(temp, q_10+136, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+136, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+135, 6, t_11+135, 6, temp);
	gf2x_mul_3_avx(temp, q_10+133, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+133, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+132, 6, t_11+132, 6, temp);
	gf2x_mul_3_avx(temp, q_10+130, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+130, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+129, 6, t_11+129, 6, temp);
	gf2x_mul_3_avx(temp, q_10+127, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+127, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+126, 6, t_11+126, 6, temp);
	gf2x_mul_3_avx(temp, q_10+124, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+124, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+123, 6, t_11+123, 6, temp);
	gf2x_mul_3_avx(temp, q_10+121, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+121, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+120, 6, t_11+120, 6, temp);
	gf2x_mul_3_avx(temp, q_10+118, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+118, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+117, 6, t_11+117, 6, temp);
	gf2x_mul_3_avx(temp, q_10+115, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+115, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+114, 6, t_11+114, 6, temp);
	gf2x_mul_3_avx(temp, q_10+112, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+112, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+111, 6, t_11+111, 6, temp);
	gf2x_mul_3_avx(temp, q_10+109, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+109, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+108, 6, t_11+108, 6, temp);
	gf2x_mul_3_avx(temp, q_10+106, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+106, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+105, 6, t_11+105, 6, temp);
	gf2x_mul_3_avx(temp, q_10+103, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+103, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+102, 6, t_11+102, 6, temp);
	gf2x_mul_3_avx(temp, q_10+100, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+100, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+99, 6, t_11+99, 6, temp);
	gf2x_mul_3_avx(temp, q_10+97, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+97, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+96, 6, t_11+96, 6, temp);
	gf2x_mul_3_avx(temp, q_10+94, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+94, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+93, 6, t_11+93, 6, temp);
	gf2x_mul_3_avx(temp, q_10+91, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+91, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+90, 6, t_11+90, 6, temp);
	gf2x_mul_3_avx(temp, q_10+88, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+88, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+87, 6, t_11+87, 6, temp);
	gf2x_mul_3_avx(temp, q_10+85, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+85, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+84, 6, t_11+84, 6, temp);
	gf2x_mul_3_avx(temp, q_10+82, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+82, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+81, 6, t_11+81, 6, temp);
	gf2x_mul_3_avx(temp, q_10+79, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+79, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+78, 6, t_11+78, 6, temp);
	gf2x_mul_3_avx(temp, q_10+76, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+76, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+75, 6, t_11+75, 6, temp);
	gf2x_mul_3_avx(temp, q_10+73, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+73, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+72, 6, t_11+72, 6, temp);
	gf2x_mul_3_avx(temp, q_10+70, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+70, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+69, 6, t_11+69, 6, temp);
	gf2x_mul_3_avx(temp, q_10+67, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+67, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+66, 6, t_11+66, 6, temp);
	gf2x_mul_3_avx(temp, q_10+64, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+64, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+63, 6, t_11+63, 6, temp);
	gf2x_mul_3_avx(temp, q_10+61, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+61, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+60, 6, t_11+60, 6, temp);
	gf2x_mul_3_avx(temp, q_10+58, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+58, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+57, 6, t_11+57, 6, temp);
	gf2x_mul_3_avx(temp, q_10+55, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+55, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+54, 6, t_11+54, 6, temp);
	gf2x_mul_3_avx(temp, q_10+52, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+52, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+51, 6, t_11+51, 6, temp);
	gf2x_mul_3_avx(temp, q_10+49, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+49, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+48, 6, t_11+48, 6, temp);
	gf2x_mul_3_avx(temp, q_10+46, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+46, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+45, 6, t_11+45, 6, temp);
	gf2x_mul_3_avx(temp, q_10+43, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+43, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+42, 6, t_11+42, 6, temp);
	gf2x_mul_3_avx(temp, q_10+40, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+40, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+39, 6, t_11+39, 6, temp);
	gf2x_mul_3_avx(temp, q_10+37, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+37, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+36, 6, t_11+36, 6, temp);
	gf2x_mul_3_avx(temp, q_10+34, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+34, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+33, 6, t_11+33, 6, temp);
	gf2x_mul_3_avx(temp, q_10+31, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+31, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+30, 6, t_11+30, 6, temp);
	gf2x_mul_3_avx(temp, q_10+28, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+28, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+27, 6, t_11+27, 6, temp);
	gf2x_mul_3_avx(temp, q_10+25, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+25, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+24, 6, t_11+24, 6, temp);
	gf2x_mul_3_avx(temp, q_10+22, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+22, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+21, 6, t_11+21, 6, temp);
	gf2x_mul_3_avx(temp, q_10+19, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+19, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+18, 6, t_11+18, 6, temp);
	gf2x_mul_3_avx(temp, q_10+16, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+16, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+15, 6, t_11+15, 6, temp);
	gf2x_mul_3_avx(temp, q_10+13, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+13, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+12, 6, t_11+12, 6, temp);
	gf2x_mul_3_avx(temp, q_10+10, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+10, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+9, 6, t_11+9, 6, temp);
	gf2x_mul_3_avx(temp, q_10+7, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+7, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+6, 6, t_11+6, 6, temp);
	gf2x_mul_3_avx(temp, q_10+4, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+4, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+3, 6, t_11+3, 6, temp);
	gf2x_mul_3_avx(temp, q_10+1, p_01+0);
	gf2x_mul_3_avx(temp2, q_11+1, p_11+0);
	gf2x_add(6, temp, 6, temp, 6, temp2);
	gf2x_add(6, t_11+0, 6, t_11+0, 6, temp);
	gf2x_mul_1_avx(temp, p_01+2, q_10+0);
	gf2x_mul_1_avx(temp2, p_11+2, q_11+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, t_11+1, 2, t_11+1, 2, temp);
	gf2x_mul_1_avx(temp, p_01+1, q_10+0);
	gf2x_mul_1_avx(temp2, p_11+1, q_11+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(2, t_11+0, 2, t_11+0, 2, temp);
	gf2x_mul_1_avx(temp, q_10+0, p_01+0);
	gf2x_mul_1_avx(temp2, q_11+0, p_11+0);
	gf2x_add(2, temp, 2, temp, 2, temp2);
	gf2x_add(1, t_11+0, 1, t_11+0, 1, temp+1);
	
	return delta;
}