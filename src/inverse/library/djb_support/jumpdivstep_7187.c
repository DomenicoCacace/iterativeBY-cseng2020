/**
  * @author Domenico Cacace <domenico.cacace@mail.polimi.it>
  * 
  *
  * This code is hereby placed in the public domain.
  *
  * THIS SOFTWARE IS PROVIDED BY THE AUTHORS ''AS IS'' AND ANY EXPRESS
  * OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
  * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHORS OR CONTRIBUTORS BE
  * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
  * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
  * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
  * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
  * EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **/

#include "../../include/inverse_DJB_facilities.h"

int jumpdivstep_7187(int delta, DIGIT *f, DIGIT *g, DIGIT *t_00, DIGIT *t_01, DIGIT *t_10, DIGIT *t_11) {
	DIGIT p_00[236];
	DIGIT p_01[236];
	DIGIT p_10[236];
	DIGIT p_11[236];
	
	DIGIT q_00[222];
	DIGIT q_01[222];
	DIGIT q_10[222];
	DIGIT q_11[222];
	
	DIGIT f_sum[700];
	DIGIT g_sum[700];
	
	DIGIT temp[232];
	DIGIT temp2[232];
	

	delta = divstepsx_256(255, delta, f+221, g+221, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f+221, p_00+232);
	gf2x_mul_4_avx(temp2, g+221, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f+217, p_00+232);
	gf2x_mul_4_avx(temp2, g+217, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f+221, p_10+232);
	gf2x_mul_4_avx(temp2, g+221, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f+217, p_10+232);
	gf2x_mul_4_avx(temp2, g+217, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, p_00+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, p_01+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, p_10+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, p_11+224, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, f+217, p_00+224);
	gf2x_mul_8_avx(temp2, g+217, p_01+224);
	gf2x_add(16, f_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f+209, p_00+224);
	gf2x_mul_8_avx(temp2, g+209, p_01+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+661, 8, f_sum+661, 8, temp+8);
	right_bit_shift_n(16, f_sum+661, 62);
	gf2x_mul_8_avx(temp, f+217, p_10+224);
	gf2x_mul_8_avx(temp2, g+217, p_11+224);
	gf2x_add(16, g_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f+209, p_10+224);
	gf2x_mul_8_avx(temp2, g+209, p_11+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+661, 8, g_sum+661, 8, temp+8);
	right_bit_shift_n(16, g_sum+661, 62);
	
	delta = divstepsx_256(255, delta, f_sum+666, g_sum+666, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+666, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+666, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, q_00+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, q_01+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, q_10+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, q_11+210, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, q_00+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_10+224);
	gf2x_add(16, p_00+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_11+224);
	gf2x_add(16, p_01+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_10+224);
	gf2x_add(16, p_10+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_11+224);
	gf2x_add(16, p_11+208, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 2040, depth: 3
	GF2X_MUL(32, temp, 16, f+209, 16, p_00+208);
	GF2X_MUL(32, temp2, 16, g+209, 16, p_01+208);
	gf2x_add(32, f_sum+612, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f+193, 16, p_00+208);
	GF2X_MUL(32, temp2, 16, g+193, 16, p_01+208);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, f_sum+612, 16, f_sum+612, 16, temp+16);
	right_bit_shift_n(32, f_sum+612, 60);
	GF2X_MUL(32, temp, 16, f+209, 16, p_10+208);
	GF2X_MUL(32, temp2, 16, g+209, 16, p_11+208);
	gf2x_add(32, g_sum+612, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, f+193, 16, p_10+208);
	GF2X_MUL(32, temp2, 16, g+193, 16, p_11+208);
	gf2x_add(32, temp, 32, temp, 32, temp2);
	gf2x_add(16, g_sum+612, 16, g_sum+612, 16, temp+16);
	right_bit_shift_n(32, g_sum+612, 60);
	
	delta = divstepsx_256(255, delta, f_sum+625, g_sum+625, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+625, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+625, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+621, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+621, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+625, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+625, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+621, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+621, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, p_00+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, p_01+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, p_10+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, p_11+224, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, f_sum+621, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+621, p_01+224);
	gf2x_add(16, f_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+613, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+613, p_01+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+661, 8, f_sum+661, 8, temp+8);
	right_bit_shift_n(16, f_sum+661, 62);
	gf2x_mul_8_avx(temp, f_sum+621, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+621, p_11+224);
	gf2x_add(16, g_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+613, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+613, p_11+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+661, 8, g_sum+661, 8, temp+8);
	right_bit_shift_n(16, g_sum+661, 62);
	
	delta = divstepsx_256(255, delta, f_sum+666, g_sum+666, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+666, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+666, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, q_00+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, q_01+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, q_10+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, q_11+210, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, q_00+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_10+224);
	gf2x_add(16, q_00+194, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_11+224);
	gf2x_add(16, q_01+194, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_10+224);
	gf2x_add(16, q_10+194, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_11+224);
	gf2x_add(16, q_11+194, 16, temp, 16, temp2);
	
	// Recombining results: n: 2040, depth: 3
	GF2X_MUL(32, temp, 16, q_00+194, 16, p_00+208);
	GF2X_MUL(32, temp2, 16, q_01+194, 16, p_10+208);
	gf2x_add(32, p_00+176, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_00+194, 16, p_01+208);
	GF2X_MUL(32, temp2, 16, q_01+194, 16, p_11+208);
	gf2x_add(32, p_01+176, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+194, 16, p_00+208);
	GF2X_MUL(32, temp2, 16, q_11+194, 16, p_10+208);
	gf2x_add(32, p_10+176, 32, temp, 32, temp2);
	GF2X_MUL(32, temp, 16, q_10+194, 16, p_01+208);
	GF2X_MUL(32, temp2, 16, q_11+194, 16, p_11+208);
	gf2x_add(32, p_11+176, 32, temp, 32, temp2);
	
	// Calculating left operands: n: 3825, depth: 2
	GF2X_MUL(64, temp, 32, f+193, 32, p_00+176);
	GF2X_MUL(64, temp2, 32, g+193, 32, p_01+176);
	gf2x_add(60, f_sum+519, 60, temp+4, 60, temp2+4);
	GF2X_MUL(56, temp, 28, p_00+180, 28, f+165);
	GF2X_MUL(56, temp2, 28, p_01+180, 28, g+165);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+519, 28, f_sum+519, 28, temp+28);
	right_bit_shift_n(60, f_sum+519, 56);
	GF2X_MUL(64, temp, 32, f+193, 32, p_10+176);
	GF2X_MUL(64, temp2, 32, g+193, 32, p_11+176);
	gf2x_add(60, g_sum+519, 60, temp+4, 60, temp2+4);
	GF2X_MUL(56, temp, 28, p_10+180, 28, f+165);
	GF2X_MUL(56, temp2, 28, p_11+180, 28, g+165);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+519, 28, g_sum+519, 28, temp+28);
	right_bit_shift_n(60, g_sum+519, 56);
	
	delta = divstepsx_256(255, delta, f_sum+544, g_sum+544, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+544, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+544, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+540, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+540, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+544, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+544, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+540, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+540, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, p_00+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, p_01+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, p_10+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, p_11+224, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, f_sum+540, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+540, p_01+224);
	gf2x_add(16, f_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+532, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+532, p_01+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+661, 8, f_sum+661, 8, temp+8);
	right_bit_shift_n(16, f_sum+661, 62);
	gf2x_mul_8_avx(temp, f_sum+540, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+540, p_11+224);
	gf2x_add(16, g_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+532, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+532, p_11+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+661, 8, g_sum+661, 8, temp+8);
	right_bit_shift_n(16, g_sum+661, 62);
	
	delta = divstepsx_256(255, delta, f_sum+666, g_sum+666, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+666, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+666, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, q_00+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, q_01+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, q_10+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, q_11+210, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, q_00+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_10+224);
	gf2x_add(16, p_00+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_11+224);
	gf2x_add(16, p_01+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_10+224);
	gf2x_add(16, p_10+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_11+224);
	gf2x_add(16, p_11+208, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 3
	GF2X_MUL(32, temp, 16, f_sum+532, 16, p_00+208);
	GF2X_MUL(32, temp2, 16, g_sum+532, 16, p_01+208);
	gf2x_add(28, f_sum+612, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+212, 12, f_sum+520);
	GF2X_MUL(24, temp2, 12, p_01+212, 12, g_sum+520);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+612, 12, f_sum+612, 12, temp+12);
	right_bit_shift_n(28, f_sum+612, 60);
	GF2X_MUL(32, temp, 16, f_sum+532, 16, p_10+208);
	GF2X_MUL(32, temp2, 16, g_sum+532, 16, p_11+208);
	gf2x_add(28, g_sum+612, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+212, 12, f_sum+520);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, g_sum+520);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+612, 12, g_sum+612, 12, temp+12);
	right_bit_shift_n(28, g_sum+612, 60);
	
	delta = divstepsx_256(255, delta, f_sum+621, g_sum+621, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+621, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+621, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+617, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+617, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+621, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+621, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+617, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+617, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, p_00+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, p_01+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, p_10+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, p_11+224, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 4
	gf2x_mul_8_avx(temp, f_sum+617, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+617, p_01+224);
	gf2x_add(12, f_sum+661, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+228, f_sum+613);
	gf2x_mul_4_avx(temp2, p_01+228, g_sum+613);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+661, 4, f_sum+661, 4, temp+4);
	right_bit_shift_n(12, f_sum+661, 62);
	gf2x_mul_8_avx(temp, f_sum+617, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+617, p_11+224);
	gf2x_add(12, g_sum+661, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+228, f_sum+613);
	gf2x_mul_4_avx(temp2, p_11+228, g_sum+613);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+661, 4, g_sum+661, 4, temp+4);
	right_bit_shift_n(12, g_sum+661, 62);
	
	delta = divstepsx_256(255, delta, f_sum+662, g_sum+662, q_00+210, q_01+210, q_10+210, q_11+210);

	// Recombining results: n: 765, depth: 4
	memset(q_00+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+228, q_00+210);
	gf2x_mul_4_avx(temp2, p_10+228, q_01+210);
	gf2x_add(8, q_00+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+210, p_00+224);
	gf2x_mul_4_avx(temp2, q_01+210, p_10+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+194, 8, q_00+194, 8, temp);
	memset(q_01+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+228, q_00+210);
	gf2x_mul_4_avx(temp2, p_11+228, q_01+210);
	gf2x_add(8, q_01+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+210, p_01+224);
	gf2x_mul_4_avx(temp2, q_01+210, p_11+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+194, 8, q_01+194, 8, temp);
	memset(q_10+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+228, q_10+210);
	gf2x_mul_4_avx(temp2, p_10+228, q_11+210);
	gf2x_add(8, q_10+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+210, p_00+224);
	gf2x_mul_4_avx(temp2, q_11+210, p_10+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+194, 8, q_10+194, 8, temp);
	memset(q_11+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+228, q_10+210);
	gf2x_mul_4_avx(temp2, p_11+228, q_11+210);
	gf2x_add(8, q_11+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+210, p_01+224);
	gf2x_mul_4_avx(temp2, q_11+210, p_11+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+194, 8, q_11+194, 8, temp);
	
	// Recombining results: n: 1785, depth: 3
	memset(q_00+166, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+212, 12, q_00+194);
	GF2X_MUL(24, temp2, 12, p_10+212, 12, q_01+194);
	gf2x_add(24, q_00+170, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+202, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+202, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+174, 8, q_00+174, 8, temp);
	gf2x_mul_4_avx(temp, q_00+198, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+198, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+170, 8, q_00+170, 8, temp);
	gf2x_mul_4_avx(temp, q_00+194, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+194, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+166, 8, q_00+166, 8, temp);
	memset(q_01+166, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+212, 12, q_00+194);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, q_01+194);
	gf2x_add(24, q_01+170, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+202, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+202, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+174, 8, q_01+174, 8, temp);
	gf2x_mul_4_avx(temp, q_00+198, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+198, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+170, 8, q_01+170, 8, temp);
	gf2x_mul_4_avx(temp, q_00+194, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+194, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+166, 8, q_01+166, 8, temp);
	memset(q_10+166, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+212, 12, q_10+194);
	GF2X_MUL(24, temp2, 12, p_10+212, 12, q_11+194);
	gf2x_add(24, q_10+170, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+202, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+202, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+174, 8, q_10+174, 8, temp);
	gf2x_mul_4_avx(temp, q_10+198, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+198, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+170, 8, q_10+170, 8, temp);
	gf2x_mul_4_avx(temp, q_10+194, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+194, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+166, 8, q_10+166, 8, temp);
	memset(q_11+166, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+212, 12, q_10+194);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, q_11+194);
	gf2x_add(24, q_11+170, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+202, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+202, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+174, 8, q_11+174, 8, temp);
	gf2x_mul_4_avx(temp, q_10+198, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+198, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+170, 8, q_11+170, 8, temp);
	gf2x_mul_4_avx(temp, q_10+194, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+194, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+166, 8, q_11+166, 8, temp);
	
	// Recombining results: n: 3825, depth: 2
	memset(p_00+116, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(56, temp, 28, p_00+180, 28, q_00+166);
	GF2X_MUL(56, temp2, 28, p_10+180, 28, q_01+166);
	gf2x_add(56, p_00+120, 56, temp, 56, temp2);
	gf2x_mul_4_avx(temp, q_00+190, p_00+176);
	gf2x_mul_4_avx(temp2, q_01+190, p_10+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+140, 8, p_00+140, 8, temp);
	gf2x_mul_4_avx(temp, q_00+186, p_00+176);
	gf2x_mul_4_avx(temp2, q_01+186, p_10+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+136, 8, p_00+136, 8, temp);
	gf2x_mul_4_avx(temp, q_00+182, p_00+176);
	gf2x_mul_4_avx(temp2, q_01+182, p_10+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+132, 8, p_00+132, 8, temp);
	gf2x_mul_4_avx(temp, q_00+178, p_00+176);
	gf2x_mul_4_avx(temp2, q_01+178, p_10+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+128, 8, p_00+128, 8, temp);
	gf2x_mul_4_avx(temp, q_00+174, p_00+176);
	gf2x_mul_4_avx(temp2, q_01+174, p_10+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+124, 8, p_00+124, 8, temp);
	gf2x_mul_4_avx(temp, q_00+170, p_00+176);
	gf2x_mul_4_avx(temp2, q_01+170, p_10+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+120, 8, p_00+120, 8, temp);
	gf2x_mul_4_avx(temp, q_00+166, p_00+176);
	gf2x_mul_4_avx(temp2, q_01+166, p_10+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+116, 8, p_00+116, 8, temp);
	memset(p_01+116, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(56, temp, 28, p_01+180, 28, q_00+166);
	GF2X_MUL(56, temp2, 28, p_11+180, 28, q_01+166);
	gf2x_add(56, p_01+120, 56, temp, 56, temp2);
	gf2x_mul_4_avx(temp, q_00+190, p_01+176);
	gf2x_mul_4_avx(temp2, q_01+190, p_11+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+140, 8, p_01+140, 8, temp);
	gf2x_mul_4_avx(temp, q_00+186, p_01+176);
	gf2x_mul_4_avx(temp2, q_01+186, p_11+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+136, 8, p_01+136, 8, temp);
	gf2x_mul_4_avx(temp, q_00+182, p_01+176);
	gf2x_mul_4_avx(temp2, q_01+182, p_11+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+132, 8, p_01+132, 8, temp);
	gf2x_mul_4_avx(temp, q_00+178, p_01+176);
	gf2x_mul_4_avx(temp2, q_01+178, p_11+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+128, 8, p_01+128, 8, temp);
	gf2x_mul_4_avx(temp, q_00+174, p_01+176);
	gf2x_mul_4_avx(temp2, q_01+174, p_11+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+124, 8, p_01+124, 8, temp);
	gf2x_mul_4_avx(temp, q_00+170, p_01+176);
	gf2x_mul_4_avx(temp2, q_01+170, p_11+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+120, 8, p_01+120, 8, temp);
	gf2x_mul_4_avx(temp, q_00+166, p_01+176);
	gf2x_mul_4_avx(temp2, q_01+166, p_11+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+116, 8, p_01+116, 8, temp);
	memset(p_10+116, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(56, temp, 28, p_00+180, 28, q_10+166);
	GF2X_MUL(56, temp2, 28, p_10+180, 28, q_11+166);
	gf2x_add(56, p_10+120, 56, temp, 56, temp2);
	gf2x_mul_4_avx(temp, q_10+190, p_00+176);
	gf2x_mul_4_avx(temp2, q_11+190, p_10+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+140, 8, p_10+140, 8, temp);
	gf2x_mul_4_avx(temp, q_10+186, p_00+176);
	gf2x_mul_4_avx(temp2, q_11+186, p_10+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+136, 8, p_10+136, 8, temp);
	gf2x_mul_4_avx(temp, q_10+182, p_00+176);
	gf2x_mul_4_avx(temp2, q_11+182, p_10+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+132, 8, p_10+132, 8, temp);
	gf2x_mul_4_avx(temp, q_10+178, p_00+176);
	gf2x_mul_4_avx(temp2, q_11+178, p_10+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+128, 8, p_10+128, 8, temp);
	gf2x_mul_4_avx(temp, q_10+174, p_00+176);
	gf2x_mul_4_avx(temp2, q_11+174, p_10+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+124, 8, p_10+124, 8, temp);
	gf2x_mul_4_avx(temp, q_10+170, p_00+176);
	gf2x_mul_4_avx(temp2, q_11+170, p_10+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+120, 8, p_10+120, 8, temp);
	gf2x_mul_4_avx(temp, q_10+166, p_00+176);
	gf2x_mul_4_avx(temp2, q_11+166, p_10+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+116, 8, p_10+116, 8, temp);
	memset(p_11+116, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(56, temp, 28, p_01+180, 28, q_10+166);
	GF2X_MUL(56, temp2, 28, p_11+180, 28, q_11+166);
	gf2x_add(56, p_11+120, 56, temp, 56, temp2);
	gf2x_mul_4_avx(temp, q_10+190, p_01+176);
	gf2x_mul_4_avx(temp2, q_11+190, p_11+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+140, 8, p_11+140, 8, temp);
	gf2x_mul_4_avx(temp, q_10+186, p_01+176);
	gf2x_mul_4_avx(temp2, q_11+186, p_11+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+136, 8, p_11+136, 8, temp);
	gf2x_mul_4_avx(temp, q_10+182, p_01+176);
	gf2x_mul_4_avx(temp2, q_11+182, p_11+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+132, 8, p_11+132, 8, temp);
	gf2x_mul_4_avx(temp, q_10+178, p_01+176);
	gf2x_mul_4_avx(temp2, q_11+178, p_11+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+128, 8, p_11+128, 8, temp);
	gf2x_mul_4_avx(temp, q_10+174, p_01+176);
	gf2x_mul_4_avx(temp2, q_11+174, p_11+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+124, 8, p_11+124, 8, temp);
	gf2x_mul_4_avx(temp, q_10+170, p_01+176);
	gf2x_mul_4_avx(temp2, q_11+170, p_11+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+120, 8, p_11+120, 8, temp);
	gf2x_mul_4_avx(temp, q_10+166, p_01+176);
	gf2x_mul_4_avx(temp2, q_11+166, p_11+176);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+116, 8, p_11+116, 8, temp);
	
	// Calculating left operands: n: 7395, depth: 1
	GF2X_MUL(120, temp, 60, f+165, 60, p_00+116);
	GF2X_MUL(120, temp2, 60, g+165, 60, p_01+116);
	gf2x_add(116, f_sum+342, 116, temp+4, 116, temp2+4);
	GF2X_MUL(112, temp, 56, p_00+120, 56, f+109);
	GF2X_MUL(112, temp2, 56, p_01+120, 56, g+109);
	gf2x_add(112, temp, 112, temp, 112, temp2);
	gf2x_add(56, f_sum+342, 56, f_sum+342, 56, temp+56);
	right_bit_shift_n(116, f_sum+342, 49);
	GF2X_MUL(120, temp, 60, f+165, 60, p_10+116);
	GF2X_MUL(120, temp2, 60, g+165, 60, p_11+116);
	gf2x_add(116, g_sum+342, 116, temp+4, 116, temp2+4);
	GF2X_MUL(112, temp, 56, p_10+120, 56, f+109);
	GF2X_MUL(112, temp2, 56, p_11+120, 56, g+109);
	gf2x_add(112, temp, 112, temp, 112, temp2);
	gf2x_add(56, g_sum+342, 56, g_sum+342, 56, temp+56);
	right_bit_shift_n(116, g_sum+342, 49);
	
	delta = divstepsx_256(255, delta, f_sum+395, g_sum+395, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+395, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+395, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+391, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+391, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+395, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+395, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+391, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+391, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, p_00+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, p_01+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, p_10+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, p_11+224, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, f_sum+391, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+391, p_01+224);
	gf2x_add(16, f_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+383, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+383, p_01+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+661, 8, f_sum+661, 8, temp+8);
	right_bit_shift_n(16, f_sum+661, 62);
	gf2x_mul_8_avx(temp, f_sum+391, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+391, p_11+224);
	gf2x_add(16, g_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+383, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+383, p_11+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+661, 8, g_sum+661, 8, temp+8);
	right_bit_shift_n(16, g_sum+661, 62);
	
	delta = divstepsx_256(255, delta, f_sum+666, g_sum+666, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+666, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+666, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, q_00+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, q_01+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, q_10+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, q_11+210, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, q_00+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_10+224);
	gf2x_add(16, p_00+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_11+224);
	gf2x_add(16, p_01+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_10+224);
	gf2x_add(16, p_10+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_11+224);
	gf2x_add(16, p_11+208, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 3
	GF2X_MUL(32, temp, 16, f_sum+383, 16, p_00+208);
	GF2X_MUL(32, temp2, 16, g_sum+383, 16, p_01+208);
	gf2x_add(28, f_sum+612, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+212, 12, f_sum+371);
	GF2X_MUL(24, temp2, 12, p_01+212, 12, g_sum+371);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+612, 12, f_sum+612, 12, temp+12);
	right_bit_shift_n(28, f_sum+612, 60);
	GF2X_MUL(32, temp, 16, f_sum+383, 16, p_10+208);
	GF2X_MUL(32, temp2, 16, g_sum+383, 16, p_11+208);
	gf2x_add(28, g_sum+612, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+212, 12, f_sum+371);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, g_sum+371);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+612, 12, g_sum+612, 12, temp+12);
	right_bit_shift_n(28, g_sum+612, 60);
	
	delta = divstepsx_256(255, delta, f_sum+621, g_sum+621, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+621, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+621, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+617, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+617, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+621, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+621, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+617, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+617, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, p_00+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, p_01+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, p_10+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, p_11+224, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 4
	gf2x_mul_8_avx(temp, f_sum+617, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+617, p_01+224);
	gf2x_add(12, f_sum+661, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+228, f_sum+613);
	gf2x_mul_4_avx(temp2, p_01+228, g_sum+613);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+661, 4, f_sum+661, 4, temp+4);
	right_bit_shift_n(12, f_sum+661, 62);
	gf2x_mul_8_avx(temp, f_sum+617, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+617, p_11+224);
	gf2x_add(12, g_sum+661, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+228, f_sum+613);
	gf2x_mul_4_avx(temp2, p_11+228, g_sum+613);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+661, 4, g_sum+661, 4, temp+4);
	right_bit_shift_n(12, g_sum+661, 62);
	
	delta = divstepsx_256(255, delta, f_sum+662, g_sum+662, q_00+210, q_01+210, q_10+210, q_11+210);

	// Recombining results: n: 765, depth: 4
	memset(q_00+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+228, q_00+210);
	gf2x_mul_4_avx(temp2, p_10+228, q_01+210);
	gf2x_add(8, q_00+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+210, p_00+224);
	gf2x_mul_4_avx(temp2, q_01+210, p_10+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+194, 8, q_00+194, 8, temp);
	memset(q_01+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+228, q_00+210);
	gf2x_mul_4_avx(temp2, p_11+228, q_01+210);
	gf2x_add(8, q_01+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+210, p_01+224);
	gf2x_mul_4_avx(temp2, q_01+210, p_11+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+194, 8, q_01+194, 8, temp);
	memset(q_10+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+228, q_10+210);
	gf2x_mul_4_avx(temp2, p_10+228, q_11+210);
	gf2x_add(8, q_10+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+210, p_00+224);
	gf2x_mul_4_avx(temp2, q_11+210, p_10+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+194, 8, q_10+194, 8, temp);
	memset(q_11+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+228, q_10+210);
	gf2x_mul_4_avx(temp2, p_11+228, q_11+210);
	gf2x_add(8, q_11+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+210, p_01+224);
	gf2x_mul_4_avx(temp2, q_11+210, p_11+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+194, 8, q_11+194, 8, temp);
	
	// Recombining results: n: 1785, depth: 3
	memset(p_00+176, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+212, 12, q_00+194);
	GF2X_MUL(24, temp2, 12, p_10+212, 12, q_01+194);
	gf2x_add(24, p_00+180, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+202, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+202, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+184, 8, p_00+184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+198, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+198, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+180, 8, p_00+180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+194, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+194, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+176, 8, p_00+176, 8, temp);
	memset(p_01+176, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+212, 12, q_00+194);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, q_01+194);
	gf2x_add(24, p_01+180, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+202, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+202, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+184, 8, p_01+184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+198, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+198, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+180, 8, p_01+180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+194, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+194, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+176, 8, p_01+176, 8, temp);
	memset(p_10+176, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+212, 12, q_10+194);
	GF2X_MUL(24, temp2, 12, p_10+212, 12, q_11+194);
	gf2x_add(24, p_10+180, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+202, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+202, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+184, 8, p_10+184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+198, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+198, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+180, 8, p_10+180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+194, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+194, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+176, 8, p_10+176, 8, temp);
	memset(p_11+176, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+212, 12, q_10+194);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, q_11+194);
	gf2x_add(24, p_11+180, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+202, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+202, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+184, 8, p_11+184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+198, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+198, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+180, 8, p_11+180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+194, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+194, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+176, 8, p_11+176, 8, temp);
	
	// Calculating left operands: n: 3570, depth: 2
	GF2X_MUL(56, temp, 28, f_sum+371, 28, p_00+176);
	GF2X_MUL(56, temp2, 28, g_sum+371, 28, p_01+176);
	gf2x_add(56, f_sum+519, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+343, 28, p_00+176);
	GF2X_MUL(56, temp2, 28, g_sum+343, 28, p_01+176);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+519, 28, f_sum+519, 28, temp+28);
	right_bit_shift_n(56, f_sum+519, 57);
	GF2X_MUL(56, temp, 28, f_sum+371, 28, p_10+176);
	GF2X_MUL(56, temp2, 28, g_sum+371, 28, p_11+176);
	gf2x_add(56, g_sum+519, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+343, 28, p_10+176);
	GF2X_MUL(56, temp2, 28, g_sum+343, 28, p_11+176);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+519, 28, g_sum+519, 28, temp+28);
	right_bit_shift_n(56, g_sum+519, 57);
	
	delta = divstepsx_256(255, delta, f_sum+544, g_sum+544, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+544, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+544, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+540, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+540, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+544, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+544, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+540, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+540, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, p_00+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, p_01+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, p_10+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, p_11+224, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, f_sum+540, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+540, p_01+224);
	gf2x_add(16, f_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+532, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+532, p_01+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+661, 8, f_sum+661, 8, temp+8);
	right_bit_shift_n(16, f_sum+661, 62);
	gf2x_mul_8_avx(temp, f_sum+540, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+540, p_11+224);
	gf2x_add(16, g_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+532, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+532, p_11+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+661, 8, g_sum+661, 8, temp+8);
	right_bit_shift_n(16, g_sum+661, 62);
	
	delta = divstepsx_256(255, delta, f_sum+666, g_sum+666, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+666, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+666, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, q_00+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, q_01+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, q_10+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, q_11+210, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, q_00+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_10+224);
	gf2x_add(16, p_00+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_11+224);
	gf2x_add(16, p_01+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_10+224);
	gf2x_add(16, p_10+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_11+224);
	gf2x_add(16, p_11+208, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 3
	GF2X_MUL(32, temp, 16, f_sum+532, 16, p_00+208);
	GF2X_MUL(32, temp2, 16, g_sum+532, 16, p_01+208);
	gf2x_add(28, f_sum+612, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+212, 12, f_sum+520);
	GF2X_MUL(24, temp2, 12, p_01+212, 12, g_sum+520);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+612, 12, f_sum+612, 12, temp+12);
	right_bit_shift_n(28, f_sum+612, 60);
	GF2X_MUL(32, temp, 16, f_sum+532, 16, p_10+208);
	GF2X_MUL(32, temp2, 16, g_sum+532, 16, p_11+208);
	gf2x_add(28, g_sum+612, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+212, 12, f_sum+520);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, g_sum+520);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+612, 12, g_sum+612, 12, temp+12);
	right_bit_shift_n(28, g_sum+612, 60);
	
	delta = divstepsx_256(255, delta, f_sum+621, g_sum+621, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+621, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+621, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+617, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+617, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+621, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+621, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+617, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+617, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, p_00+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, p_01+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, p_10+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, p_11+224, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 4
	gf2x_mul_8_avx(temp, f_sum+617, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+617, p_01+224);
	gf2x_add(12, f_sum+661, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+228, f_sum+613);
	gf2x_mul_4_avx(temp2, p_01+228, g_sum+613);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+661, 4, f_sum+661, 4, temp+4);
	right_bit_shift_n(12, f_sum+661, 62);
	gf2x_mul_8_avx(temp, f_sum+617, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+617, p_11+224);
	gf2x_add(12, g_sum+661, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+228, f_sum+613);
	gf2x_mul_4_avx(temp2, p_11+228, g_sum+613);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+661, 4, g_sum+661, 4, temp+4);
	right_bit_shift_n(12, g_sum+661, 62);
	
	delta = divstepsx_256(255, delta, f_sum+662, g_sum+662, q_00+210, q_01+210, q_10+210, q_11+210);

	// Recombining results: n: 765, depth: 4
	memset(q_00+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+228, q_00+210);
	gf2x_mul_4_avx(temp2, p_10+228, q_01+210);
	gf2x_add(8, q_00+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+210, p_00+224);
	gf2x_mul_4_avx(temp2, q_01+210, p_10+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+194, 8, q_00+194, 8, temp);
	memset(q_01+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+228, q_00+210);
	gf2x_mul_4_avx(temp2, p_11+228, q_01+210);
	gf2x_add(8, q_01+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+210, p_01+224);
	gf2x_mul_4_avx(temp2, q_01+210, p_11+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+194, 8, q_01+194, 8, temp);
	memset(q_10+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+228, q_10+210);
	gf2x_mul_4_avx(temp2, p_10+228, q_11+210);
	gf2x_add(8, q_10+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+210, p_00+224);
	gf2x_mul_4_avx(temp2, q_11+210, p_10+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+194, 8, q_10+194, 8, temp);
	memset(q_11+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+228, q_10+210);
	gf2x_mul_4_avx(temp2, p_11+228, q_11+210);
	gf2x_add(8, q_11+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+210, p_01+224);
	gf2x_mul_4_avx(temp2, q_11+210, p_11+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+194, 8, q_11+194, 8, temp);
	
	// Recombining results: n: 1785, depth: 3
	memset(q_00+166, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+212, 12, q_00+194);
	GF2X_MUL(24, temp2, 12, p_10+212, 12, q_01+194);
	gf2x_add(24, q_00+170, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+202, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+202, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+174, 8, q_00+174, 8, temp);
	gf2x_mul_4_avx(temp, q_00+198, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+198, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+170, 8, q_00+170, 8, temp);
	gf2x_mul_4_avx(temp, q_00+194, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+194, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+166, 8, q_00+166, 8, temp);
	memset(q_01+166, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+212, 12, q_00+194);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, q_01+194);
	gf2x_add(24, q_01+170, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+202, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+202, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+174, 8, q_01+174, 8, temp);
	gf2x_mul_4_avx(temp, q_00+198, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+198, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+170, 8, q_01+170, 8, temp);
	gf2x_mul_4_avx(temp, q_00+194, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+194, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+166, 8, q_01+166, 8, temp);
	memset(q_10+166, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+212, 12, q_10+194);
	GF2X_MUL(24, temp2, 12, p_10+212, 12, q_11+194);
	gf2x_add(24, q_10+170, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+202, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+202, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+174, 8, q_10+174, 8, temp);
	gf2x_mul_4_avx(temp, q_10+198, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+198, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+170, 8, q_10+170, 8, temp);
	gf2x_mul_4_avx(temp, q_10+194, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+194, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+166, 8, q_10+166, 8, temp);
	memset(q_11+166, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+212, 12, q_10+194);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, q_11+194);
	gf2x_add(24, q_11+170, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+202, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+202, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+174, 8, q_11+174, 8, temp);
	gf2x_mul_4_avx(temp, q_10+198, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+198, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+170, 8, q_11+170, 8, temp);
	gf2x_mul_4_avx(temp, q_10+194, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+194, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+166, 8, q_11+166, 8, temp);
	
	// Recombining results: n: 3570, depth: 2
	GF2X_MUL(56, temp, 28, q_00+166, 28, p_00+176);
	GF2X_MUL(56, temp2, 28, q_01+166, 28, p_10+176);
	gf2x_add(56, q_00+110, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_00+166, 28, p_01+176);
	GF2X_MUL(56, temp2, 28, q_01+166, 28, p_11+176);
	gf2x_add(56, q_01+110, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+166, 28, p_00+176);
	GF2X_MUL(56, temp2, 28, q_11+166, 28, p_10+176);
	gf2x_add(56, q_10+110, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+166, 28, p_01+176);
	GF2X_MUL(56, temp2, 28, q_11+166, 28, p_11+176);
	gf2x_add(56, q_11+110, 56, temp, 56, temp2);
	
	// Recombining results: n: 7395, depth: 1
	memset(p_00+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(112, temp, 56, p_00+120, 56, q_00+110);
	GF2X_MUL(112, temp2, 56, p_10+120, 56, q_01+110);
	gf2x_add(112, p_00+4, 112, temp, 112, temp2);
	gf2x_mul_4_avx(temp, q_00+162, p_00+116);
	gf2x_mul_4_avx(temp2, q_01+162, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+52, 8, p_00+52, 8, temp);
	gf2x_mul_4_avx(temp, q_00+158, p_00+116);
	gf2x_mul_4_avx(temp2, q_01+158, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+48, 8, p_00+48, 8, temp);
	gf2x_mul_4_avx(temp, q_00+154, p_00+116);
	gf2x_mul_4_avx(temp2, q_01+154, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+44, 8, p_00+44, 8, temp);
	gf2x_mul_4_avx(temp, q_00+150, p_00+116);
	gf2x_mul_4_avx(temp2, q_01+150, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+40, 8, p_00+40, 8, temp);
	gf2x_mul_4_avx(temp, q_00+146, p_00+116);
	gf2x_mul_4_avx(temp2, q_01+146, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+36, 8, p_00+36, 8, temp);
	gf2x_mul_4_avx(temp, q_00+142, p_00+116);
	gf2x_mul_4_avx(temp2, q_01+142, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+32, 8, p_00+32, 8, temp);
	gf2x_mul_4_avx(temp, q_00+138, p_00+116);
	gf2x_mul_4_avx(temp2, q_01+138, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+28, 8, p_00+28, 8, temp);
	gf2x_mul_4_avx(temp, q_00+134, p_00+116);
	gf2x_mul_4_avx(temp2, q_01+134, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+24, 8, p_00+24, 8, temp);
	gf2x_mul_4_avx(temp, q_00+130, p_00+116);
	gf2x_mul_4_avx(temp2, q_01+130, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+20, 8, p_00+20, 8, temp);
	gf2x_mul_4_avx(temp, q_00+126, p_00+116);
	gf2x_mul_4_avx(temp2, q_01+126, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+16, 8, p_00+16, 8, temp);
	gf2x_mul_4_avx(temp, q_00+122, p_00+116);
	gf2x_mul_4_avx(temp2, q_01+122, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+12, 8, p_00+12, 8, temp);
	gf2x_mul_4_avx(temp, q_00+118, p_00+116);
	gf2x_mul_4_avx(temp2, q_01+118, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+8, 8, p_00+8, 8, temp);
	gf2x_mul_4_avx(temp, q_00+114, p_00+116);
	gf2x_mul_4_avx(temp2, q_01+114, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+4, 8, p_00+4, 8, temp);
	gf2x_mul_4_avx(temp, q_00+110, p_00+116);
	gf2x_mul_4_avx(temp2, q_01+110, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+0, 8, p_00+0, 8, temp);
	memset(p_01+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(112, temp, 56, p_01+120, 56, q_00+110);
	GF2X_MUL(112, temp2, 56, p_11+120, 56, q_01+110);
	gf2x_add(112, p_01+4, 112, temp, 112, temp2);
	gf2x_mul_4_avx(temp, q_00+162, p_01+116);
	gf2x_mul_4_avx(temp2, q_01+162, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+52, 8, p_01+52, 8, temp);
	gf2x_mul_4_avx(temp, q_00+158, p_01+116);
	gf2x_mul_4_avx(temp2, q_01+158, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+48, 8, p_01+48, 8, temp);
	gf2x_mul_4_avx(temp, q_00+154, p_01+116);
	gf2x_mul_4_avx(temp2, q_01+154, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+44, 8, p_01+44, 8, temp);
	gf2x_mul_4_avx(temp, q_00+150, p_01+116);
	gf2x_mul_4_avx(temp2, q_01+150, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+40, 8, p_01+40, 8, temp);
	gf2x_mul_4_avx(temp, q_00+146, p_01+116);
	gf2x_mul_4_avx(temp2, q_01+146, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+36, 8, p_01+36, 8, temp);
	gf2x_mul_4_avx(temp, q_00+142, p_01+116);
	gf2x_mul_4_avx(temp2, q_01+142, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+32, 8, p_01+32, 8, temp);
	gf2x_mul_4_avx(temp, q_00+138, p_01+116);
	gf2x_mul_4_avx(temp2, q_01+138, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+28, 8, p_01+28, 8, temp);
	gf2x_mul_4_avx(temp, q_00+134, p_01+116);
	gf2x_mul_4_avx(temp2, q_01+134, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+24, 8, p_01+24, 8, temp);
	gf2x_mul_4_avx(temp, q_00+130, p_01+116);
	gf2x_mul_4_avx(temp2, q_01+130, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+20, 8, p_01+20, 8, temp);
	gf2x_mul_4_avx(temp, q_00+126, p_01+116);
	gf2x_mul_4_avx(temp2, q_01+126, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+16, 8, p_01+16, 8, temp);
	gf2x_mul_4_avx(temp, q_00+122, p_01+116);
	gf2x_mul_4_avx(temp2, q_01+122, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+12, 8, p_01+12, 8, temp);
	gf2x_mul_4_avx(temp, q_00+118, p_01+116);
	gf2x_mul_4_avx(temp2, q_01+118, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+8, 8, p_01+8, 8, temp);
	gf2x_mul_4_avx(temp, q_00+114, p_01+116);
	gf2x_mul_4_avx(temp2, q_01+114, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+4, 8, p_01+4, 8, temp);
	gf2x_mul_4_avx(temp, q_00+110, p_01+116);
	gf2x_mul_4_avx(temp2, q_01+110, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+0, 8, p_01+0, 8, temp);
	memset(p_10+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(112, temp, 56, p_00+120, 56, q_10+110);
	GF2X_MUL(112, temp2, 56, p_10+120, 56, q_11+110);
	gf2x_add(112, p_10+4, 112, temp, 112, temp2);
	gf2x_mul_4_avx(temp, q_10+162, p_00+116);
	gf2x_mul_4_avx(temp2, q_11+162, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+52, 8, p_10+52, 8, temp);
	gf2x_mul_4_avx(temp, q_10+158, p_00+116);
	gf2x_mul_4_avx(temp2, q_11+158, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+48, 8, p_10+48, 8, temp);
	gf2x_mul_4_avx(temp, q_10+154, p_00+116);
	gf2x_mul_4_avx(temp2, q_11+154, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+44, 8, p_10+44, 8, temp);
	gf2x_mul_4_avx(temp, q_10+150, p_00+116);
	gf2x_mul_4_avx(temp2, q_11+150, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+40, 8, p_10+40, 8, temp);
	gf2x_mul_4_avx(temp, q_10+146, p_00+116);
	gf2x_mul_4_avx(temp2, q_11+146, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+36, 8, p_10+36, 8, temp);
	gf2x_mul_4_avx(temp, q_10+142, p_00+116);
	gf2x_mul_4_avx(temp2, q_11+142, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+32, 8, p_10+32, 8, temp);
	gf2x_mul_4_avx(temp, q_10+138, p_00+116);
	gf2x_mul_4_avx(temp2, q_11+138, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+28, 8, p_10+28, 8, temp);
	gf2x_mul_4_avx(temp, q_10+134, p_00+116);
	gf2x_mul_4_avx(temp2, q_11+134, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+24, 8, p_10+24, 8, temp);
	gf2x_mul_4_avx(temp, q_10+130, p_00+116);
	gf2x_mul_4_avx(temp2, q_11+130, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+20, 8, p_10+20, 8, temp);
	gf2x_mul_4_avx(temp, q_10+126, p_00+116);
	gf2x_mul_4_avx(temp2, q_11+126, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+16, 8, p_10+16, 8, temp);
	gf2x_mul_4_avx(temp, q_10+122, p_00+116);
	gf2x_mul_4_avx(temp2, q_11+122, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+12, 8, p_10+12, 8, temp);
	gf2x_mul_4_avx(temp, q_10+118, p_00+116);
	gf2x_mul_4_avx(temp2, q_11+118, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+8, 8, p_10+8, 8, temp);
	gf2x_mul_4_avx(temp, q_10+114, p_00+116);
	gf2x_mul_4_avx(temp2, q_11+114, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+4, 8, p_10+4, 8, temp);
	gf2x_mul_4_avx(temp, q_10+110, p_00+116);
	gf2x_mul_4_avx(temp2, q_11+110, p_10+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+0, 8, p_10+0, 8, temp);
	memset(p_11+0, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(112, temp, 56, p_01+120, 56, q_10+110);
	GF2X_MUL(112, temp2, 56, p_11+120, 56, q_11+110);
	gf2x_add(112, p_11+4, 112, temp, 112, temp2);
	gf2x_mul_4_avx(temp, q_10+162, p_01+116);
	gf2x_mul_4_avx(temp2, q_11+162, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+52, 8, p_11+52, 8, temp);
	gf2x_mul_4_avx(temp, q_10+158, p_01+116);
	gf2x_mul_4_avx(temp2, q_11+158, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+48, 8, p_11+48, 8, temp);
	gf2x_mul_4_avx(temp, q_10+154, p_01+116);
	gf2x_mul_4_avx(temp2, q_11+154, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+44, 8, p_11+44, 8, temp);
	gf2x_mul_4_avx(temp, q_10+150, p_01+116);
	gf2x_mul_4_avx(temp2, q_11+150, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+40, 8, p_11+40, 8, temp);
	gf2x_mul_4_avx(temp, q_10+146, p_01+116);
	gf2x_mul_4_avx(temp2, q_11+146, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+36, 8, p_11+36, 8, temp);
	gf2x_mul_4_avx(temp, q_10+142, p_01+116);
	gf2x_mul_4_avx(temp2, q_11+142, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+32, 8, p_11+32, 8, temp);
	gf2x_mul_4_avx(temp, q_10+138, p_01+116);
	gf2x_mul_4_avx(temp2, q_11+138, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+28, 8, p_11+28, 8, temp);
	gf2x_mul_4_avx(temp, q_10+134, p_01+116);
	gf2x_mul_4_avx(temp2, q_11+134, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+24, 8, p_11+24, 8, temp);
	gf2x_mul_4_avx(temp, q_10+130, p_01+116);
	gf2x_mul_4_avx(temp2, q_11+130, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+20, 8, p_11+20, 8, temp);
	gf2x_mul_4_avx(temp, q_10+126, p_01+116);
	gf2x_mul_4_avx(temp2, q_11+126, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+16, 8, p_11+16, 8, temp);
	gf2x_mul_4_avx(temp, q_10+122, p_01+116);
	gf2x_mul_4_avx(temp2, q_11+122, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+12, 8, p_11+12, 8, temp);
	gf2x_mul_4_avx(temp, q_10+118, p_01+116);
	gf2x_mul_4_avx(temp2, q_11+118, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+8, 8, p_11+8, 8, temp);
	gf2x_mul_4_avx(temp, q_10+114, p_01+116);
	gf2x_mul_4_avx(temp2, q_11+114, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+4, 8, p_11+4, 8, temp);
	gf2x_mul_4_avx(temp, q_10+110, p_01+116);
	gf2x_mul_4_avx(temp2, q_11+110, p_11+116);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+0, 8, p_11+0, 8, temp);
	
	// Calculating left operands: n: 14373, depth: 0
	GF2X_MUL(232, temp, 116, f+109, 116, p_00+0);
	GF2X_MUL(232, temp2, 116, g+109, 116, p_01+0);
	gf2x_add(226, f_sum+0, 226, temp+6, 226, temp2+6);
	GF2X_MUL(218, temp, 109, p_00+7, 109, f+0);
	GF2X_MUL(218, temp2, 109, p_01+7, 109, g+0);
	gf2x_add(218, temp, 218, temp, 218, temp2);
	gf2x_add(110, f_sum+0, 110, f_sum+0, 110, temp+108);
	gf2x_mul_7_avx(temp, f+102, p_00+0);
	gf2x_mul_7_avx(temp2, g+102, p_01+0);
	gf2x_add(14, temp, 14, temp, 14, temp2);
	gf2x_add(1, f_sum+0, 1, f_sum+0, 1, temp+13);
	right_bit_shift_n(225, f_sum+0, 35);
	GF2X_MUL(232, temp, 116, f+109, 116, p_10+0);
	GF2X_MUL(232, temp2, 116, g+109, 116, p_11+0);
	gf2x_add(226, g_sum+0, 226, temp+6, 226, temp2+6);
	GF2X_MUL(218, temp, 109, p_10+7, 109, f+0);
	GF2X_MUL(218, temp2, 109, p_11+7, 109, g+0);
	gf2x_add(218, temp, 218, temp, 218, temp2);
	gf2x_add(110, g_sum+0, 110, g_sum+0, 110, temp+108);
	gf2x_mul_7_avx(temp, f+102, p_10+0);
	gf2x_mul_7_avx(temp2, g+102, p_11+0);
	gf2x_add(14, temp, 14, temp, 14, temp2);
	gf2x_add(1, g_sum+0, 1, g_sum+0, 1, temp+13);
	right_bit_shift_n(225, g_sum+0, 35);
	
	delta = divstepsx_256(255, delta, f_sum+107, g_sum+107, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+107, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+107, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+103, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+103, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+107, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+107, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+103, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+103, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, p_00+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, p_01+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, p_10+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, p_11+224, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, f_sum+103, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+103, p_01+224);
	gf2x_add(16, f_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+95, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+95, p_01+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+661, 8, f_sum+661, 8, temp+8);
	right_bit_shift_n(16, f_sum+661, 62);
	gf2x_mul_8_avx(temp, f_sum+103, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+103, p_11+224);
	gf2x_add(16, g_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+95, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+95, p_11+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+661, 8, g_sum+661, 8, temp+8);
	right_bit_shift_n(16, g_sum+661, 62);
	
	delta = divstepsx_256(255, delta, f_sum+666, g_sum+666, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+666, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+666, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, q_00+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, q_01+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, q_10+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, q_11+210, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, q_00+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_10+224);
	gf2x_add(16, p_00+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_11+224);
	gf2x_add(16, p_01+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_10+224);
	gf2x_add(16, p_10+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_11+224);
	gf2x_add(16, p_11+208, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 3
	GF2X_MUL(32, temp, 16, f_sum+95, 16, p_00+208);
	GF2X_MUL(32, temp2, 16, g_sum+95, 16, p_01+208);
	gf2x_add(28, f_sum+612, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+212, 12, f_sum+83);
	GF2X_MUL(24, temp2, 12, p_01+212, 12, g_sum+83);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+612, 12, f_sum+612, 12, temp+12);
	right_bit_shift_n(28, f_sum+612, 60);
	GF2X_MUL(32, temp, 16, f_sum+95, 16, p_10+208);
	GF2X_MUL(32, temp2, 16, g_sum+95, 16, p_11+208);
	gf2x_add(28, g_sum+612, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+212, 12, f_sum+83);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, g_sum+83);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+612, 12, g_sum+612, 12, temp+12);
	right_bit_shift_n(28, g_sum+612, 60);
	
	delta = divstepsx_256(255, delta, f_sum+621, g_sum+621, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+621, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+621, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+617, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+617, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+621, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+621, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+617, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+617, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, p_00+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, p_01+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, p_10+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, p_11+224, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 4
	gf2x_mul_8_avx(temp, f_sum+617, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+617, p_01+224);
	gf2x_add(12, f_sum+661, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+228, f_sum+613);
	gf2x_mul_4_avx(temp2, p_01+228, g_sum+613);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+661, 4, f_sum+661, 4, temp+4);
	right_bit_shift_n(12, f_sum+661, 62);
	gf2x_mul_8_avx(temp, f_sum+617, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+617, p_11+224);
	gf2x_add(12, g_sum+661, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+228, f_sum+613);
	gf2x_mul_4_avx(temp2, p_11+228, g_sum+613);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+661, 4, g_sum+661, 4, temp+4);
	right_bit_shift_n(12, g_sum+661, 62);
	
	delta = divstepsx_256(255, delta, f_sum+662, g_sum+662, q_00+210, q_01+210, q_10+210, q_11+210);

	// Recombining results: n: 765, depth: 4
	memset(q_00+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+228, q_00+210);
	gf2x_mul_4_avx(temp2, p_10+228, q_01+210);
	gf2x_add(8, q_00+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+210, p_00+224);
	gf2x_mul_4_avx(temp2, q_01+210, p_10+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+194, 8, q_00+194, 8, temp);
	memset(q_01+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+228, q_00+210);
	gf2x_mul_4_avx(temp2, p_11+228, q_01+210);
	gf2x_add(8, q_01+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+210, p_01+224);
	gf2x_mul_4_avx(temp2, q_01+210, p_11+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+194, 8, q_01+194, 8, temp);
	memset(q_10+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+228, q_10+210);
	gf2x_mul_4_avx(temp2, p_10+228, q_11+210);
	gf2x_add(8, q_10+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+210, p_00+224);
	gf2x_mul_4_avx(temp2, q_11+210, p_10+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+194, 8, q_10+194, 8, temp);
	memset(q_11+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+228, q_10+210);
	gf2x_mul_4_avx(temp2, p_11+228, q_11+210);
	gf2x_add(8, q_11+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+210, p_01+224);
	gf2x_mul_4_avx(temp2, q_11+210, p_11+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+194, 8, q_11+194, 8, temp);
	
	// Recombining results: n: 1785, depth: 3
	memset(p_00+176, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+212, 12, q_00+194);
	GF2X_MUL(24, temp2, 12, p_10+212, 12, q_01+194);
	gf2x_add(24, p_00+180, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+202, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+202, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+184, 8, p_00+184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+198, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+198, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+180, 8, p_00+180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+194, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+194, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+176, 8, p_00+176, 8, temp);
	memset(p_01+176, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+212, 12, q_00+194);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, q_01+194);
	gf2x_add(24, p_01+180, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+202, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+202, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+184, 8, p_01+184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+198, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+198, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+180, 8, p_01+180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+194, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+194, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+176, 8, p_01+176, 8, temp);
	memset(p_10+176, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+212, 12, q_10+194);
	GF2X_MUL(24, temp2, 12, p_10+212, 12, q_11+194);
	gf2x_add(24, p_10+180, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+202, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+202, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+184, 8, p_10+184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+198, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+198, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+180, 8, p_10+180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+194, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+194, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+176, 8, p_10+176, 8, temp);
	memset(p_11+176, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+212, 12, q_10+194);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, q_11+194);
	gf2x_add(24, p_11+180, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+202, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+202, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+184, 8, p_11+184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+198, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+198, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+180, 8, p_11+180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+194, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+194, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+176, 8, p_11+176, 8, temp);
	
	// Calculating left operands: n: 3570, depth: 2
	GF2X_MUL(56, temp, 28, f_sum+83, 28, p_00+176);
	GF2X_MUL(56, temp2, 28, g_sum+83, 28, p_01+176);
	gf2x_add(56, f_sum+519, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+55, 28, p_00+176);
	GF2X_MUL(56, temp2, 28, g_sum+55, 28, p_01+176);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, f_sum+519, 28, f_sum+519, 28, temp+28);
	right_bit_shift_n(56, f_sum+519, 57);
	GF2X_MUL(56, temp, 28, f_sum+83, 28, p_10+176);
	GF2X_MUL(56, temp2, 28, g_sum+83, 28, p_11+176);
	gf2x_add(56, g_sum+519, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, f_sum+55, 28, p_10+176);
	GF2X_MUL(56, temp2, 28, g_sum+55, 28, p_11+176);
	gf2x_add(56, temp, 56, temp, 56, temp2);
	gf2x_add(28, g_sum+519, 28, g_sum+519, 28, temp+28);
	right_bit_shift_n(56, g_sum+519, 57);
	
	delta = divstepsx_256(255, delta, f_sum+544, g_sum+544, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+544, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+544, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+540, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+540, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+544, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+544, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+540, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+540, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, p_00+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, p_01+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, p_10+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, p_11+224, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, f_sum+540, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+540, p_01+224);
	gf2x_add(16, f_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+532, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+532, p_01+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+661, 8, f_sum+661, 8, temp+8);
	right_bit_shift_n(16, f_sum+661, 62);
	gf2x_mul_8_avx(temp, f_sum+540, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+540, p_11+224);
	gf2x_add(16, g_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+532, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+532, p_11+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+661, 8, g_sum+661, 8, temp+8);
	right_bit_shift_n(16, g_sum+661, 62);
	
	delta = divstepsx_256(255, delta, f_sum+666, g_sum+666, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+666, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+666, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, q_00+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, q_01+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, q_10+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, q_11+210, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, q_00+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_10+224);
	gf2x_add(16, p_00+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_11+224);
	gf2x_add(16, p_01+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_10+224);
	gf2x_add(16, p_10+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_11+224);
	gf2x_add(16, p_11+208, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 3
	GF2X_MUL(32, temp, 16, f_sum+532, 16, p_00+208);
	GF2X_MUL(32, temp2, 16, g_sum+532, 16, p_01+208);
	gf2x_add(28, f_sum+612, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+212, 12, f_sum+520);
	GF2X_MUL(24, temp2, 12, p_01+212, 12, g_sum+520);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+612, 12, f_sum+612, 12, temp+12);
	right_bit_shift_n(28, f_sum+612, 60);
	GF2X_MUL(32, temp, 16, f_sum+532, 16, p_10+208);
	GF2X_MUL(32, temp2, 16, g_sum+532, 16, p_11+208);
	gf2x_add(28, g_sum+612, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+212, 12, f_sum+520);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, g_sum+520);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+612, 12, g_sum+612, 12, temp+12);
	right_bit_shift_n(28, g_sum+612, 60);
	
	delta = divstepsx_256(255, delta, f_sum+621, g_sum+621, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+621, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+621, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+617, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+617, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+621, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+621, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+617, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+617, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, p_00+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, p_01+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, p_10+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, p_11+224, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 4
	gf2x_mul_8_avx(temp, f_sum+617, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+617, p_01+224);
	gf2x_add(12, f_sum+661, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+228, f_sum+613);
	gf2x_mul_4_avx(temp2, p_01+228, g_sum+613);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+661, 4, f_sum+661, 4, temp+4);
	right_bit_shift_n(12, f_sum+661, 62);
	gf2x_mul_8_avx(temp, f_sum+617, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+617, p_11+224);
	gf2x_add(12, g_sum+661, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+228, f_sum+613);
	gf2x_mul_4_avx(temp2, p_11+228, g_sum+613);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+661, 4, g_sum+661, 4, temp+4);
	right_bit_shift_n(12, g_sum+661, 62);
	
	delta = divstepsx_256(255, delta, f_sum+662, g_sum+662, q_00+210, q_01+210, q_10+210, q_11+210);

	// Recombining results: n: 765, depth: 4
	memset(q_00+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+228, q_00+210);
	gf2x_mul_4_avx(temp2, p_10+228, q_01+210);
	gf2x_add(8, q_00+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+210, p_00+224);
	gf2x_mul_4_avx(temp2, q_01+210, p_10+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+194, 8, q_00+194, 8, temp);
	memset(q_01+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+228, q_00+210);
	gf2x_mul_4_avx(temp2, p_11+228, q_01+210);
	gf2x_add(8, q_01+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+210, p_01+224);
	gf2x_mul_4_avx(temp2, q_01+210, p_11+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+194, 8, q_01+194, 8, temp);
	memset(q_10+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+228, q_10+210);
	gf2x_mul_4_avx(temp2, p_10+228, q_11+210);
	gf2x_add(8, q_10+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+210, p_00+224);
	gf2x_mul_4_avx(temp2, q_11+210, p_10+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+194, 8, q_10+194, 8, temp);
	memset(q_11+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+228, q_10+210);
	gf2x_mul_4_avx(temp2, p_11+228, q_11+210);
	gf2x_add(8, q_11+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+210, p_01+224);
	gf2x_mul_4_avx(temp2, q_11+210, p_11+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+194, 8, q_11+194, 8, temp);
	
	// Recombining results: n: 1785, depth: 3
	memset(q_00+166, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+212, 12, q_00+194);
	GF2X_MUL(24, temp2, 12, p_10+212, 12, q_01+194);
	gf2x_add(24, q_00+170, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+202, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+202, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+174, 8, q_00+174, 8, temp);
	gf2x_mul_4_avx(temp, q_00+198, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+198, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+170, 8, q_00+170, 8, temp);
	gf2x_mul_4_avx(temp, q_00+194, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+194, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+166, 8, q_00+166, 8, temp);
	memset(q_01+166, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+212, 12, q_00+194);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, q_01+194);
	gf2x_add(24, q_01+170, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+202, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+202, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+174, 8, q_01+174, 8, temp);
	gf2x_mul_4_avx(temp, q_00+198, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+198, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+170, 8, q_01+170, 8, temp);
	gf2x_mul_4_avx(temp, q_00+194, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+194, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+166, 8, q_01+166, 8, temp);
	memset(q_10+166, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+212, 12, q_10+194);
	GF2X_MUL(24, temp2, 12, p_10+212, 12, q_11+194);
	gf2x_add(24, q_10+170, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+202, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+202, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+174, 8, q_10+174, 8, temp);
	gf2x_mul_4_avx(temp, q_10+198, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+198, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+170, 8, q_10+170, 8, temp);
	gf2x_mul_4_avx(temp, q_10+194, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+194, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+166, 8, q_10+166, 8, temp);
	memset(q_11+166, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+212, 12, q_10+194);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, q_11+194);
	gf2x_add(24, q_11+170, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+202, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+202, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+174, 8, q_11+174, 8, temp);
	gf2x_mul_4_avx(temp, q_10+198, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+198, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+170, 8, q_11+170, 8, temp);
	gf2x_mul_4_avx(temp, q_10+194, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+194, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+166, 8, q_11+166, 8, temp);
	
	// Recombining results: n: 3570, depth: 2
	GF2X_MUL(56, temp, 28, q_00+166, 28, p_00+176);
	GF2X_MUL(56, temp2, 28, q_01+166, 28, p_10+176);
	gf2x_add(56, p_00+116, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_00+166, 28, p_01+176);
	GF2X_MUL(56, temp2, 28, q_01+166, 28, p_11+176);
	gf2x_add(56, p_01+116, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+166, 28, p_00+176);
	GF2X_MUL(56, temp2, 28, q_11+166, 28, p_10+176);
	gf2x_add(56, p_10+116, 56, temp, 56, temp2);
	GF2X_MUL(56, temp, 28, q_10+166, 28, p_01+176);
	GF2X_MUL(56, temp2, 28, q_11+166, 28, p_11+176);
	gf2x_add(56, p_11+116, 56, temp, 56, temp2);
	
	// Calculating left operands: n: 6978, depth: 1
	GF2X_MUL(112, temp, 56, f_sum+55, 56, p_00+116);
	GF2X_MUL(112, temp2, 56, g_sum+55, 56, p_01+116);
	gf2x_add(110, f_sum+342, 110, temp+2, 110, temp2+2);
	GF2X_MUL(108, temp, 54, p_00+118, 54, f_sum+1);
	GF2X_MUL(108, temp2, 54, p_01+118, 54, g_sum+1);
	gf2x_add(108, temp, 108, temp, 108, temp2);
	gf2x_add(54, f_sum+342, 54, f_sum+342, 54, temp+54);
	right_bit_shift_n(110, f_sum+342, 50);
	GF2X_MUL(112, temp, 56, f_sum+55, 56, p_10+116);
	GF2X_MUL(112, temp2, 56, g_sum+55, 56, p_11+116);
	gf2x_add(110, g_sum+342, 110, temp+2, 110, temp2+2);
	GF2X_MUL(108, temp, 54, p_10+118, 54, f_sum+1);
	GF2X_MUL(108, temp2, 54, p_11+118, 54, g_sum+1);
	gf2x_add(108, temp, 108, temp, 108, temp2);
	gf2x_add(54, g_sum+342, 54, g_sum+342, 54, temp+54);
	right_bit_shift_n(110, g_sum+342, 50);
	
	delta = divstepsx_256(255, delta, f_sum+393, g_sum+393, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+393, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+393, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+389, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+389, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+393, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+393, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+389, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+389, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, p_00+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, p_01+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, p_10+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, p_11+224, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, f_sum+389, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+389, p_01+224);
	gf2x_add(16, f_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+381, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+381, p_01+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+661, 8, f_sum+661, 8, temp+8);
	right_bit_shift_n(16, f_sum+661, 62);
	gf2x_mul_8_avx(temp, f_sum+389, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+389, p_11+224);
	gf2x_add(16, g_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+381, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+381, p_11+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+661, 8, g_sum+661, 8, temp+8);
	right_bit_shift_n(16, g_sum+661, 62);
	
	delta = divstepsx_256(255, delta, f_sum+666, g_sum+666, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+666, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+666, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, q_00+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, q_01+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, q_10+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, q_11+210, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, q_00+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_10+224);
	gf2x_add(16, p_00+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_11+224);
	gf2x_add(16, p_01+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_10+224);
	gf2x_add(16, p_10+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_11+224);
	gf2x_add(16, p_11+208, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1785, depth: 3
	GF2X_MUL(32, temp, 16, f_sum+381, 16, p_00+208);
	GF2X_MUL(32, temp2, 16, g_sum+381, 16, p_01+208);
	gf2x_add(28, f_sum+612, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_00+212, 12, f_sum+369);
	GF2X_MUL(24, temp2, 12, p_01+212, 12, g_sum+369);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, f_sum+612, 12, f_sum+612, 12, temp+12);
	right_bit_shift_n(28, f_sum+612, 60);
	GF2X_MUL(32, temp, 16, f_sum+381, 16, p_10+208);
	GF2X_MUL(32, temp2, 16, g_sum+381, 16, p_11+208);
	gf2x_add(28, g_sum+612, 28, temp+4, 28, temp2+4);
	GF2X_MUL(24, temp, 12, p_10+212, 12, f_sum+369);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, g_sum+369);
	gf2x_add(24, temp, 24, temp, 24, temp2);
	gf2x_add(12, g_sum+612, 12, g_sum+612, 12, temp+12);
	right_bit_shift_n(28, g_sum+612, 60);
	
	delta = divstepsx_256(255, delta, f_sum+621, g_sum+621, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+621, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+621, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+617, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+617, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+621, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+621, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+617, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+617, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, p_00+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, p_01+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, p_10+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, p_11+224, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 765, depth: 4
	gf2x_mul_8_avx(temp, f_sum+617, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+617, p_01+224);
	gf2x_add(12, f_sum+661, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_00+228, f_sum+613);
	gf2x_mul_4_avx(temp2, p_01+228, g_sum+613);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+661, 4, f_sum+661, 4, temp+4);
	right_bit_shift_n(12, f_sum+661, 62);
	gf2x_mul_8_avx(temp, f_sum+617, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+617, p_11+224);
	gf2x_add(12, g_sum+661, 12, temp+4, 12, temp2+4);
	gf2x_mul_4_avx(temp, p_10+228, f_sum+613);
	gf2x_mul_4_avx(temp2, p_11+228, g_sum+613);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+661, 4, g_sum+661, 4, temp+4);
	right_bit_shift_n(12, g_sum+661, 62);
	
	delta = divstepsx_256(255, delta, f_sum+662, g_sum+662, q_00+210, q_01+210, q_10+210, q_11+210);

	// Recombining results: n: 765, depth: 4
	memset(q_00+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+228, q_00+210);
	gf2x_mul_4_avx(temp2, p_10+228, q_01+210);
	gf2x_add(8, q_00+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+210, p_00+224);
	gf2x_mul_4_avx(temp2, q_01+210, p_10+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+194, 8, q_00+194, 8, temp);
	memset(q_01+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+228, q_00+210);
	gf2x_mul_4_avx(temp2, p_11+228, q_01+210);
	gf2x_add(8, q_01+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+210, p_01+224);
	gf2x_mul_4_avx(temp2, q_01+210, p_11+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+194, 8, q_01+194, 8, temp);
	memset(q_10+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_00+228, q_10+210);
	gf2x_mul_4_avx(temp2, p_10+228, q_11+210);
	gf2x_add(8, q_10+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+210, p_00+224);
	gf2x_mul_4_avx(temp2, q_11+210, p_10+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+194, 8, q_10+194, 8, temp);
	memset(q_11+194, 0x00, 4*DIGIT_SIZE_B);
	gf2x_mul_4_avx(temp, p_01+228, q_10+210);
	gf2x_mul_4_avx(temp2, p_11+228, q_11+210);
	gf2x_add(8, q_11+198, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+210, p_01+224);
	gf2x_mul_4_avx(temp2, q_11+210, p_11+224);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+194, 8, q_11+194, 8, temp);
	
	// Recombining results: n: 1785, depth: 3
	memset(p_00+176, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+212, 12, q_00+194);
	GF2X_MUL(24, temp2, 12, p_10+212, 12, q_01+194);
	gf2x_add(24, p_00+180, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+202, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+202, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+184, 8, p_00+184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+198, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+198, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+180, 8, p_00+180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+194, p_00+208);
	gf2x_mul_4_avx(temp2, q_01+194, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_00+176, 8, p_00+176, 8, temp);
	memset(p_01+176, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+212, 12, q_00+194);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, q_01+194);
	gf2x_add(24, p_01+180, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_00+202, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+202, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+184, 8, p_01+184, 8, temp);
	gf2x_mul_4_avx(temp, q_00+198, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+198, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+180, 8, p_01+180, 8, temp);
	gf2x_mul_4_avx(temp, q_00+194, p_01+208);
	gf2x_mul_4_avx(temp2, q_01+194, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_01+176, 8, p_01+176, 8, temp);
	memset(p_10+176, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_00+212, 12, q_10+194);
	GF2X_MUL(24, temp2, 12, p_10+212, 12, q_11+194);
	gf2x_add(24, p_10+180, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+202, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+202, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+184, 8, p_10+184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+198, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+198, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+180, 8, p_10+180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+194, p_00+208);
	gf2x_mul_4_avx(temp2, q_11+194, p_10+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_10+176, 8, p_10+176, 8, temp);
	memset(p_11+176, 0x00, 4*DIGIT_SIZE_B);
	GF2X_MUL(24, temp, 12, p_01+212, 12, q_10+194);
	GF2X_MUL(24, temp2, 12, p_11+212, 12, q_11+194);
	gf2x_add(24, p_11+180, 24, temp, 24, temp2);
	gf2x_mul_4_avx(temp, q_10+202, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+202, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+184, 8, p_11+184, 8, temp);
	gf2x_mul_4_avx(temp, q_10+198, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+198, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+180, 8, p_11+180, 8, temp);
	gf2x_mul_4_avx(temp, q_10+194, p_01+208);
	gf2x_mul_4_avx(temp2, q_11+194, p_11+208);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, p_11+176, 8, p_11+176, 8, temp);
	
	// Calculating left operands: n: 3408, depth: 2
	GF2X_MUL(56, temp, 28, f_sum+369, 28, p_00+176);
	GF2X_MUL(56, temp2, 28, g_sum+369, 28, p_01+176);
	gf2x_add(54, f_sum+519, 54, temp+2, 54, temp2+2);
	GF2X_MUL(52, temp, 26, p_00+178, 26, f_sum+343);
	GF2X_MUL(52, temp2, 26, p_01+178, 26, g_sum+343);
	gf2x_add(52, temp, 52, temp, 52, temp2);
	gf2x_add(26, f_sum+519, 26, f_sum+519, 26, temp+26);
	right_bit_shift_n(54, f_sum+519, 57);
	GF2X_MUL(56, temp, 28, f_sum+369, 28, p_10+176);
	GF2X_MUL(56, temp2, 28, g_sum+369, 28, p_11+176);
	gf2x_add(54, g_sum+519, 54, temp+2, 54, temp2+2);
	GF2X_MUL(52, temp, 26, p_10+178, 26, f_sum+343);
	GF2X_MUL(52, temp2, 26, p_11+178, 26, g_sum+343);
	gf2x_add(52, temp, 52, temp, 52, temp2);
	gf2x_add(26, g_sum+519, 26, g_sum+519, 26, temp+26);
	right_bit_shift_n(54, g_sum+519, 57);
	
	delta = divstepsx_256(255, delta, f_sum+542, g_sum+542, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+542, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+542, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+538, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+538, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+542, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+542, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+538, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+538, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, p_00+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, p_01+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, p_10+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, p_11+224, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, f_sum+538, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+538, p_01+224);
	gf2x_add(16, f_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+530, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+530, p_01+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, f_sum+661, 8, f_sum+661, 8, temp+8);
	right_bit_shift_n(16, f_sum+661, 62);
	gf2x_mul_8_avx(temp, f_sum+538, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+538, p_11+224);
	gf2x_add(16, g_sum+661, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, f_sum+530, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+530, p_11+224);
	gf2x_add(16, temp, 16, temp, 16, temp2);
	gf2x_add(8, g_sum+661, 8, g_sum+661, 8, temp+8);
	right_bit_shift_n(16, g_sum+661, 62);
	
	delta = divstepsx_256(255, delta, f_sum+666, g_sum+666, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+666, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+666, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+666, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+662, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+662, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, q_00+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, q_01+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, q_10+210, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, q_11+210, 8, temp, 8, temp2);
	
	// Recombining results: n: 1020, depth: 4
	gf2x_mul_8_avx(temp, q_00+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_10+224);
	gf2x_add(16, p_00+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_00+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_01+210, p_11+224);
	gf2x_add(16, p_01+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_00+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_10+224);
	gf2x_add(16, p_10+208, 16, temp, 16, temp2);
	gf2x_mul_8_avx(temp, q_10+210, p_01+224);
	gf2x_mul_8_avx(temp2, q_11+210, p_11+224);
	gf2x_add(16, p_11+208, 16, temp, 16, temp2);
	
	// Calculating left operands: n: 1623, depth: 3
	GF2X_MUL(32, temp, 16, f_sum+530, 16, p_00+208);
	GF2X_MUL(32, temp2, 16, g_sum+530, 16, p_01+208);
	gf2x_add(26, f_sum+612, 26, temp+6, 26, temp2+6);
	GF2X_MUL(20, temp, 10, p_00+214, 10, f_sum+520);
	GF2X_MUL(20, temp2, 10, p_01+214, 10, g_sum+520);
	gf2x_add(20, temp, 20, temp, 20, temp2);
	gf2x_add(10, f_sum+612, 10, f_sum+612, 10, temp+10);
	right_bit_shift_n(26, f_sum+612, 60);
	GF2X_MUL(32, temp, 16, f_sum+530, 16, p_10+208);
	GF2X_MUL(32, temp2, 16, g_sum+530, 16, p_11+208);
	gf2x_add(26, g_sum+612, 26, temp+6, 26, temp2+6);
	GF2X_MUL(20, temp, 10, p_10+214, 10, f_sum+520);
	GF2X_MUL(20, temp2, 10, p_11+214, 10, g_sum+520);
	gf2x_add(20, temp, 20, temp, 20, temp2);
	gf2x_add(10, g_sum+612, 10, g_sum+612, 10, temp+10);
	right_bit_shift_n(26, g_sum+612, 60);
	
	delta = divstepsx_256(255, delta, f_sum+619, g_sum+619, p_00+232, p_01+232, p_10+232, p_11+232);

	// Calculating left operands: n: 510, depth: 5
	gf2x_mul_4_avx(temp, f_sum+619, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+619, p_01+232);
	gf2x_add(8, f_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+615, p_00+232);
	gf2x_mul_4_avx(temp2, g_sum+615, p_01+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, f_sum+686, 4, f_sum+686, 4, temp+4);
	right_bit_shift_n(8, f_sum+686, 63);
	gf2x_mul_4_avx(temp, f_sum+619, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+619, p_11+232);
	gf2x_add(8, g_sum+686, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, f_sum+615, p_10+232);
	gf2x_mul_4_avx(temp2, g_sum+615, p_11+232);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(4, g_sum+686, 4, g_sum+686, 4, temp+4);
	right_bit_shift_n(8, g_sum+686, 63);
	
	delta = divstepsx_256(255, delta, f_sum+687, g_sum+687, q_00+218, q_01+218, q_10+218, q_11+218);

	// Recombining results: n: 510, depth: 5
	gf2x_mul_4_avx(temp, q_00+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_10+232);
	gf2x_add(8, p_00+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_00+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_01+218, p_11+232);
	gf2x_add(8, p_01+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_00+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_10+232);
	gf2x_add(8, p_10+224, 8, temp, 8, temp2);
	gf2x_mul_4_avx(temp, q_10+218, p_01+232);
	gf2x_mul_4_avx(temp2, q_11+218, p_11+232);
	gf2x_add(8, p_11+224, 8, temp, 8, temp2);
	
	// Calculating left operands: n: 603, depth: 4
	gf2x_mul_8_avx(temp, f_sum+615, p_00+224);
	gf2x_mul_8_avx(temp2, g_sum+615, p_01+224);
	gf2x_add(10, f_sum+661, 10, temp+6, 10, temp2+6);
	gf2x_mul_2_avx(temp, p_00+230, f_sum+613);
	gf2x_mul_2_avx(temp2, p_01+230, g_sum+613);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(2, f_sum+661, 2, f_sum+661, 2, temp+2);
	right_bit_shift_n(10, f_sum+661, 62);
	gf2x_mul_8_avx(temp, f_sum+615, p_10+224);
	gf2x_mul_8_avx(temp2, g_sum+615, p_11+224);
	gf2x_add(10, g_sum+661, 10, temp+6, 10, temp2+6);
	gf2x_mul_2_avx(temp, p_10+230, f_sum+613);
	gf2x_mul_2_avx(temp2, p_11+230, g_sum+613);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(2, g_sum+661, 2, g_sum+661, 2, temp+2);
	right_bit_shift_n(10, g_sum+661, 62);
	
	delta = divstepsx_128(93, delta, f_sum+662, g_sum+662, q_00+210, q_01+210, q_10+210, q_11+210);

	// Recombining results: n: 603, depth: 4
	memset(q_00+194, 0x00, 6*DIGIT_SIZE_B);
	gf2x_mul_2_avx(temp, p_00+230, q_00+210);
	gf2x_mul_2_avx(temp2, p_10+230, q_01+210);
	gf2x_add(4, q_00+200, 4, temp, 4, temp2);
	gf2x_mul_2_avx(temp, p_00+228, q_00+210);
	gf2x_mul_2_avx(temp2, p_10+228, q_01+210);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+198, 4, q_00+198, 4, temp);
	gf2x_mul_2_avx(temp, p_00+226, q_00+210);
	gf2x_mul_2_avx(temp2, p_10+226, q_01+210);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+196, 4, q_00+196, 4, temp);
	gf2x_mul_2_avx(temp, q_00+210, p_00+224);
	gf2x_mul_2_avx(temp2, q_01+210, p_10+224);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+194, 4, q_00+194, 4, temp);
	memset(q_01+194, 0x00, 6*DIGIT_SIZE_B);
	gf2x_mul_2_avx(temp, p_01+230, q_00+210);
	gf2x_mul_2_avx(temp2, p_11+230, q_01+210);
	gf2x_add(4, q_01+200, 4, temp, 4, temp2);
	gf2x_mul_2_avx(temp, p_01+228, q_00+210);
	gf2x_mul_2_avx(temp2, p_11+228, q_01+210);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+198, 4, q_01+198, 4, temp);
	gf2x_mul_2_avx(temp, p_01+226, q_00+210);
	gf2x_mul_2_avx(temp2, p_11+226, q_01+210);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+196, 4, q_01+196, 4, temp);
	gf2x_mul_2_avx(temp, q_00+210, p_01+224);
	gf2x_mul_2_avx(temp2, q_01+210, p_11+224);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+194, 4, q_01+194, 4, temp);
	memset(q_10+194, 0x00, 6*DIGIT_SIZE_B);
	gf2x_mul_2_avx(temp, p_00+230, q_10+210);
	gf2x_mul_2_avx(temp2, p_10+230, q_11+210);
	gf2x_add(4, q_10+200, 4, temp, 4, temp2);
	gf2x_mul_2_avx(temp, p_00+228, q_10+210);
	gf2x_mul_2_avx(temp2, p_10+228, q_11+210);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+198, 4, q_10+198, 4, temp);
	gf2x_mul_2_avx(temp, p_00+226, q_10+210);
	gf2x_mul_2_avx(temp2, p_10+226, q_11+210);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+196, 4, q_10+196, 4, temp);
	gf2x_mul_2_avx(temp, q_10+210, p_00+224);
	gf2x_mul_2_avx(temp2, q_11+210, p_10+224);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+194, 4, q_10+194, 4, temp);
	memset(q_11+194, 0x00, 6*DIGIT_SIZE_B);
	gf2x_mul_2_avx(temp, p_01+230, q_10+210);
	gf2x_mul_2_avx(temp2, p_11+230, q_11+210);
	gf2x_add(4, q_11+200, 4, temp, 4, temp2);
	gf2x_mul_2_avx(temp, p_01+228, q_10+210);
	gf2x_mul_2_avx(temp2, p_11+228, q_11+210);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+198, 4, q_11+198, 4, temp);
	gf2x_mul_2_avx(temp, p_01+226, q_10+210);
	gf2x_mul_2_avx(temp2, p_11+226, q_11+210);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+196, 4, q_11+196, 4, temp);
	gf2x_mul_2_avx(temp, q_10+210, p_01+224);
	gf2x_mul_2_avx(temp2, q_11+210, p_11+224);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+194, 4, q_11+194, 4, temp);
	
	// Recombining results: n: 1623, depth: 3
	memset(q_00+166, 0x00, 6*DIGIT_SIZE_B);
	GF2X_MUL(20, temp, 10, p_00+214, 10, q_00+194);
	GF2X_MUL(20, temp2, 10, p_10+214, 10, q_01+194);
	gf2x_add(20, q_00+172, 20, temp, 20, temp2);
	gf2x_mul_6_avx(temp, q_00+198, p_00+208);
	gf2x_mul_6_avx(temp2, q_01+198, p_10+208);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, q_00+170, 12, q_00+170, 12, temp);
	gf2x_mul_4_avx(temp, p_00+210, q_00+194);
	gf2x_mul_4_avx(temp2, p_10+210, q_01+194);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_00+168, 8, q_00+168, 8, temp);
	gf2x_mul_2_avx(temp, q_00+196, p_00+208);
	gf2x_mul_2_avx(temp2, q_01+196, p_10+208);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+168, 4, q_00+168, 4, temp);
	gf2x_mul_2_avx(temp, q_00+194, p_00+208);
	gf2x_mul_2_avx(temp2, q_01+194, p_10+208);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+166, 4, q_00+166, 4, temp);
	memset(q_01+166, 0x00, 6*DIGIT_SIZE_B);
	GF2X_MUL(20, temp, 10, p_01+214, 10, q_00+194);
	GF2X_MUL(20, temp2, 10, p_11+214, 10, q_01+194);
	gf2x_add(20, q_01+172, 20, temp, 20, temp2);
	gf2x_mul_6_avx(temp, q_00+198, p_01+208);
	gf2x_mul_6_avx(temp2, q_01+198, p_11+208);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, q_01+170, 12, q_01+170, 12, temp);
	gf2x_mul_4_avx(temp, p_01+210, q_00+194);
	gf2x_mul_4_avx(temp2, p_11+210, q_01+194);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_01+168, 8, q_01+168, 8, temp);
	gf2x_mul_2_avx(temp, q_00+196, p_01+208);
	gf2x_mul_2_avx(temp2, q_01+196, p_11+208);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+168, 4, q_01+168, 4, temp);
	gf2x_mul_2_avx(temp, q_00+194, p_01+208);
	gf2x_mul_2_avx(temp2, q_01+194, p_11+208);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+166, 4, q_01+166, 4, temp);
	memset(q_10+166, 0x00, 6*DIGIT_SIZE_B);
	GF2X_MUL(20, temp, 10, p_00+214, 10, q_10+194);
	GF2X_MUL(20, temp2, 10, p_10+214, 10, q_11+194);
	gf2x_add(20, q_10+172, 20, temp, 20, temp2);
	gf2x_mul_6_avx(temp, q_10+198, p_00+208);
	gf2x_mul_6_avx(temp2, q_11+198, p_10+208);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, q_10+170, 12, q_10+170, 12, temp);
	gf2x_mul_4_avx(temp, p_00+210, q_10+194);
	gf2x_mul_4_avx(temp2, p_10+210, q_11+194);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_10+168, 8, q_10+168, 8, temp);
	gf2x_mul_2_avx(temp, q_10+196, p_00+208);
	gf2x_mul_2_avx(temp2, q_11+196, p_10+208);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+168, 4, q_10+168, 4, temp);
	gf2x_mul_2_avx(temp, q_10+194, p_00+208);
	gf2x_mul_2_avx(temp2, q_11+194, p_10+208);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+166, 4, q_10+166, 4, temp);
	memset(q_11+166, 0x00, 6*DIGIT_SIZE_B);
	GF2X_MUL(20, temp, 10, p_01+214, 10, q_10+194);
	GF2X_MUL(20, temp2, 10, p_11+214, 10, q_11+194);
	gf2x_add(20, q_11+172, 20, temp, 20, temp2);
	gf2x_mul_6_avx(temp, q_10+198, p_01+208);
	gf2x_mul_6_avx(temp2, q_11+198, p_11+208);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, q_11+170, 12, q_11+170, 12, temp);
	gf2x_mul_4_avx(temp, p_01+210, q_10+194);
	gf2x_mul_4_avx(temp2, p_11+210, q_11+194);
	gf2x_add(8, temp, 8, temp, 8, temp2);
	gf2x_add(8, q_11+168, 8, q_11+168, 8, temp);
	gf2x_mul_2_avx(temp, q_10+196, p_01+208);
	gf2x_mul_2_avx(temp2, q_11+196, p_11+208);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+168, 4, q_11+168, 4, temp);
	gf2x_mul_2_avx(temp, q_10+194, p_01+208);
	gf2x_mul_2_avx(temp2, q_11+194, p_11+208);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+166, 4, q_11+166, 4, temp);
	
	// Recombining results: n: 3408, depth: 2
	memset(q_00+110, 0x00, 2*DIGIT_SIZE_B);
	GF2X_MUL(52, temp, 26, p_00+178, 26, q_00+166);
	GF2X_MUL(52, temp2, 26, p_10+178, 26, q_01+166);
	gf2x_add(52, q_00+112, 52, temp, 52, temp2);
	gf2x_mul_2_avx(temp, q_00+190, p_00+176);
	gf2x_mul_2_avx(temp2, q_01+190, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+134, 4, q_00+134, 4, temp);
	gf2x_mul_2_avx(temp, q_00+188, p_00+176);
	gf2x_mul_2_avx(temp2, q_01+188, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+132, 4, q_00+132, 4, temp);
	gf2x_mul_2_avx(temp, q_00+186, p_00+176);
	gf2x_mul_2_avx(temp2, q_01+186, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+130, 4, q_00+130, 4, temp);
	gf2x_mul_2_avx(temp, q_00+184, p_00+176);
	gf2x_mul_2_avx(temp2, q_01+184, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+128, 4, q_00+128, 4, temp);
	gf2x_mul_2_avx(temp, q_00+182, p_00+176);
	gf2x_mul_2_avx(temp2, q_01+182, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+126, 4, q_00+126, 4, temp);
	gf2x_mul_2_avx(temp, q_00+180, p_00+176);
	gf2x_mul_2_avx(temp2, q_01+180, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+124, 4, q_00+124, 4, temp);
	gf2x_mul_2_avx(temp, q_00+178, p_00+176);
	gf2x_mul_2_avx(temp2, q_01+178, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+122, 4, q_00+122, 4, temp);
	gf2x_mul_2_avx(temp, q_00+176, p_00+176);
	gf2x_mul_2_avx(temp2, q_01+176, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+120, 4, q_00+120, 4, temp);
	gf2x_mul_2_avx(temp, q_00+174, p_00+176);
	gf2x_mul_2_avx(temp2, q_01+174, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+118, 4, q_00+118, 4, temp);
	gf2x_mul_2_avx(temp, q_00+172, p_00+176);
	gf2x_mul_2_avx(temp2, q_01+172, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+116, 4, q_00+116, 4, temp);
	gf2x_mul_2_avx(temp, q_00+170, p_00+176);
	gf2x_mul_2_avx(temp2, q_01+170, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+114, 4, q_00+114, 4, temp);
	gf2x_mul_2_avx(temp, q_00+168, p_00+176);
	gf2x_mul_2_avx(temp2, q_01+168, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+112, 4, q_00+112, 4, temp);
	gf2x_mul_2_avx(temp, q_00+166, p_00+176);
	gf2x_mul_2_avx(temp2, q_01+166, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+110, 4, q_00+110, 4, temp);
	memset(q_01+110, 0x00, 2*DIGIT_SIZE_B);
	GF2X_MUL(52, temp, 26, p_01+178, 26, q_00+166);
	GF2X_MUL(52, temp2, 26, p_11+178, 26, q_01+166);
	gf2x_add(52, q_01+112, 52, temp, 52, temp2);
	gf2x_mul_2_avx(temp, q_00+190, p_01+176);
	gf2x_mul_2_avx(temp2, q_01+190, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+134, 4, q_01+134, 4, temp);
	gf2x_mul_2_avx(temp, q_00+188, p_01+176);
	gf2x_mul_2_avx(temp2, q_01+188, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+132, 4, q_01+132, 4, temp);
	gf2x_mul_2_avx(temp, q_00+186, p_01+176);
	gf2x_mul_2_avx(temp2, q_01+186, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+130, 4, q_01+130, 4, temp);
	gf2x_mul_2_avx(temp, q_00+184, p_01+176);
	gf2x_mul_2_avx(temp2, q_01+184, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+128, 4, q_01+128, 4, temp);
	gf2x_mul_2_avx(temp, q_00+182, p_01+176);
	gf2x_mul_2_avx(temp2, q_01+182, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+126, 4, q_01+126, 4, temp);
	gf2x_mul_2_avx(temp, q_00+180, p_01+176);
	gf2x_mul_2_avx(temp2, q_01+180, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+124, 4, q_01+124, 4, temp);
	gf2x_mul_2_avx(temp, q_00+178, p_01+176);
	gf2x_mul_2_avx(temp2, q_01+178, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+122, 4, q_01+122, 4, temp);
	gf2x_mul_2_avx(temp, q_00+176, p_01+176);
	gf2x_mul_2_avx(temp2, q_01+176, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+120, 4, q_01+120, 4, temp);
	gf2x_mul_2_avx(temp, q_00+174, p_01+176);
	gf2x_mul_2_avx(temp2, q_01+174, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+118, 4, q_01+118, 4, temp);
	gf2x_mul_2_avx(temp, q_00+172, p_01+176);
	gf2x_mul_2_avx(temp2, q_01+172, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+116, 4, q_01+116, 4, temp);
	gf2x_mul_2_avx(temp, q_00+170, p_01+176);
	gf2x_mul_2_avx(temp2, q_01+170, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+114, 4, q_01+114, 4, temp);
	gf2x_mul_2_avx(temp, q_00+168, p_01+176);
	gf2x_mul_2_avx(temp2, q_01+168, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+112, 4, q_01+112, 4, temp);
	gf2x_mul_2_avx(temp, q_00+166, p_01+176);
	gf2x_mul_2_avx(temp2, q_01+166, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+110, 4, q_01+110, 4, temp);
	memset(q_10+110, 0x00, 2*DIGIT_SIZE_B);
	GF2X_MUL(52, temp, 26, p_00+178, 26, q_10+166);
	GF2X_MUL(52, temp2, 26, p_10+178, 26, q_11+166);
	gf2x_add(52, q_10+112, 52, temp, 52, temp2);
	gf2x_mul_2_avx(temp, q_10+190, p_00+176);
	gf2x_mul_2_avx(temp2, q_11+190, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+134, 4, q_10+134, 4, temp);
	gf2x_mul_2_avx(temp, q_10+188, p_00+176);
	gf2x_mul_2_avx(temp2, q_11+188, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+132, 4, q_10+132, 4, temp);
	gf2x_mul_2_avx(temp, q_10+186, p_00+176);
	gf2x_mul_2_avx(temp2, q_11+186, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+130, 4, q_10+130, 4, temp);
	gf2x_mul_2_avx(temp, q_10+184, p_00+176);
	gf2x_mul_2_avx(temp2, q_11+184, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+128, 4, q_10+128, 4, temp);
	gf2x_mul_2_avx(temp, q_10+182, p_00+176);
	gf2x_mul_2_avx(temp2, q_11+182, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+126, 4, q_10+126, 4, temp);
	gf2x_mul_2_avx(temp, q_10+180, p_00+176);
	gf2x_mul_2_avx(temp2, q_11+180, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+124, 4, q_10+124, 4, temp);
	gf2x_mul_2_avx(temp, q_10+178, p_00+176);
	gf2x_mul_2_avx(temp2, q_11+178, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+122, 4, q_10+122, 4, temp);
	gf2x_mul_2_avx(temp, q_10+176, p_00+176);
	gf2x_mul_2_avx(temp2, q_11+176, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+120, 4, q_10+120, 4, temp);
	gf2x_mul_2_avx(temp, q_10+174, p_00+176);
	gf2x_mul_2_avx(temp2, q_11+174, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+118, 4, q_10+118, 4, temp);
	gf2x_mul_2_avx(temp, q_10+172, p_00+176);
	gf2x_mul_2_avx(temp2, q_11+172, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+116, 4, q_10+116, 4, temp);
	gf2x_mul_2_avx(temp, q_10+170, p_00+176);
	gf2x_mul_2_avx(temp2, q_11+170, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+114, 4, q_10+114, 4, temp);
	gf2x_mul_2_avx(temp, q_10+168, p_00+176);
	gf2x_mul_2_avx(temp2, q_11+168, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+112, 4, q_10+112, 4, temp);
	gf2x_mul_2_avx(temp, q_10+166, p_00+176);
	gf2x_mul_2_avx(temp2, q_11+166, p_10+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+110, 4, q_10+110, 4, temp);
	memset(q_11+110, 0x00, 2*DIGIT_SIZE_B);
	GF2X_MUL(52, temp, 26, p_01+178, 26, q_10+166);
	GF2X_MUL(52, temp2, 26, p_11+178, 26, q_11+166);
	gf2x_add(52, q_11+112, 52, temp, 52, temp2);
	gf2x_mul_2_avx(temp, q_10+190, p_01+176);
	gf2x_mul_2_avx(temp2, q_11+190, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+134, 4, q_11+134, 4, temp);
	gf2x_mul_2_avx(temp, q_10+188, p_01+176);
	gf2x_mul_2_avx(temp2, q_11+188, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+132, 4, q_11+132, 4, temp);
	gf2x_mul_2_avx(temp, q_10+186, p_01+176);
	gf2x_mul_2_avx(temp2, q_11+186, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+130, 4, q_11+130, 4, temp);
	gf2x_mul_2_avx(temp, q_10+184, p_01+176);
	gf2x_mul_2_avx(temp2, q_11+184, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+128, 4, q_11+128, 4, temp);
	gf2x_mul_2_avx(temp, q_10+182, p_01+176);
	gf2x_mul_2_avx(temp2, q_11+182, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+126, 4, q_11+126, 4, temp);
	gf2x_mul_2_avx(temp, q_10+180, p_01+176);
	gf2x_mul_2_avx(temp2, q_11+180, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+124, 4, q_11+124, 4, temp);
	gf2x_mul_2_avx(temp, q_10+178, p_01+176);
	gf2x_mul_2_avx(temp2, q_11+178, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+122, 4, q_11+122, 4, temp);
	gf2x_mul_2_avx(temp, q_10+176, p_01+176);
	gf2x_mul_2_avx(temp2, q_11+176, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+120, 4, q_11+120, 4, temp);
	gf2x_mul_2_avx(temp, q_10+174, p_01+176);
	gf2x_mul_2_avx(temp2, q_11+174, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+118, 4, q_11+118, 4, temp);
	gf2x_mul_2_avx(temp, q_10+172, p_01+176);
	gf2x_mul_2_avx(temp2, q_11+172, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+116, 4, q_11+116, 4, temp);
	gf2x_mul_2_avx(temp, q_10+170, p_01+176);
	gf2x_mul_2_avx(temp2, q_11+170, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+114, 4, q_11+114, 4, temp);
	gf2x_mul_2_avx(temp, q_10+168, p_01+176);
	gf2x_mul_2_avx(temp2, q_11+168, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+112, 4, q_11+112, 4, temp);
	gf2x_mul_2_avx(temp, q_10+166, p_01+176);
	gf2x_mul_2_avx(temp2, q_11+166, p_11+176);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+110, 4, q_11+110, 4, temp);
	
	// Recombining results: n: 6978, depth: 1
	memset(q_00+0, 0x00, 2*DIGIT_SIZE_B);
	GF2X_MUL(108, temp, 54, p_00+118, 54, q_00+110);
	GF2X_MUL(108, temp2, 54, p_10+118, 54, q_01+110);
	gf2x_add(108, q_00+2, 108, temp, 108, temp2);
	gf2x_mul_2_avx(temp, q_00+162, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+162, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+52, 4, q_00+52, 4, temp);
	gf2x_mul_2_avx(temp, q_00+160, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+160, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+50, 4, q_00+50, 4, temp);
	gf2x_mul_2_avx(temp, q_00+158, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+158, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+48, 4, q_00+48, 4, temp);
	gf2x_mul_2_avx(temp, q_00+156, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+156, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+46, 4, q_00+46, 4, temp);
	gf2x_mul_2_avx(temp, q_00+154, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+154, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+44, 4, q_00+44, 4, temp);
	gf2x_mul_2_avx(temp, q_00+152, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+152, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+42, 4, q_00+42, 4, temp);
	gf2x_mul_2_avx(temp, q_00+150, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+150, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+40, 4, q_00+40, 4, temp);
	gf2x_mul_2_avx(temp, q_00+148, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+148, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+38, 4, q_00+38, 4, temp);
	gf2x_mul_2_avx(temp, q_00+146, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+146, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+36, 4, q_00+36, 4, temp);
	gf2x_mul_2_avx(temp, q_00+144, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+144, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+34, 4, q_00+34, 4, temp);
	gf2x_mul_2_avx(temp, q_00+142, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+142, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+32, 4, q_00+32, 4, temp);
	gf2x_mul_2_avx(temp, q_00+140, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+140, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+30, 4, q_00+30, 4, temp);
	gf2x_mul_2_avx(temp, q_00+138, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+138, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+28, 4, q_00+28, 4, temp);
	gf2x_mul_2_avx(temp, q_00+136, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+136, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+26, 4, q_00+26, 4, temp);
	gf2x_mul_2_avx(temp, q_00+134, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+134, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+24, 4, q_00+24, 4, temp);
	gf2x_mul_2_avx(temp, q_00+132, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+132, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+22, 4, q_00+22, 4, temp);
	gf2x_mul_2_avx(temp, q_00+130, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+130, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+20, 4, q_00+20, 4, temp);
	gf2x_mul_2_avx(temp, q_00+128, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+128, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+18, 4, q_00+18, 4, temp);
	gf2x_mul_2_avx(temp, q_00+126, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+126, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+16, 4, q_00+16, 4, temp);
	gf2x_mul_2_avx(temp, q_00+124, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+124, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+14, 4, q_00+14, 4, temp);
	gf2x_mul_2_avx(temp, q_00+122, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+122, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+12, 4, q_00+12, 4, temp);
	gf2x_mul_2_avx(temp, q_00+120, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+120, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+10, 4, q_00+10, 4, temp);
	gf2x_mul_2_avx(temp, q_00+118, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+118, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+8, 4, q_00+8, 4, temp);
	gf2x_mul_2_avx(temp, q_00+116, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+116, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+6, 4, q_00+6, 4, temp);
	gf2x_mul_2_avx(temp, q_00+114, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+114, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+4, 4, q_00+4, 4, temp);
	gf2x_mul_2_avx(temp, q_00+112, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+112, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+2, 4, q_00+2, 4, temp);
	gf2x_mul_2_avx(temp, q_00+110, p_00+116);
	gf2x_mul_2_avx(temp2, q_01+110, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_00+0, 4, q_00+0, 4, temp);
	memset(q_01+0, 0x00, 2*DIGIT_SIZE_B);
	GF2X_MUL(108, temp, 54, p_01+118, 54, q_00+110);
	GF2X_MUL(108, temp2, 54, p_11+118, 54, q_01+110);
	gf2x_add(108, q_01+2, 108, temp, 108, temp2);
	gf2x_mul_2_avx(temp, q_00+162, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+162, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+52, 4, q_01+52, 4, temp);
	gf2x_mul_2_avx(temp, q_00+160, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+160, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+50, 4, q_01+50, 4, temp);
	gf2x_mul_2_avx(temp, q_00+158, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+158, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+48, 4, q_01+48, 4, temp);
	gf2x_mul_2_avx(temp, q_00+156, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+156, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+46, 4, q_01+46, 4, temp);
	gf2x_mul_2_avx(temp, q_00+154, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+154, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+44, 4, q_01+44, 4, temp);
	gf2x_mul_2_avx(temp, q_00+152, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+152, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+42, 4, q_01+42, 4, temp);
	gf2x_mul_2_avx(temp, q_00+150, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+150, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+40, 4, q_01+40, 4, temp);
	gf2x_mul_2_avx(temp, q_00+148, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+148, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+38, 4, q_01+38, 4, temp);
	gf2x_mul_2_avx(temp, q_00+146, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+146, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+36, 4, q_01+36, 4, temp);
	gf2x_mul_2_avx(temp, q_00+144, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+144, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+34, 4, q_01+34, 4, temp);
	gf2x_mul_2_avx(temp, q_00+142, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+142, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+32, 4, q_01+32, 4, temp);
	gf2x_mul_2_avx(temp, q_00+140, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+140, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+30, 4, q_01+30, 4, temp);
	gf2x_mul_2_avx(temp, q_00+138, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+138, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+28, 4, q_01+28, 4, temp);
	gf2x_mul_2_avx(temp, q_00+136, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+136, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+26, 4, q_01+26, 4, temp);
	gf2x_mul_2_avx(temp, q_00+134, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+134, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+24, 4, q_01+24, 4, temp);
	gf2x_mul_2_avx(temp, q_00+132, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+132, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+22, 4, q_01+22, 4, temp);
	gf2x_mul_2_avx(temp, q_00+130, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+130, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+20, 4, q_01+20, 4, temp);
	gf2x_mul_2_avx(temp, q_00+128, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+128, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+18, 4, q_01+18, 4, temp);
	gf2x_mul_2_avx(temp, q_00+126, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+126, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+16, 4, q_01+16, 4, temp);
	gf2x_mul_2_avx(temp, q_00+124, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+124, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+14, 4, q_01+14, 4, temp);
	gf2x_mul_2_avx(temp, q_00+122, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+122, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+12, 4, q_01+12, 4, temp);
	gf2x_mul_2_avx(temp, q_00+120, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+120, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+10, 4, q_01+10, 4, temp);
	gf2x_mul_2_avx(temp, q_00+118, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+118, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+8, 4, q_01+8, 4, temp);
	gf2x_mul_2_avx(temp, q_00+116, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+116, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+6, 4, q_01+6, 4, temp);
	gf2x_mul_2_avx(temp, q_00+114, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+114, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+4, 4, q_01+4, 4, temp);
	gf2x_mul_2_avx(temp, q_00+112, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+112, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+2, 4, q_01+2, 4, temp);
	gf2x_mul_2_avx(temp, q_00+110, p_01+116);
	gf2x_mul_2_avx(temp2, q_01+110, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_01+0, 4, q_01+0, 4, temp);
	memset(q_10+0, 0x00, 2*DIGIT_SIZE_B);
	GF2X_MUL(108, temp, 54, p_00+118, 54, q_10+110);
	GF2X_MUL(108, temp2, 54, p_10+118, 54, q_11+110);
	gf2x_add(108, q_10+2, 108, temp, 108, temp2);
	gf2x_mul_2_avx(temp, q_10+162, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+162, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+52, 4, q_10+52, 4, temp);
	gf2x_mul_2_avx(temp, q_10+160, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+160, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+50, 4, q_10+50, 4, temp);
	gf2x_mul_2_avx(temp, q_10+158, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+158, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+48, 4, q_10+48, 4, temp);
	gf2x_mul_2_avx(temp, q_10+156, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+156, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+46, 4, q_10+46, 4, temp);
	gf2x_mul_2_avx(temp, q_10+154, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+154, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+44, 4, q_10+44, 4, temp);
	gf2x_mul_2_avx(temp, q_10+152, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+152, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+42, 4, q_10+42, 4, temp);
	gf2x_mul_2_avx(temp, q_10+150, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+150, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+40, 4, q_10+40, 4, temp);
	gf2x_mul_2_avx(temp, q_10+148, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+148, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+38, 4, q_10+38, 4, temp);
	gf2x_mul_2_avx(temp, q_10+146, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+146, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+36, 4, q_10+36, 4, temp);
	gf2x_mul_2_avx(temp, q_10+144, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+144, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+34, 4, q_10+34, 4, temp);
	gf2x_mul_2_avx(temp, q_10+142, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+142, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+32, 4, q_10+32, 4, temp);
	gf2x_mul_2_avx(temp, q_10+140, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+140, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+30, 4, q_10+30, 4, temp);
	gf2x_mul_2_avx(temp, q_10+138, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+138, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+28, 4, q_10+28, 4, temp);
	gf2x_mul_2_avx(temp, q_10+136, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+136, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+26, 4, q_10+26, 4, temp);
	gf2x_mul_2_avx(temp, q_10+134, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+134, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+24, 4, q_10+24, 4, temp);
	gf2x_mul_2_avx(temp, q_10+132, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+132, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+22, 4, q_10+22, 4, temp);
	gf2x_mul_2_avx(temp, q_10+130, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+130, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+20, 4, q_10+20, 4, temp);
	gf2x_mul_2_avx(temp, q_10+128, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+128, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+18, 4, q_10+18, 4, temp);
	gf2x_mul_2_avx(temp, q_10+126, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+126, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+16, 4, q_10+16, 4, temp);
	gf2x_mul_2_avx(temp, q_10+124, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+124, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+14, 4, q_10+14, 4, temp);
	gf2x_mul_2_avx(temp, q_10+122, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+122, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+12, 4, q_10+12, 4, temp);
	gf2x_mul_2_avx(temp, q_10+120, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+120, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+10, 4, q_10+10, 4, temp);
	gf2x_mul_2_avx(temp, q_10+118, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+118, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+8, 4, q_10+8, 4, temp);
	gf2x_mul_2_avx(temp, q_10+116, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+116, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+6, 4, q_10+6, 4, temp);
	gf2x_mul_2_avx(temp, q_10+114, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+114, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+4, 4, q_10+4, 4, temp);
	gf2x_mul_2_avx(temp, q_10+112, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+112, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+2, 4, q_10+2, 4, temp);
	gf2x_mul_2_avx(temp, q_10+110, p_00+116);
	gf2x_mul_2_avx(temp2, q_11+110, p_10+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_10+0, 4, q_10+0, 4, temp);
	memset(q_11+0, 0x00, 2*DIGIT_SIZE_B);
	GF2X_MUL(108, temp, 54, p_01+118, 54, q_10+110);
	GF2X_MUL(108, temp2, 54, p_11+118, 54, q_11+110);
	gf2x_add(108, q_11+2, 108, temp, 108, temp2);
	gf2x_mul_2_avx(temp, q_10+162, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+162, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+52, 4, q_11+52, 4, temp);
	gf2x_mul_2_avx(temp, q_10+160, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+160, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+50, 4, q_11+50, 4, temp);
	gf2x_mul_2_avx(temp, q_10+158, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+158, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+48, 4, q_11+48, 4, temp);
	gf2x_mul_2_avx(temp, q_10+156, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+156, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+46, 4, q_11+46, 4, temp);
	gf2x_mul_2_avx(temp, q_10+154, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+154, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+44, 4, q_11+44, 4, temp);
	gf2x_mul_2_avx(temp, q_10+152, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+152, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+42, 4, q_11+42, 4, temp);
	gf2x_mul_2_avx(temp, q_10+150, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+150, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+40, 4, q_11+40, 4, temp);
	gf2x_mul_2_avx(temp, q_10+148, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+148, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+38, 4, q_11+38, 4, temp);
	gf2x_mul_2_avx(temp, q_10+146, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+146, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+36, 4, q_11+36, 4, temp);
	gf2x_mul_2_avx(temp, q_10+144, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+144, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+34, 4, q_11+34, 4, temp);
	gf2x_mul_2_avx(temp, q_10+142, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+142, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+32, 4, q_11+32, 4, temp);
	gf2x_mul_2_avx(temp, q_10+140, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+140, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+30, 4, q_11+30, 4, temp);
	gf2x_mul_2_avx(temp, q_10+138, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+138, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+28, 4, q_11+28, 4, temp);
	gf2x_mul_2_avx(temp, q_10+136, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+136, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+26, 4, q_11+26, 4, temp);
	gf2x_mul_2_avx(temp, q_10+134, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+134, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+24, 4, q_11+24, 4, temp);
	gf2x_mul_2_avx(temp, q_10+132, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+132, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+22, 4, q_11+22, 4, temp);
	gf2x_mul_2_avx(temp, q_10+130, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+130, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+20, 4, q_11+20, 4, temp);
	gf2x_mul_2_avx(temp, q_10+128, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+128, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+18, 4, q_11+18, 4, temp);
	gf2x_mul_2_avx(temp, q_10+126, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+126, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+16, 4, q_11+16, 4, temp);
	gf2x_mul_2_avx(temp, q_10+124, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+124, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+14, 4, q_11+14, 4, temp);
	gf2x_mul_2_avx(temp, q_10+122, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+122, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+12, 4, q_11+12, 4, temp);
	gf2x_mul_2_avx(temp, q_10+120, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+120, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+10, 4, q_11+10, 4, temp);
	gf2x_mul_2_avx(temp, q_10+118, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+118, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+8, 4, q_11+8, 4, temp);
	gf2x_mul_2_avx(temp, q_10+116, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+116, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+6, 4, q_11+6, 4, temp);
	gf2x_mul_2_avx(temp, q_10+114, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+114, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+4, 4, q_11+4, 4, temp);
	gf2x_mul_2_avx(temp, q_10+112, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+112, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+2, 4, q_11+2, 4, temp);
	gf2x_mul_2_avx(temp, q_10+110, p_01+116);
	gf2x_mul_2_avx(temp2, q_11+110, p_11+116);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, q_11+0, 4, q_11+0, 4, temp);
	
	// Recombining results: n: 14373, depth: 0
	memset(t_00+0, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(220, temp, 110, p_00+6, 110, q_00+0);
	GF2X_MUL(220, temp2, 110, p_10+6, 110, q_01+0);
	gf2x_add(220, t_00+5, 220, temp, 220, temp2);
	gf2x_mul_6_avx(temp, q_00+104, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+104, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+103, 12, t_00+103, 12, temp);
	gf2x_mul_6_avx(temp, q_00+98, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+98, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+97, 12, t_00+97, 12, temp);
	gf2x_mul_6_avx(temp, q_00+92, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+92, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+91, 12, t_00+91, 12, temp);
	gf2x_mul_6_avx(temp, q_00+86, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+86, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+85, 12, t_00+85, 12, temp);
	gf2x_mul_6_avx(temp, q_00+80, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+80, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+79, 12, t_00+79, 12, temp);
	gf2x_mul_6_avx(temp, q_00+74, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+74, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+73, 12, t_00+73, 12, temp);
	gf2x_mul_6_avx(temp, q_00+68, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+68, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+67, 12, t_00+67, 12, temp);
	gf2x_mul_6_avx(temp, q_00+62, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+62, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+61, 12, t_00+61, 12, temp);
	gf2x_mul_6_avx(temp, q_00+56, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+56, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+55, 12, t_00+55, 12, temp);
	gf2x_mul_6_avx(temp, q_00+50, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+50, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+49, 12, t_00+49, 12, temp);
	gf2x_mul_6_avx(temp, q_00+44, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+44, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+43, 12, t_00+43, 12, temp);
	gf2x_mul_6_avx(temp, q_00+38, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+38, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+37, 12, t_00+37, 12, temp);
	gf2x_mul_6_avx(temp, q_00+32, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+32, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+31, 12, t_00+31, 12, temp);
	gf2x_mul_6_avx(temp, q_00+26, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+26, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+25, 12, t_00+25, 12, temp);
	gf2x_mul_6_avx(temp, q_00+20, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+20, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+19, 12, t_00+19, 12, temp);
	gf2x_mul_6_avx(temp, q_00+14, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+14, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+13, 12, t_00+13, 12, temp);
	gf2x_mul_6_avx(temp, q_00+8, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+8, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+7, 12, t_00+7, 12, temp);
	gf2x_mul_6_avx(temp, q_00+2, p_00+0);
	gf2x_mul_6_avx(temp2, q_01+2, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_00+1, 12, t_00+1, 12, temp);
	gf2x_mul_2_avx(temp, p_00+4, q_00+0);
	gf2x_mul_2_avx(temp2, p_10+4, q_01+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_00+3, 4, t_00+3, 4, temp);
	gf2x_mul_2_avx(temp, p_00+2, q_00+0);
	gf2x_mul_2_avx(temp2, p_10+2, q_01+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_00+1, 4, t_00+1, 4, temp);
	gf2x_mul_2_avx(temp, q_00+0, p_00+0);
	gf2x_mul_2_avx(temp2, q_01+0, p_10+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(3, t_00+0, 3, t_00+0, 3, temp+1);
	memset(t_01+0, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(220, temp, 110, p_01+6, 110, q_00+0);
	GF2X_MUL(220, temp2, 110, p_11+6, 110, q_01+0);
	gf2x_add(220, t_01+5, 220, temp, 220, temp2);
	gf2x_mul_6_avx(temp, q_00+104, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+104, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+103, 12, t_01+103, 12, temp);
	gf2x_mul_6_avx(temp, q_00+98, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+98, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+97, 12, t_01+97, 12, temp);
	gf2x_mul_6_avx(temp, q_00+92, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+92, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+91, 12, t_01+91, 12, temp);
	gf2x_mul_6_avx(temp, q_00+86, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+86, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+85, 12, t_01+85, 12, temp);
	gf2x_mul_6_avx(temp, q_00+80, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+80, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+79, 12, t_01+79, 12, temp);
	gf2x_mul_6_avx(temp, q_00+74, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+74, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+73, 12, t_01+73, 12, temp);
	gf2x_mul_6_avx(temp, q_00+68, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+68, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+67, 12, t_01+67, 12, temp);
	gf2x_mul_6_avx(temp, q_00+62, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+62, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+61, 12, t_01+61, 12, temp);
	gf2x_mul_6_avx(temp, q_00+56, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+56, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+55, 12, t_01+55, 12, temp);
	gf2x_mul_6_avx(temp, q_00+50, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+50, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+49, 12, t_01+49, 12, temp);
	gf2x_mul_6_avx(temp, q_00+44, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+44, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+43, 12, t_01+43, 12, temp);
	gf2x_mul_6_avx(temp, q_00+38, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+38, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+37, 12, t_01+37, 12, temp);
	gf2x_mul_6_avx(temp, q_00+32, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+32, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+31, 12, t_01+31, 12, temp);
	gf2x_mul_6_avx(temp, q_00+26, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+26, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+25, 12, t_01+25, 12, temp);
	gf2x_mul_6_avx(temp, q_00+20, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+20, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+19, 12, t_01+19, 12, temp);
	gf2x_mul_6_avx(temp, q_00+14, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+14, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+13, 12, t_01+13, 12, temp);
	gf2x_mul_6_avx(temp, q_00+8, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+8, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+7, 12, t_01+7, 12, temp);
	gf2x_mul_6_avx(temp, q_00+2, p_01+0);
	gf2x_mul_6_avx(temp2, q_01+2, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_01+1, 12, t_01+1, 12, temp);
	gf2x_mul_2_avx(temp, p_01+4, q_00+0);
	gf2x_mul_2_avx(temp2, p_11+4, q_01+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_01+3, 4, t_01+3, 4, temp);
	gf2x_mul_2_avx(temp, p_01+2, q_00+0);
	gf2x_mul_2_avx(temp2, p_11+2, q_01+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_01+1, 4, t_01+1, 4, temp);
	gf2x_mul_2_avx(temp, q_00+0, p_01+0);
	gf2x_mul_2_avx(temp2, q_01+0, p_11+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(3, t_01+0, 3, t_01+0, 3, temp+1);
	memset(t_10+0, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(220, temp, 110, p_00+6, 110, q_10+0);
	GF2X_MUL(220, temp2, 110, p_10+6, 110, q_11+0);
	gf2x_add(220, t_10+5, 220, temp, 220, temp2);
	gf2x_mul_6_avx(temp, q_10+104, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+104, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+103, 12, t_10+103, 12, temp);
	gf2x_mul_6_avx(temp, q_10+98, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+98, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+97, 12, t_10+97, 12, temp);
	gf2x_mul_6_avx(temp, q_10+92, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+92, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+91, 12, t_10+91, 12, temp);
	gf2x_mul_6_avx(temp, q_10+86, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+86, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+85, 12, t_10+85, 12, temp);
	gf2x_mul_6_avx(temp, q_10+80, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+80, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+79, 12, t_10+79, 12, temp);
	gf2x_mul_6_avx(temp, q_10+74, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+74, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+73, 12, t_10+73, 12, temp);
	gf2x_mul_6_avx(temp, q_10+68, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+68, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+67, 12, t_10+67, 12, temp);
	gf2x_mul_6_avx(temp, q_10+62, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+62, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+61, 12, t_10+61, 12, temp);
	gf2x_mul_6_avx(temp, q_10+56, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+56, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+55, 12, t_10+55, 12, temp);
	gf2x_mul_6_avx(temp, q_10+50, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+50, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+49, 12, t_10+49, 12, temp);
	gf2x_mul_6_avx(temp, q_10+44, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+44, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+43, 12, t_10+43, 12, temp);
	gf2x_mul_6_avx(temp, q_10+38, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+38, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+37, 12, t_10+37, 12, temp);
	gf2x_mul_6_avx(temp, q_10+32, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+32, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+31, 12, t_10+31, 12, temp);
	gf2x_mul_6_avx(temp, q_10+26, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+26, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+25, 12, t_10+25, 12, temp);
	gf2x_mul_6_avx(temp, q_10+20, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+20, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+19, 12, t_10+19, 12, temp);
	gf2x_mul_6_avx(temp, q_10+14, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+14, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+13, 12, t_10+13, 12, temp);
	gf2x_mul_6_avx(temp, q_10+8, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+8, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+7, 12, t_10+7, 12, temp);
	gf2x_mul_6_avx(temp, q_10+2, p_00+0);
	gf2x_mul_6_avx(temp2, q_11+2, p_10+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_10+1, 12, t_10+1, 12, temp);
	gf2x_mul_2_avx(temp, p_00+4, q_10+0);
	gf2x_mul_2_avx(temp2, p_10+4, q_11+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_10+3, 4, t_10+3, 4, temp);
	gf2x_mul_2_avx(temp, p_00+2, q_10+0);
	gf2x_mul_2_avx(temp2, p_10+2, q_11+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_10+1, 4, t_10+1, 4, temp);
	gf2x_mul_2_avx(temp, q_10+0, p_00+0);
	gf2x_mul_2_avx(temp2, q_11+0, p_10+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(3, t_10+0, 3, t_10+0, 3, temp+1);
	memset(t_11+0, 0x00, 5*DIGIT_SIZE_B);
	GF2X_MUL(220, temp, 110, p_01+6, 110, q_10+0);
	GF2X_MUL(220, temp2, 110, p_11+6, 110, q_11+0);
	gf2x_add(220, t_11+5, 220, temp, 220, temp2);
	gf2x_mul_6_avx(temp, q_10+104, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+104, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+103, 12, t_11+103, 12, temp);
	gf2x_mul_6_avx(temp, q_10+98, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+98, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+97, 12, t_11+97, 12, temp);
	gf2x_mul_6_avx(temp, q_10+92, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+92, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+91, 12, t_11+91, 12, temp);
	gf2x_mul_6_avx(temp, q_10+86, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+86, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+85, 12, t_11+85, 12, temp);
	gf2x_mul_6_avx(temp, q_10+80, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+80, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+79, 12, t_11+79, 12, temp);
	gf2x_mul_6_avx(temp, q_10+74, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+74, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+73, 12, t_11+73, 12, temp);
	gf2x_mul_6_avx(temp, q_10+68, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+68, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+67, 12, t_11+67, 12, temp);
	gf2x_mul_6_avx(temp, q_10+62, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+62, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+61, 12, t_11+61, 12, temp);
	gf2x_mul_6_avx(temp, q_10+56, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+56, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+55, 12, t_11+55, 12, temp);
	gf2x_mul_6_avx(temp, q_10+50, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+50, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+49, 12, t_11+49, 12, temp);
	gf2x_mul_6_avx(temp, q_10+44, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+44, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+43, 12, t_11+43, 12, temp);
	gf2x_mul_6_avx(temp, q_10+38, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+38, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+37, 12, t_11+37, 12, temp);
	gf2x_mul_6_avx(temp, q_10+32, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+32, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+31, 12, t_11+31, 12, temp);
	gf2x_mul_6_avx(temp, q_10+26, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+26, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+25, 12, t_11+25, 12, temp);
	gf2x_mul_6_avx(temp, q_10+20, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+20, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+19, 12, t_11+19, 12, temp);
	gf2x_mul_6_avx(temp, q_10+14, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+14, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+13, 12, t_11+13, 12, temp);
	gf2x_mul_6_avx(temp, q_10+8, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+8, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+7, 12, t_11+7, 12, temp);
	gf2x_mul_6_avx(temp, q_10+2, p_01+0);
	gf2x_mul_6_avx(temp2, q_11+2, p_11+0);
	gf2x_add(12, temp, 12, temp, 12, temp2);
	gf2x_add(12, t_11+1, 12, t_11+1, 12, temp);
	gf2x_mul_2_avx(temp, p_01+4, q_10+0);
	gf2x_mul_2_avx(temp2, p_11+4, q_11+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_11+3, 4, t_11+3, 4, temp);
	gf2x_mul_2_avx(temp, p_01+2, q_10+0);
	gf2x_mul_2_avx(temp2, p_11+2, q_11+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(4, t_11+1, 4, t_11+1, 4, temp);
	gf2x_mul_2_avx(temp, q_10+0, p_01+0);
	gf2x_mul_2_avx(temp2, q_11+0, p_11+0);
	gf2x_add(4, temp, 4, temp, 4, temp2);
	gf2x_add(3, t_11+0, 3, t_11+0, 3, temp+1);
	
	return delta;
}